{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "df_train = pd.read_csv(\"./fine_tuning.csv\")\n",
    "\n",
    "train_data_domain = df_train.domain.values\n",
    "train_data_label = df_train.label.values\n",
    "train_data_label = train_data_label.tolist()\n",
    "train_data_label = [0 if item == 2 else 1 for item in train_data_label]\n",
    "train_data_label = np.array(train_data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer(vocab_file=\"./bert_tokenizer/vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "input_ids_train = []\n",
    "attention_masks_train = []\n",
    "\n",
    "for sent in train_data_domain:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        sent,                      # Sentence to encode.\n",
    "        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "        max_length = 64,           # Pad & truncate all sentences.\n",
    "        pad_to_max_length = True,\n",
    "        return_attention_mask = True,   # Construct attn. masks.\n",
    "        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "    )\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_train.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks_train.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_train = torch.cat(input_ids_train, dim=0)\n",
    "attention_masks_train = torch.cat(attention_masks_train, dim=0)\n",
    "labels_train = torch.tensor(train_data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train) # 打包处理，所以数据第一维必须相等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "构造MyModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "EmbeddingPath = \"./FedBert/FedTransformer.pt\"\n",
    "TransformerPath = \"./FedBert/FedEmbedding.pt\"\n",
    "num_users = 10\n",
    "frac = 0.5\n",
    "local_epochs = 5\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_name_or_path\": \"./bert-base-uncased-model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.2,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.34.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 1000\n",
      "}\n",
      "\n",
      "BertPooler(\n",
      "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (activation): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoTokenizer,DataCollatorForLanguageModeling,HfArgumentParser,Trainer,TrainingArguments,set_seed,\n",
    ")\n",
    "# 自己修改部分配置参数\n",
    "config_kwargs = {\n",
    "    \"cache_dir\": None,\n",
    "    \"revision\": 'main',\n",
    "    \"use_auth_token\": None,\n",
    "    #      \"hidden_size\": 512,\n",
    "    #     \"num_attention_heads\": 4,\n",
    "    \"hidden_dropout_prob\": 0.2,\n",
    "    \"vocab_size\": 1000 # 自己设置词汇大小\n",
    "}\n",
    "# 将模型的配置参数载入\n",
    "config = AutoConfig.from_pretrained('./bert-base-uncased-model/', **config_kwargs)\n",
    "print(config)\n",
    "# 载入预训练模型\n",
    "model = AutoModelForMaskedLM.from_config(\n",
    "    config=config,\n",
    ")\n",
    "model.resize_token_embeddings(config_kwargs[\"vocab_size\"])\n",
    "\n",
    "embedding = model.bert.embeddings\n",
    "\n",
    "class Bert_Embedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Bert_Embedding, self).__init__()\n",
    "        self.embeddings = copy.deepcopy(embedding)\n",
    "\n",
    "    def forward(self, input_ids, attn_mask):\n",
    "        embedding_output = self.embeddings(input_ids, attn_mask)\n",
    "        return embedding_output\n",
    "\n",
    "embedding_model = Bert_Embedding()\n",
    "embedding_model.load_state_dict(torch.load(EmbeddingPath))\n",
    "\n",
    "encoder = model.bert.encoder\n",
    "cls = model.cls\n",
    "\n",
    "class Bert_Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Bert_Encoder, self).__init__()\n",
    "        self.encoder = copy.deepcopy(encoder)\n",
    "        self.cls = copy.deepcopy(cls)\n",
    "\n",
    "    def forward(self, embedding_output):\n",
    "        output_encoder = self.encoder(embedding_output).last_hidden_state\n",
    "        return output_encoder\n",
    "encoder_model = Bert_Encoder()\n",
    "encoder_model.load_state_dict(torch.load(TransformerPath))\n",
    "\n",
    "from transformers.models.bert.modeling_bert import BertPooler\n",
    "class Pooler_Config:\n",
    "    def __init__(self, entries: dict={}):\n",
    "        for k, v in entries.items():\n",
    "            if isinstance(v, dict):\n",
    "                self.__dict__[k] = Pooler_Config(v)\n",
    "            else:\n",
    "                self.__dict__[k] = v\n",
    "\n",
    "config_pooler = {\"hidden_size\": 768}\n",
    "config_pooler = Pooler_Config(config_pooler)\n",
    "pooler = BertPooler(config_pooler)\n",
    "print(pooler)\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, hidden_size=768, num_classes=2, freeze_bert=False):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.embedding = Bert_Embedding()\n",
    "        self.encoder = Bert_Encoder()\n",
    "        self.pooler = copy.deepcopy(pooler)\n",
    "        if freeze_bert:\n",
    "            for p in self.embedding.parameters():\n",
    "                p.requires_grad = False\n",
    "            for p in self.encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(hidden_size, num_classes, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attn_mask):\n",
    "        embedding_outputs = self.embedding(input_ids, attn_mask)\n",
    "        encoder_outputs = self.encoder(embedding_outputs)\n",
    "        pooler_outputs = self.pooler(encoder_outputs)\n",
    "        #它代表了一句话的embedding\n",
    "        logits = self.fc(pooler_outputs)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "iid数据分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def dataset_iid(dataset, num_users):\n",
    "\n",
    "    num_items = int(len(dataset)/num_users)\n",
    "    dict_users, all_idxs = {}, [i for i in range(len(dataset))]\n",
    "    for i in range(num_users):\n",
    "        dict_users[i] = set(np.random.choice(all_idxs, num_items, replace = False))\n",
    "        all_idxs = list(set(all_idxs) - dict_users[i])\n",
    "    return dict_users\n",
    "\n",
    "# train_dataset[:][:][:][2]\n",
    "def dirichlet_split_noniid(train_labels, num_users):\n",
    "    '''\n",
    "    按照参数为alpha的Dirichlet分布将样本索引集合划分为n_clients个子集\n",
    "    '''\n",
    "    alpha = 0.7\n",
    "    n_classes = 2\n",
    "    # (K, N) 类别标签分布矩阵X，记录每个类别划分到每个client去的比例\n",
    "    label_distribution = np.random.dirichlet([alpha]*num_users, n_classes)\n",
    "    # (K, ...) 记录K个类别对应的样本索引集合\n",
    "    class_idcs = [np.argwhere(train_labels == y).flatten()\n",
    "                  for y in range(n_classes)]\n",
    "\n",
    "    # 记录N个client分别对应的样本索引集合\n",
    "    client_idcs = [[] for _ in range(num_users)]\n",
    "    for k_idcs, fracs in zip(class_idcs, label_distribution):\n",
    "        # np.split按照比例fracs将类别为k的样本索引k_idcs划分为了N个子集\n",
    "        # i表示第i个client，idcs表示其对应的样本索引集合idcs\n",
    "        for i, idcs in enumerate(np.split(k_idcs,\n",
    "                                          (np.cumsum(fracs)[:-1]*len(k_idcs)).\n",
    "                                                  astype(int))):\n",
    "            client_idcs[i] += [idcs]\n",
    "\n",
    "    dict_users = [np.concatenate(idcs) for idcs in client_idcs]\n",
    "\n",
    "    return dict_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "dict_user_train = dirichlet_split_noniid(dataset_train[:][:][:][2], num_users)\n",
    "dict_user_test = [i for i in range(num_users)]\n",
    "dict_user_train_tmp = [i for i in range(num_users)]\n",
    "for i,item in enumerate(dict_user_train):\n",
    "    train_size = int(0.7 * len(item))\n",
    "    dict_user_train_tmp[i] = np.random.choice(item, train_size, replace = False)\n",
    "    dict_user_test[i] = np.setdiff1d(item, dict_user_train_tmp[i])\n",
    "dict_user_train = dict_user_train_tmp\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it\n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch\n",
    "# size of 16 or 32.\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (embedding): Bert_Embedding(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(1000, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (encoder): Bert_Encoder(\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cls): Sequential()\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=768, out_features=2, bias=False)\n",
      "    (2): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net_glob = MyModel()\n",
    "net_glob.encoder.cls = nn.Sequential()\n",
    "print(net_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 训练loss记录\n",
    "loss_train_collect = {}\n",
    "# 训练acc记录\n",
    "acc_train_collect = {}\n",
    "loss_test_collect = {}\n",
    "# 测试acc记录\n",
    "acc_test_collect = {}\n",
    "# 训练TPR记录\n",
    "TPR_train_collect = {}\n",
    "# 测试TPR记录\n",
    "TPR_test_collect = {}\n",
    "# 训练FPR记录\n",
    "FPR_train_collect = {}\n",
    "# 测试FPR记录\n",
    "FPR_test_collect = {}\n",
    "# 训练测试F1-score记录\n",
    "f1_train_collect = {}\n",
    "f1_test_collect = {}\n",
    "# 训练测试AUC记录\n",
    "AUC_train_collect = {}\n",
    "AUC_test_collect = {}\n",
    "# 训练测试ROC曲线记录\n",
    "ROC_train_collect = {}\n",
    "ROC_test_collect = {}\n",
    "# 本地测试记录\n",
    "local_test = {}\n",
    "local_testing = {}\n",
    "\n",
    "loss_collect = []\n",
    "acc_collect = []\n",
    "TPR_collect = []\n",
    "FPR_collect = []\n",
    "F1_collect = []\n",
    "AUC_collect = []\n",
    "\n",
    "count1 = 0\n",
    "count2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def FedAvg(w):\n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    for k in w_avg.keys():\n",
    "        for i in range(1, len(w)):\n",
    "            w_avg[k] += w[i][k]\n",
    "        w_avg[k] = torch.div(w_avg[k], len(w))\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "idx_collect = []\n",
    "l_epoch_check = False\n",
    "fed_check = False\n",
    "# Initialization of net_model_server and net_server (server-side model)\n",
    "net_model = [net_glob for i in range(num_users)]\n",
    "net_server = copy.deepcopy(net_model[0]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "class DatasetSplit(Dataset):\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = list(idxs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        domain, attn_mask, label = self.dataset[self.idxs[item]]\n",
    "        return domain, attn_mask, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    return np.sum(preds == labels) / len(labels)\n",
    "\n",
    "def tpr_calculate(preds, labels):\n",
    "    return recall_score(labels, preds,zero_division=1)\n",
    "\n",
    "def fpr_calculate(preds, labels):\n",
    "    conf_matrix = confusion_matrix(labels, preds)\n",
    "    #print(conf_matrix)\n",
    "    fp = conf_matrix[0, 1]  # 0 表示负类别，1 表示正类别\n",
    "    tn = conf_matrix[0, 0]\n",
    "    fpr = fp / (fp + tn)\n",
    "    return fpr\n",
    "\n",
    "def f1_score_calculate(preds, labels):\n",
    "    return f1_score(labels, preds, zero_division=1)\n",
    "\n",
    "def AUC_calculate(preds, labels):\n",
    "    return roc_auc_score(labels, preds)\n",
    "\n",
    "def roc_curve_calculate(preds, labels):\n",
    "    return roc_curve(labels, preds)\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Client(object):\n",
    "    def __init__(self, device, idx, lr, local_epochs, batch_size, dataset_train = None, idxs = None, idxs_test = None):\n",
    "        self.device = device\n",
    "        self.lr = lr\n",
    "        self.idx = idx\n",
    "        self.local_ep = local_epochs\n",
    "        self.ldr_train = DataLoader(DatasetSplit(dataset_train, idxs), batch_size = batch_size, shuffle = True)\n",
    "        self.ldr_test = DataLoader(DatasetSplit(dataset_train, idxs_test), batch_size = batch_size, shuffle= True)\n",
    "        self.ala = ALA(idx, idxs, criterion, dataset_train, batch_size, 20, 0, lr*4, self.device, 0.1, 10)\n",
    "\n",
    "    def local_initialization(self, net):\n",
    "        print(\"local_initialization!\")\n",
    "        local_model = net_local[self.idx].to(self.device)\n",
    "        self.ala.adaptive_local_aggregation(net, local_model)\n",
    "\n",
    "    def train(self, net):\n",
    "        net.train()\n",
    "        optimizer_client = torch.optim.Adam(net.parameters(), lr = self.lr)\n",
    "\n",
    "        TPR_train_collect[self.idx] = []\n",
    "        FPR_train_collect[self.idx] = []\n",
    "        f1_train_collect[self.idx] = []\n",
    "        AUC_train_collect[self.idx] = []\n",
    "        loss_train_collect[self.idx] = []\n",
    "        acc_train_collect[self.idx] = []\n",
    "\n",
    "        epoch_loss = []\n",
    "        epoch_accuracy = []\n",
    "        for iter in range(self.local_ep):\n",
    "            tmp_t0 = time.time()\n",
    "            batch_loss_train = []\n",
    "            batch_acc_train = []\n",
    "            batch_tpr_train = []\n",
    "            batch_fpr_train = []\n",
    "            batch_f1_train = []\n",
    "            batch_auc_train = []\n",
    "            for batch_idx, (ids, attn_mask, b_labels) in enumerate(self.ldr_train):\n",
    "                ids, attn_mask, b_labels = ids.to(self.device), attn_mask.to(self.device), b_labels.to(self.device)\n",
    "                optimizer_client.zero_grad()\n",
    "                b_labels = b_labels.unsqueeze(1)\n",
    "                b_labels = b_labels.repeat(1,2)\n",
    "                for i in range(len(b_labels)):\n",
    "                    b_labels[i][1] = 1-b_labels[i][0]\n",
    "                logits = net(ids, attn_mask)\n",
    "                BCEloss = criterion(logits, b_labels.float())\n",
    "                BCEloss.backward()\n",
    "                optimizer_client.step()\n",
    "                batch_loss_train.append(BCEloss.item())\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                label_ids = b_labels.to('cpu').numpy()\n",
    "                logits = np.argmax(logits, axis=1).flatten()\n",
    "                label_ids = np.argmax(label_ids,axis=1).flatten()\n",
    "                accuracy = flat_accuracy(logits, label_ids)\n",
    "                tpr = tpr_calculate(logits, label_ids)\n",
    "                if len(set(label_ids)) == 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    fpr = fpr_calculate(logits, label_ids)\n",
    "                    batch_fpr_train.append(fpr)\n",
    "                f1 = f1_score_calculate(logits, label_ids)\n",
    "                if len(set(label_ids)) == 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    auc = AUC_calculate(logits, label_ids)\n",
    "                    batch_auc_train.append(auc)\n",
    "                batch_acc_train.append(accuracy)\n",
    "                batch_tpr_train.append(tpr)\n",
    "                batch_f1_train.append(f1)\n",
    "            elapsed = format_time(time.time()-tmp_t0)\n",
    "            epoch_avg_loss = sum(batch_loss_train)/len(batch_loss_train)\n",
    "            epoch_avg_acc = sum(batch_acc_train)/len(batch_acc_train)\n",
    "            epoch_avg_tpr = sum(batch_tpr_train)/len(batch_tpr_train)\n",
    "            epoch_avg_fpr = sum(batch_fpr_train)/len(batch_fpr_train)\n",
    "            epoch_avg_f1 = sum(batch_f1_train)/len(batch_f1_train)\n",
    "            epoch_avg_auc = sum(batch_auc_train)/len(batch_auc_train)\n",
    "            epoch_loss.append(sum(batch_loss_train)/len(batch_loss_train))\n",
    "            epoch_accuracy.append(sum(batch_acc_train)/len(batch_acc_train))\n",
    "            loss_train_collect[self.idx].append(epoch_avg_loss)\n",
    "            acc_train_collect[self.idx].append(epoch_avg_acc)\n",
    "            TPR_train_collect[self.idx].append(epoch_avg_tpr)\n",
    "            FPR_train_collect[self.idx].append(epoch_avg_fpr)\n",
    "            f1_train_collect[self.idx].append(epoch_avg_f1)\n",
    "            AUC_train_collect[self.idx].append(epoch_avg_auc)\n",
    "            loss_collect.append(epoch_avg_loss)\n",
    "            acc_collect.append(epoch_avg_acc)\n",
    "            TPR_collect.append(epoch_avg_tpr)\n",
    "            FPR_collect.append(epoch_avg_fpr)\n",
    "            F1_collect.append(epoch_avg_f1)\n",
    "            AUC_collect.append(epoch_avg_auc)\n",
    "\n",
    "            print('Client{} Local Train => Local Epoch: {} \\tLoss: {:.10f} \\tAcc: {:.10f} \\tTPR:{:.10f} \\tFPR:{:.10f} \\tF1:{:.10f} \\t AUC:{:.10f}\\tTrain cost: {:}'.format(self.idx, iter, epoch_avg_loss, \\\n",
    "                                                                                                                                                                           epoch_avg_acc, epoch_avg_tpr, epoch_avg_fpr, epoch_avg_f1, epoch_avg_auc, elapsed))\n",
    "        net_glob.load_state_dict(net.state_dict())\n",
    "        return net.state_dict(), sum(epoch_loss) / len(epoch_loss), sum(epoch_accuracy) / len(epoch_accuracy)\n",
    "\n",
    "    def evaluate(self, net, ell):\n",
    "        net.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tmp_t0 = time.time()\n",
    "            len_batch = len(self.ldr_test)\n",
    "\n",
    "            batch_acc_test = []\n",
    "            batch_loss_test = []\n",
    "            batch_tpr_test = []\n",
    "            batch_fpr_test = []\n",
    "            batch_f1_test = []\n",
    "            batch_auc_test = []\n",
    "            for batch_idx, (ids, attn_mask, b_labels) in enumerate(self.ldr_test):\n",
    "                ids, attn_mask, b_labels = ids.to(self.device), attn_mask.to(self.device), b_labels.to(self.device)\n",
    "                b_labels = b_labels.unsqueeze(1)\n",
    "                b_labels = b_labels.repeat(1,2)\n",
    "                for i in range(len(b_labels)):\n",
    "                    b_labels[i][1] = 1-b_labels[i][0]\n",
    "                logits = net(ids, attn_mask)\n",
    "                BCEloss = criterion(logits, b_labels.float())\n",
    "                batch_loss_test.append(BCEloss.item())\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                label_ids = b_labels.to('cpu').numpy()\n",
    "                logits = np.argmax(logits, axis=1).flatten()\n",
    "                label_ids = np.argmax(label_ids,axis=1).flatten()\n",
    "                accuracy = flat_accuracy(logits, label_ids)\n",
    "                tpr = tpr_calculate(logits, label_ids)\n",
    "                if len(set(label_ids)) == 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    fpr = fpr_calculate(logits, label_ids)\n",
    "                    batch_fpr_test.append(fpr)\n",
    "                f1 = f1_score_calculate(logits, label_ids)\n",
    "                if len(set(label_ids)) == 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    auc = AUC_calculate(logits, label_ids)\n",
    "                    batch_auc_test.append(auc)\n",
    "                batch_acc_test.append(accuracy)\n",
    "                batch_tpr_test.append(tpr)\n",
    "                batch_f1_test.append(f1)\n",
    "            elapsed = format_time(time.time()-tmp_t0)\n",
    "            test_avg_loss = sum(batch_loss_test) / len(batch_loss_test)\n",
    "            test_avg_acc = sum(batch_acc_test) / len(batch_acc_test)\n",
    "            test_avg_tpr = sum(batch_tpr_test)/len(batch_tpr_test)\n",
    "            test_avg_fpr = sum(batch_fpr_test) / len(batch_fpr_test)\n",
    "            test_avg_f1 = sum(batch_f1_test)/len(batch_f1_test)\n",
    "            test_avg_auc = sum(batch_auc_test)/len(batch_auc_test)\n",
    "            local_test[\"loss\"].append(test_avg_loss)\n",
    "            local_test[\"acc\"].append(test_avg_acc)\n",
    "            local_test[\"tpr\"].append(test_avg_tpr)\n",
    "            local_test[\"fpr\"].append(test_avg_fpr)\n",
    "            local_test[\"f1\"].append(test_avg_f1)\n",
    "            local_test[\"auc\"].append(test_avg_auc)\n",
    "            print('Client{} Test =>                 \\tLoss: {:.10f} \\tAcc: {:.10f} \\tTPR:{:.10f} \\tFPR:{:.10f} \\tF1:{:.10f} \\tAUC:{:.10f} \\ttest cost: {:}'.format(self.idx, test_avg_loss, test_avg_acc, test_avg_tpr, test_avg_fpr, test_avg_f1, test_avg_auc, elapsed))\n",
    "\n",
    "        return test_avg_loss, test_avg_acc, test_avg_tpr, test_avg_fpr, test_avg_f1, test_avg_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class ALA:\n",
    "    def __init__(self,\n",
    "                 cid: int,\n",
    "                 idxs,\n",
    "                 loss,\n",
    "                 train_data: TensorDataset,\n",
    "                 batch_size: int,\n",
    "                 rand_percent: int,\n",
    "                 layer_idx: int = 0,\n",
    "                 eta: float = 1.0,\n",
    "                 device: str = 'cpu',\n",
    "                 threshold: float = 0.1,\n",
    "                 num_pre_loss: int = 10) -> None:\n",
    "        \"\"\"\n",
    "        Initialize ALA module\n",
    "\n",
    "        Args:\n",
    "            cid: Client ID.\n",
    "            loss: The loss function.\n",
    "            train_data: The reference of the local training data.\n",
    "            batch_size: Weight learning batch size.\n",
    "            rand_percent: The percent of the local training data to sample.\n",
    "            layer_idx: Control the weight range. By default, all the layers are selected. Default: 0\n",
    "            eta: Weight learning rate. Default: 1.0\n",
    "            device: Using cuda or cpu. Default: 'cpu'\n",
    "            threshold: Train the weight until the standard deviation of the recorded losses is less than a given threshold. Default: 0.1\n",
    "            num_pre_loss: The number of the recorded losses to be considered to calculate the standard deviation. Default: 10\n",
    "\n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "\n",
    "        self.cid = cid\n",
    "        self.idxs = idxs\n",
    "        self.loss = loss\n",
    "        self.train_data = train_data\n",
    "        self.batch_size = batch_size\n",
    "        self.rand_percent = rand_percent\n",
    "        self.layer_idx = layer_idx\n",
    "        self.eta = eta\n",
    "        self.threshold = threshold\n",
    "        self.num_pre_loss = num_pre_loss\n",
    "        self.device = device\n",
    "\n",
    "        self.weights = None # Learnable local aggregation weights.\n",
    "        self.start_phase = True\n",
    "\n",
    "\n",
    "    def adaptive_local_aggregation(self,\n",
    "                                   global_model: nn.Module,\n",
    "                                   local_model: nn.Module) -> None:\n",
    "        \"\"\"\n",
    "        Generates the Dataloader for the randomly sampled local training data and\n",
    "        preserves the lower layers of the update.\n",
    "\n",
    "        Args:\n",
    "            global_model: The received global/aggregated model.\n",
    "            local_model: The trained local model.\n",
    "\n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "\n",
    "        # randomly sample partial local training data\n",
    "        rand_ratio = self.rand_percent / 100\n",
    "        rand_loader = DataLoader(DatasetSplit(self.train_data, self.idxs), self.batch_size, drop_last=True, shuffle=True)\n",
    "        rand_num = int(rand_ratio*len(rand_loader))\n",
    "\n",
    "\n",
    "        # obtain the references of the parameters\n",
    "        params_g = list(global_model.parameters())\n",
    "        params = list(local_model.parameters())\n",
    "\n",
    "        # deactivate ALA at the 1st communication iteration\n",
    "        if torch.sum(params_g[-1] - params[-1]) == 0:\n",
    "            print(\"deactivate ALA\")\n",
    "            return\n",
    "\n",
    "        # preserve all the updates in the lower layers\n",
    "        for param, param_g in zip(params[:-self.layer_idx], params_g[:-self.layer_idx]):\n",
    "            param.data = param_g.data.clone()\n",
    "\n",
    "\n",
    "        # temp local model only for weight learning\n",
    "        model_t = copy.deepcopy(local_model)\n",
    "        params_t = list(model_t.parameters())\n",
    "        params_t[-1].requires_grad_()\n",
    "\n",
    "        # only consider higher layers\n",
    "        params_p = params[-self.layer_idx:]\n",
    "        params_gp = params_g[-self.layer_idx:]\n",
    "        params_tp = params_t[-self.layer_idx:]\n",
    "\n",
    "\n",
    "        # used to obtain the gradient of higher layers\n",
    "        # no need to use optimizer.step(), so lr=0\n",
    "        optimizer = torch.optim.Adam(params_tp, lr = lr)\n",
    "\n",
    "        # initialize the weight to all ones in the beginning\n",
    "        if self.weights == None:\n",
    "            self.weights = [torch.ones_like(param.data).to(self.device) for param in params_p]\n",
    "\n",
    "        # initialize the higher layers in the temp local model\n",
    "        for param_t, param, param_g, weight in zip(params_tp, params_p, params_gp,\n",
    "                                                   self.weights):\n",
    "            param_t.data = param + (param_g - param) * weight\n",
    "\n",
    "        # weight learning\n",
    "        losses = []  # record losses\n",
    "        losses_round = []\n",
    "        cnt = 0  # weight training iteration counter\n",
    "        while True:\n",
    "            for batch_idx, (x, m, y) in enumerate(rand_loader):\n",
    "                if batch_idx >= rand_num:\n",
    "                    break\n",
    "                x = x.to(self.device)\n",
    "                m = m.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                y = y.unsqueeze(1)\n",
    "                y = y.repeat(1,2)\n",
    "                for i in range(len(y)):\n",
    "                    y[i][1] = 1-y[i][0]\n",
    "                optimizer.zero_grad()\n",
    "                output = model_t(x, m)\n",
    "                loss_value = self.loss(output, y.float()) # modify according to the local objective\n",
    "                losses.append(loss_value.item())\n",
    "                loss_value.backward()\n",
    "\n",
    "                # update weight in this batch\n",
    "                for param_t, param, param_g, weight in zip(params_tp, params_p,\n",
    "                                                           params_gp, self.weights):\n",
    "                    #print(\"param_t.grad:\",param_t.requires_grad)\n",
    "                    #print(\"param_g - param:\",type(param_g - param))\n",
    "                    weight.data = torch.clamp(weight - self.eta * (param_t.grad * (param_g - param)), 0, 1)\n",
    "\n",
    "                # update temp local model in this batch\n",
    "                for param_t, param, param_g, weight in zip(params_tp, params_p,\n",
    "                                                           params_gp, self.weights):\n",
    "                    param_t.data = param + (param_g - param) * weight\n",
    "\n",
    "            losses_round.append(sum(losses) / len(losses))\n",
    "            cnt += 1\n",
    "\n",
    "            # only train one epoch in the subsequent iterations\n",
    "            if not self.start_phase:\n",
    "                break\n",
    "\n",
    "            # train the weight until convergence\n",
    "            if len(losses_round) > self.num_pre_loss or np.std(losses[-self.num_pre_loss:]) < self.threshold:\n",
    "                print('Client:', self.cid, '\\tStd:', np.std(losses[-self.num_pre_loss:]),\n",
    "                      '\\tALA epochs:', cnt)\n",
    "                break\n",
    "\n",
    "        self.start_phase = False\n",
    "\n",
    "        # obtain initialized local model\n",
    "        for param, param_t in zip(params_p, params_tp):\n",
    "            param.data = param_t.data.clone()\n",
    "        print(\"Client {}: Local Initial ALA epochs: {} Loss: {:.20f}\".format(self.cid, cnt, losses_round[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test Begin!\n",
      "============== Round 0:  =============\n",
      "local_initialization!\n",
      "deactivate ALA\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.4879372154 \tAcc: 0.7875704748 \tTPR:0.9538817064 \tFPR:0.7691308156 \tF1:0.8713824560 \t AUC:0.5923754454\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.4641613697 \tAcc: 0.8064873887 \tTPR:0.9520763546 \tFPR:0.6861730258 \tF1:0.8815640149 \t AUC:0.6329516644\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.4194963934 \tAcc: 0.8369176558 \tTPR:0.9637587437 \tFPR:0.5939000169 \tF1:0.8994514970 \t AUC:0.6849293634\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.3573227299 \tAcc: 0.8639132047 \tTPR:0.9621832905 \tFPR:0.4751156731 \tF1:0.9143203333 \t AUC:0.7435338087\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.3228018213 \tAcc: 0.8769881306 \tTPR:0.9622501235 \tFPR:0.4088403272 \tF1:0.9214503821 \t AUC:0.7767048982\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.2806110941 \tAcc: 0.8916144201 \tTPR:0.9545616252 \tFPR:0.3079715304 \tF1:0.9295228094 \tAUC:0.8232950474 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.20061612999922182 \tALA epochs: 11\n",
      "Client 5: Local Initial ALA epochs: 11 Loss: 0.71950878795091210982\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.2835491866 \tAcc: 0.8777308866 \tTPR:0.4597092800 \tFPR:0.0432092510 \tF1:0.4936863072 \t AUC:0.7067150977\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.2608369772 \tAcc: 0.8890160835 \tTPR:0.5026476427 \tFPR:0.0392363715 \tF1:0.5420703138 \t AUC:0.7310011705\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.2501195359 \tAcc: 0.8933416484 \tTPR:0.5434818320 \tFPR:0.0407525926 \tF1:0.5705477255 \t AUC:0.7500676931\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.2460223750 \tAcc: 0.8931764853 \tTPR:0.5519235943 \tFPR:0.0435180388 \tF1:0.5753892243 \t AUC:0.7535681086\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.2315937031 \tAcc: 0.9005006151 \tTPR:0.5880797482 \tFPR:0.0419399754 \tF1:0.6124265695 \t AUC:0.7724864300\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.2101641588 \tAcc: 0.9120512729 \tTPR:0.5680686090 \tFPR:0.0317558722 \tF1:0.6086535906 \tAUC:0.7652768258 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.09431411590279579 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.41339309571625348916\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.3306957324 \tAcc: 0.8522623756 \tTPR:0.8774909517 \tFPR:0.1696552088 \tF1:0.8453750309 \t AUC:0.8539178714\tTrain cost: 0:00:38\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.3115559037 \tAcc: 0.8666542615 \tTPR:0.8873089447 \tFPR:0.1543334692 \tF1:0.8598880044 \t AUC:0.8664877377\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.2997258527 \tAcc: 0.8723004799 \tTPR:0.8881146287 \tFPR:0.1415695218 \tF1:0.8639620149 \t AUC:0.8732725535\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.2916814016 \tAcc: 0.8757637531 \tTPR:0.8948378720 \tFPR:0.1420824012 \tF1:0.8682378230 \t AUC:0.8763777354\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.2814224743 \tAcc: 0.8835207074 \tTPR:0.9036637448 \tFPR:0.1329747687 \tF1:0.8763624620 \t AUC:0.8853444880\tTrain cost: 0:00:42\n",
      "Client6 Test =>                 \tLoss: 0.2903533689 \tAcc: 0.8808840652 \tTPR:0.8246032824 \tFPR:0.0683575102 \tF1:0.8640788130 \tAUC:0.8781228861 \ttest cost: 0:00:06\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.07993268112038807 \tALA epochs: 3\n",
      "Client 1: Local Initial ALA epochs: 3 Loss: 0.25053999612253963214\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1659462374 \tAcc: 0.9309762774 \tTPR:0.5850700962 \tFPR:0.0265385189 \tF1:0.5990947672 \t AUC:0.7755665622\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1545749394 \tAcc: 0.9354470803 \tTPR:0.6343905689 \tFPR:0.0263526264 \tF1:0.6329979371 \t AUC:0.7990857105\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1489970277 \tAcc: 0.9371350365 \tTPR:0.6499878345 \tFPR:0.0271609392 \tF1:0.6479449955 \t AUC:0.8077620540\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1424106414 \tAcc: 0.9416970803 \tTPR:0.6784086433 \tFPR:0.0245532144 \tF1:0.6756559663 \t AUC:0.8233278112\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1386741361 \tAcc: 0.9430656934 \tTPR:0.6811609315 \tFPR:0.0241047349 \tF1:0.6722576050 \t AUC:0.8252019083\tTrain cost: 0:01:11\n",
      "Client1 Test =>                 \tLoss: 0.1273967226 \tAcc: 0.9475977891 \tTPR:0.7865632761 \tFPR:0.0336446640 \tF1:0.7221470456 \tAUC:0.8719180991 \ttest cost: 0:00:10\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.08561534620426246 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.33262574672698974609\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.2099251905 \tAcc: 0.9162202381 \tTPR:0.9574069580 \tFPR:0.1707530331 \tF1:0.9384683843 \t AUC:0.8933269624\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.2051733304 \tAcc: 0.9206101190 \tTPR:0.9558830869 \tFPR:0.1557070439 \tF1:0.9417223483 \t AUC:0.9000880215\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1942441993 \tAcc: 0.9262648810 \tTPR:0.9606156060 \tFPR:0.1477207977 \tF1:0.9457317981 \t AUC:0.9064474041\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1899297902 \tAcc: 0.9258184524 \tTPR:0.9616288324 \tFPR:0.1461527725 \tF1:0.9447343802 \t AUC:0.9077380300\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1780930232 \tAcc: 0.9322916667 \tTPR:0.9650712215 \tFPR:0.1316496500 \tF1:0.9497440098 \t AUC:0.9167107858\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2515775195 \tAcc: 0.8972297705 \tTPR:0.8763358368 \tFPR:0.0650822172 \tF1:0.9156401657 \tAUC:0.9056268098 \ttest cost: 0:00:01\n",
      "Test =>                 \tLoss: 0.2320205728 \tAcc: 0.9058754636 \tTPR:0.8020265259 \tFPR:0.1013623588 \tF1:0.8080084849 \tAUC:0.8488479337\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 1:  =============\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.0986065346362566 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.26200560799666811063\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.2043310997 \tAcc: 0.9139215418 \tTPR:0.6600749219 \tFPR:0.0376767195 \tF1:0.6743791543 \t AUC:0.8107176209\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1910922120 \tAcc: 0.9209808411 \tTPR:0.6955410644 \tFPR:0.0363672756 \tF1:0.6995962968 \t AUC:0.8291556495\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1868154413 \tAcc: 0.9237231183 \tTPR:0.7159409015 \tFPR:0.0364249265 \tF1:0.7182439989 \t AUC:0.8389510014\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1804564118 \tAcc: 0.9240733780 \tTPR:0.7148349924 \tFPR:0.0364714755 \tF1:0.7149379608 \t AUC:0.8383716306\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1744780628 \tAcc: 0.9269893612 \tTPR:0.7287701470 \tFPR:0.0363539717 \tF1:0.7282294150 \t AUC:0.8462080876\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.1596930262 \tAcc: 0.9380005721 \tTPR:0.7118917084 \tFPR:0.0250654266 \tF1:0.7435267594 \tAUC:0.8434131409 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.08393349589109145 \tALA epochs: 8\n",
      "Client 8: Local Initial ALA epochs: 8 Loss: 0.47255748627123550509\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.2000226615 \tAcc: 0.9282158754 \tTPR:0.9719380997 \tFPR:0.2180028182 \tF1:0.9532738901 \t AUC:0.8769676408\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1859029315 \tAcc: 0.9328115727 \tTPR:0.9713078577 \tFPR:0.2000219859 \tF1:0.9563229216 \t AUC:0.8856429359\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1817611821 \tAcc: 0.9354080119 \tTPR:0.9718661016 \tFPR:0.1915655232 \tF1:0.9581285612 \t AUC:0.8901502892\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1849434074 \tAcc: 0.9320029674 \tTPR:0.9699004843 \tFPR:0.1968150379 \tF1:0.9555793082 \t AUC:0.8865427232\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1731969544 \tAcc: 0.9368657270 \tTPR:0.9721198787 \tFPR:0.1824002078 \tF1:0.9588517391 \t AUC:0.8948598355\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.1903096231 \tAcc: 0.9336402821 \tTPR:0.9590539309 \tFPR:0.1429740566 \tF1:0.9560919374 \tAUC:0.9080399372 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.057670311147744964 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.09910473823547363836\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1870086946 \tAcc: 0.9330357143 \tTPR:0.9727752475 \tFPR:0.2426162132 \tF1:0.9586737123 \t AUC:0.8650795172\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1712797367 \tAcc: 0.9497767857 \tTPR:0.9830489260 \tFPR:0.1832792208 \tF1:0.9683423452 \t AUC:0.8998848526\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1676767015 \tAcc: 0.9397321429 \tTPR:0.9737121344 \tFPR:0.1898100907 \tF1:0.9623422013 \t AUC:0.8919510219\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1622885261 \tAcc: 0.9375000000 \tTPR:0.9709102845 \tFPR:0.2103688970 \tF1:0.9602286310 \t AUC:0.8802706937\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1480878871 \tAcc: 0.9476759454 \tTPR:0.9750012766 \tFPR:0.1429176974 \tF1:0.9654678292 \t AUC:0.9160417896\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.2112074682 \tAcc: 0.9258814103 \tTPR:0.9969135802 \tFPR:0.3150132275 \tF1:0.9530945992 \tAUC:0.8409501764 \ttest cost: 0:00:00\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.05951736642614396 \tALA epochs: 3\n",
      "Client 2: Local Initial ALA epochs: 3 Loss: 0.22607241487224596921\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1761721877 \tAcc: 0.9365587349 \tTPR:0.9741063060 \tFPR:0.2193374982 \tF1:0.9603859467 \t AUC:0.8773844039\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1641510402 \tAcc: 0.9402744908 \tTPR:0.9762658156 \tFPR:0.2063074810 \tF1:0.9627488200 \t AUC:0.8849791673\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.1587182685 \tAcc: 0.9439006024 \tTPR:0.9779146123 \tFPR:0.1921701959 \tF1:0.9649945847 \t AUC:0.8928722082\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.1543675663 \tAcc: 0.9444653614 \tTPR:0.9763728795 \tFPR:0.1868645578 \tF1:0.9651060851 \t AUC:0.8947541608\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.1552564579 \tAcc: 0.9429100330 \tTPR:0.9753151671 \tFPR:0.1902277107 \tF1:0.9642024671 \t AUC:0.8925437282\tTrain cost: 0:00:35\n",
      "Client2 Test =>                 \tLoss: 0.1889324127 \tAcc: 0.9235139860 \tTPR:0.9295360562 \tFPR:0.1091655019 \tF1:0.9499903761 \tAUC:0.9099371646 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.0843312963540222 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.19871182832866907120\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1869853028 \tAcc: 0.9236607143 \tTPR:0.9541884841 \tFPR:0.1487362272 \tF1:0.9427669148 \t AUC:0.9027261284\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1793414030 \tAcc: 0.9270833333 \tTPR:0.9608511061 \tFPR:0.1393156427 \tF1:0.9463454808 \t AUC:0.9107677317\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1747402879 \tAcc: 0.9356398810 \tTPR:0.9659043789 \tFPR:0.1268132000 \tF1:0.9527436564 \t AUC:0.9195455894\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1752051194 \tAcc: 0.9334077381 \tTPR:0.9665110734 \tFPR:0.1322553866 \tF1:0.9509186931 \t AUC:0.9171278434\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1598990669 \tAcc: 0.9412202381 \tTPR:0.9687559877 \tFPR:0.1152961651 \tF1:0.9570203071 \t AUC:0.9267299113\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2485520878 \tAcc: 0.9003623188 \tTPR:0.8780629609 \tFPR:0.0535160827 \tF1:0.9185317484 \tAUC:0.9122734391 \ttest cost: 0:00:01\n",
      "Test =>                 \tLoss: 0.1997389236 \tAcc: 0.9242797139 \tTPR:0.8950916473 \tFPR:0.1291468591 \tF1:0.9042470841 \tAUC:0.8829227716\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 2:  =============\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.0948280986108172 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.24754526093602180481\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.2384217731 \tAcc: 0.9030873494 \tTPR:0.9070133464 \tFPR:0.0965571396 \tF1:0.8899439850 \t AUC:0.9052281034\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.2323908116 \tAcc: 0.9015813253 \tTPR:0.9051929821 \tFPR:0.1035073502 \tF1:0.8857475328 \t AUC:0.9008428159\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.2242699022 \tAcc: 0.9042168675 \tTPR:0.9110305881 \tFPR:0.1004753179 \tF1:0.8900754020 \t AUC:0.9052776351\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.2096439827 \tAcc: 0.9115210843 \tTPR:0.9165320044 \tFPR:0.0900873622 \tF1:0.8992046467 \t AUC:0.9132223211\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.2172272153 \tAcc: 0.9147590361 \tTPR:0.9177766835 \tFPR:0.0965325043 \tF1:0.9039116451 \t AUC:0.9106220896\tTrain cost: 0:00:09\n",
      "Client3 Test =>                 \tLoss: 0.2304213216 \tAcc: 0.9050347222 \tTPR:0.8346539276 \tFPR:0.0367894158 \tF1:0.8835982879 \tAUC:0.8989322559 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.07585017014466781 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.22063815128058195114\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.2075382405 \tAcc: 0.9236607143 \tTPR:0.9604781519 \tFPR:0.1558892166 \tF1:0.9439194352 \t AUC:0.9022944677\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1808079718 \tAcc: 0.9315476190 \tTPR:0.9690982199 \tFPR:0.1457252899 \tF1:0.9497626366 \t AUC:0.9116864650\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1749059330 \tAcc: 0.9341517857 \tTPR:0.9645175122 \tFPR:0.1351937181 \tF1:0.9515631806 \t AUC:0.9146618970\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1607566489 \tAcc: 0.9419642857 \tTPR:0.9718804117 \tFPR:0.1253545066 \tF1:0.9578442432 \t AUC:0.9232629525\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1668981967 \tAcc: 0.9392857143 \tTPR:0.9668596729 \tFPR:0.1191643470 \tF1:0.9549817777 \t AUC:0.9238476630\tTrain cost: 0:00:08\n",
      "Client7 Test =>                 \tLoss: 0.2060303466 \tAcc: 0.9237998188 \tTPR:0.9275247844 \tFPR:0.0848637474 \tF1:0.9404381761 \tAUC:0.9213305185 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.05792136907703011 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.15074389377859101491\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1669142739 \tAcc: 0.9402818991 \tTPR:0.9743356032 \tFPR:0.1717546878 \tF1:0.9610174290 \t AUC:0.9012904577\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1656740971 \tAcc: 0.9398330861 \tTPR:0.9735940619 \tFPR:0.1719938074 \tF1:0.9606808658 \t AUC:0.9008001273\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1602360855 \tAcc: 0.9412500000 \tTPR:0.9751132642 \tFPR:0.1674883392 \tF1:0.9616062841 \t AUC:0.9038124625\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1541060564 \tAcc: 0.9436609792 \tTPR:0.9760192855 \tFPR:0.1652332954 \tF1:0.9631499075 \t AUC:0.9053929951\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1521958183 \tAcc: 0.9432492582 \tTPR:0.9758738413 \tFPR:0.1702141495 \tF1:0.9630621445 \t AUC:0.9028298459\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.1842530729 \tAcc: 0.9308777429 \tTPR:0.9513363802 \tFPR:0.1347889084 \tF1:0.9534755954 \tAUC:0.9082737359 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.06959349306653956 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.29357256435535172834\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.2304301560 \tAcc: 0.9052585096 \tTPR:0.9177133559 \tFPR:0.1049666152 \tF1:0.8978312147 \t AUC:0.9063733703\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.2160926485 \tAcc: 0.9114601849 \tTPR:0.9232632424 \tFPR:0.0995287786 \tF1:0.9049531901 \t AUC:0.9118672319\tTrain cost: 0:00:42\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.2082324427 \tAcc: 0.9174369001 \tTPR:0.9306619757 \tFPR:0.0930158058 \tF1:0.9116271061 \t AUC:0.9188230850\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.2002573647 \tAcc: 0.9191838118 \tTPR:0.9311902431 \tFPR:0.0906180651 \tF1:0.9133186273 \t AUC:0.9202860890\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1992225443 \tAcc: 0.9186200231 \tTPR:0.9309106886 \tFPR:0.0922758493 \tF1:0.9137217676 \t AUC:0.9193174197\tTrain cost: 0:00:41\n",
      "Client6 Test =>                 \tLoss: 0.2377580925 \tAcc: 0.9113855622 \tTPR:0.8599957222 \tFPR:0.0441036258 \tF1:0.8974666733 \tAUC:0.9079460482 \ttest cost: 0:00:06\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.07281926458179373 \tALA epochs: 4\n",
      "Client 1: Local Initial ALA epochs: 4 Loss: 0.18349443192025371996\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1225909342 \tAcc: 0.9496350365 \tTPR:0.7217060596 \tFPR:0.0217854029 \tF1:0.7188861182 \t AUC:0.8468450977\tTrain cost: 0:01:14\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1164802930 \tAcc: 0.9524635036 \tTPR:0.7355710915 \tFPR:0.0209726041 \tF1:0.7268674474 \t AUC:0.8533228691\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1155332833 \tAcc: 0.9522354015 \tTPR:0.7504182598 \tFPR:0.0214768600 \tF1:0.7364198273 \t AUC:0.8609106000\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1118470396 \tAcc: 0.9543795620 \tTPR:0.7616458116 \tFPR:0.0205193203 \tF1:0.7470923619 \t AUC:0.8667940906\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1064048167 \tAcc: 0.9554288321 \tTPR:0.7639914263 \tFPR:0.0205819114 \tF1:0.7539130146 \t AUC:0.8701336944\tTrain cost: 0:01:11\n",
      "Client1 Test =>                 \tLoss: 0.1139423771 \tAcc: 0.9555697279 \tTPR:0.7872570457 \tFPR:0.0234171510 \tF1:0.7547007731 \tAUC:0.8766013735 \ttest cost: 0:00:10\n",
      "Test =>                 \tLoss: 0.1944810421 \tAcc: 0.9253335148 \tTPR:0.8721535720 \tFPR:0.0647925697 \tF1:0.8859359012 \tAUC:0.9026167864\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 3:  =============\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.08118497706362228 \tALA epochs: 3\n",
      "Client 6: Local Initial ALA epochs: 3 Loss: 0.20459730270040499267\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.2103837901 \tAcc: 0.9142069188 \tTPR:0.9265893575 \tFPR:0.0968967366 \tF1:0.9078838653 \t AUC:0.9148463104\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.2081680071 \tAcc: 0.9145374156 \tTPR:0.9267250239 \tFPR:0.0963762688 \tF1:0.9088955948 \t AUC:0.9151743775\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.2030679758 \tAcc: 0.9181617712 \tTPR:0.9320805502 \tFPR:0.0943687204 \tF1:0.9131416476 \t AUC:0.9188559149\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.2012799623 \tAcc: 0.9180728982 \tTPR:0.9312426106 \tFPR:0.0938274466 \tF1:0.9126763261 \t AUC:0.9187075820\tTrain cost: 0:00:42\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1945865379 \tAcc: 0.9212778839 \tTPR:0.9317099440 \tFPR:0.0883242748 \tF1:0.9162189393 \t AUC:0.9216928346\tTrain cost: 0:00:41\n",
      "Client6 Test =>                 \tLoss: 0.2035021977 \tAcc: 0.9202636394 \tTPR:0.9146636514 \tFPR:0.0746192616 \tF1:0.9124038571 \tAUC:0.9200221949 \ttest cost: 0:00:06\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.06783511935731064 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.17167331678653829918\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1505549057 \tAcc: 0.9449332344 \tTPR:0.9776869323 \tFPR:0.1649317712 \tF1:0.9641431256 \t AUC:0.9063775806\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1451639768 \tAcc: 0.9468805638 \tTPR:0.9787043929 \tFPR:0.1647367593 \tF1:0.9653552003 \t AUC:0.9069838168\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1436028951 \tAcc: 0.9473293769 \tTPR:0.9778928427 \tFPR:0.1515592905 \tF1:0.9653975658 \t AUC:0.9131667761\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1368046100 \tAcc: 0.9478857567 \tTPR:0.9763428772 \tFPR:0.1494713620 \tF1:0.9656737583 \t AUC:0.9134357576\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1341465024 \tAcc: 0.9508531157 \tTPR:0.9797397834 \tFPR:0.1444709758 \tF1:0.9680858500 \t AUC:0.9176344038\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.1858678617 \tAcc: 0.9314655172 \tTPR:0.9422308762 \tFPR:0.1083719250 \tF1:0.9536470657 \tAUC:0.9169294756 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.0843488137147894 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.36853197578872953777\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1428965534 \tAcc: 0.9420847002 \tTPR:0.7758511263 \tFPR:0.0290411526 \tF1:0.7769170559 \t AUC:0.8734049868\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1399552659 \tAcc: 0.9430528978 \tTPR:0.7862343165 \tFPR:0.0300814808 \tF1:0.7859785784 \t AUC:0.8774691290\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1352238541 \tAcc: 0.9444596319 \tTPR:0.8011547461 \tFPR:0.0278429577 \tF1:0.7951653117 \t AUC:0.8863742437\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1327484235 \tAcc: 0.9449152542 \tTPR:0.8061328580 \tFPR:0.0291878381 \tF1:0.8031819225 \t AUC:0.8881979106\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1261139346 \tAcc: 0.9491411518 \tTPR:0.8173207129 \tFPR:0.0267473871 \tF1:0.8084379579 \t AUC:0.8947676876\tTrain cost: 0:00:38\n",
      "Client5 Test =>                 \tLoss: 0.1488016328 \tAcc: 0.9479851974 \tTPR:0.7784330618 \tFPR:0.0211180779 \tF1:0.7982217408 \tAUC:0.8786574919 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.09977586024817911 \tALA epochs: 2\n",
      "Client 2: Local Initial ALA epochs: 2 Loss: 0.43214180693030357361\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1481816113 \tAcc: 0.9477597892 \tTPR:0.9789470217 \tFPR:0.1808180357 \tF1:0.9672237737 \t AUC:0.8990644930\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1364317576 \tAcc: 0.9511483434 \tTPR:0.9808766435 \tFPR:0.1722976990 \tF1:0.9693584925 \t AUC:0.9042894723\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.1278684119 \tAcc: 0.9551464788 \tTPR:0.9814693666 \tFPR:0.1556754073 \tF1:0.9720200819 \t AUC:0.9128969797\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.1281940258 \tAcc: 0.9516144937 \tTPR:0.9799748258 \tFPR:0.1691522584 \tF1:0.9697868583 \t AUC:0.9054112837\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.1265382507 \tAcc: 0.9564642499 \tTPR:0.9833815143 \tFPR:0.1553986509 \tF1:0.9727571210 \t AUC:0.9139914317\tTrain cost: 0:00:35\n",
      "Client2 Test =>                 \tLoss: 0.1811429741 \tAcc: 0.9285402098 \tTPR:0.9328009080 \tFPR:0.0942152918 \tF1:0.9538818770 \tAUC:0.9190561916 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.09758536271500087 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.17933257613331080038\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1796699204 \tAcc: 0.9308542931 \tTPR:0.9602371038 \tFPR:0.1223984239 \tF1:0.9458609424 \t AUC:0.9189193399\tTrain cost: 0:01:57\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1734997501 \tAcc: 0.9330785632 \tTPR:0.9613673426 \tFPR:0.1182455776 \tF1:0.9474808608 \t AUC:0.9215608825\tTrain cost: 0:02:03\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1691493056 \tAcc: 0.9346505493 \tTPR:0.9634784109 \tFPR:0.1165747148 \tF1:0.9488543088 \t AUC:0.9234518480\tTrain cost: 0:02:01\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1619925886 \tAcc: 0.9375542064 \tTPR:0.9644936785 \tFPR:0.1115115733 \tF1:0.9510572671 \t AUC:0.9264910526\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1601159013 \tAcc: 0.9378180110 \tTPR:0.9644934574 \tFPR:0.1105801545 \tF1:0.9514906448 \t AUC:0.9269566515\tTrain cost: 0:02:02\n",
      "Client4 Test =>                 \tLoss: 0.1850308820 \tAcc: 0.9304292929 \tTPR:0.9302108459 \tFPR:0.0682173025 \tF1:0.9438929920 \tAUC:0.9309967717 \ttest cost: 0:00:17\n",
      "Test =>                 \tLoss: 0.1808691097 \tAcc: 0.9317367713 \tTPR:0.8996678687 \tFPR:0.0733083718 \tF1:0.9124095065 \tAUC:0.9131324251\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 4:  =============\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.0875606800155823 \tALA epochs: 3\n",
      "Client 5: Local Initial ALA epochs: 3 Loss: 0.20816370105104786692\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1319144549 \tAcc: 0.9467690678 \tTPR:0.7995391771 \tFPR:0.0260563158 \tF1:0.8017803554 \t AUC:0.8861719397\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1244129374 \tAcc: 0.9503855704 \tTPR:0.8170438240 \tFPR:0.0246631236 \tF1:0.8168315008 \t AUC:0.8951448864\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1271205541 \tAcc: 0.9496765081 \tTPR:0.8159062375 \tFPR:0.0256801652 \tF1:0.8172183255 \t AUC:0.8948522801\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1196578233 \tAcc: 0.9525042145 \tTPR:0.8283562012 \tFPR:0.0243257251 \tF1:0.8240695044 \t AUC:0.9017721165\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1194252557 \tAcc: 0.9527605021 \tTPR:0.8357273298 \tFPR:0.0247608580 \tF1:0.8343573887 \t AUC:0.9045445349\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.1385309743 \tAcc: 0.9513998141 \tTPR:0.7734221918 \tFPR:0.0175269539 \tF1:0.7826720611 \tAUC:0.8748857567 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.08362784111836122 \tALA epochs: 7\n",
      "Client 8: Local Initial ALA epochs: 7 Loss: 0.38457237098262764263\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1393992458 \tAcc: 0.9499925816 \tTPR:0.9791242814 \tFPR:0.1543543510 \tF1:0.9673273938 \t AUC:0.9124134240\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1305220443 \tAcc: 0.9532121662 \tTPR:0.9809430212 \tFPR:0.1426676686 \tF1:0.9697480254 \t AUC:0.9191376763\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1270105835 \tAcc: 0.9539132047 \tTPR:0.9790011861 \tFPR:0.1336244451 \tF1:0.9698190962 \t AUC:0.9226883705\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1280665544 \tAcc: 0.9540059347 \tTPR:0.9819790807 \tFPR:0.1342571952 \tF1:0.9699082996 \t AUC:0.9238609427\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1227706979 \tAcc: 0.9551186944 \tTPR:0.9807352718 \tFPR:0.1331536581 \tF1:0.9708112357 \t AUC:0.9237908069\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.1676364600 \tAcc: 0.9411833856 \tTPR:0.9618890154 \tFPR:0.1305337957 \tF1:0.9613467044 \tAUC:0.9156776099 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.08484564274220563 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.21567346566842626743\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1762553527 \tAcc: 0.9311289390 \tTPR:0.9611736313 \tFPR:0.1233700120 \tF1:0.9460192428 \t AUC:0.9189018096\tTrain cost: 0:01:59\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1671402145 \tAcc: 0.9357888841 \tTPR:0.9637861205 \tFPR:0.1145412465 \tF1:0.9497865424 \t AUC:0.9246224370\tTrain cost: 0:02:03\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1626005863 \tAcc: 0.9376879156 \tTPR:0.9648794731 \tFPR:0.1103415780 \tF1:0.9511569406 \t AUC:0.9272689475\tTrain cost: 0:02:04\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1597052608 \tAcc: 0.9376824949 \tTPR:0.9648940638 \tFPR:0.1129126202 \tF1:0.9512272405 \t AUC:0.9259907218\tTrain cost: 0:02:02\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1561767760 \tAcc: 0.9395598439 \tTPR:0.9657921391 \tFPR:0.1079517263 \tF1:0.9527257554 \t AUC:0.9289202064\tTrain cost: 0:02:02\n",
      "Client4 Test =>                 \tLoss: 0.1774596246 \tAcc: 0.9376893939 \tTPR:0.9439033584 \tFPR:0.0743778618 \tF1:0.9503218542 \tAUC:0.9347627483 \ttest cost: 0:00:17\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.07167193731506007 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.11975209127095612360\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1206156005 \tAcc: 0.9576430723 \tTPR:0.9844711834 \tFPR:0.1482082091 \tF1:0.9734316393 \t AUC:0.9181314872\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1201334911 \tAcc: 0.9556619334 \tTPR:0.9837052299 \tFPR:0.1615626592 \tF1:0.9724669184 \t AUC:0.9110712854\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.1164274145 \tAcc: 0.9598483219 \tTPR:0.9847480321 \tFPR:0.1354313274 \tF1:0.9746305890 \t AUC:0.9246583524\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.1081312052 \tAcc: 0.9612647017 \tTPR:0.9859871781 \tFPR:0.1405677823 \tF1:0.9757823499 \t AUC:0.9227096979\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.1063398231 \tAcc: 0.9624883462 \tTPR:0.9860418442 \tFPR:0.1377706213 \tF1:0.9766433815 \t AUC:0.9241356115\tTrain cost: 0:00:35\n",
      "Client2 Test =>                 \tLoss: 0.1989962644 \tAcc: 0.9254807692 \tTPR:0.9271887450 \tFPR:0.0789573298 \tF1:0.9513186349 \tAUC:0.9238593299 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.076788161418803 \tALA epochs: 6\n",
      "Client 1: Local Initial ALA epochs: 6 Loss: 0.28788561549485097713\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1094587703 \tAcc: 0.9536952555 \tTPR:0.7766840459 \tFPR:0.0225625846 \tF1:0.7588406033 \t AUC:0.8737025960\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1066770984 \tAcc: 0.9553375912 \tTPR:0.7685946009 \tFPR:0.0213654156 \tF1:0.7548581741 \t AUC:0.8708474130\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0994182434 \tAcc: 0.9598996350 \tTPR:0.7807634215 \tFPR:0.0176268063 \tF1:0.7743456563 \t AUC:0.8789466445\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0962348530 \tAcc: 0.9612226277 \tTPR:0.7990592943 \tFPR:0.0187638295 \tF1:0.7786839776 \t AUC:0.8877448540\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0960180073 \tAcc: 0.9593521898 \tTPR:0.7847890795 \tFPR:0.0188496140 \tF1:0.7784638207 \t AUC:0.8812135606\tTrain cost: 0:01:11\n",
      "Client1 Test =>                 \tLoss: 0.1085189885 \tAcc: 0.9608843537 \tTPR:0.7775415722 \tFPR:0.0153839723 \tF1:0.7739200586 \tAUC:0.8746771186 \ttest cost: 0:00:10\n",
      "Test =>                 \tLoss: 0.1582284624 \tAcc: 0.9433275433 \tTPR:0.8767889766 \tFPR:0.0633559827 \tF1:0.8839158627 \tAUC:0.9047725127\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 5:  =============\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.05325861842888715 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.15080542350187897682\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1543467594 \tAcc: 0.9423363095 \tTPR:0.9723319094 \tFPR:0.1179760881 \tF1:0.9578605117 \t AUC:0.9271779107\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1351196981 \tAcc: 0.9501488095 \tTPR:0.9756788659 \tFPR:0.1034650865 \tF1:0.9635438110 \t AUC:0.9361068897\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1356947469 \tAcc: 0.9460565476 \tTPR:0.9713369371 \tFPR:0.1103995541 \tF1:0.9604015787 \t AUC:0.9304686915\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1376609397 \tAcc: 0.9464285714 \tTPR:0.9722124180 \tFPR:0.1062475719 \tF1:0.9604729059 \t AUC:0.9329824231\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1264022184 \tAcc: 0.9516369048 \tTPR:0.9755985931 \tFPR:0.0994832743 \tF1:0.9639245121 \t AUC:0.9380576594\tTrain cost: 0:00:08\n",
      "Client7 Test =>                 \tLoss: 0.1833716325 \tAcc: 0.9354242150 \tTPR:0.9382199686 \tFPR:0.0640120364 \tF1:0.9502098226 \tAUC:0.9371039661 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.07733990526379494 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.12621451894555127393\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1190935337 \tAcc: 0.9567466294 \tTPR:0.9833044171 \tFPR:0.1567221969 \tF1:0.9730309907 \t AUC:0.9132658902\tTrain cost: 0:00:32\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1142519939 \tAcc: 0.9587232860 \tTPR:0.9834288646 \tFPR:0.1467377084 \tF1:0.9741454795 \t AUC:0.9183455781\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.1084693608 \tAcc: 0.9620177137 \tTPR:0.9857373799 \tFPR:0.1379368791 \tF1:0.9762557780 \t AUC:0.9239002504\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.1067971726 \tAcc: 0.9627707258 \tTPR:0.9860527654 \tFPR:0.1334198934 \tF1:0.9767579073 \t AUC:0.9263164360\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.1043737983 \tAcc: 0.9631965361 \tTPR:0.9866649142 \tFPR:0.1291963976 \tF1:0.9768196183 \t AUC:0.9287342583\tTrain cost: 0:00:35\n",
      "Client2 Test =>                 \tLoss: 0.1727431611 \tAcc: 0.9349213287 \tTPR:0.9414999204 \tFPR:0.0927244473 \tF1:0.9572730009 \tAUC:0.9243877365 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.06797394940210873 \tALA epochs: 4\n",
      "Client 6: Local Initial ALA epochs: 4 Loss: 0.22769864244604265391\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1817701072 \tAcc: 0.9269324342 \tTPR:0.9382142735 \tFPR:0.0837911252 \tF1:0.9214427313 \t AUC:0.9272115742\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1719733647 \tAcc: 0.9301540837 \tTPR:0.9387325938 \tFPR:0.0786206901 \tF1:0.9252764660 \t AUC:0.9300559518\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1670978020 \tAcc: 0.9320148640 \tTPR:0.9425987460 \tFPR:0.0788893035 \tF1:0.9271534934 \t AUC:0.9318547213\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1627209719 \tAcc: 0.9326675258 \tTPR:0.9404820736 \tFPR:0.0753774428 \tF1:0.9281284865 \t AUC:0.9325523154\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1625233764 \tAcc: 0.9345199742 \tTPR:0.9454118464 \tFPR:0.0742332368 \tF1:0.9300989727 \t AUC:0.9355893048\tTrain cost: 0:00:41\n",
      "Client6 Test =>                 \tLoss: 0.2097660309 \tAcc: 0.9222388556 \tTPR:0.8951929220 \tFPR:0.0555265590 \tF1:0.9125077160 \tAUC:0.9198331815 \ttest cost: 0:00:06\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.0813439283175283 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.18370872805161134189\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1190321586 \tAcc: 0.9497647849 \tTPR:0.8248840300 \tFPR:0.0262789884 \tF1:0.8174841520 \t AUC:0.8990544812\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1166602773 \tAcc: 0.9527690450 \tTPR:0.8307046453 \tFPR:0.0241075897 \tF1:0.8308268948 \t AUC:0.9032985278\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1125314637 \tAcc: 0.9552379488 \tTPR:0.8341069790 \tFPR:0.0229363136 \tF1:0.8378934556 \t AUC:0.9051140457\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1088197713 \tAcc: 0.9555027793 \tTPR:0.8391823258 \tFPR:0.0229459691 \tF1:0.8394846990 \t AUC:0.9078903913\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1058021036 \tAcc: 0.9563883953 \tTPR:0.8255624241 \tFPR:0.0215281297 \tF1:0.8321561362 \t AUC:0.9020171472\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.1502876701 \tAcc: 0.9489327088 \tTPR:0.7269831776 \tFPR:0.0163753880 \tF1:0.7617340956 \tAUC:0.8543998656 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.0935980210465674 \tALA epochs: 2\n",
      "Client 8: Local Initial ALA epochs: 2 Loss: 0.43446130027521900896\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1300316768 \tAcc: 0.9533976261 \tTPR:0.9794449896 \tFPR:0.1367227398 \tF1:0.9695898022 \t AUC:0.9213611249\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1215718378 \tAcc: 0.9547477745 \tTPR:0.9817288637 \tFPR:0.1366408896 \tF1:0.9705486223 \t AUC:0.9225439870\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1157085883 \tAcc: 0.9586164688 \tTPR:0.9828549286 \tFPR:0.1202907377 \tF1:0.9728499167 \t AUC:0.9313030849\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1136089231 \tAcc: 0.9590133531 \tTPR:0.9843477813 \tFPR:0.1234180673 \tF1:0.9733325217 \t AUC:0.9304648570\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1098310147 \tAcc: 0.9621402077 \tTPR:0.9837692195 \tFPR:0.1068767945 \tF1:0.9751174325 \t AUC:0.9384462125\tTrain cost: 0:00:36\n",
      "Client8 Test =>                 \tLoss: 0.1642400273 \tAcc: 0.9413793103 \tTPR:0.9562702514 \tFPR:0.1106657710 \tF1:0.9610352651 \tAUC:0.9228022402 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.1760817044 \tAcc: 0.9365792837 \tTPR:0.8916332480 \tFPR:0.0678608403 \tF1:0.9085519800 \tAUC:0.9117053980\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 6:  =============\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.08278703931467082 \tALA epochs: 2\n",
      "Client 2: Local Initial ALA epochs: 2 Loss: 0.12943682531741532160\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1075355599 \tAcc: 0.9607492470 \tTPR:0.9844575908 \tFPR:0.1406528825 \tF1:0.9754318972 \t AUC:0.9219026045\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1033818901 \tAcc: 0.9636178643 \tTPR:0.9861056703 \tFPR:0.1312902041 \tF1:0.9772660320 \t AUC:0.9274077331\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.1015922546 \tAcc: 0.9637119908 \tTPR:0.9855555977 \tFPR:0.1260748622 \tF1:0.9772312252 \t AUC:0.9297403677\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0959024965 \tAcc: 0.9653614458 \tTPR:0.9877396727 \tFPR:0.1282796772 \tF1:0.9783646710 \t AUC:0.9297299978\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0929463376 \tAcc: 0.9673829246 \tTPR:0.9891758418 \tFPR:0.1208023653 \tF1:0.9797496984 \t AUC:0.9341867382\tTrain cost: 0:00:34\n",
      "Client2 Test =>                 \tLoss: 0.2193875515 \tAcc: 0.9227709790 \tTPR:0.9232344339 \tFPR:0.0703844278 \tF1:0.9497400368 \tAUC:0.9268589271 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.06141758791084077 \tALA epochs: 2\n",
      "Client 8: Local Initial ALA epochs: 2 Loss: 0.12318516151506954392\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1282378019 \tAcc: 0.9520734421 \tTPR:0.9806471498 \tFPR:0.1437549798 \tF1:0.9684906739 \t AUC:0.9184460850\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1179524472 \tAcc: 0.9566691395 \tTPR:0.9826727744 \tFPR:0.1290931867 \tF1:0.9716104337 \t AUC:0.9267897938\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1127190868 \tAcc: 0.9598627596 \tTPR:0.9847436999 \tFPR:0.1258148586 \tF1:0.9738729331 \t AUC:0.9294644207\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1075824323 \tAcc: 0.9618879822 \tTPR:0.9854187110 \tFPR:0.1177612776 \tF1:0.9751173853 \t AUC:0.9338287167\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1064646417 \tAcc: 0.9615170623 \tTPR:0.9843313642 \tFPR:0.1102443798 \tF1:0.9746041227 \t AUC:0.9370434922\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.1617708481 \tAcc: 0.9446120690 \tTPR:0.9659734493 \tFPR:0.1231917699 \tF1:0.9633143043 \tAUC:0.9213908397 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.11034169297179192 \tALA epochs: 11\n",
      "Client 1: Local Initial ALA epochs: 11 Loss: 0.44684621911585570286\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1069615466 \tAcc: 0.9568886861 \tTPR:0.7754756112 \tFPR:0.0211746749 \tF1:0.7585389335 \t AUC:0.8748081869\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1005357693 \tAcc: 0.9587135036 \tTPR:0.7976688680 \tFPR:0.0195717678 \tF1:0.7835592072 \t AUC:0.8867836494\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0969625650 \tAcc: 0.9607664234 \tTPR:0.7969771753 \tFPR:0.0175596371 \tF1:0.7827759750 \t AUC:0.8871253948\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0938023455 \tAcc: 0.9609945255 \tTPR:0.8058336230 \tFPR:0.0185096701 \tF1:0.7952807473 \t AUC:0.8919309240\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0947070548 \tAcc: 0.9622262774 \tTPR:0.8038680338 \tFPR:0.0164130756 \tF1:0.7905008895 \t AUC:0.8912317879\tTrain cost: 0:01:09\n",
      "Client1 Test =>                 \tLoss: 0.1100264906 \tAcc: 0.9604591837 \tTPR:0.7487568837 \tFPR:0.0137282942 \tF1:0.7703681806 \tAUC:0.8626314780 \ttest cost: 0:00:10\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.09216712880167531 \tALA epochs: 2\n",
      "Client 4: Local Initial ALA epochs: 2 Loss: 0.38687333153641739747\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1554798079 \tAcc: 0.9399085718 \tTPR:0.9657219638 \tFPR:0.1071510138 \tF1:0.9529790647 \t AUC:0.9292854750\tTrain cost: 0:01:56\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1495168051 \tAcc: 0.9414570685 \tTPR:0.9663002772 \tFPR:0.1035212583 \tF1:0.9539156370 \t AUC:0.9313895095\tTrain cost: 0:02:03\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1440561654 \tAcc: 0.9443842151 \tTPR:0.9694941799 \tFPR:0.1007656792 \tF1:0.9563634666 \t AUC:0.9343642504\tTrain cost: 0:02:02\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1397476096 \tAcc: 0.9469554062 \tTPR:0.9704779635 \tFPR:0.0952404523 \tF1:0.9584808064 \t AUC:0.9376187556\tTrain cost: 0:02:01\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1379408610 \tAcc: 0.9477395924 \tTPR:0.9707078916 \tFPR:0.0930852209 \tF1:0.9588050818 \t AUC:0.9388113354\tTrain cost: 0:02:03\n",
      "Client4 Test =>                 \tLoss: 0.1756561682 \tAcc: 0.9351641414 \tTPR:0.9351071590 \tFPR:0.0666325888 \tF1:0.9474108875 \tAUC:0.9341716041 \ttest cost: 0:00:17\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.09052107857781247 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.16384175323046645811\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1648686350 \tAcc: 0.9325786527 \tTPR:0.9421244634 \tFPR:0.0771510058 \tF1:0.9268003433 \t AUC:0.9324867288\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1562989182 \tAcc: 0.9361696809 \tTPR:0.9454896009 \tFPR:0.0725860783 \tF1:0.9317615123 \t AUC:0.9364517613\tTrain cost: 0:00:42\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1505218774 \tAcc: 0.9376527506 \tTPR:0.9449969959 \tFPR:0.0696390560 \tF1:0.9331955952 \t AUC:0.9376789700\tTrain cost: 0:00:42\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1484352292 \tAcc: 0.9378943743 \tTPR:0.9489368763 \tFPR:0.0712452044 \tF1:0.9332684103 \t AUC:0.9388458359\tTrain cost: 0:00:42\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1469128232 \tAcc: 0.9387636642 \tTPR:0.9471244227 \tFPR:0.0676735066 \tF1:0.9343276732 \t AUC:0.9397254580\tTrain cost: 0:00:41\n",
      "Client6 Test =>                 \tLoss: 0.1973166986 \tAcc: 0.9293496341 \tTPR:0.9130677432 \tFPR:0.0553745996 \tF1:0.9209884715 \tAUC:0.9288465718 \ttest cost: 0:00:06\n",
      "Test =>                 \tLoss: 0.1728315514 \tAcc: 0.9384712014 \tTPR:0.8972279338 \tFPR:0.0658623361 \tF1:0.9103643761 \tAUC:0.9147798841\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 7:  =============\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.0364744629659341 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.11301081116074945809\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1073449162 \tAcc: 0.9594770030 \tTPR:0.9832527038 \tFPR:0.1189809737 \tF1:0.9736049344 \t AUC:0.9321358651\tTrain cost: 0:00:32\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1023998089 \tAcc: 0.9636238872 \tTPR:0.9857394912 \tFPR:0.1114569242 \tF1:0.9762198935 \t AUC:0.9371412835\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0988293528 \tAcc: 0.9650816024 \tTPR:0.9844241914 \tFPR:0.0980442983 \tF1:0.9769614045 \t AUC:0.9431899465\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0964002994 \tAcc: 0.9645771513 \tTPR:0.9853413905 \tFPR:0.1036439998 \tF1:0.9767158818 \t AUC:0.9409198879\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0943971429 \tAcc: 0.9652002967 \tTPR:0.9855536356 \tFPR:0.1014448130 \tF1:0.9771273941 \t AUC:0.9420544113\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.1891167648 \tAcc: 0.9351293103 \tTPR:0.9408472933 \tFPR:0.0794829883 \tF1:0.9565104254 \tAUC:0.9306821525 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.08090094751493163 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.27732488858912673901\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1164621572 \tAcc: 0.9529484463 \tTPR:0.8371054166 \tFPR:0.0262128525 \tF1:0.8262904010 \t AUC:0.9052155531\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1085249175 \tAcc: 0.9552407964 \tTPR:0.8393712534 \tFPR:0.0227283955 \tF1:0.8273471351 \t AUC:0.9071707932\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1040289751 \tAcc: 0.9577040049 \tTPR:0.8580804005 \tFPR:0.0233384047 \tF1:0.8506632086 \t AUC:0.9171699786\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1006076244 \tAcc: 0.9584130672 \tTPR:0.8447029822 \tFPR:0.0208964236 \tF1:0.8463665890 \t AUC:0.9112396168\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0984909955 \tAcc: 0.9614230226 \tTPR:0.8642766446 \tFPR:0.0198739793 \tF1:0.8578173314 \t AUC:0.9216213183\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.1377794716 \tAcc: 0.9528836527 \tTPR:0.7887960906 \tFPR:0.0174894890 \tF1:0.8174554859 \tAUC:0.8856533008 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.05235220959965909 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.09663277366609476782\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0969854659 \tAcc: 0.9601733577 \tTPR:0.8024498899 \tFPR:0.0185918027 \tF1:0.7867690639 \t AUC:0.8901678242\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0911380937 \tAcc: 0.9624087591 \tTPR:0.7973635732 \tFPR:0.0180192116 \tF1:0.7836245007 \t AUC:0.8878656153\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0886869428 \tAcc: 0.9640054745 \tTPR:0.8131879272 \tFPR:0.0168682413 \tF1:0.7984638597 \t AUC:0.8962109838\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0852030860 \tAcc: 0.9662864964 \tTPR:0.8178751014 \tFPR:0.0160539817 \tF1:0.8074660773 \t AUC:0.8992868609\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0839586395 \tAcc: 0.9656934307 \tTPR:0.8198094079 \tFPR:0.0160825713 \tF1:0.8141356067 \t AUC:0.8998463595\tTrain cost: 0:01:13\n",
      "Client1 Test =>                 \tLoss: 0.1064450644 \tAcc: 0.9632227891 \tTPR:0.7926114890 \tFPR:0.0168860169 \tF1:0.7858954382 \tAUC:0.8845881806 \ttest cost: 0:00:10\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.09068902029671128 \tALA epochs: 7\n",
      "Client 7: Local Initial ALA epochs: 7 Loss: 0.31438139566619482945\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1447203920 \tAcc: 0.9412202381 \tTPR:0.9639722316 \tFPR:0.1086962573 \tF1:0.9552747307 \t AUC:0.9276379872\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1263442869 \tAcc: 0.9494047619 \tTPR:0.9731413359 \tFPR:0.1030644124 \tF1:0.9620500163 \t AUC:0.9350384617\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1233361425 \tAcc: 0.9512648810 \tTPR:0.9749088343 \tFPR:0.1020969606 \tF1:0.9640690654 \t AUC:0.9364059368\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1155574428 \tAcc: 0.9557291667 \tTPR:0.9765331006 \tFPR:0.0889797867 \tF1:0.9664238377 \t AUC:0.9437766569\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1142503965 \tAcc: 0.9512648810 \tTPR:0.9722186622 \tFPR:0.0968337549 \tF1:0.9630848905 \t AUC:0.9376924537\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2130832156 \tAcc: 0.9368206522 \tTPR:0.9257473765 \tFPR:0.0463076276 \tF1:0.9483615490 \tAUC:0.9397198745 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.09889103709294152 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.15117618516087533154\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1433171961 \tAcc: 0.9564732143 \tTPR:0.9815024951 \tFPR:0.1514172336 \tF1:0.9727781731 \t AUC:0.9150426308\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1182926032 \tAcc: 0.9612001050 \tTPR:0.9901388889 \tFPR:0.1431972789 \tF1:0.9755075632 \t AUC:0.9234708050\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1145076152 \tAcc: 0.9631696429 \tTPR:0.9895389267 \tFPR:0.1530165271 \tF1:0.9772473240 \t AUC:0.9182611998\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1033296129 \tAcc: 0.9690126050 \tTPR:0.9909859163 \tFPR:0.1081460206 \tF1:0.9798021508 \t AUC:0.9414199478\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1098917440 \tAcc: 0.9666491597 \tTPR:0.9932380040 \tFPR:0.1365800866 \tF1:0.9790546304 \t AUC:0.9283289587\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.1478534065 \tAcc: 0.9403044872 \tTPR:0.9552424275 \tFPR:0.0912127225 \tF1:0.9571932426 \tAUC:0.9320148525 \ttest cost: 0:00:00\n",
      "Test =>                 \tLoss: 0.1588555846 \tAcc: 0.9456721783 \tTPR:0.8806489354 \tFPR:0.0502757689 \tF1:0.8930832282 \tAUC:0.9145316722\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 8:  =============\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.09919492958296498 \tALA epochs: 2\n",
      "Client 0: Local Initial ALA epochs: 2 Loss: 0.17235532365739344995\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1267282042 \tAcc: 0.9631696429 \tTPR:0.9892503925 \tFPR:0.1285997732 \tF1:0.9768303907 \t AUC:0.9303253096\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1086339717 \tAcc: 0.9654017857 \tTPR:0.9894208239 \tFPR:0.1157999738 \tF1:0.9784014034 \t AUC:0.9368104250\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1056745650 \tAcc: 0.9666491597 \tTPR:0.9914743590 \tFPR:0.1350481859 \tF1:0.9790117370 \t AUC:0.9282130865\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0955988548 \tAcc: 0.9698660714 \tTPR:0.9882023435 \tFPR:0.1011577708 \tF1:0.9800359799 \t AUC:0.9435222863\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0906266242 \tAcc: 0.9765625000 \tTPR:0.9956363584 \tFPR:0.1160856009 \tF1:0.9856939033 \t AUC:0.9397753788\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.1986081948 \tAcc: 0.9368990385 \tTPR:0.9464378927 \tFPR:0.0940806878 \tF1:0.9583048529 \tAUC:0.9261786024 \ttest cost: 0:00:00\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.0937766380627738 \tALA epochs: 3\n",
      "Client 6: Local Initial ALA epochs: 3 Loss: 0.20582045715108707173\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1616880890 \tAcc: 0.9343505599 \tTPR:0.9476592747 \tFPR:0.0785612615 \tF1:0.9297772878 \t AUC:0.9345490066\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1554472276 \tAcc: 0.9374111269 \tTPR:0.9448396430 \tFPR:0.0699889421 \tF1:0.9323673251 \t AUC:0.9374253504\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1480276655 \tAcc: 0.9407133176 \tTPR:0.9479859436 \tFPR:0.0661120086 \tF1:0.9358356813 \t AUC:0.9409369675\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1475062448 \tAcc: 0.9416714806 \tTPR:0.9547447988 \tFPR:0.0703049009 \tF1:0.9382305597 \t AUC:0.9422199490\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1400002464 \tAcc: 0.9436933434 \tTPR:0.9541722570 \tFPR:0.0655579601 \tF1:0.9398179160 \t AUC:0.9443071485\tTrain cost: 0:00:40\n",
      "Client6 Test =>                 \tLoss: 0.2138653348 \tAcc: 0.9231744844 \tTPR:0.8891662221 \tFPR:0.0461170037 \tF1:0.9134582545 \tAUC:0.9215246092 \ttest cost: 0:00:06\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.06797610993642406 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.21175702864473516795\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0724679732 \tAcc: 0.9781250000 \tTPR:0.9933247920 \tFPR:0.2278846154 \tF1:0.9879986644 \t AUC:0.8828075723\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0587882224 \tAcc: 0.9838541667 \tTPR:0.9961755952 \tFPR:0.1520476190 \tF1:0.9910918538 \t AUC:0.9226190476\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0586550740 \tAcc: 0.9807291667 \tTPR:0.9955325582 \tFPR:0.1922619048 \tF1:0.9895268712 \t AUC:0.9014757752\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0529317282 \tAcc: 0.9843750000 \tTPR:0.9955426303 \tFPR:0.1488571429 \tF1:0.9913752441 \t AUC:0.9232095067\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0477617284 \tAcc: 0.9848958333 \tTPR:0.9965998621 \tFPR:0.1605570530 \tF1:0.9917057871 \t AUC:0.9177968671\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.1287121071 \tAcc: 0.9577724359 \tTPR:0.9730271756 \tFPR:0.2766666667 \tF1:0.9771492116 \tAUC:0.8482657980 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.17560028563435146 \tALA epochs: 11\n",
      "Client 1: Local Initial ALA epochs: 11 Loss: 0.50825336547369226459\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0925868962 \tAcc: 0.9620437956 \tTPR:0.8128548256 \tFPR:0.0187707710 \tF1:0.7947040203 \t AUC:0.8943725391\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0862197739 \tAcc: 0.9644160584 \tTPR:0.8254449079 \tFPR:0.0171068839 \tF1:0.8104742750 \t AUC:0.9023480200\tTrain cost: 0:01:14\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0816994775 \tAcc: 0.9675638686 \tTPR:0.8401535164 \tFPR:0.0154520392 \tF1:0.8247449752 \t AUC:0.9108046045\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0802825980 \tAcc: 0.9675182482 \tTPR:0.8320988298 \tFPR:0.0161296829 \tF1:0.8191450837 \t AUC:0.9055895868\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0769922146 \tAcc: 0.9689781022 \tTPR:0.8487064071 \tFPR:0.0152595867 \tF1:0.8352497520 \t AUC:0.9149142193\tTrain cost: 0:01:11\n",
      "Client1 Test =>                 \tLoss: 0.1230047171 \tAcc: 0.9602111678 \tTPR:0.7117157974 \tFPR:0.0098376496 \tF1:0.7435792577 \tAUC:0.8448053675 \ttest cost: 0:00:10\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.05567620753054667 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.11671347322740725783\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1065936042 \tAcc: 0.9557733051 \tTPR:0.8396789729 \tFPR:0.0226205687 \tF1:0.8401072119 \t AUC:0.9083021185\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1008637475 \tAcc: 0.9593926554 \tTPR:0.8438884405 \tFPR:0.0200173976 \tF1:0.8488896373 \t AUC:0.9117144003\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0959856413 \tAcc: 0.9625649262 \tTPR:0.8612455263 \tFPR:0.0189438175 \tF1:0.8634756452 \t AUC:0.9211508544\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0910009990 \tAcc: 0.9636299435 \tTPR:0.8648894107 \tFPR:0.0178725650 \tF1:0.8670976509 \t AUC:0.9233170481\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0839706752 \tAcc: 0.9684851695 \tTPR:0.8886646075 \tFPR:0.0169782951 \tF1:0.8810124421 \t AUC:0.9358431562\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.1405148123 \tAcc: 0.9551004720 \tTPR:0.8325292398 \tFPR:0.0249077635 \tF1:0.8140983973 \tAUC:0.9015476198 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.1609410332 \tAcc: 0.9466315197 \tTPR:0.8705752655 \tFPR:0.0903219543 \tF1:0.8813179948 \tAUC:0.8884643994\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 9:  =============\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.03631321541041558 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.16372001022100449164\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1205064198 \tAcc: 0.9654017857 \tTPR:0.9873036917 \tFPR:0.1185941043 \tF1:0.9782464272 \t AUC:0.9343547937\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1107448072 \tAcc: 0.9676339286 \tTPR:0.9911835578 \tFPR:0.1264880952 \tF1:0.9794019427 \t AUC:0.9323477313\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0908909906 \tAcc: 0.9688813025 \tTPR:0.9916611167 \tFPR:0.1274543908 \tF1:0.9806053072 \t AUC:0.9321033629\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0864976483 \tAcc: 0.9720982143 \tTPR:0.9943839494 \tFPR:0.1057539683 \tF1:0.9823004316 \t AUC:0.9443149906\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0846469499 \tAcc: 0.9732142857 \tTPR:0.9910343823 \tFPR:0.1024659864 \tF1:0.9828022417 \t AUC:0.9442841979\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.2079978940 \tAcc: 0.9322916667 \tTPR:0.9408187465 \tFPR:0.0919372294 \tF1:0.9550474972 \tAUC:0.9244407585 \ttest cost: 0:00:00\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.08658187773108875 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.10622030856426466217\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1021915257 \tAcc: 0.9625376506 \tTPR:0.9872517032 \tFPR:0.1416532932 \tF1:0.9766288744 \t AUC:0.9227992050\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0955528685 \tAcc: 0.9669571142 \tTPR:0.9884386842 \tFPR:0.1239002547 \tF1:0.9794740555 \t AUC:0.9322692147\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0892368125 \tAcc: 0.9677146084 \tTPR:0.9875797859 \tFPR:0.1135935851 \tF1:0.9797459919 \t AUC:0.9369931004\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0847626034 \tAcc: 0.9701618976 \tTPR:0.9884183761 \tFPR:0.1061309758 \tF1:0.9812188401 \t AUC:0.9411437002\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0820250470 \tAcc: 0.9706773523 \tTPR:0.9892375044 \tFPR:0.1082146454 \tF1:0.9816146243 \t AUC:0.9404951720\tTrain cost: 0:00:35\n",
      "Client2 Test =>                 \tLoss: 0.1546832232 \tAcc: 0.9499562937 \tTPR:0.9635258363 \tFPR:0.1042707293 \tF1:0.9679833923 \tAUC:0.9296275535 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.09690994174337016 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.18324509168084224253\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1451058747 \tAcc: 0.9441655825 \tTPR:0.9694006394 \tFPR:0.1022023299 \tF1:0.9564708177 \t AUC:0.9335991548\tTrain cost: 0:01:56\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1384804856 \tAcc: 0.9457899682 \tTPR:0.9686649069 \tFPR:0.0966606410 \tF1:0.9574117256 \t AUC:0.9360021330\tTrain cost: 0:02:02\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1332886594 \tAcc: 0.9487731281 \tTPR:0.9718347835 \tFPR:0.0930174088 \tF1:0.9599070174 \t AUC:0.9394086873\tTrain cost: 0:02:01\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1283005263 \tAcc: 0.9513714224 \tTPR:0.9727042407 \tFPR:0.0868805175 \tF1:0.9617459119 \t AUC:0.9429118616\tTrain cost: 0:02:03\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1273359742 \tAcc: 0.9506685458 \tTPR:0.9713842902 \tFPR:0.0863162526 \tF1:0.9609615448 \t AUC:0.9425340188\tTrain cost: 0:02:02\n",
      "Client4 Test =>                 \tLoss: 0.1792042736 \tAcc: 0.9364898990 \tTPR:0.9367848800 \tFPR:0.0652481497 \tF1:0.9487763521 \tAUC:0.9357683652 \ttest cost: 0:00:17\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.07667548281098308 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.15304221760015934706\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1657937805 \tAcc: 0.9374246988 \tTPR:0.9478928797 \tFPR:0.0695694602 \tF1:0.9296438087 \t AUC:0.9391617097\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1481044122 \tAcc: 0.9407379518 \tTPR:0.9559241600 \tFPR:0.0707766888 \tF1:0.9322096367 \t AUC:0.9425737356\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1384609683 \tAcc: 0.9465361446 \tTPR:0.9503584570 \tFPR:0.0562882794 \tF1:0.9391482687 \t AUC:0.9470350888\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1325757199 \tAcc: 0.9502259036 \tTPR:0.9596234254 \tFPR:0.0572501445 \tF1:0.9424143495 \t AUC:0.9511866405\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1243775428 \tAcc: 0.9476656627 \tTPR:0.9572904377 \tFPR:0.0585785046 \tF1:0.9393360725 \t AUC:0.9493559666\tTrain cost: 0:00:09\n",
      "Client3 Test =>                 \tLoss: 0.1797145594 \tAcc: 0.9442708333 \tTPR:0.9092525016 \tFPR:0.0276780805 \tF1:0.9349104540 \tAUC:0.9407872105 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.09068757246243139 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.13015110348351299763\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1305628716 \tAcc: 0.9519345238 \tTPR:0.9771988914 \tFPR:0.1033742265 \tF1:0.9645188423 \t AUC:0.9369123324\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1204197079 \tAcc: 0.9486607143 \tTPR:0.9746876831 \tFPR:0.1074716600 \tF1:0.9621418914 \t AUC:0.9336080115\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1101041712 \tAcc: 0.9563988095 \tTPR:0.9789672397 \tFPR:0.0901742204 \tF1:0.9672645222 \t AUC:0.9443965096\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1062781815 \tAcc: 0.9583333333 \tTPR:0.9776120833 \tFPR:0.0816626311 \tF1:0.9677540868 \t AUC:0.9479747261\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0963380773 \tAcc: 0.9590029762 \tTPR:0.9809901653 \tFPR:0.0840860198 \tF1:0.9696334177 \t AUC:0.9484520728\tTrain cost: 0:00:08\n",
      "Client7 Test =>                 \tLoss: 0.1873813348 \tAcc: 0.9409722222 \tTPR:0.9398741391 \tFPR:0.0553740740 \tF1:0.9536484803 \tAUC:0.9422500326 \ttest cost: 0:00:01\n",
      "Test =>                 \tLoss: 0.1817962570 \tAcc: 0.9407961830 \tTPR:0.9380512207 \tFPR:0.0689016526 \tF1:0.9520732352 \tAUC:0.9345747841\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 10:  =============\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.08822988187421305 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.16204878361895680428\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1404120484 \tAcc: 0.9442018072 \tTPR:0.9507871084 \tFPR:0.0607992998 \tF1:0.9357327970 \t AUC:0.9449939043\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1348854039 \tAcc: 0.9491716867 \tTPR:0.9571315912 \tFPR:0.0552207565 \tF1:0.9412701020 \t AUC:0.9509554174\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1268856927 \tAcc: 0.9495481928 \tTPR:0.9557995368 \tFPR:0.0551737516 \tF1:0.9413960635 \t AUC:0.9503128926\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1285642270 \tAcc: 0.9501506024 \tTPR:0.9577429518 \tFPR:0.0568110710 \tF1:0.9427724269 \t AUC:0.9504659404\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1214741008 \tAcc: 0.9532379518 \tTPR:0.9569302415 \tFPR:0.0478621768 \tF1:0.9460275429 \t AUC:0.9545340323\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.2020940926 \tAcc: 0.9371527778 \tTPR:0.9138679722 \tFPR:0.0365787534 \tF1:0.9299588270 \tAUC:0.9386446094 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.06531517425314808 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.13214609175920485895\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1187723745 \tAcc: 0.9634322479 \tTPR:0.9931004835 \tFPR:0.1329931973 \tF1:0.9768321906 \t AUC:0.9300536431\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0963697181 \tAcc: 0.9698660714 \tTPR:0.9921855889 \tFPR:0.1178597196 \tF1:0.9813539800 \t AUC:0.9371629346\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0895683548 \tAcc: 0.9732142857 \tTPR:0.9919031630 \tFPR:0.0918607186 \tF1:0.9827950925 \t AUC:0.9500212222\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0828302682 \tAcc: 0.9732142857 \tTPR:0.9919780345 \tFPR:0.0948296743 \tF1:0.9828244263 \t AUC:0.9485741801\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0739496871 \tAcc: 0.9800420168 \tTPR:0.9973036223 \tFPR:0.0947704082 \tF1:0.9876640741 \t AUC:0.9512666071\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.2476700484 \tAcc: 0.9322916667 \tTPR:0.9428501008 \tFPR:0.1055224868 \tF1:0.9551809900 \tAUC:0.9186638070 \ttest cost: 0:00:00\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.05149517252392389 \tALA epochs: 6\n",
      "Client 7: Local Initial ALA epochs: 6 Loss: 0.14714593645961335233\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1230236056 \tAcc: 0.9512648810 \tTPR:0.9785426310 \tFPR:0.1008289330 \tF1:0.9638465439 \t AUC:0.9388568490\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1184486638 \tAcc: 0.9556547619 \tTPR:0.9809588431 \tFPR:0.1035720397 \tF1:0.9671416860 \t AUC:0.9386934017\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1110775062 \tAcc: 0.9558779762 \tTPR:0.9778564789 \tFPR:0.0920940006 \tF1:0.9679528138 \t AUC:0.9428812392\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0988310173 \tAcc: 0.9619791667 \tTPR:0.9823369002 \tFPR:0.0836940439 \tF1:0.9718261879 \t AUC:0.9493214282\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0983412034 \tAcc: 0.9605654762 \tTPR:0.9819578600 \tFPR:0.0860042074 \tF1:0.9712988459 \t AUC:0.9479768263\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2077093565 \tAcc: 0.9392361111 \tTPR:0.9406245384 \tFPR:0.0678607658 \tF1:0.9526182510 \tAUC:0.9363818863 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.09585443472360974 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.17406725775837511572\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1488844802 \tAcc: 0.9399717828 \tTPR:0.9524102009 \tFPR:0.0712596260 \tF1:0.9361211411 \t AUC:0.9405752875\tTrain cost: 0:00:38\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1429660518 \tAcc: 0.9413493157 \tTPR:0.9520863739 \tFPR:0.0683378065 \tF1:0.9378837598 \t AUC:0.9418742837\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1357092763 \tAcc: 0.9438627577 \tTPR:0.9508351915 \tFPR:0.0617842330 \tF1:0.9390813223 \t AUC:0.9445254793\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1315396708 \tAcc: 0.9458346294 \tTPR:0.9523491802 \tFPR:0.0610442874 \tF1:0.9418650169 \t AUC:0.9456524464\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1247543302 \tAcc: 0.9476398640 \tTPR:0.9544779781 \tFPR:0.0591310862 \tF1:0.9439710583 \t AUC:0.9476734459\tTrain cost: 0:00:41\n",
      "Client6 Test =>                 \tLoss: 0.2072001241 \tAcc: 0.9294328011 \tTPR:0.9154404817 \tFPR:0.0565571847 \tF1:0.9222755539 \tAUC:0.9294416485 \ttest cost: 0:00:06\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.06017948107503687 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.12347162215772902738\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0951898620 \tAcc: 0.9667688612 \tTPR:0.9875510750 \tFPR:0.1193532371 \tF1:0.9791760699 \t AUC:0.9340989189\tTrain cost: 0:00:32\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0854932535 \tAcc: 0.9687006956 \tTPR:0.9885612378 \tFPR:0.1109457310 \tF1:0.9805562126 \t AUC:0.9388077534\tTrain cost: 0:00:32\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0820001159 \tAcc: 0.9705339214 \tTPR:0.9893544082 \tFPR:0.1040996851 \tF1:0.9814363408 \t AUC:0.9426112806\tTrain cost: 0:00:32\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0761871447 \tAcc: 0.9712869334 \tTPR:0.9891936977 \tFPR:0.1011853274 \tF1:0.9819132661 \t AUC:0.9440041852\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0756511601 \tAcc: 0.9737387048 \tTPR:0.9911772965 \tFPR:0.1002540047 \tF1:0.9835183939 \t AUC:0.9454616459\tTrain cost: 0:00:36\n",
      "Client2 Test =>                 \tLoss: 0.1385468697 \tAcc: 0.9573863636 \tTPR:0.9722254292 \tFPR:0.1026687851 \tF1:0.9729141677 \tAUC:0.9348029705 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2006440983 \tAcc: 0.9390999441 \tTPR:0.9370017045 \tFPR:0.0738375951 \tF1:0.9465895579 \tAUC:0.9315869844\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 11:  =============\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.06490893273254575 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.08397776844459726997\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0818635250 \tAcc: 0.9707714788 \tTPR:0.9894898503 \tFPR:0.1084795894 \tF1:0.9815419689 \t AUC:0.9405051305\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0773832713 \tAcc: 0.9731739458 \tTPR:0.9895981026 \tFPR:0.0965762400 \tF1:0.9832569877 \t AUC:0.9465109313\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0734146526 \tAcc: 0.9749623494 \tTPR:0.9912708707 \tFPR:0.0926026199 \tF1:0.9841328662 \t AUC:0.9493341254\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0712275953 \tAcc: 0.9749130450 \tTPR:0.9908738990 \tFPR:0.0938375045 \tF1:0.9842779028 \t AUC:0.9485181973\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0686769435 \tAcc: 0.9755719306 \tTPR:0.9914260510 \tFPR:0.0889504252 \tF1:0.9846603855 \t AUC:0.9512248613\tTrain cost: 0:00:35\n",
      "Client2 Test =>                 \tLoss: 0.1693788068 \tAcc: 0.9452797203 \tTPR:0.9559334966 \tFPR:0.0924720037 \tF1:0.9647746645 \tAUC:0.9316856179 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.06975830861703917 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.08330679602865408151\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1002996067 \tAcc: 0.9641023739 \tTPR:0.9865857464 \tFPR:0.1088770857 \tF1:0.9764586623 \t AUC:0.9388543304\tTrain cost: 0:00:32\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0949829458 \tAcc: 0.9672663205 \tTPR:0.9870940297 \tFPR:0.0993063319 \tF1:0.9785339145 \t AUC:0.9438746436\tTrain cost: 0:00:32\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0890374446 \tAcc: 0.9678894659 \tTPR:0.9871275439 \tFPR:0.0979752060 \tF1:0.9790231773 \t AUC:0.9445570135\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0857761794 \tAcc: 0.9684718101 \tTPR:0.9871604753 \tFPR:0.0934527634 \tF1:0.9792540867 \t AUC:0.9468538560\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0778619730 \tAcc: 0.9716246291 \tTPR:0.9891526657 \tFPR:0.0856809857 \tF1:0.9813198933 \t AUC:0.9517358400\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.2049554406 \tAcc: 0.9390086207 \tTPR:0.9489743492 \tFPR:0.0881549035 \tF1:0.9588798446 \tAUC:0.9304097229 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.07080133746822823 \tALA epochs: 10\n",
      "Client 1: Local Initial ALA epochs: 10 Loss: 0.31115656893440141184\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0884023749 \tAcc: 0.9635036496 \tTPR:0.8260311667 \tFPR:0.0186050745 \tF1:0.8125817992 \t AUC:0.9024243881\tTrain cost: 0:01:15\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0819910880 \tAcc: 0.9661040146 \tTPR:0.8253753910 \tFPR:0.0166745199 \tF1:0.8117970298 \t AUC:0.9011802460\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0757003223 \tAcc: 0.9705748175 \tTPR:0.8587979377 \tFPR:0.0149692313 \tF1:0.8441192846 \t AUC:0.9203337331\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0722229289 \tAcc: 0.9702554745 \tTPR:0.8506604101 \tFPR:0.0153298450 \tF1:0.8324517913 \t AUC:0.9150710148\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0706481183 \tAcc: 0.9707116788 \tTPR:0.8715374812 \tFPR:0.0151957643 \tF1:0.8461518396 \t AUC:0.9260395044\tTrain cost: 0:01:11\n",
      "Client1 Test =>                 \tLoss: 0.1389655286 \tAcc: 0.9609552154 \tTPR:0.7085155491 \tFPR:0.0085438440 \tF1:0.7587273082 \tAUC:0.8459091469 \ttest cost: 0:00:10\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.17941194204801775 \tALA epochs: 11\n",
      "Client 7: Local Initial ALA epochs: 11 Loss: 0.51860508521680126481\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1351501201 \tAcc: 0.9441964286 \tTPR:0.9654541611 \tFPR:0.1061988937 \tF1:0.9584520911 \t AUC:0.9296276337\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1097690584 \tAcc: 0.9557291667 \tTPR:0.9788236415 \tFPR:0.0954333035 \tF1:0.9676443707 \t AUC:0.9416951690\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1026079278 \tAcc: 0.9583333333 \tTPR:0.9785276787 \tFPR:0.0837720150 \tF1:0.9695328013 \t AUC:0.9473778318\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0979306133 \tAcc: 0.9646577381 \tTPR:0.9845258736 \tFPR:0.0742984247 \tF1:0.9731664042 \t AUC:0.9551137245\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0893357685 \tAcc: 0.9631696429 \tTPR:0.9793944489 \tFPR:0.0688418559 \tF1:0.9723982849 \t AUC:0.9552762965\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2181734967 \tAcc: 0.9362922705 \tTPR:0.9296769342 \tFPR:0.0500016188 \tF1:0.9508629261 \tAUC:0.9398376577 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.09468307771617795 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.16235635569319128990\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1458242449 \tAcc: 0.9426957831 \tTPR:0.9441355605 \tFPR:0.0597812075 \tF1:0.9340037498 \t AUC:0.9421771765\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1288800375 \tAcc: 0.9518072289 \tTPR:0.9604389055 \tFPR:0.0541688352 \tF1:0.9426633411 \t AUC:0.9531350352\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1228061161 \tAcc: 0.9536144578 \tTPR:0.9636483932 \tFPR:0.0547271909 \tF1:0.9469589691 \t AUC:0.9544606011\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1220329538 \tAcc: 0.9506024096 \tTPR:0.9558187850 \tFPR:0.0551662123 \tF1:0.9451450869 \t AUC:0.9503262863\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1083850728 \tAcc: 0.9555722892 \tTPR:0.9642498185 \tFPR:0.0495707557 \tF1:0.9491479588 \t AUC:0.9573395314\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.1981881119 \tAcc: 0.9373263889 \tTPR:0.8902996322 \tFPR:0.0230419458 \tF1:0.9258313489 \tAUC:0.9336288432 \ttest cost: 0:00:01\n",
      "Test =>                 \tLoss: 0.1859322769 \tAcc: 0.9437724432 \tTPR:0.8866799923 \tFPR:0.0524428631 \tF1:0.9118152185 \tAUC:0.9162941977\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 12:  =============\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.058892898529886245 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.11260724967966477539\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0702693661 \tAcc: 0.9744424125 \tTPR:0.9892984196 \tFPR:0.0859841965 \tF1:0.9839787103 \t AUC:0.9516571116\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0652761540 \tAcc: 0.9767014487 \tTPR:0.9905784754 \tFPR:0.0864122702 \tF1:0.9851595973 \t AUC:0.9520688707\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0600543220 \tAcc: 0.9769390060 \tTPR:0.9901511392 \tFPR:0.0783139050 \tF1:0.9854434997 \t AUC:0.9559186171\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0628675823 \tAcc: 0.9783509036 \tTPR:0.9918443193 \tFPR:0.0716235070 \tF1:0.9862837844 \t AUC:0.9601104061\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0561898660 \tAcc: 0.9790994334 \tTPR:0.9918929942 \tFPR:0.0752666510 \tF1:0.9869238353 \t AUC:0.9583131716\tTrain cost: 0:00:36\n",
      "Client2 Test =>                 \tLoss: 0.2673830840 \tAcc: 0.9264860140 \tTPR:0.9241914365 \tFPR:0.0627657696 \tF1:0.9520283200 \tAUC:0.9307128335 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.07094898689202572 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.11829856855911202729\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1079727153 \tAcc: 0.9612351190 \tTPR:0.9841748271 \tFPR:0.0869781226 \tF1:0.9716969253 \t AUC:0.9485983522\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0961459414 \tAcc: 0.9620535714 \tTPR:0.9811334257 \tFPR:0.0816559598 \tF1:0.9717851237 \t AUC:0.9497387330\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1001360086 \tAcc: 0.9613095238 \tTPR:0.9803969642 \tFPR:0.0794252705 \tF1:0.9717194643 \t AUC:0.9504858468\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0820016835 \tAcc: 0.9668898810 \tTPR:0.9802943154 \tFPR:0.0693638042 \tF1:0.9757679491 \t AUC:0.9554652556\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0826255174 \tAcc: 0.9683779762 \tTPR:0.9843853860 \tFPR:0.0661039688 \tF1:0.9762919904 \t AUC:0.9591407086\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2118945509 \tAcc: 0.9380283816 \tTPR:0.9326852974 \tFPR:0.0529697398 \tF1:0.9504110390 \tAUC:0.9398577788 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.08814342437188968 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.25037856769215849351\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1069112106 \tAcc: 0.9581539320 \tTPR:0.8487465454 \tFPR:0.0226288681 \tF1:0.8435572826 \t AUC:0.9126291413\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0972621146 \tAcc: 0.9604491298 \tTPR:0.8582023830 \tFPR:0.0199390531 \tF1:0.8597124733 \t AUC:0.9189308185\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0915789652 \tAcc: 0.9637153727 \tTPR:0.8671441004 \tFPR:0.0184543863 \tF1:0.8651645493 \t AUC:0.9243448571\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0877532133 \tAcc: 0.9656603107 \tTPR:0.8835147276 \tFPR:0.0185111068 \tF1:0.8770091236 \t AUC:0.9325018104\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0834709389 \tAcc: 0.9677761072 \tTPR:0.8825706622 \tFPR:0.0165329380 \tF1:0.8795983635 \t AUC:0.9330188621\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.1399121981 \tAcc: 0.9541529605 \tTPR:0.8258119256 \tFPR:0.0237416725 \tF1:0.8145391159 \tAUC:0.9004583449 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.05838661582944303 \tALA epochs: 2\n",
      "Client 1: Local Initial ALA epochs: 2 Loss: 0.08198139576587196165\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0794674598 \tAcc: 0.9691149635 \tTPR:0.8481021898 \tFPR:0.0151864692 \tF1:0.8353331383 \t AUC:0.9141736827\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0735126125 \tAcc: 0.9702098540 \tTPR:0.8535364595 \tFPR:0.0145825561 \tF1:0.8394985057 \t AUC:0.9175006821\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0689267522 \tAcc: 0.9721259124 \tTPR:0.8618426707 \tFPR:0.0132411473 \tF1:0.8438742918 \t AUC:0.9226486561\tTrain cost: 0:01:14\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0669549244 \tAcc: 0.9733576642 \tTPR:0.8677731433 \tFPR:0.0130939254 \tF1:0.8453391474 \t AUC:0.9250426167\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0634430174 \tAcc: 0.9744069343 \tTPR:0.8795504577 \tFPR:0.0129822586 \tF1:0.8602817515 \t AUC:0.9322102552\tTrain cost: 0:01:13\n",
      "Client1 Test =>                 \tLoss: 0.1176146768 \tAcc: 0.9620535714 \tTPR:0.8105712126 \tFPR:0.0186603610 \tF1:0.7844641564 \tAUC:0.8922739476 \ttest cost: 0:00:10\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.0921588262829638 \tALA epochs: 3\n",
      "Client 8: Local Initial ALA epochs: 3 Loss: 0.32795962424420599390\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0917011361 \tAcc: 0.9672663205 \tTPR:0.9842329413 \tFPR:0.0942992797 \tF1:0.9785566505 \t AUC:0.9449668308\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0865632519 \tAcc: 0.9688167656 \tTPR:0.9862694109 \tFPR:0.0875357467 \tF1:0.9791942315 \t AUC:0.9493668321\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0855437898 \tAcc: 0.9687500000 \tTPR:0.9878600588 \tFPR:0.0962563895 \tF1:0.9795869131 \t AUC:0.9458018346\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0788784351 \tAcc: 0.9705786350 \tTPR:0.9877400051 \tFPR:0.0907346404 \tF1:0.9806048298 \t AUC:0.9485026824\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0709454442 \tAcc: 0.9738909496 \tTPR:0.9899899192 \tFPR:0.0761530548 \tF1:0.9828159725 \t AUC:0.9569184322\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.1928115119 \tAcc: 0.9452586207 \tTPR:0.9504323695 \tFPR:0.0712360054 \tF1:0.9629759160 \tAUC:0.9395981820 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.1859232043 \tAcc: 0.9451959097 \tTPR:0.8887384483 \tFPR:0.0458747097 \tF1:0.8928837094 \tAUC:0.9205802174\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 13:  =============\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.08655513339290671 \tALA epochs: 2\n",
      "Client 5: Local Initial ALA epochs: 2 Loss: 0.13212756837186004355\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0910648732 \tAcc: 0.9642478814 \tTPR:0.8769819556 \tFPR:0.0194230176 \tF1:0.8731228055 \t AUC:0.9282537509\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0849734988 \tAcc: 0.9653954802 \tTPR:0.8819924426 \tFPR:0.0189054881 \tF1:0.8744974255 \t AUC:0.9308691483\tTrain cost: 0:00:35\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0809338390 \tAcc: 0.9667167851 \tTPR:0.8755234957 \tFPR:0.0169025814 \tF1:0.8733176866 \t AUC:0.9291341448\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0757673637 \tAcc: 0.9692711181 \tTPR:0.8866086205 \tFPR:0.0160246591 \tF1:0.8904922710 \t AUC:0.9352919807\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0738030676 \tAcc: 0.9705126891 \tTPR:0.8946236986 \tFPR:0.0155068279 \tF1:0.8863891017 \t AUC:0.9392590709\tTrain cost: 0:00:38\n",
      "Client5 Test =>                 \tLoss: 0.1358355878 \tAcc: 0.9562088816 \tTPR:0.8287863087 \tFPR:0.0213095126 \tF1:0.8168250641 \tAUC:0.9031714653 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.05450389199346977 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.07754369549494345704\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0740742372 \tAcc: 0.9698905109 \tTPR:0.8513161858 \tFPR:0.0147554372 \tF1:0.8368413381 \t AUC:0.9160445275\tTrain cost: 0:01:06\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0687753684 \tAcc: 0.9720802920 \tTPR:0.8652838605 \tFPR:0.0140500955 \tF1:0.8538669254 \t AUC:0.9241088660\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0656021112 \tAcc: 0.9733120438 \tTPR:0.8706754721 \tFPR:0.0133751115 \tF1:0.8557319582 \t AUC:0.9270045838\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0602918567 \tAcc: 0.9762773723 \tTPR:0.8771764570 \tFPR:0.0123154920 \tF1:0.8654444708 \t AUC:0.9311491638\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0580373832 \tAcc: 0.9767335766 \tTPR:0.8924197660 \tFPR:0.0118247719 \tF1:0.8809586779 \t AUC:0.9382599926\tTrain cost: 0:01:14\n",
      "Client1 Test =>                 \tLoss: 0.1332193893 \tAcc: 0.9612032313 \tTPR:0.7802505129 \tFPR:0.0159064465 \tF1:0.7782881518 \tAUC:0.8766782960 \ttest cost: 0:00:10\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.28302246555157895 \tALA epochs: 11\n",
      "Client 9: Local Initial ALA epochs: 11 Loss: 0.63413436279809176632\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0813001483 \tAcc: 0.9708333333 \tTPR:0.9853141498 \tFPR:0.2157738095 \tF1:0.9837957648 \t AUC:0.8842456755\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0530795839 \tAcc: 0.9817708333 \tTPR:0.9936660547 \tFPR:0.1700000000 \tF1:0.9898463017 \t AUC:0.9115121328\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0513127437 \tAcc: 0.9854166667 \tTPR:0.9994444444 \tFPR:0.2019688645 \tF1:0.9920395788 \t AUC:0.8986950549\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0504598765 \tAcc: 0.9838541667 \tTPR:0.9960715610 \tFPR:0.1788690476 \tF1:0.9912203088 \t AUC:0.9084609553\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0454258111 \tAcc: 0.9848958333 \tTPR:0.9961072709 \tFPR:0.1706896552 \tF1:0.9918605830 \t AUC:0.9126416918\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.1275319524 \tAcc: 0.9591346154 \tTPR:0.9743599350 \tFPR:0.2242424242 \tF1:0.9774791250 \tAUC:0.8748585222 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.08606618536491985 \tALA epochs: 8\n",
      "Client 3: Local Initial ALA epochs: 8 Loss: 0.34633487428072839975\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1456548248 \tAcc: 0.9412650602 \tTPR:0.9521969959 \tFPR:0.0685098615 \tF1:0.9340693977 \t AUC:0.9418435672\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1223236601 \tAcc: 0.9502259036 \tTPR:0.9566856445 \tFPR:0.0560812237 \tF1:0.9426217488 \t AUC:0.9503022104\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1226674132 \tAcc: 0.9493975904 \tTPR:0.9592750791 \tFPR:0.0559823924 \tF1:0.9394418814 \t AUC:0.9516463433\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1118353404 \tAcc: 0.9570783133 \tTPR:0.9598769960 \tFPR:0.0454294043 \tF1:0.9521322078 \t AUC:0.9572237959\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1034936068 \tAcc: 0.9585843373 \tTPR:0.9622258598 \tFPR:0.0457936840 \tF1:0.9515218947 \t AUC:0.9582160879\tTrain cost: 0:00:09\n",
      "Client3 Test =>                 \tLoss: 0.1738175444 \tAcc: 0.9453125000 \tTPR:0.9154450993 \tFPR:0.0333880896 \tF1:0.9358232710 \tAUC:0.9410285048 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.04628624285753781 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.10185066796839237213\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1093548989 \tAcc: 0.9556547619 \tTPR:0.9781780315 \tFPR:0.0939963641 \tF1:0.9674460709 \t AUC:0.9420908337\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0939902873 \tAcc: 0.9639136905 \tTPR:0.9797618564 \tFPR:0.0740206106 \tF1:0.9730451496 \t AUC:0.9528706229\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0889870094 \tAcc: 0.9631696429 \tTPR:0.9800553382 \tFPR:0.0708523619 \tF1:0.9727074084 \t AUC:0.9546014881\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0803286039 \tAcc: 0.9656994048 \tTPR:0.9857535352 \tFPR:0.0730973061 \tF1:0.9746983634 \t AUC:0.9563281145\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0764924918 \tAcc: 0.9724702381 \tTPR:0.9858807229 \tFPR:0.0569275846 \tF1:0.9795935791 \t AUC:0.9644765692\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.1876910791 \tAcc: 0.9458408816 \tTPR:0.9505567705 \tFPR:0.0626926314 \tF1:0.9574189390 \tAUC:0.9439320696 \ttest cost: 0:00:01\n",
      "Test =>                 \tLoss: 0.1516191106 \tAcc: 0.9535400220 \tTPR:0.8898797253 \tFPR:0.0715078209 \tF1:0.8931669102 \tAUC:0.9079337716\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 14:  =============\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.04953329585562167 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.12017314954261694437\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0783223900 \tAcc: 0.9683968927 \tTPR:0.8887419392 \tFPR:0.0172397057 \tF1:0.8830767268 \t AUC:0.9352756549\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0701709222 \tAcc: 0.9720162429 \tTPR:0.9027632051 \tFPR:0.0145991536 \tF1:0.8985271218 \t AUC:0.9438057848\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0693327517 \tAcc: 0.9718339940 \tTPR:0.8918000628 \tFPR:0.0137203139 \tF1:0.8953221633 \t AUC:0.9388866167\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0659559517 \tAcc: 0.9751942090 \tTPR:0.9150376852 \tFPR:0.0134054296 \tF1:0.9123787220 \t AUC:0.9508161278\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0611956063 \tAcc: 0.9759830053 \tTPR:0.9114136726 \tFPR:0.0128390311 \tF1:0.9077028189 \t AUC:0.9490356551\tTrain cost: 0:00:38\n",
      "Client5 Test =>                 \tLoss: 0.1714642044 \tAcc: 0.9557976974 \tTPR:0.8241593567 \tFPR:0.0202097575 \tF1:0.8325388799 \tAUC:0.9019747996 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.10068861640345357 \tALA epochs: 11\n",
      "Client 9: Local Initial ALA epochs: 11 Loss: 0.55133335889617274272\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0826737724 \tAcc: 0.9750000000 \tTPR:0.9868144444 \tFPR:0.1518181818 \tF1:0.9863169367 \t AUC:0.9177510606\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0511497481 \tAcc: 0.9822916667 \tTPR:0.9943689306 \tFPR:0.1692528736 \tF1:0.9903000306 \t AUC:0.9124609411\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0404368448 \tAcc: 0.9880208333 \tTPR:0.9966628264 \tFPR:0.1111111111 \tF1:0.9935070375 \t AUC:0.9426880373\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0381124200 \tAcc: 0.9906250000 \tTPR:0.9994444444 \tFPR:0.1378787879 \tF1:0.9949476294 \t AUC:0.9307575758\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0417949512 \tAcc: 0.9864583333 \tTPR:0.9944294476 \tFPR:0.1084795322 \tF1:0.9926396074 \t AUC:0.9433766099\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.1339065446 \tAcc: 0.9601762821 \tTPR:0.9763244943 \tFPR:0.3243055556 \tF1:0.9781091644 \tAUC:0.8250229900 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.09982051878512635 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.18977554677985608578\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1006240463 \tAcc: 0.9613095238 \tTPR:0.9808407068 \tFPR:0.0804940508 \tF1:0.9706383976 \t AUC:0.9501733280\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0912625661 \tAcc: 0.9650297619 \tTPR:0.9835591765 \tFPR:0.0749727785 \tF1:0.9739710198 \t AUC:0.9542931990\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0881824320 \tAcc: 0.9668898810 \tTPR:0.9834484952 \tFPR:0.0666012724 \tF1:0.9748811540 \t AUC:0.9584236114\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0781847117 \tAcc: 0.9683779762 \tTPR:0.9843766642 \tFPR:0.0637797388 \tF1:0.9762085877 \t AUC:0.9602984627\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0699787847 \tAcc: 0.9717261905 \tTPR:0.9859066694 \tFPR:0.0556528942 \tF1:0.9786117325 \t AUC:0.9651268876\tTrain cost: 0:00:08\n",
      "Client7 Test =>                 \tLoss: 0.2141861425 \tAcc: 0.9390851449 \tTPR:0.9328145719 \tFPR:0.0511136240 \tF1:0.9519271779 \tAUC:0.9408504739 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.09349889157021644 \tALA epochs: 2\n",
      "Client 4: Local Initial ALA epochs: 2 Loss: 0.14489056626233556835\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1333116982 \tAcc: 0.9499656693 \tTPR:0.9733250755 \tFPR:0.0917276721 \tF1:0.9607461914 \t AUC:0.9407987017\tTrain cost: 0:02:03\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1258486080 \tAcc: 0.9522152356 \tTPR:0.9735947308 \tFPR:0.0872195874 \tF1:0.9625392505 \t AUC:0.9431875717\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1183173448 \tAcc: 0.9555489303 \tTPR:0.9740159729 \tFPR:0.0781847625 \tF1:0.9649517109 \t AUC:0.9479156052\tTrain cost: 0:02:03\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1155852081 \tAcc: 0.9557639491 \tTPR:0.9752833347 \tFPR:0.0799603092 \tF1:0.9649598455 \t AUC:0.9476615128\tTrain cost: 0:02:02\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1114014436 \tAcc: 0.9570396068 \tTPR:0.9758658041 \tFPR:0.0759518533 \tF1:0.9662878351 \t AUC:0.9499569754\tTrain cost: 0:02:00\n",
      "Client4 Test =>                 \tLoss: 0.1644212812 \tAcc: 0.9406565657 \tTPR:0.9473307459 \tFPR:0.0713623436 \tF1:0.9522451105 \tAUC:0.9379842012 \ttest cost: 0:00:17\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.08833873049829778 \tALA epochs: 3\n",
      "Client 6: Local Initial ALA epochs: 3 Loss: 0.15694975469148519931\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1381976478 \tAcc: 0.9443376733 \tTPR:0.9521060724 \tFPR:0.0636440618 \tF1:0.9399299440 \t AUC:0.9442310053\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1299049824 \tAcc: 0.9483564033 \tTPR:0.9550431431 \tFPR:0.0584944901 \tF1:0.9443506756 \t AUC:0.9482743265\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1247382959 \tAcc: 0.9486063589 \tTPR:0.9545783632 \tFPR:0.0582305146 \tF1:0.9450548256 \t AUC:0.9481739243\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1198248491 \tAcc: 0.9504254799 \tTPR:0.9554929515 \tFPR:0.0542802166 \tF1:0.9454348289 \t AUC:0.9506063675\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1149195152 \tAcc: 0.9534221694 \tTPR:0.9599899872 \tFPR:0.0518961589 \tF1:0.9502901989 \t AUC:0.9540469142\tTrain cost: 0:00:42\n",
      "Client6 Test =>                 \tLoss: 0.2218514318 \tAcc: 0.9262516633 \tTPR:0.8842578055 \tFPR:0.0364628856 \tF1:0.9168124223 \tAUC:0.9238974600 \ttest cost: 0:00:06\n",
      "Test =>                 \tLoss: 0.1811659209 \tAcc: 0.9443934707 \tTPR:0.9129773949 \tFPR:0.1006908333 \tF1:0.9263265510 \tAUC:0.9059459849\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 15:  =============\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.02953529000160114 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.10576013272458856251\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0491542760 \tAcc: 0.9838541667 \tTPR:0.9954345386 \tFPR:0.1406708595 \tF1:0.9910025417 \t AUC:0.9270803468\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0367919652 \tAcc: 0.9875000000 \tTPR:0.9956618465 \tFPR:0.1125000000 \tF1:0.9932998891 \t AUC:0.9415809232\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0302663938 \tAcc: 0.9916666667 \tTPR:0.9977507716 \tFPR:0.0894230769 \tF1:0.9954410790 \t AUC:0.9542913105\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0326843025 \tAcc: 0.9906250000 \tTPR:0.9977573847 \tFPR:0.0900641026 \tF1:0.9948516856 \t AUC:0.9536741322\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0279289594 \tAcc: 0.9906250000 \tTPR:0.9976666667 \tFPR:0.0965986395 \tF1:0.9947656821 \t AUC:0.9504506803\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.1364827362 \tAcc: 0.9709935897 \tTPR:0.9870736130 \tFPR:0.2951388889 \tF1:0.9844211748 \tAUC:0.8460798043 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.08610915328926004 \tALA epochs: 4\n",
      "Client 7: Local Initial ALA epochs: 4 Loss: 0.25629662430219468661\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0939779054 \tAcc: 0.9609375000 \tTPR:0.9816980501 \tFPR:0.0864049369 \tF1:0.9715782216 \t AUC:0.9475363039\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0797419974 \tAcc: 0.9694940476 \tTPR:0.9851804501 \tFPR:0.0638052686 \tF1:0.9769791541 \t AUC:0.9606875908\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0733301011 \tAcc: 0.9720982143 \tTPR:0.9867124801 \tFPR:0.0550549979 \tF1:0.9790228919 \t AUC:0.9658287411\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0732476713 \tAcc: 0.9650297619 \tTPR:0.9803257832 \tFPR:0.0627307528 \tF1:0.9739487063 \t AUC:0.9587975152\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0600101688 \tAcc: 0.9784226190 \tTPR:0.9895831835 \tFPR:0.0452391359 \tF1:0.9839102878 \t AUC:0.9721720238\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.1889606072 \tAcc: 0.9531250000 \tTPR:0.9572882105 \tFPR:0.0606632950 \tF1:0.9643505634 \tAUC:0.9483124577 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.08133214752325522 \tALA epochs: 4\n",
      "Client 5: Local Initial ALA epochs: 4 Loss: 0.24734808115754275404\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0703279824 \tAcc: 0.9722753782 \tTPR:0.9090260963 \tFPR:0.0156313861 \tF1:0.9042269985 \t AUC:0.9464389065\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0624253530 \tAcc: 0.9765183616 \tTPR:0.9230470565 \tFPR:0.0131058705 \tF1:0.9166362129 \t AUC:0.9545308619\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0584453441 \tAcc: 0.9776659605 \tTPR:0.9142901982 \tFPR:0.0112696823 \tF1:0.9129249791 \t AUC:0.9510204877\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0560019026 \tAcc: 0.9778425141 \tTPR:0.9272957582 \tFPR:0.0125952571 \tF1:0.9207310155 \t AUC:0.9572472700\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0510466369 \tAcc: 0.9792520959 \tTPR:0.9316638948 \tFPR:0.0112187870 \tF1:0.9258891110 \t AUC:0.9601257606\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.1768492850 \tAcc: 0.9568256579 \tTPR:0.8296683214 \tFPR:0.0215818892 \tF1:0.8205087070 \tAUC:0.9034792040 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.10623302187583335 \tALA epochs: 11\n",
      "Client 3: Local Initial ALA epochs: 11 Loss: 0.19602678571192716506\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1345145351 \tAcc: 0.9476656627 \tTPR:0.9464979394 \tFPR:0.0520007408 \tF1:0.9392893505 \t AUC:0.9472485993\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1253550317 \tAcc: 0.9517319277 \tTPR:0.9616550510 \tFPR:0.0566057011 \tF1:0.9456210077 \t AUC:0.9525246749\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1130663909 \tAcc: 0.9544427711 \tTPR:0.9508924444 \tFPR:0.0434729021 \tF1:0.9455742106 \t AUC:0.9537097711\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1115269537 \tAcc: 0.9597138554 \tTPR:0.9634720789 \tFPR:0.0437038558 \tF1:0.9539232787 \t AUC:0.9598841116\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1010131019 \tAcc: 0.9585843373 \tTPR:0.9661774328 \tFPR:0.0471262908 \tF1:0.9516369856 \t AUC:0.9595255710\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.1938057240 \tAcc: 0.9444444444 \tTPR:0.9006842400 \tFPR:0.0197472337 \tF1:0.9334237408 \tAUC:0.9404685031 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.07212060049911549 \tALA epochs: 3\n",
      "Client 8: Local Initial ALA epochs: 3 Loss: 0.18058636512106923666\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0915250459 \tAcc: 0.9674258160 \tTPR:0.9863285025 \tFPR:0.0966703096 \tF1:0.9786265043 \t AUC:0.9448290965\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0846933973 \tAcc: 0.9671476261 \tTPR:0.9859502053 \tFPR:0.0939842551 \tF1:0.9783568437 \t AUC:0.9459829751\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0777452201 \tAcc: 0.9710682493 \tTPR:0.9882325488 \tFPR:0.0884233142 \tF1:0.9810175283 \t AUC:0.9499046173\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0756521147 \tAcc: 0.9720623145 \tTPR:0.9893481773 \tFPR:0.0872079805 \tF1:0.9815702371 \t AUC:0.9511007505\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0750221279 \tAcc: 0.9738501484 \tTPR:0.9893194379 \tFPR:0.0769218912 \tF1:0.9829129729 \t AUC:0.9561987734\tTrain cost: 0:00:34\n",
      "Client8 Test =>                 \tLoss: 0.1675807916 \tAcc: 0.9482954545 \tTPR:0.9605176645 \tFPR:0.0892439553 \tF1:0.9652528264 \tAUC:0.9356368546 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.1727358288 \tAcc: 0.9547368293 \tTPR:0.9270464099 \tFPR:0.0972750524 \tF1:0.9335914025 \tAUC:0.9147953647\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 16:  =============\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.09293823451243842 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.19709435212151968364\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0698371861 \tAcc: 0.9722627737 \tTPR:0.8641524736 \tFPR:0.0147054201 \tF1:0.8474898595 \t AUC:0.9225753355\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0594663530 \tAcc: 0.9766879562 \tTPR:0.8814720195 \tFPR:0.0113424331 \tF1:0.8723410428 \t AUC:0.9337379874\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0560541561 \tAcc: 0.9781021898 \tTPR:0.8934706291 \tFPR:0.0105361071 \tF1:0.8750231418 \t AUC:0.9400298332\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0540987011 \tAcc: 0.9782390511 \tTPR:0.8946836983 \tFPR:0.0112529216 \tF1:0.8832206550 \t AUC:0.9403752857\tTrain cost: 0:01:14\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0520022647 \tAcc: 0.9797445255 \tTPR:0.9053903477 \tFPR:0.0106961985 \tF1:0.8925560847 \t AUC:0.9454059951\tTrain cost: 0:01:14\n",
      "Client1 Test =>                 \tLoss: 0.1228384259 \tAcc: 0.9618409864 \tTPR:0.8071819998 \tFPR:0.0193627093 \tF1:0.7997906462 \tAUC:0.8915582062 \ttest cost: 0:00:10\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.29412274145742134 \tALA epochs: 11\n",
      "Client 2: Local Initial ALA epochs: 11 Loss: 0.44402679654233384587\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0845523467 \tAcc: 0.9694537077 \tTPR:0.9867683321 \tFPR:0.1070782046 \tF1:0.9807666895 \t AUC:0.9398450638\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0711600420 \tAcc: 0.9724164515 \tTPR:0.9886666751 \tFPR:0.0936728014 \tF1:0.9826765772 \t AUC:0.9474969368\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0637728984 \tAcc: 0.9761859940 \tTPR:0.9899560201 \tFPR:0.0792125211 \tF1:0.9849899683 \t AUC:0.9553717495\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0587055405 \tAcc: 0.9775978916 \tTPR:0.9913569326 \tFPR:0.0818079059 \tF1:0.9860701466 \t AUC:0.9548430192\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0563516624 \tAcc: 0.9787274096 \tTPR:0.9915202776 \tFPR:0.0690080920 \tF1:0.9864377703 \t AUC:0.9612560928\tTrain cost: 0:00:35\n",
      "Client2 Test =>                 \tLoss: 0.2007235697 \tAcc: 0.9363199301 \tTPR:0.9398348472 \tFPR:0.0803782077 \tF1:0.9585751198 \tAUC:0.9297283198 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.046946137507687884 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.06879145447164773663\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1189435137 \tAcc: 0.9655330882 \tTPR:0.9851481125 \tFPR:0.0974021019 \tF1:0.9779426319 \t AUC:0.9438730053\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0952296606 \tAcc: 0.9709821429 \tTPR:0.9945323129 \tFPR:0.1190965780 \tF1:0.9816483491 \t AUC:0.9377178675\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0872526412 \tAcc: 0.9720982143 \tTPR:0.9883549442 \tFPR:0.0878826531 \tF1:0.9819592057 \t AUC:0.9502361456\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0764845111 \tAcc: 0.9754464286 \tTPR:0.9944341968 \tFPR:0.1049823633 \tF1:0.9846967331 \t AUC:0.9446228463\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0748210060 \tAcc: 0.9743303571 \tTPR:0.9943263258 \tFPR:0.1132227891 \tF1:0.9840078218 \t AUC:0.9405517684\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.2956528390 \tAcc: 0.9238782051 \tTPR:0.9341967680 \tFPR:0.1126352814 \tF1:0.9502646795 \tAUC:0.9107807433 \ttest cost: 0:00:00\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.0758576001626968 \tALA epochs: 2\n",
      "Client 3: Local Initial ALA epochs: 2 Loss: 0.15831031205016188323\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1256251942 \tAcc: 0.9491716867 \tTPR:0.9532554052 \tFPR:0.0530449253 \tF1:0.9405166627 \t AUC:0.9501052400\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1137552491 \tAcc: 0.9574548193 \tTPR:0.9628188823 \tFPR:0.0451020080 \tF1:0.9505879916 \t AUC:0.9588584372\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1100984691 \tAcc: 0.9582078313 \tTPR:0.9576714748 \tFPR:0.0411427663 \tF1:0.9482191329 \t AUC:0.9582643542\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0996064290 \tAcc: 0.9634789157 \tTPR:0.9647629659 \tFPR:0.0375363837 \tF1:0.9580595126 \t AUC:0.9636132911\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0952326083 \tAcc: 0.9634036145 \tTPR:0.9706313005 \tFPR:0.0429457977 \tF1:0.9577960648 \t AUC:0.9638427514\tTrain cost: 0:00:09\n",
      "Client3 Test =>                 \tLoss: 0.2235383332 \tAcc: 0.9322916667 \tTPR:0.8828768081 \tFPR:0.0283333110 \tF1:0.9194431910 \tAUC:0.9272717486 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.09976507085346858 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.21134834047406911295\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1239695177 \tAcc: 0.9532180544 \tTPR:0.9743831752 \tFPR:0.0834755884 \tF1:0.9631259171 \t AUC:0.9454537934\tTrain cost: 0:02:02\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1171286036 \tAcc: 0.9551423822 \tTPR:0.9744017439 \tFPR:0.0797451053 \tF1:0.9647368134 \t AUC:0.9473283193\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1105050909 \tAcc: 0.9583405609 \tTPR:0.9770695632 \tFPR:0.0758961006 \tF1:0.9670092080 \t AUC:0.9505867313\tTrain cost: 0:02:04\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1089184723 \tAcc: 0.9584489737 \tTPR:0.9767914945 \tFPR:0.0738117898 \tF1:0.9672433592 \t AUC:0.9514898524\tTrain cost: 0:02:02\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1047774145 \tAcc: 0.9604275080 \tTPR:0.9778213220 \tFPR:0.0709240105 \tF1:0.9686801958 \t AUC:0.9534486557\tTrain cost: 0:02:03\n",
      "Client4 Test =>                 \tLoss: 0.1626770549 \tAcc: 0.9437500000 \tTPR:0.9481594027 \tFPR:0.0637032519 \tF1:0.9546827809 \tAUC:0.9421756052 \ttest cost: 0:00:17\n",
      "Test =>                 \tLoss: 0.2010860446 \tAcc: 0.9396161577 \tTPR:0.9024499652 \tFPR:0.0608825523 \tF1:0.9165512835 \tAUC:0.9203029246\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 17:  =============\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.09721283540222667 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.11080616063305309682\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0661906408 \tAcc: 0.9729872881 \tTPR:0.9154058747 \tFPR:0.0157626322 \tF1:0.9017298742 \t AUC:0.9497017996\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0573219164 \tAcc: 0.9780190678 \tTPR:0.9098454276 \tFPR:0.0101734947 \tF1:0.9116075056 \t AUC:0.9497082688\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0572444762 \tAcc: 0.9774011299 \tTPR:0.9257432774 \tFPR:0.0130310233 \tF1:0.9182614723 \t AUC:0.9563561271\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0498672858 \tAcc: 0.9797846045 \tTPR:0.9300006726 \tFPR:0.0110918876 \tF1:0.9285378943 \t AUC:0.9591552501\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0459492521 \tAcc: 0.9833156780 \tTPR:0.9413875124 \tFPR:0.0090246776 \tF1:0.9410204835 \t AUC:0.9659309367\tTrain cost: 0:00:38\n",
      "Client5 Test =>                 \tLoss: 0.1753848101 \tAcc: 0.9574424342 \tTPR:0.8505456349 \tFPR:0.0233943470 \tF1:0.8373010276 \tAUC:0.9120710698 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.08207205595480202 \tALA epochs: 4\n",
      "Client 6: Local Initial ALA epochs: 4 Loss: 0.23420056462130667274\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1396690286 \tAcc: 0.9436933434 \tTPR:0.9509896220 \tFPR:0.0633105499 \tF1:0.9391031199 \t AUC:0.9438395361\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1310270651 \tAcc: 0.9458596250 \tTPR:0.9530576005 \tFPR:0.0600618822 \tF1:0.9423782475 \t AUC:0.9464978591\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1225766907 \tAcc: 0.9504588073 \tTPR:0.9592883530 \tFPR:0.0590315351 \tF1:0.9471334414 \t AUC:0.9501284090\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1156428872 \tAcc: 0.9523112558 \tTPR:0.9607249602 \tFPR:0.0542532085 \tF1:0.9487667874 \t AUC:0.9532358759\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1088938411 \tAcc: 0.9561855670 \tTPR:0.9606867473 \tFPR:0.0485597041 \tF1:0.9521028218 \t AUC:0.9560635216\tTrain cost: 0:00:41\n",
      "Client6 Test =>                 \tLoss: 0.1963878994 \tAcc: 0.9353376580 \tTPR:0.9348566801 \tFPR:0.0650776098 \tF1:0.9296546195 \tAUC:0.9348895352 \ttest cost: 0:00:06\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.09512157426490295 \tALA epochs: 2\n",
      "Client 4: Local Initial ALA epochs: 2 Loss: 0.12881437467573128575\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1203487282 \tAcc: 0.9539498410 \tTPR:0.9748822924 \tFPR:0.0842718749 \tF1:0.9638446469 \t AUC:0.9453052087\tTrain cost: 0:02:01\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1122561761 \tAcc: 0.9577732003 \tTPR:0.9770897795 \tFPR:0.0770851331 \tF1:0.9670023870 \t AUC:0.9500023232\tTrain cost: 0:01:59\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1085987790 \tAcc: 0.9591012576 \tTPR:0.9768604173 \tFPR:0.0730865160 \tF1:0.9677943247 \t AUC:0.9518869507\tTrain cost: 0:02:01\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1032028526 \tAcc: 0.9607274501 \tTPR:0.9784341767 \tFPR:0.0716261977 \tF1:0.9692181656 \t AUC:0.9534039895\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1001686151 \tAcc: 0.9620518936 \tTPR:0.9779417221 \tFPR:0.0676656844 \tF1:0.9699392022 \t AUC:0.9551380189\tTrain cost: 0:02:01\n",
      "Client4 Test =>                 \tLoss: 0.1696559222 \tAcc: 0.9451388889 \tTPR:0.9677289814 \tFPR:0.0963445713 \tF1:0.9569283024 \tAUC:0.9356595421 \ttest cost: 0:00:17\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.04250212851303327 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.06740121831270781683\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0422425183 \tAcc: 0.9869791667 \tTPR:0.9960460752 \tFPR:0.0919913420 \tF1:0.9927672676 \t AUC:0.9521317337\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0323840600 \tAcc: 0.9906250000 \tTPR:0.9982524479 \tFPR:0.0981132075 \tF1:0.9948499514 \t AUC:0.9499542158\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0295381380 \tAcc: 0.9911458333 \tTPR:0.9966654307 \tFPR:0.0883040936 \tF1:0.9952504701 \t AUC:0.9540929168\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0247744904 \tAcc: 0.9927083333 \tTPR:0.9972365514 \tFPR:0.0700617284 \tF1:0.9960585747 \t AUC:0.9637232384\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0193289443 \tAcc: 0.9942708333 \tTPR:0.9983115719 \tFPR:0.0570175439 \tF1:0.9968556081 \t AUC:0.9706025817\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.1589610720 \tAcc: 0.9663461538 \tTPR:0.9791758158 \tFPR:0.2395833333 \tF1:0.9816706168 \tAUC:0.8695796085 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.2867673880008565 \tALA epochs: 11\n",
      "Client 1: Local Initial ALA epochs: 11 Loss: 0.63467553868531223493\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0653833997 \tAcc: 0.9749543796 \tTPR:0.8920629128 \tFPR:0.0143259974 \tF1:0.8667476487 \t AUC:0.9370776463\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0556640321 \tAcc: 0.9781478102 \tTPR:0.8921272158 \tFPR:0.0103614815 \tF1:0.8795709684 \t AUC:0.9394273124\tTrain cost: 0:01:14\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0518510081 \tAcc: 0.9804288321 \tTPR:0.9055509211 \tFPR:0.0095397120 \tF1:0.8909978398 \t AUC:0.9469483387\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0494558259 \tAcc: 0.9798813869 \tTPR:0.9011719384 \tFPR:0.0106809487 \tF1:0.8831031013 \t AUC:0.9436827017\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0438763257 \tAcc: 0.9829835766 \tTPR:0.9181398447 \tFPR:0.0083559068 \tF1:0.9047333757 \t AUC:0.9539756240\tTrain cost: 0:01:12\n",
      "Client1 Test =>                 \tLoss: 0.1146692323 \tAcc: 0.9650297619 \tTPR:0.8253806284 \tFPR:0.0185142859 \tF1:0.8033194602 \tAUC:0.9016142195 \ttest cost: 0:00:10\n",
      "Test =>                 \tLoss: 0.1630117872 \tAcc: 0.9538589794 \tTPR:0.9115375481 \tFPR:0.0885828295 \tF1:0.9017748053 \tAUC:0.9107627950\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 18:  =============\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.07914781685910506 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.09273135603871196508\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0878630572 \tAcc: 0.9649553571 \tTPR:0.9817420638 \tFPR:0.0735335101 \tF1:0.9740537382 \t AUC:0.9541042768\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0755038046 \tAcc: 0.9720982143 \tTPR:0.9876021988 \tFPR:0.0629343045 \tF1:0.9794682382 \t AUC:0.9623339472\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0732581296 \tAcc: 0.9724702381 \tTPR:0.9845875177 \tFPR:0.0548962116 \tF1:0.9794833504 \t AUC:0.9648456530\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0653903842 \tAcc: 0.9735119048 \tTPR:0.9845472669 \tFPR:0.0500960845 \tF1:0.9797536187 \t AUC:0.9672255912\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0674070613 \tAcc: 0.9732142857 \tTPR:0.9870930725 \tFPR:0.0518714292 \tF1:0.9793596574 \t AUC:0.9676108217\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.1569437440 \tAcc: 0.9531250000 \tTPR:0.9647021282 \tFPR:0.0690313759 \tF1:0.9640762414 \tAUC:0.9478353761 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.06851777245845786 \tALA epochs: 2\n",
      "Client 8: Local Initial ALA epochs: 2 Loss: 0.09121090424101133132\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0875893665 \tAcc: 0.9690949555 \tTPR:0.9874085773 \tFPR:0.0909009718 \tF1:0.9797234029 \t AUC:0.9482538028\tTrain cost: 0:00:32\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0781462356 \tAcc: 0.9721290801 \tTPR:0.9884498232 \tFPR:0.0822195362 \tF1:0.9819303527 \t AUC:0.9531151435\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0718134941 \tAcc: 0.9744732938 \tTPR:0.9897368421 \tFPR:0.0750537297 \tF1:0.9832050635 \t AUC:0.9573415562\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0701933960 \tAcc: 0.9741951039 \tTPR:0.9888887802 \tFPR:0.0749959981 \tF1:0.9831103355 \t AUC:0.9569463911\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0650382132 \tAcc: 0.9767247774 \tTPR:0.9899238459 \tFPR:0.0663653413 \tF1:0.9844667053 \t AUC:0.9617792523\tTrain cost: 0:00:36\n",
      "Client8 Test =>                 \tLoss: 0.1759745050 \tAcc: 0.9467868339 \tTPR:0.9549352170 \tFPR:0.0776192007 \tF1:0.9641048532 \tAUC:0.9386580081 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.0728891053499903 \tALA epochs: 2\n",
      "Client 3: Local Initial ALA epochs: 2 Loss: 0.14720563183072954416\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1183383843 \tAcc: 0.9503012048 \tTPR:0.9540834218 \tFPR:0.0527237533 \tF1:0.9417051591 \t AUC:0.9506798342\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1035589778 \tAcc: 0.9582078313 \tTPR:0.9616901368 \tFPR:0.0417124937 \tF1:0.9507023030 \t AUC:0.9599888216\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0996825323 \tAcc: 0.9585843373 \tTPR:0.9630363180 \tFPR:0.0452122892 \tF1:0.9527591951 \t AUC:0.9589120144\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0886778640 \tAcc: 0.9672439759 \tTPR:0.9739738075 \tFPR:0.0378750872 \tF1:0.9613678609 \t AUC:0.9680493602\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0858272679 \tAcc: 0.9683734940 \tTPR:0.9723755279 \tFPR:0.0360698775 \tF1:0.9633118405 \t AUC:0.9681528252\tTrain cost: 0:00:09\n",
      "Client3 Test =>                 \tLoss: 0.1555806291 \tAcc: 0.9548611111 \tTPR:0.9395442997 \tFPR:0.0294236492 \tF1:0.9488489226 \tAUC:0.9550603252 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.05414351395517721 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.11982258205192491962\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0563842695 \tAcc: 0.9777372263 \tTPR:0.8907675820 \tFPR:0.0112623501 \tF1:0.8740155699 \t AUC:0.9382787152\tTrain cost: 0:01:07\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0518095723 \tAcc: 0.9790602190 \tTPR:0.8944774650 \tFPR:0.0103005262 \tF1:0.8740359898 \t AUC:0.9402553740\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0473128693 \tAcc: 0.9816149635 \tTPR:0.9146958637 \tFPR:0.0095853333 \tF1:0.8994520796 \t AUC:0.9514698084\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0436870647 \tAcc: 0.9830748175 \tTPR:0.9147827598 \tFPR:0.0085479257 \tF1:0.9009003326 \t AUC:0.9520983768\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0383311763 \tAcc: 0.9847171533 \tTPR:0.9214557989 \tFPR:0.0075811072 \tF1:0.9111480682 \t AUC:0.9559379061\tTrain cost: 0:01:13\n",
      "Client1 Test =>                 \tLoss: 0.1269814198 \tAcc: 0.9667304422 \tTPR:0.7925008098 \tFPR:0.0126909685 \tF1:0.7995336863 \tAUC:0.8873744428 \ttest cost: 0:00:10\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.1862384356134442 \tALA epochs: 11\n",
      "Client 4: Local Initial ALA epochs: 11 Loss: 0.44541357474202813993\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1138040464 \tAcc: 0.9569854004 \tTPR:0.9755605894 \tFPR:0.0769398274 \tF1:0.9661755345 \t AUC:0.9493103810\tTrain cost: 0:02:04\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1032486567 \tAcc: 0.9608087598 \tTPR:0.9788344538 \tFPR:0.0721249889 \tF1:0.9691991510 \t AUC:0.9533547325\tTrain cost: 0:02:01\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0999652860 \tAcc: 0.9622705262 \tTPR:0.9783369175 \tFPR:0.0675550156 \tF1:0.9703060275 \t AUC:0.9553909510\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0969982518 \tAcc: 0.9634088609 \tTPR:0.9792415700 \tFPR:0.0657833694 \tF1:0.9711438157 \t AUC:0.9567291003\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0920099603 \tAcc: 0.9644676930 \tTPR:0.9800358939 \tFPR:0.0641292878 \tF1:0.9719452099 \t AUC:0.9579533031\tTrain cost: 0:02:01\n",
      "Client4 Test =>                 \tLoss: 0.1742886175 \tAcc: 0.9432449495 \tTPR:0.9597570663 \tFPR:0.0866265149 \tF1:0.9550687038 \tAUC:0.9365652757 \ttest cost: 0:00:17\n",
      "Test =>                 \tLoss: 0.1579537831 \tAcc: 0.9529496673 \tTPR:0.9222879042 \tFPR:0.0550783419 \tF1:0.9263264814 \tAUC:0.9330986856\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 19:  =============\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.06521545516288525 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.09645600281091350203\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0655495896 \tAcc: 0.9780685241 \tTPR:0.9912915079 \tFPR:0.0836015390 \tF1:0.9863847471 \t AUC:0.9538449844\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0574124339 \tAcc: 0.9796193703 \tTPR:0.9926101826 \tFPR:0.0718004051 \tF1:0.9871408497 \t AUC:0.9604048888\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0512347095 \tAcc: 0.9808430149 \tTPR:0.9928685862 \tFPR:0.0681000308 \tF1:0.9879980002 \t AUC:0.9623842777\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0493687471 \tAcc: 0.9835726836 \tTPR:0.9934588100 \tFPR:0.0572985666 \tF1:0.9897033925 \t AUC:0.9680801217\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0463407424 \tAcc: 0.9840433161 \tTPR:0.9943078475 \tFPR:0.0624136270 \tF1:0.9899706313 \t AUC:0.9659857173\tTrain cost: 0:00:35\n",
      "Client2 Test =>                 \tLoss: 0.1900187910 \tAcc: 0.9466783217 \tTPR:0.9512316538 \tFPR:0.0728961210 \tF1:0.9658581748 \tAUC:0.9391677664 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.07913402283029171 \tALA epochs: 2\n",
      "Client 9: Local Initial ALA epochs: 2 Loss: 0.11341349037618121687\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0493374558 \tAcc: 0.9828125000 \tTPR:0.9944703661 \tFPR:0.1615151515 \tF1:0.9907032779 \t AUC:0.9167944421\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0341442547 \tAcc: 0.9895833333 \tTPR:0.9976751309 \tFPR:0.1021212121 \tF1:0.9942169754 \t AUC:0.9476712835\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0350480000 \tAcc: 0.9895833333 \tTPR:0.9971813037 \tFPR:0.1330735931 \tF1:0.9943032766 \t AUC:0.9319257328\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0285249675 \tAcc: 0.9916666667 \tTPR:0.9988697318 \tFPR:0.1116959064 \tF1:0.9955122810 \t AUC:0.9435571688\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0262248320 \tAcc: 0.9916666667 \tTPR:0.9982744937 \tFPR:0.0862121212 \tF1:0.9953348674 \t AUC:0.9559527541\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.1421881721 \tAcc: 0.9651442308 \tTPR:0.9822055667 \tFPR:0.2360000000 \tF1:0.9811361119 \tAUC:0.8733718947 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.26938992364326153 \tALA epochs: 11\n",
      "Client 1: Local Initial ALA epochs: 11 Loss: 0.56322782116825065302\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0568686687 \tAcc: 0.9781021898 \tTPR:0.9042318387 \tFPR:0.0125446695 \tF1:0.8838762254 \t AUC:0.9444775222\tTrain cost: 0:01:14\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0474093431 \tAcc: 0.9805656934 \tTPR:0.9039833160 \tFPR:0.0097765070 \tF1:0.8952936646 \t AUC:0.9461017401\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0427095087 \tAcc: 0.9826186131 \tTPR:0.9163439926 \tFPR:0.0083680301 \tF1:0.9039200435 \t AUC:0.9528591895\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0385027629 \tAcc: 0.9850364964 \tTPR:0.9288599235 \tFPR:0.0075962287 \tF1:0.9214307025 \t AUC:0.9597266219\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0374711862 \tAcc: 0.9849908759 \tTPR:0.9335151831 \tFPR:0.0077636867 \tF1:0.9195047073 \t AUC:0.9621821659\tTrain cost: 0:01:12\n",
      "Client1 Test =>                 \tLoss: 0.1283996649 \tAcc: 0.9671556122 \tTPR:0.8212139618 \tFPR:0.0159064486 \tF1:0.8067111932 \tAUC:0.9011071646 \ttest cost: 0:00:10\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.04037319333262369 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.07428828178921581538\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0631169574 \tAcc: 0.9743085930 \tTPR:0.9123451015 \tFPR:0.0142889421 \tF1:0.9076805275 \t AUC:0.9489039226\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0559548530 \tAcc: 0.9761595590 \tTPR:0.9223429819 \tFPR:0.0136463637 \tF1:0.9160264007 \t AUC:0.9540164415\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0515934931 \tAcc: 0.9799611582 \tTPR:0.9259416196 \tFPR:0.0112021546 \tF1:0.9249027729 \t AUC:0.9571593393\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0456627030 \tAcc: 0.9835776608 \tTPR:0.9473006905 \tFPR:0.0097037510 \tF1:0.9424479458 \t AUC:0.9687984697\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0447056037 \tAcc: 0.9826977401 \tTPR:0.9396745909 \tFPR:0.0098702244 \tF1:0.9345042117 \t AUC:0.9647308043\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.1675961510 \tAcc: 0.9544032466 \tTPR:0.8684027778 \tFPR:0.0303732023 \tF1:0.8266845447 \tAUC:0.9176899835 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.09735976460982763 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.20539262576494365931\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0887936105 \tAcc: 0.9623511905 \tTPR:0.9732205752 \tFPR:0.0627930271 \tF1:0.9710943259 \t AUC:0.9552137741\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0678399483 \tAcc: 0.9728422619 \tTPR:0.9861272967 \tFPR:0.0537107617 \tF1:0.9796044677 \t AUC:0.9662082675\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0661301998 \tAcc: 0.9730654762 \tTPR:0.9890192385 \tFPR:0.0557621281 \tF1:0.9792030083 \t AUC:0.9666285552\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0593324874 \tAcc: 0.9765625000 \tTPR:0.9885095347 \tFPR:0.0439755681 \tF1:0.9826124126 \t AUC:0.9722669833\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0547112495 \tAcc: 0.9761904762 \tTPR:0.9870033187 \tFPR:0.0482854777 \tF1:0.9821479359 \t AUC:0.9693589205\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.1657004376 \tAcc: 0.9550498188 \tTPR:0.9601779250 \tFPR:0.0621535101 \tF1:0.9651983020 \tAUC:0.9490122075 \ttest cost: 0:00:01\n",
      "Test =>                 \tLoss: 0.1587806433 \tAcc: 0.9576862460 \tTPR:0.9166463770 \tFPR:0.0834658564 \tF1:0.9091176653 \tAUC:0.9160698033\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 20:  =============\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.05761061773497207 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.09953135455196554515\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0372875221 \tAcc: 0.9875000000 \tTPR:0.9955875576 \tFPR:0.1260233918 \tF1:0.9932860857 \t AUC:0.9346659660\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0221884946 \tAcc: 0.9937500000 \tTPR:0.9983320974 \tFPR:0.0694444444 \tF1:0.9966162435 \t AUC:0.9643511652\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0243504449 \tAcc: 0.9927083333 \tTPR:0.9983283730 \tFPR:0.0848484848 \tF1:0.9960684865 \t AUC:0.9569480519\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0187011765 \tAcc: 0.9942708333 \tTPR:0.9989415323 \tFPR:0.0534591195 \tF1:0.9968867277 \t AUC:0.9729661189\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0223653839 \tAcc: 0.9937500000 \tTPR:0.9982936508 \tFPR:0.0714285714 \tF1:0.9966155226 \t AUC:0.9633715986\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.1453502279 \tAcc: 0.9639423077 \tTPR:0.9819965756 \tFPR:0.2608695652 \tF1:0.9803611047 \tAUC:0.8607480645 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.08805633003451324 \tALA epochs: 11\n",
      "Client 7: Local Initial ALA epochs: 11 Loss: 0.18289641506668308235\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0762348317 \tAcc: 0.9712797619 \tTPR:0.9853739643 \tFPR:0.0601435436 \tF1:0.9785326113 \t AUC:0.9626152104\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0581477636 \tAcc: 0.9761904762 \tTPR:0.9882993684 \tFPR:0.0493206529 \tF1:0.9825938749 \t AUC:0.9694893577\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0549435884 \tAcc: 0.9784226190 \tTPR:0.9877980527 \tFPR:0.0403174372 \tF1:0.9836489816 \t AUC:0.9737403078\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0490375499 \tAcc: 0.9810267857 \tTPR:0.9900715324 \tFPR:0.0437462670 \tF1:0.9861429818 \t AUC:0.9731626327\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0458683007 \tAcc: 0.9836309524 \tTPR:0.9916044844 \tFPR:0.0347811580 \tF1:0.9880898403 \t AUC:0.9784116632\tTrain cost: 0:00:08\n",
      "Client7 Test =>                 \tLoss: 0.1865200749 \tAcc: 0.9541817633 \tTPR:0.9561013614 \tFPR:0.0560591415 \tF1:0.9647369041 \tAUC:0.9500211100 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.06768078393536733 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.06458389870822429935\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1256158364 \tAcc: 0.9676339286 \tTPR:0.9859097439 \tFPR:0.0966695011 \tF1:0.9793657765 \t AUC:0.9446201214\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0906748939 \tAcc: 0.9732142857 \tTPR:0.9942252457 \tFPR:0.1416821274 \tF1:0.9828784970 \t AUC:0.9262715591\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0930035802 \tAcc: 0.9698660714 \tTPR:0.9905295366 \tFPR:0.1052154195 \tF1:0.9812536349 \t AUC:0.9426570585\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0784446701 \tAcc: 0.9778098739 \tTPR:0.9960204082 \tFPR:0.0892006803 \tF1:0.9859922564 \t AUC:0.9534098639\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0702577032 \tAcc: 0.9776785714 \tTPR:0.9974929627 \tFPR:0.1001248751 \tF1:0.9857634435 \t AUC:0.9486840438\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.2317257961 \tAcc: 0.9264823718 \tTPR:0.9432595613 \tFPR:0.1053902116 \tF1:0.9506290831 \tAUC:0.9189346748 \ttest cost: 0:00:00\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.024846844162133376 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.05489057885257132147\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0519799058 \tAcc: 0.9809864458 \tTPR:0.9914806426 \tFPR:0.0672438672 \tF1:0.9880316069 \t AUC:0.9621527240\tTrain cost: 0:00:31\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0450130578 \tAcc: 0.9838102410 \tTPR:0.9927441633 \tFPR:0.0523776827 \tF1:0.9898203385 \t AUC:0.9701722798\tTrain cost: 0:00:31\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0393394244 \tAcc: 0.9854103916 \tTPR:0.9938790468 \tFPR:0.0516198577 \tF1:0.9906818172 \t AUC:0.9711295946\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0362212969 \tAcc: 0.9863516566 \tTPR:0.9946306812 \tFPR:0.0496309915 \tF1:0.9914620985 \t AUC:0.9724998448\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0329145105 \tAcc: 0.9879518072 \tTPR:0.9949756417 \tFPR:0.0420513189 \tF1:0.9925024478 \t AUC:0.9764545717\tTrain cost: 0:00:35\n",
      "Client2 Test =>                 \tLoss: 0.2439222153 \tAcc: 0.9418706294 \tTPR:0.9449481861 \tFPR:0.0682133523 \tF1:0.9623425248 \tAUC:0.9383674169 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.09932764633810888 \tALA epochs: 3\n",
      "Client 3: Local Initial ALA epochs: 3 Loss: 0.16212264006996215948\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1158248225 \tAcc: 0.9551957831 \tTPR:0.9556560420 \tFPR:0.0466466110 \tF1:0.9479110961 \t AUC:0.9545047155\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1012796699 \tAcc: 0.9574548193 \tTPR:0.9618820216 \tFPR:0.0449982710 \tF1:0.9504340253 \t AUC:0.9584418753\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0912640620 \tAcc: 0.9634036145 \tTPR:0.9646432403 \tFPR:0.0393031279 \tF1:0.9578368164 \t AUC:0.9626700562\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0864768941 \tAcc: 0.9691265060 \tTPR:0.9700424104 \tFPR:0.0313249589 \tF1:0.9631304713 \t AUC:0.9693587258\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0797587796 \tAcc: 0.9706325301 \tTPR:0.9697281814 \tFPR:0.0309215011 \tF1:0.9658206620 \t AUC:0.9694033401\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.1785296356 \tAcc: 0.9522569444 \tTPR:0.9225313438 \tFPR:0.0280756291 \tF1:0.9429641158 \tAUC:0.9472278573 \ttest cost: 0:00:01\n",
      "Test =>                 \tLoss: 0.1972095900 \tAcc: 0.9477468033 \tTPR:0.9497674056 \tFPR:0.1037215800 \tF1:0.9602067465 \tAUC:0.9230598247\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 21:  =============\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.014137479103403091 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.03334176164935342968\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0450531374 \tAcc: 0.9813988095 \tTPR:0.9929192511 \tFPR:0.0459306994 \tF1:0.9863904464 \t AUC:0.9734942759\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0413216266 \tAcc: 0.9813988095 \tTPR:0.9860500186 \tFPR:0.0291153952 \tF1:0.9860256314 \t AUC:0.9784673117\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0411229818 \tAcc: 0.9832589286 \tTPR:0.9918739325 \tFPR:0.0341012658 \tF1:0.9873340671 \t AUC:0.9788863334\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0286638017 \tAcc: 0.9895833333 \tTPR:0.9938332680 \tFPR:0.0208942843 \tF1:0.9922526814 \t AUC:0.9864694919\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0312926787 \tAcc: 0.9877232143 \tTPR:0.9920339266 \tFPR:0.0229545917 \tF1:0.9910524391 \t AUC:0.9845396675\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2082384141 \tAcc: 0.9531250000 \tTPR:0.9574149131 \tFPR:0.0546475901 \tF1:0.9628213406 \tAUC:0.9513836615 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.07123268834567925 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.05213574273511767387\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0462173323 \tAcc: 0.9836219880 \tTPR:0.9929312277 \tFPR:0.0586349728 \tF1:0.9897352749 \t AUC:0.9671481274\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0359808026 \tAcc: 0.9863516566 \tTPR:0.9947145223 \tFPR:0.0517338905 \tF1:0.9914373232 \t AUC:0.9714823318\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0355514295 \tAcc: 0.9876694277 \tTPR:0.9949966787 \tFPR:0.0456211000 \tF1:0.9922643302 \t AUC:0.9746877894\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0351439991 \tAcc: 0.9882341867 \tTPR:0.9950321472 \tFPR:0.0408817349 \tF1:0.9925374940 \t AUC:0.9770677018\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0309593916 \tAcc: 0.9897402108 \tTPR:0.9957986932 \tFPR:0.0329807659 \tF1:0.9934602081 \t AUC:0.9814089637\tTrain cost: 0:00:35\n",
      "Client2 Test =>                 \tLoss: 0.1976109525 \tAcc: 0.9490821678 \tTPR:0.9553428379 \tFPR:0.0777394323 \tF1:0.9669670553 \tAUC:0.9388017028 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.14679252076861704 \tALA epochs: 11\n",
      "Client 1: Local Initial ALA epochs: 11 Loss: 0.24263434772592762378\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0497963000 \tAcc: 0.9804288321 \tTPR:0.9083014714 \tFPR:0.0102606843 \tF1:0.8965505259 \t AUC:0.9476414683\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0395827180 \tAcc: 0.9849452555 \tTPR:0.9308869192 \tFPR:0.0074273317 \tF1:0.9227154645 \t AUC:0.9608503609\tTrain cost: 0:01:14\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0384408076 \tAcc: 0.9853102190 \tTPR:0.9268827482 \tFPR:0.0077020301 \tF1:0.9148535368 \t AUC:0.9586599749\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0358422353 \tAcc: 0.9859489051 \tTPR:0.9371955741 \tFPR:0.0076395496 \tF1:0.9257549251 \t AUC:0.9637848700\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0323512075 \tAcc: 0.9875000000 \tTPR:0.9414378403 \tFPR:0.0062140978 \tF1:0.9352030856 \t AUC:0.9669115764\tTrain cost: 0:01:12\n",
      "Client1 Test =>                 \tLoss: 0.1456972907 \tAcc: 0.9647108844 \tTPR:0.8138726919 \tFPR:0.0177822707 \tF1:0.8033158619 \tAUC:0.8947683214 \ttest cost: 0:00:10\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.1841359635846171 \tALA epochs: 11\n",
      "Client 0: Local Initial ALA epochs: 11 Loss: 0.51988865218379276545\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1623679739 \tAcc: 0.9465598739 \tTPR:0.9610327477 \tFPR:0.1141182230 \tF1:0.9643917429 \t AUC:0.9234572623\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1015155005 \tAcc: 0.9687500000 \tTPR:0.9888552849 \tFPR:0.1080498866 \tF1:0.9804574392 \t AUC:0.9404026992\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0926595331 \tAcc: 0.9688813025 \tTPR:0.9884522805 \tFPR:0.1218292620 \tF1:0.9803003730 \t AUC:0.9333115092\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0833262046 \tAcc: 0.9733455882 \tTPR:0.9928341606 \tFPR:0.1012308128 \tF1:0.9828118177 \t AUC:0.9458016739\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0744268857 \tAcc: 0.9765625000 \tTPR:0.9926427093 \tFPR:0.0857155741 \tF1:0.9848918885 \t AUC:0.9534635676\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.2263069901 \tAcc: 0.9330929487 \tTPR:0.9450005410 \tFPR:0.0954773576 \tF1:0.9543675074 \tAUC:0.9247615917 \ttest cost: 0:00:00\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.06369739400418897 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.08360878346182072651\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0803481204 \tAcc: 0.9709235905 \tTPR:0.9875869707 \tFPR:0.0842093991 \tF1:0.9808704671 \t AUC:0.9516887858\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0731561938 \tAcc: 0.9744992582 \tTPR:0.9902559386 \tFPR:0.0794226194 \tF1:0.9833074379 \t AUC:0.9554021595\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0652986639 \tAcc: 0.9769102374 \tTPR:0.9899512508 \tFPR:0.0665103690 \tF1:0.9848777068 \t AUC:0.9617204409\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0608655185 \tAcc: 0.9779302671 \tTPR:0.9903370705 \tFPR:0.0648261234 \tF1:0.9854355949 \t AUC:0.9627554736\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0565511214 \tAcc: 0.9796402077 \tTPR:0.9911038242 \tFPR:0.0602344902 \tF1:0.9864852255 \t AUC:0.9654346670\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.1682079314 \tAcc: 0.9538793103 \tTPR:0.9699213335 \tFPR:0.0972150072 \tF1:0.9694295358 \tAUC:0.9363531631 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.1892123158 \tAcc: 0.9507780622 \tTPR:0.9283104635 \tFPR:0.0685723316 \tF1:0.9313802602 \tAUC:0.9292136881\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 22:  =============\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.08055485125299747 \tALA epochs: 4\n",
      "Client 6: Local Initial ALA epochs: 4 Loss: 0.15103288984316243226\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1254371905 \tAcc: 0.9506920992 \tTPR:0.9574460217 \tFPR:0.0560703341 \tF1:0.9469445883 \t AUC:0.9506878438\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1157744271 \tAcc: 0.9526417526 \tTPR:0.9616487598 \tFPR:0.0553724207 \tF1:0.9490363253 \t AUC:0.9531381695\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1086068771 \tAcc: 0.9577880599 \tTPR:0.9655858431 \tFPR:0.0496378551 \tF1:0.9546969125 \t AUC:0.9579739940\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1048024044 \tAcc: 0.9570631888 \tTPR:0.9640018062 \tFPR:0.0490049089 \tF1:0.9532943934 \t AUC:0.9574984486\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0983262446 \tAcc: 0.9605986713 \tTPR:0.9658837093 \tFPR:0.0438695073 \tF1:0.9573808861 \t AUC:0.9610071010\tTrain cost: 0:00:41\n",
      "Client6 Test =>                 \tLoss: 0.1943098701 \tAcc: 0.9388930472 \tTPR:0.9205279655 \tFPR:0.0434507990 \tF1:0.9297364793 \tAUC:0.9385385833 \ttest cost: 0:00:06\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.08387905658538848 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.09581937517642098723\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0443404037 \tAcc: 0.9827554745 \tTPR:0.9240174951 \tFPR:0.0091359833 \tF1:0.9105439441 \t AUC:0.9565902055\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0348939187 \tAcc: 0.9863594891 \tTPR:0.9337011934 \tFPR:0.0071065057 \tF1:0.9278750705 \t AUC:0.9623516401\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0337596480 \tAcc: 0.9872718978 \tTPR:0.9411673039 \tFPR:0.0064709925 \tF1:0.9321687114 \t AUC:0.9666446257\tTrain cost: 0:01:09\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0304028149 \tAcc: 0.9879105839 \tTPR:0.9427042058 \tFPR:0.0065214080 \tF1:0.9307875283 \t AUC:0.9671853660\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0267570099 \tAcc: 0.9895072993 \tTPR:0.9515380605 \tFPR:0.0056372168 \tF1:0.9390380477 \t AUC:0.9719561419\tTrain cost: 0:01:12\n",
      "Client1 Test =>                 \tLoss: 0.1646324161 \tAcc: 0.9642857143 \tTPR:0.7820078825 \tFPR:0.0129529823 \tF1:0.7860838835 \tAUC:0.8826417052 \ttest cost: 0:00:10\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.1818995053494935 \tALA epochs: 11\n",
      "Client 3: Local Initial ALA epochs: 11 Loss: 0.37406767447034572349\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1264512452 \tAcc: 0.9521837349 \tTPR:0.9527857240 \tFPR:0.0480771287 \tF1:0.9457998390 \t AUC:0.9523542977\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1040022405 \tAcc: 0.9559487952 \tTPR:0.9590707957 \tFPR:0.0446905969 \tF1:0.9500102530 \t AUC:0.9571900994\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0946203811 \tAcc: 0.9683734940 \tTPR:0.9759824079 \tFPR:0.0377198426 \tF1:0.9646866876 \t AUC:0.9691312826\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0898416949 \tAcc: 0.9642319277 \tTPR:0.9679153481 \tFPR:0.0395397635 \tF1:0.9580906497 \t AUC:0.9641877923\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0852203722 \tAcc: 0.9706325301 \tTPR:0.9739515109 \tFPR:0.0313115496 \tF1:0.9646408257 \t AUC:0.9713199806\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.1785213904 \tAcc: 0.9479166667 \tTPR:0.9405193005 \tFPR:0.0468838255 \tF1:0.9411102522 \tAUC:0.9468177375 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.047523942471522584 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.08747328669110786270\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0810067289 \tAcc: 0.9713872404 \tTPR:0.9884313719 \tFPR:0.0868020369 \tF1:0.9813182946 \t AUC:0.9508146675\tTrain cost: 0:00:32\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0683169504 \tAcc: 0.9754933234 \tTPR:0.9898272275 \tFPR:0.0712264574 \tF1:0.9839647455 \t AUC:0.9593003851\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0648744579 \tAcc: 0.9782084570 \tTPR:0.9914443027 \tFPR:0.0643269852 \tF1:0.9855831627 \t AUC:0.9635586587\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0576449121 \tAcc: 0.9789243323 \tTPR:0.9913601833 \tFPR:0.0661213045 \tF1:0.9861910520 \t AUC:0.9626194394\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0572020075 \tAcc: 0.9810830861 \tTPR:0.9921210184 \tFPR:0.0563815347 \tF1:0.9876203641 \t AUC:0.9678697419\tTrain cost: 0:00:36\n",
      "Client8 Test =>                 \tLoss: 0.1659739854 \tAcc: 0.9581896552 \tTPR:0.9742814668 \tFPR:0.0991098174 \tF1:0.9723306357 \tAUC:0.9375858247 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.09164910090453242 \tALA epochs: 3\n",
      "Client 0: Local Initial ALA epochs: 3 Loss: 0.08205417936357359276\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1029032488 \tAcc: 0.9676339286 \tTPR:0.9903911565 \tFPR:0.1160147392 \tF1:0.9797669195 \t AUC:0.9371882086\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0876107081 \tAcc: 0.9757090336 \tTPR:0.9972803777 \tFPR:0.1027365492 \tF1:0.9847700957 \t AUC:0.9472719143\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0756656903 \tAcc: 0.9822741597 \tTPR:0.9972363946 \tFPR:0.0707766440 \tF1:0.9885892264 \t AUC:0.9632298753\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0600250059 \tAcc: 0.9866071429 \tTPR:1.0000000000 \tFPR:0.0587314471 \tF1:0.9912248654 \t AUC:0.9706342764\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0599937106 \tAcc: 0.9799107143 \tTPR:0.9946544857 \tFPR:0.0769699546 \tF1:0.9876243851 \t AUC:0.9588422655\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.2688019550 \tAcc: 0.9244791667 \tTPR:0.9469132627 \tFPR:0.1577831890 \tF1:0.9507535573 \tAUC:0.8945650368 \ttest cost: 0:00:00\n",
      "Test =>                 \tLoss: 0.1944479234 \tAcc: 0.9467528500 \tTPR:0.9128499756 \tFPR:0.0720361226 \tF1:0.9160029616 \tAUC:0.9200297775\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 23:  =============\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.08871297248860653 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.11096982880610392619\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1030106378 \tAcc: 0.9583435167 \tTPR:0.9641696201 \tFPR:0.0466270716 \tF1:0.9544375222 \t AUC:0.9587712742\tTrain cost: 0:00:38\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.0940631792 \tAcc: 0.9615012887 \tTPR:0.9666239749 \tFPR:0.0435132770 \tF1:0.9579938569 \t AUC:0.9615553489\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0858422042 \tAcc: 0.9651978537 \tTPR:0.9716022097 \tFPR:0.0406986634 \tF1:0.9620576499 \t AUC:0.9654517731\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0826450962 \tAcc: 0.9673002577 \tTPR:0.9730143071 \tFPR:0.0375453885 \tF1:0.9646847105 \t AUC:0.9677344593\tTrain cost: 0:00:42\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0795504919 \tAcc: 0.9683472938 \tTPR:0.9741524760 \tFPR:0.0363329980 \tF1:0.9657067648 \t AUC:0.9689097390\tTrain cost: 0:00:42\n",
      "Client6 Test =>                 \tLoss: 0.1874092358 \tAcc: 0.9446107784 \tTPR:0.9377469394 \tFPR:0.0490904920 \tF1:0.9395312392 \tAUC:0.9443282237 \ttest cost: 0:00:06\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.0764658995195847 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.09548921105592991787\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0512297241 \tAcc: 0.9808923193 \tTPR:0.9914487989 \tFPR:0.0584643770 \tF1:0.9878042560 \t AUC:0.9664922109\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0441431490 \tAcc: 0.9842315691 \tTPR:0.9930730315 \tFPR:0.0514300709 \tF1:0.9900932425 \t AUC:0.9708214803\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0393796844 \tAcc: 0.9850338855 \tTPR:0.9931635553 \tFPR:0.0493935700 \tF1:0.9906122592 \t AUC:0.9718849927\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0314373084 \tAcc: 0.9897402108 \tTPR:0.9958516702 \tFPR:0.0380298584 \tF1:0.9935315450 \t AUC:0.9789109059\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0296445049 \tAcc: 0.9884224398 \tTPR:0.9951257585 \tFPR:0.0385911194 \tF1:0.9926928737 \t AUC:0.9782673196\tTrain cost: 0:00:33\n",
      "Client2 Test =>                 \tLoss: 0.1871056355 \tAcc: 0.9555506993 \tTPR:0.9676102020 \tFPR:0.0860534419 \tF1:0.9714479782 \tAUC:0.9407743667 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.027275848632943953 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.06832520417810883373\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0653644624 \tAcc: 0.9720982143 \tTPR:0.9837621168 \tFPR:0.0479193591 \tF1:0.9790998011 \t AUC:0.9679213789\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0441358295 \tAcc: 0.9825148810 \tTPR:0.9908613844 \tFPR:0.0361656084 \tF1:0.9870831744 \t AUC:0.9773478880\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0421363929 \tAcc: 0.9854910714 \tTPR:0.9924206652 \tFPR:0.0307909022 \tF1:0.9889676538 \t AUC:0.9808148815\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0384781905 \tAcc: 0.9824404762 \tTPR:0.9902747335 \tFPR:0.0344766675 \tF1:0.9870330397 \t AUC:0.9778990330\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0366930695 \tAcc: 0.9866071429 \tTPR:0.9909625861 \tFPR:0.0217099699 \tF1:0.9901018412 \t AUC:0.9846263081\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2002311194 \tAcc: 0.9510492150 \tTPR:0.9588103840 \tFPR:0.0628958619 \tF1:0.9611939562 \tAUC:0.9479572611 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.0804247568314502 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.05584003772078589833\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0435814078 \tAcc: 0.9890625000 \tTPR:0.9960852250 \tFPR:0.0943452381 \tF1:0.9940697230 \t AUC:0.9507301801\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0307953243 \tAcc: 0.9895833333 \tTPR:0.9955313223 \tFPR:0.0899331662 \tF1:0.9942967827 \t AUC:0.9526814812\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0245017376 \tAcc: 0.9916666667 \tTPR:0.9989068100 \tFPR:0.0953216374 \tF1:0.9953984668 \t AUC:0.9517638181\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0246548189 \tAcc: 0.9927083333 \tTPR:0.9971566536 \tFPR:0.0760233918 \tF1:0.9960337672 \t AUC:0.9604918060\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0207704047 \tAcc: 0.9927083333 \tTPR:0.9976751309 \tFPR:0.0730769231 \tF1:0.9959571279 \t AUC:0.9621202678\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.1251769165 \tAcc: 0.9685897436 \tTPR:0.9859715924 \tFPR:0.2608974359 \tF1:0.9830805797 \tAUC:0.8625370782 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.14911002135483542 \tALA epochs: 11\n",
      "Client 0: Local Initial ALA epochs: 11 Loss: 0.15984680387191474438\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1188988911 \tAcc: 0.9655330882 \tTPR:0.9838352044 \tFPR:0.1168238508 \tF1:0.9783119176 \t AUC:0.9335056768\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0975723295 \tAcc: 0.9688813025 \tTPR:0.9970735786 \tFPR:0.1475111198 \tF1:0.9803102692 \t AUC:0.9247812294\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0775044474 \tAcc: 0.9754464286 \tTPR:0.9948034769 \tFPR:0.1082057823 \tF1:0.9848091081 \t AUC:0.9432988473\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0725633466 \tAcc: 0.9776785714 \tTPR:0.9934262166 \tFPR:0.0750283447 \tF1:0.9860407095 \t AUC:0.9591989360\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0671046429 \tAcc: 0.9787946429 \tTPR:0.9959731670 \tFPR:0.0822729850 \tF1:0.9864725496 \t AUC:0.9568500910\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.2126809764 \tAcc: 0.9356971154 \tTPR:0.9530680830 \tFPR:0.1304491804 \tF1:0.9558626137 \tAUC:0.9113094513 \ttest cost: 0:00:00\n",
      "Test =>                 \tLoss: 0.1825207767 \tAcc: 0.9510995103 \tTPR:0.9606414401 \tFPR:0.1178772824 \tF1:0.9622232734 \tAUC:0.9213812762\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 24:  =============\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.09368435149065159 \tALA epochs: 3\n",
      "Client 3: Local Initial ALA epochs: 3 Loss: 0.16244488237134646624\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1061425338 \tAcc: 0.9592620482 \tTPR:0.9637620827 \tFPR:0.0453015350 \tF1:0.9528383284 \t AUC:0.9592302738\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.0946671194 \tAcc: 0.9615963855 \tTPR:0.9609694729 \tFPR:0.0383674763 \tF1:0.9550097383 \t AUC:0.9613009983\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0762851729 \tAcc: 0.9687500000 \tTPR:0.9697251586 \tFPR:0.0317144526 \tF1:0.9642675769 \t AUC:0.9690053530\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0859145179 \tAcc: 0.9626506024 \tTPR:0.9631924004 \tFPR:0.0376465034 \tF1:0.9561262146 \t AUC:0.9627729485\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0623128205 \tAcc: 0.9781626506 \tTPR:0.9844672755 \tFPR:0.0266684546 \tF1:0.9744960991 \t AUC:0.9788994104\tTrain cost: 0:00:09\n",
      "Client3 Test =>                 \tLoss: 0.1864910483 \tAcc: 0.9538194444 \tTPR:0.9461771140 \tFPR:0.0411788889 \tF1:0.9461914280 \tAUC:0.9524991125 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.076901871634661 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.07102947634971373825\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.0794109155 \tAcc: 0.9680251289 \tTPR:0.9744300009 \tFPR:0.0381347240 \tF1:0.9658449602 \t AUC:0.9681476384\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0691746251 \tAcc: 0.9720521907 \tTPR:0.9756704275 \tFPR:0.0320332201 \tF1:0.9698489221 \t AUC:0.9718186037\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0655471974 \tAcc: 0.9733408505 \tTPR:0.9764981921 \tFPR:0.0292530734 \tF1:0.9711411937 \t AUC:0.9736225594\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0596767403 \tAcc: 0.9761597938 \tTPR:0.9809716596 \tFPR:0.0286051207 \tF1:0.9739458658 \t AUC:0.9761832694\tTrain cost: 0:00:41\n",
      "Client6 Test =>                 \tLoss: 0.2495144481 \tAcc: 0.9370217898 \tTPR:0.9357096636 \tFPR:0.0619571692 \tF1:0.9311988595 \tAUC:0.9368762472 \ttest cost: 0:00:06\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.05995012641321551 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.10488189838360995054\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0588777425 \tAcc: 0.9758184524 \tTPR:0.9856404926 \tFPR:0.0413880432 \tF1:0.9817429972 \t AUC:0.9721262247\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0473791294 \tAcc: 0.9832589286 \tTPR:0.9909051670 \tFPR:0.0289720414 \tF1:0.9867839717 \t AUC:0.9809665628\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0522406310 \tAcc: 0.9787946429 \tTPR:0.9871022448 \tFPR:0.0369731459 \tF1:0.9842123536 \t AUC:0.9750645495\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0324172603 \tAcc: 0.9877232143 \tTPR:0.9941360998 \tFPR:0.0298578075 \tF1:0.9912491435 \t AUC:0.9821391461\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0318005828 \tAcc: 0.9854910714 \tTPR:0.9905644139 \tFPR:0.0257713351 \tF1:0.9886679341 \t AUC:0.9823965394\tTrain cost: 0:00:08\n",
      "Client7 Test =>                 \tLoss: 0.2058365895 \tAcc: 0.9510492150 \tTPR:0.9542087413 \tFPR:0.0537964350 \tF1:0.9618604365 \tAUC:0.9502061531 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.09733287458984523 \tALA epochs: 10\n",
      "Client 5: Local Initial ALA epochs: 10 Loss: 0.26058728178663709274\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0673383755 \tAcc: 0.9738615136 \tTPR:0.9092524315 \tFPR:0.0147267977 \tF1:0.9038566948 \t AUC:0.9468750068\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0585922277 \tAcc: 0.9777542373 \tTPR:0.9208544281 \tFPR:0.0116237897 \tF1:0.9217392160 \t AUC:0.9545032150\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0526512958 \tAcc: 0.9787252825 \tTPR:0.9189355215 \tFPR:0.0115938290 \tF1:0.9166879975 \t AUC:0.9536708462\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0486278020 \tAcc: 0.9816327228 \tTPR:0.9251243264 \tFPR:0.0089915765 \tF1:0.9282335668 \t AUC:0.9580663750\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0438933491 \tAcc: 0.9831362767 \tTPR:0.9430274998 \tFPR:0.0089921223 \tF1:0.9415279043 \t AUC:0.9670176887\tTrain cost: 0:00:38\n",
      "Client5 Test =>                 \tLoss: 0.1836212369 \tAcc: 0.9519361413 \tTPR:0.8419460109 \tFPR:0.0306450664 \tF1:0.8073427685 \tAUC:0.9051271146 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.14315766648447917 \tALA epochs: 11\n",
      "Client 8: Local Initial ALA epochs: 11 Loss: 0.30837439252329001960\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0680327349 \tAcc: 0.9750296736 \tTPR:0.9883634735 \tFPR:0.0678212984 \tF1:0.9834514226 \t AUC:0.9602710875\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0630706615 \tAcc: 0.9777188427 \tTPR:0.9899686493 \tFPR:0.0622082665 \tF1:0.9851869741 \t AUC:0.9638801914\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0542201356 \tAcc: 0.9799183976 \tTPR:0.9907645523 \tFPR:0.0598979244 \tF1:0.9867732264 \t AUC:0.9654333140\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0525368089 \tAcc: 0.9802485163 \tTPR:0.9908479835 \tFPR:0.0518932024 \tF1:0.9868225136 \t AUC:0.9694773905\tTrain cost: 0:00:36\n",
      "Client8 Test =>                 \tLoss: 0.1765280151 \tAcc: 0.9558189655 \tTPR:0.9804346299 \tFPR:0.1274410774 \tF1:0.9710760113 \tAUC:0.9264288409 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2003982676 \tAcc: 0.9499291112 \tTPR:0.9316952320 \tFPR:0.0630037274 \tF1:0.9235339008 \tAUC:0.9342274937\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 25:  =============\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.07887920055701812 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.07251177760530505556\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.0663881610 \tAcc: 0.9737268930 \tTPR:0.9790330047 \tFPR:0.0314797318 \tF1:0.9719737467 \t AUC:0.9737766365\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.0637090995 \tAcc: 0.9762320032 \tTPR:0.9791632365 \tFPR:0.0263731427 \tF1:0.9732054653 \t AUC:0.9763950469\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0581659913 \tAcc: 0.9768846649 \tTPR:0.9802030726 \tFPR:0.0259525786 \tF1:0.9749126248 \t AUC:0.9771252470\tTrain cost: 0:00:42\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0522517982 \tAcc: 0.9795341939 \tTPR:0.9828022393 \tFPR:0.0230196483 \tF1:0.9779686909 \t AUC:0.9798912955\tTrain cost: 0:00:42\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0514889202 \tAcc: 0.9801063144 \tTPR:0.9829153421 \tFPR:0.0219451333 \tF1:0.9782490398 \t AUC:0.9804851044\tTrain cost: 0:00:42\n",
      "Client6 Test =>                 \tLoss: 0.2774466593 \tAcc: 0.9349634065 \tTPR:0.9107978591 \tFPR:0.0448275769 \tF1:0.9272835120 \tAUC:0.9329851411 \ttest cost: 0:00:06\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.06786171363416074 \tALA epochs: 2\n",
      "Client 8: Local Initial ALA epochs: 2 Loss: 0.15655500650642190097\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0758799753 \tAcc: 0.9718768546 \tTPR:0.9874227586 \tFPR:0.0807187784 \tF1:0.9815182076 \t AUC:0.9533519901\tTrain cost: 0:00:32\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0639454363 \tAcc: 0.9760497033 \tTPR:0.9897534264 \tFPR:0.0682437107 \tF1:0.9842455864 \t AUC:0.9607861130\tTrain cost: 0:00:32\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0564969930 \tAcc: 0.9795994065 \tTPR:0.9909331908 \tFPR:0.0575088858 \tF1:0.9865775526 \t AUC:0.9667121525\tTrain cost: 0:00:32\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0529169391 \tAcc: 0.9803412463 \tTPR:0.9915737085 \tFPR:0.0594954419 \tF1:0.9872580128 \t AUC:0.9660391333\tTrain cost: 0:00:32\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0509666888 \tAcc: 0.9808976261 \tTPR:0.9904978854 \tFPR:0.0541817727 \tF1:0.9874091085 \t AUC:0.9681580563\tTrain cost: 0:00:32\n",
      "Client8 Test =>                 \tLoss: 0.1733713998 \tAcc: 0.9538793103 \tTPR:0.9780070223 \tFPR:0.1255669426 \tF1:0.9694999788 \tAUC:0.9262200398 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.08630550033683985 \tALA epochs: 5\n",
      "Client 0: Local Initial ALA epochs: 5 Loss: 0.10399819623678922820\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1057802891 \tAcc: 0.9720982143 \tTPR:0.9896030439 \tFPR:0.0949971655 \tF1:0.9820221349 \t AUC:0.9473029392\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0903848228 \tAcc: 0.9743303571 \tTPR:0.9929639772 \tFPR:0.0931277056 \tF1:0.9836254886 \t AUC:0.9499181358\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0801058682 \tAcc: 0.9776785714 \tTPR:0.9909992785 \tFPR:0.0674757782 \tF1:0.9852448429 \t AUC:0.9617617502\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0640569704 \tAcc: 0.9776785714 \tTPR:0.9931191494 \tFPR:0.0777636054 \tF1:0.9859507428 \t AUC:0.9576777720\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0585127836 \tAcc: 0.9810267857 \tTPR:0.9957605820 \tFPR:0.0780612245 \tF1:0.9877994588 \t AUC:0.9588496788\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.2510232689 \tAcc: 0.9310897436 \tTPR:0.9516074297 \tFPR:0.1277447090 \tF1:0.9534453271 \tAUC:0.9119313604 \ttest cost: 0:00:00\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.09450008203649485 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.25776420284391327042\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0458054099 \tAcc: 0.9822536496 \tTPR:0.9210618700 \tFPR:0.0100075511 \tF1:0.9049814514 \t AUC:0.9547036618\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0360659041 \tAcc: 0.9867244526 \tTPR:0.9303076121 \tFPR:0.0063887232 \tF1:0.9212906383 \t AUC:0.9612324002\tTrain cost: 0:01:09\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0311862258 \tAcc: 0.9877737226 \tTPR:0.9466504461 \tFPR:0.0067899138 \tF1:0.9391880668 \t AUC:0.9692514170\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0294250053 \tAcc: 0.9881386861 \tTPR:0.9439676747 \tFPR:0.0062208442 \tF1:0.9379326298 \t AUC:0.9681604290\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0258488609 \tAcc: 0.9904197080 \tTPR:0.9572360203 \tFPR:0.0055676871 \tF1:0.9504958494 \t AUC:0.9754852023\tTrain cost: 0:01:13\n",
      "Client1 Test =>                 \tLoss: 0.1471192694 \tAcc: 0.9644982993 \tTPR:0.8016655869 \tFPR:0.0154072600 \tF1:0.7994130092 \tAUC:0.8914134678 \ttest cost: 0:00:10\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.1662100162385257 \tALA epochs: 11\n",
      "Client 7: Local Initial ALA epochs: 11 Loss: 0.43868327792733907700\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0824317041 \tAcc: 0.9683779762 \tTPR:0.9752532034 \tFPR:0.0498443686 \tF1:0.9763584957 \t AUC:0.9627044174\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0564059829 \tAcc: 0.9776785714 \tTPR:0.9879879058 \tFPR:0.0451452978 \tF1:0.9834214459 \t AUC:0.9714213040\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0413941139 \tAcc: 0.9858630952 \tTPR:0.9923725252 \tFPR:0.0262946049 \tF1:0.9893325832 \t AUC:0.9830389602\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0317878407 \tAcc: 0.9857886905 \tTPR:0.9918615626 \tFPR:0.0280086151 \tF1:0.9896177228 \t AUC:0.9819264738\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0353023350 \tAcc: 0.9862351190 \tTPR:0.9919960213 \tFPR:0.0239593934 \tF1:0.9895652867 \t AUC:0.9840183139\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2074284599 \tAcc: 0.9535024155 \tTPR:0.9568931293 \tFPR:0.0517642851 \tF1:0.9636342829 \tAUC:0.9525644221 \ttest cost: 0:00:01\n",
      "Test =>                 \tLoss: 0.2112778115 \tAcc: 0.9475866350 \tTPR:0.9197942055 \tFPR:0.0730621547 \tF1:0.9226552220 \tAUC:0.9230228862\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 26:  =============\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.03860083868020671 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.05299598397687077522\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0399689049 \tAcc: 0.9847470238 \tTPR:0.9920433544 \tFPR:0.0272891460 \tF1:0.9884029661 \t AUC:0.9823771042\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0370938080 \tAcc: 0.9843750000 \tTPR:0.9925526449 \tFPR:0.0335056808 \tF1:0.9881256198 \t AUC:0.9795234820\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0313148103 \tAcc: 0.9880952381 \tTPR:0.9923522459 \tFPR:0.0211641533 \tF1:0.9911598076 \t AUC:0.9855940463\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0317496727 \tAcc: 0.9862351190 \tTPR:0.9923258444 \tFPR:0.0274941659 \tF1:0.9895001898 \t AUC:0.9824158393\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0299838116 \tAcc: 0.9872767857 \tTPR:0.9928663959 \tFPR:0.0244529115 \tF1:0.9904892318 \t AUC:0.9842067422\tTrain cost: 0:00:08\n",
      "Client7 Test =>                 \tLoss: 0.1991689372 \tAcc: 0.9545214372 \tTPR:0.9697051773 \tFPR:0.0760260573 \tF1:0.9652838586 \tAUC:0.9468395600 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.09316539599161655 \tALA epochs: 2\n",
      "Client 6: Local Initial ALA epochs: 2 Loss: 0.11471479460891856328\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.0620567069 \tAcc: 0.9758376289 \tTPR:0.9798426375 \tFPR:0.0284168851 \tF1:0.9743846644 \t AUC:0.9757128762\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.0533825015 \tAcc: 0.9783982847 \tTPR:0.9807777777 \tFPR:0.0240572057 \tF1:0.9763707217 \t AUC:0.9783602860\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0455997375 \tAcc: 0.9823614691 \tTPR:0.9840593128 \tFPR:0.0187099793 \tF1:0.9809491411 \t AUC:0.9826746667\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0472703312 \tAcc: 0.9821198454 \tTPR:0.9839039681 \tFPR:0.0197217131 \tF1:0.9802419142 \t AUC:0.9820911275\tTrain cost: 0:00:42\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0429848090 \tAcc: 0.9835612558 \tTPR:0.9866095723 \tFPR:0.0188731951 \tF1:0.9822185517 \t AUC:0.9838681886\tTrain cost: 0:00:42\n",
      "Client6 Test =>                 \tLoss: 0.2848001194 \tAcc: 0.9345891550 \tTPR:0.9107853437 \tFPR:0.0450965187 \tF1:0.9254860862 \tAUC:0.9328444125 \ttest cost: 0:00:06\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.0383775902075118 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.09025110877701081336\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.0944339587 \tAcc: 0.9653614458 \tTPR:0.9680040518 \tFPR:0.0355723003 \tF1:0.9613909011 \t AUC:0.9662158757\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.0845631385 \tAcc: 0.9702560241 \tTPR:0.9765367635 \tFPR:0.0342331507 \tF1:0.9651804853 \t AUC:0.9711518064\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0754943628 \tAcc: 0.9706325301 \tTPR:0.9748519356 \tFPR:0.0334814466 \tF1:0.9672002224 \t AUC:0.9706852445\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0665181543 \tAcc: 0.9747740964 \tTPR:0.9751363955 \tFPR:0.0255077489 \tF1:0.9704114235 \t AUC:0.9748143233\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0628730534 \tAcc: 0.9759036145 \tTPR:0.9815661662 \tFPR:0.0266653648 \tF1:0.9729957788 \t AUC:0.9774504007\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.2236114720 \tAcc: 0.9414930556 \tTPR:0.9282921067 \tFPR:0.0461166051 \tF1:0.9303350947 \tAUC:0.9410877508 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.05944990396052211 \tALA epochs: 2\n",
      "Client 8: Local Initial ALA epochs: 2 Loss: 0.12164063620860618431\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0640659001 \tAcc: 0.9768842730 \tTPR:0.9898017361 \tFPR:0.0679805644 \tF1:0.9849111612 \t AUC:0.9608954099\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0522689031 \tAcc: 0.9793212166 \tTPR:0.9905837761 \tFPR:0.0602098794 \tF1:0.9865321328 \t AUC:0.9652194391\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0483646881 \tAcc: 0.9829376855 \tTPR:0.9922084991 \tFPR:0.0544865372 \tF1:0.9886678745 \t AUC:0.9688609810\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0422671618 \tAcc: 0.9846068249 \tTPR:0.9924484702 \tFPR:0.0394793551 \tF1:0.9898222305 \t AUC:0.9764845575\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0379268683 \tAcc: 0.9868323442 \tTPR:0.9939732241 \tFPR:0.0357792883 \tF1:0.9912038088 \t AUC:0.9790969679\tTrain cost: 0:00:36\n",
      "Client8 Test =>                 \tLoss: 0.1946995927 \tAcc: 0.9532327586 \tTPR:0.9703386633 \tFPR:0.1049353711 \tF1:0.9683253297 \tAUC:0.9327016461 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.03882911125658996 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.04739704982476365680\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0493561762 \tAcc: 0.9818335843 \tTPR:0.9916366001 \tFPR:0.0560320093 \tF1:0.9883668706 \t AUC:0.9677896619\tTrain cost: 0:00:32\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0386948522 \tAcc: 0.9855045181 \tTPR:0.9933673429 \tFPR:0.0473309154 \tF1:0.9907978391 \t AUC:0.9730182137\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0367696285 \tAcc: 0.9864906053 \tTPR:0.9933554830 \tFPR:0.0429844921 \tF1:0.9914954048 \t AUC:0.9751854955\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0307453147 \tAcc: 0.9887003371 \tTPR:0.9953942296 \tFPR:0.0369722113 \tF1:0.9928459926 \t AUC:0.9792444008\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0242035511 \tAcc: 0.9908204246 \tTPR:0.9958579538 \tFPR:0.0273430301 \tF1:0.9941598251 \t AUC:0.9842574618\tTrain cost: 0:00:35\n",
      "Client2 Test =>                 \tLoss: 0.1917363629 \tAcc: 0.9601398601 \tTPR:0.9811521463 \tFPR:0.1281150668 \tF1:0.9748249077 \tAUC:0.9265185398 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2188032969 \tAcc: 0.9487952533 \tTPR:0.9520546875 \tFPR:0.0800579238 \tF1:0.9528510554 \tAUC:0.9359983818\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 27:  =============\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.0229576954853506 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.01963947571130120195\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0386987894 \tAcc: 0.9869791667 \tTPR:0.9942463143 \tFPR:0.0273258157 \tF1:0.9904593224 \t AUC:0.9834602493\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0241442548 \tAcc: 0.9903273810 \tTPR:0.9951753350 \tFPR:0.0196067374 \tF1:0.9928068155 \t AUC:0.9877842988\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0209977282 \tAcc: 0.9925595238 \tTPR:0.9955758715 \tFPR:0.0136911699 \tF1:0.9943879768 \t AUC:0.9909423508\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0202536412 \tAcc: 0.9918154762 \tTPR:0.9960442840 \tFPR:0.0151398419 \tF1:0.9934927417 \t AUC:0.9904522211\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0193598029 \tAcc: 0.9925595238 \tTPR:0.9962381544 \tFPR:0.0141717410 \tF1:0.9944129384 \t AUC:0.9910332067\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2204413256 \tAcc: 0.9588617150 \tTPR:0.9708489363 \tFPR:0.0627180690 \tF1:0.9682395254 \tAUC:0.9540654336 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.07838030922878089 \tALA epochs: 7\n",
      "Client 4: Local Initial ALA epochs: 7 Loss: 0.18286877008621735263\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1135046555 \tAcc: 0.9570938132 \tTPR:0.9760140816 \tFPR:0.0762278304 \tF1:0.9661042425 \t AUC:0.9498931256\tTrain cost: 0:02:03\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1044143587 \tAcc: 0.9602666956 \tTPR:0.9782224305 \tFPR:0.0720821340 \tF1:0.9685904484 \t AUC:0.9530701483\tTrain cost: 0:02:01\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0997324710 \tAcc: 0.9615929459 \tTPR:0.9787048155 \tFPR:0.0683030661 \tF1:0.9697853034 \t AUC:0.9552008747\tTrain cost: 0:02:02\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0937417902 \tAcc: 0.9641948540 \tTPR:0.9794648570 \tFPR:0.0632798549 \tF1:0.9716426533 \t AUC:0.9580925011\tTrain cost: 0:02:01\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0899845837 \tAcc: 0.9660920786 \tTPR:0.9810138879 \tFPR:0.0604029773 \tF1:0.9731871708 \t AUC:0.9603054553\tTrain cost: 0:02:01\n",
      "Client4 Test =>                 \tLoss: 0.1567186547 \tAcc: 0.9512626263 \tTPR:0.9637190651 \tFPR:0.0708402596 \tF1:0.9607321413 \tAUC:0.9464394027 \ttest cost: 0:00:17\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.0645270652898117 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.06123172491788864136\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0323367193 \tAcc: 0.9895833333 \tTPR:0.9959782418 \tFPR:0.0919540230 \tF1:0.9942426447 \t AUC:0.9522121653\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0290630042 \tAcc: 0.9880208333 \tTPR:0.9959274907 \tFPR:0.1266025641 \tF1:0.9934237165 \t AUC:0.9346496741\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0218441657 \tAcc: 0.9937500000 \tTPR:0.9988888889 \tFPR:0.0640589569 \tF1:0.9965392702 \t AUC:0.9673752834\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0141178948 \tAcc: 0.9947916667 \tTPR:0.9983859767 \tFPR:0.0573099415 \tF1:0.9971765766 \t AUC:0.9707696661\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0147199966 \tAcc: 0.9958333333 \tTPR:0.9988300493 \tFPR:0.0333333333 \tF1:0.9976785506 \t AUC:0.9827065740\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.1695155793 \tAcc: 0.9625801282 \tTPR:0.9779795841 \tFPR:0.2780303030 \tF1:0.9796275846 \tAUC:0.8501034663 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.20443208609487185 \tALA epochs: 11\n",
      "Client 6: Local Initial ALA epochs: 11 Loss: 0.40162936772850432732\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.0733720993 \tAcc: 0.9724548969 \tTPR:0.9764391174 \tFPR:0.0304298770 \tF1:0.9702922674 \t AUC:0.9730046202\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.0577843387 \tAcc: 0.9773595805 \tTPR:0.9811639565 \tFPR:0.0255128479 \tF1:0.9755554297 \t AUC:0.9778255543\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0530623253 \tAcc: 0.9776012042 \tTPR:0.9805619650 \tFPR:0.0255118220 \tF1:0.9756925853 \t AUC:0.9775250715\tTrain cost: 0:00:42\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0478782425 \tAcc: 0.9819587629 \tTPR:0.9843943289 \tFPR:0.0204323555 \tF1:0.9805315681 \t AUC:0.9819809867\tTrain cost: 0:00:42\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0439410999 \tAcc: 0.9822809278 \tTPR:0.9867182746 \tFPR:0.0205546905 \tF1:0.9811518073 \t AUC:0.9830817920\tTrain cost: 0:00:40\n",
      "Client6 Test =>                 \tLoss: 0.2397833526 \tAcc: 0.9408682635 \tTPR:0.9277342247 \tFPR:0.0473036315 \tF1:0.9347344804 \tAUC:0.9402152966 \ttest cost: 0:00:06\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.05013062862627948 \tALA epochs: 3\n",
      "Client 1: Local Initial ALA epochs: 3 Loss: 0.12515364906742915130\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0439448423 \tAcc: 0.9845802920 \tTPR:0.9219522651 \tFPR:0.0076854378 \tF1:0.9129865123 \t AUC:0.9562001074\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0358330489 \tAcc: 0.9863138686 \tTPR:0.9320571197 \tFPR:0.0068326908 \tF1:0.9190948227 \t AUC:0.9613787582\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0318383532 \tAcc: 0.9873175182 \tTPR:0.9380378867 \tFPR:0.0069194015 \tF1:0.9295290962 \t AUC:0.9647231721\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0262394608 \tAcc: 0.9896897810 \tTPR:0.9492050853 \tFPR:0.0055325534 \tF1:0.9435292500 \t AUC:0.9711508773\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0238383179 \tAcc: 0.9910583942 \tTPR:0.9572569280 \tFPR:0.0046626525 \tF1:0.9498227673 \t AUC:0.9757860098\tTrain cost: 0:01:13\n",
      "Client1 Test =>                 \tLoss: 0.1513345879 \tAcc: 0.9646045918 \tTPR:0.8411389159 \tFPR:0.0209609302 \tF1:0.7996106501 \tAUC:0.9055174508 \ttest cost: 0:00:10\n",
      "Test =>                 \tLoss: 0.1875587000 \tAcc: 0.9556354650 \tTPR:0.9362841452 \tFPR:0.0959706387 \tF1:0.9285888764 \tAUC:0.9192682100\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 28:  =============\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.09023334924970237 \tALA epochs: 2\n",
      "Client 1: Local Initial ALA epochs: 2 Loss: 0.15242531777467399623\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0351316317 \tAcc: 0.9860857664 \tTPR:0.9363440817 \tFPR:0.0072491896 \tF1:0.9268590477 \t AUC:0.9638348798\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0307568834 \tAcc: 0.9880930657 \tTPR:0.9389427645 \tFPR:0.0063421873 \tF1:0.9286781562 \t AUC:0.9655701572\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0270119641 \tAcc: 0.9891423358 \tTPR:0.9479405631 \tFPR:0.0059025599 \tF1:0.9421264463 \t AUC:0.9704759076\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0233405201 \tAcc: 0.9911040146 \tTPR:0.9564737574 \tFPR:0.0047897210 \tF1:0.9496457544 \t AUC:0.9752211483\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0219396941 \tAcc: 0.9920164234 \tTPR:0.9614644885 \tFPR:0.0045271919 \tF1:0.9576770662 \t AUC:0.9779486789\tTrain cost: 0:01:12\n",
      "Client1 Test =>                 \tLoss: 0.1662285108 \tAcc: 0.9615221088 \tTPR:0.8455255912 \tFPR:0.0244651703 \tF1:0.7931261488 \tAUC:0.9072435209 \ttest cost: 0:00:10\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.18162607201516995 \tALA epochs: 11\n",
      "Client 3: Local Initial ALA epochs: 11 Loss: 0.21195268646657827727\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1114998406 \tAcc: 0.9608433735 \tTPR:0.9547484812 \tFPR:0.0346003400 \tF1:0.9528861985 \t AUC:0.9600740706\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.0758715415 \tAcc: 0.9717620482 \tTPR:0.9717452531 \tFPR:0.0263585370 \tF1:0.9667854649 \t AUC:0.9726933581\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0679891660 \tAcc: 0.9743975904 \tTPR:0.9741111114 \tFPR:0.0256558260 \tF1:0.9707109437 \t AUC:0.9742276427\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0667021289 \tAcc: 0.9762801205 \tTPR:0.9780884129 \tFPR:0.0252315800 \tF1:0.9719713194 \t AUC:0.9764284165\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0544774790 \tAcc: 0.9819277108 \tTPR:0.9827248951 \tFPR:0.0182557710 \tF1:0.9771842795 \t AUC:0.9822345620\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.1897069049 \tAcc: 0.9557291667 \tTPR:0.9529999322 \tFPR:0.0420636286 \tF1:0.9515090176 \tAUC:0.9554681518 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.05707614931969395 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.05898685590364038944\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0404908344 \tAcc: 0.9843750000 \tTPR:0.9905015666 \tFPR:0.0317694376 \tF1:0.9881622745 \t AUC:0.9793660645\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0338583640 \tAcc: 0.9884672619 \tTPR:0.9916788534 \tFPR:0.0156134093 \tF1:0.9913405941 \t AUC:0.9880327220\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0275352149 \tAcc: 0.9872767857 \tTPR:0.9927397321 \tFPR:0.0232646089 \tF1:0.9900768949 \t AUC:0.9847375616\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0206301011 \tAcc: 0.9921875000 \tTPR:0.9956317776 \tFPR:0.0169273517 \tF1:0.9943318664 \t AUC:0.9893522129\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0197217006 \tAcc: 0.9910714286 \tTPR:0.9962467636 \tFPR:0.0193013501 \tF1:0.9932411893 \t AUC:0.9884727067\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2165659541 \tAcc: 0.9513888889 \tTPR:0.9531951140 \tFPR:0.0499496872 \tF1:0.9621828854 \tAUC:0.9516227134 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.2031658433934752 \tALA epochs: 11\n",
      "Client 0: Local Initial ALA epochs: 11 Loss: 0.16300306993176821857\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1097270990 \tAcc: 0.9711134454 \tTPR:0.9888251075 \tFPR:0.0989512472 \tF1:0.9818072065 \t AUC:0.9449369302\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0794062546 \tAcc: 0.9744616597 \tTPR:0.9863233526 \tFPR:0.0710343228 \tF1:0.9831338565 \t AUC:0.9576445149\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0688030279 \tAcc: 0.9776785714 \tTPR:0.9882560033 \tFPR:0.0639880952 \tF1:0.9856929344 \t AUC:0.9621339540\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0573357688 \tAcc: 0.9833902311 \tTPR:0.9985714286 \tFPR:0.0822420635 \tF1:0.9895402160 \t AUC:0.9581646825\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0747112056 \tAcc: 0.9720982143 \tTPR:0.9860615020 \tFPR:0.0880810658 \tF1:0.9825268267 \t AUC:0.9489902181\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.2269416858 \tAcc: 0.9401041667 \tTPR:0.9653896875 \tFPR:0.1421957672 \tF1:0.9606085257 \tAUC:0.9115969601 \ttest cost: 0:00:00\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.06993216966705142 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.07573450616658178314\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0598628503 \tAcc: 0.9790430267 \tTPR:0.9904793203 \tFPR:0.0611856893 \tF1:0.9862847481 \t AUC:0.9646791508\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0528924539 \tAcc: 0.9811238872 \tTPR:0.9918914975 \tFPR:0.0579096912 \tF1:0.9876051230 \t AUC:0.9669788369\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0487441270 \tAcc: 0.9823553412 \tTPR:0.9919365253 \tFPR:0.0500843864 \tF1:0.9883738992 \t AUC:0.9709260694\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0414365905 \tAcc: 0.9855749258 \tTPR:0.9939344569 \tFPR:0.0409689269 \tF1:0.9904580191 \t AUC:0.9764737389\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0405913298 \tAcc: 0.9860905045 \tTPR:0.9938237462 \tFPR:0.0416436844 \tF1:0.9908650034 \t AUC:0.9760900309\tTrain cost: 0:00:36\n",
      "Client8 Test =>                 \tLoss: 0.1988812243 \tAcc: 0.9523706897 \tTPR:0.9703741836 \tFPR:0.1060425493 \tF1:0.9681893433 \tAUC:0.9320629498 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.1996648560 \tAcc: 0.9522230041 \tTPR:0.9374969017 \tFPR:0.0729433605 \tF1:0.9271231842 \tAUC:0.9315988592\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 29:  =============\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.046128063016018996 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.10379050090585066612\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0959195231 \tAcc: 0.9639509251 \tTPR:0.9795730116 \tFPR:0.0649682478 \tF1:0.9715386398 \t AUC:0.9573023819\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0892282291 \tAcc: 0.9662565048 \tTPR:0.9812675595 \tFPR:0.0604965675 \tF1:0.9734614433 \t AUC:0.9603854960\tTrain cost: 0:02:02\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0838647297 \tAcc: 0.9674761492 \tTPR:0.9806632606 \tFPR:0.0566726520 \tF1:0.9740961054 \t AUC:0.9619953043\tTrain cost: 0:02:01\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0806933887 \tAcc: 0.9696949986 \tTPR:0.9828072674 \tFPR:0.0541341775 \tF1:0.9762102875 \t AUC:0.9643365450\tTrain cost: 0:02:01\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0764557013 \tAcc: 0.9708911535 \tTPR:0.9840733518 \tFPR:0.0525695369 \tF1:0.9770265568 \t AUC:0.9657519074\tTrain cost: 0:02:02\n",
      "Client4 Test =>                 \tLoss: 0.1760741077 \tAcc: 0.9500631313 \tTPR:0.9655992577 \tFPR:0.0763657650 \tF1:0.9603640276 \tAUC:0.9446167463 \ttest cost: 0:00:17\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.08881520976056903 \tALA epochs: 5\n",
      "Client 5: Local Initial ALA epochs: 5 Loss: 0.20935351896498885504\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0678649077 \tAcc: 0.9735995307 \tTPR:0.9142688997 \tFPR:0.0161937465 \tF1:0.9007238596 \t AUC:0.9490375766\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0576987859 \tAcc: 0.9768714689 \tTPR:0.9217378588 \tFPR:0.0126442534 \tF1:0.9187534615 \t AUC:0.9545468027\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0498602819 \tAcc: 0.9805762484 \tTPR:0.9289662550 \tFPR:0.0103603420 \tF1:0.9230461125 \t AUC:0.9592023422\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0457257041 \tAcc: 0.9821680791 \tTPR:0.9376625415 \tFPR:0.0096600416 \tF1:0.9268383174 \t AUC:0.9638241549\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0415774253 \tAcc: 0.9842838755 \tTPR:0.9486437919 \tFPR:0.0083618057 \tF1:0.9471938900 \t AUC:0.9699950948\tTrain cost: 0:00:38\n",
      "Client5 Test =>                 \tLoss: 0.1688876057 \tAcc: 0.9581039045 \tTPR:0.8590225564 \tFPR:0.0240778354 \tF1:0.8373868274 \tAUC:0.9160531245 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.08665308352798132 \tALA epochs: 4\n",
      "Client 6: Local Initial ALA epochs: 4 Loss: 0.16688995613631876780\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.0760618109 \tAcc: 0.9689832919 \tTPR:0.9740341387 \tFPR:0.0352922966 \tF1:0.9667646151 \t AUC:0.9693709210\tTrain cost: 0:00:37\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.0624050996 \tAcc: 0.9763930857 \tTPR:0.9805604150 \tFPR:0.0270766845 \tF1:0.9742591767 \t AUC:0.9767418653\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0556528459 \tAcc: 0.9778511598 \tTPR:0.9825832975 \tFPR:0.0256691142 \tF1:0.9761962963 \t AUC:0.9784570916\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0500580244 \tAcc: 0.9802673969 \tTPR:0.9825651053 \tFPR:0.0212851518 \tF1:0.9784035813 \t AUC:0.9806399767\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0456636827 \tAcc: 0.9813949742 \tTPR:0.9854771324 \tFPR:0.0224423572 \tF1:0.9797445857 \t AUC:0.9815173876\tTrain cost: 0:00:39\n",
      "Client6 Test =>                 \tLoss: 0.2414311461 \tAcc: 0.9408682635 \tTPR:0.9310899876 \tFPR:0.0489588071 \tF1:0.9357784767 \tAUC:0.9410655902 \ttest cost: 0:00:06\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.062361079651039035 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.06786523357732221484\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0496781541 \tAcc: 0.9787946429 \tTPR:0.9867401377 \tFPR:0.0373092020 \tF1:0.9844116199 \t AUC:0.9747154678\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0311005289 \tAcc: 0.9887648810 \tTPR:0.9917913728 \tFPR:0.0170525407 \tF1:0.9915618387 \t AUC:0.9873694160\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0271705692 \tAcc: 0.9899553571 \tTPR:0.9949820077 \tFPR:0.0216590288 \tF1:0.9925299479 \t AUC:0.9866614894\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0244381677 \tAcc: 0.9914434524 \tTPR:0.9938557179 \tFPR:0.0138228835 \tF1:0.9934866529 \t AUC:0.9900164172\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0237199564 \tAcc: 0.9910714286 \tTPR:0.9958427080 \tFPR:0.0177359182 \tF1:0.9933366683 \t AUC:0.9890533949\tTrain cost: 0:00:08\n",
      "Client7 Test =>                 \tLoss: 0.1696594493 \tAcc: 0.9652777778 \tTPR:0.9743035380 \tFPR:0.0584959022 \tF1:0.9734954447 \tAUC:0.9579038179 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.06604972008083605 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.06350063245983293692\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0642640372 \tAcc: 0.9778375371 \tTPR:0.9893448951 \tFPR:0.0587684077 \tF1:0.9854783396 \t AUC:0.9652882437\tTrain cost: 0:00:32\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0513091121 \tAcc: 0.9820771513 \tTPR:0.9930856563 \tFPR:0.0520683599 \tF1:0.9881399761 \t AUC:0.9705913650\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0459557223 \tAcc: 0.9827262611 \tTPR:0.9925232343 \tFPR:0.0543347890 \tF1:0.9885626008 \t AUC:0.9690942226\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0433170168 \tAcc: 0.9858123145 \tTPR:0.9937231947 \tFPR:0.0394665506 \tF1:0.9906086033 \t AUC:0.9771283221\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0375597084 \tAcc: 0.9857195846 \tTPR:0.9936212723 \tFPR:0.0416059707 \tF1:0.9905749461 \t AUC:0.9760076508\tTrain cost: 0:00:36\n",
      "Client8 Test =>                 \tLoss: 0.1757245602 \tAcc: 0.9595023511 \tTPR:0.9777205127 \tFPR:0.0906131799 \tF1:0.9729934664 \tAUC:0.9435536664 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.1863553738 \tAcc: 0.9547630856 \tTPR:0.9415471705 \tFPR:0.0597022980 \tF1:0.9360036486 \tAUC:0.9406385891\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "Training and Test completed! total time cost: 8:28:20\n"
     ]
    }
   ],
   "source": [
    "print(\"Train and Test Begin!\")\n",
    "net_glob.train()\n",
    "w_net_glob = net_glob.state_dict()\n",
    "t0 = time.time()\n",
    "net_local = [copy.deepcopy(net_glob) for i in range(num_users)]\n",
    "\n",
    "lr = 2e-6\n",
    "\n",
    "local_test[\"loss\"] = []\n",
    "local_test[\"acc\"] = []\n",
    "local_test[\"tpr\"] = []\n",
    "local_test[\"fpr\"] = []\n",
    "local_test[\"f1\"] = []\n",
    "local_test[\"auc\"] = []\n",
    "\n",
    "local_testing[\"loss\"] = []\n",
    "local_testing[\"acc\"] = []\n",
    "local_testing[\"tpr\"] = []\n",
    "local_testing[\"fpr\"] = []\n",
    "local_testing[\"f1\"] = []\n",
    "local_testing[\"auc\"] = []\n",
    "\n",
    "for iter in range(epochs):\n",
    "    print(\"============== Round {}:  =============\".format(iter))\n",
    "    idx_collect = []\n",
    "    m = max(int(frac * num_users) ,1)\n",
    "    idxs_users = np.random.choice(range(num_users), m, replace = False)\n",
    "    w_locals_client = []\n",
    "\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    tpr_list = []\n",
    "    fpr_list = []\n",
    "    f1_list = []\n",
    "    auc_list = []\n",
    "\n",
    "    for idx in idxs_users:\n",
    "        local = Client(device, idx, lr, local_epochs, batch_size, dataset_train, dict_user_train[idx], dict_user_test[idx])\n",
    "        local.local_initialization(net = copy.deepcopy(net_glob).to(device))\n",
    "        w_client, client_loss, client_acc = local.train(net = copy.deepcopy(net_local[idx]).to(device))\n",
    "        w_locals_client.append(copy.deepcopy(w_client))\n",
    "        loss, acc, tpr, fpr, f1, auc = local.evaluate(net = copy.deepcopy(net_glob).to(device), ell=iter)\n",
    "\n",
    "        loss_list.append(loss)\n",
    "        acc_list.append(acc)\n",
    "        tpr_list.append(tpr)\n",
    "        fpr_list.append(fpr)\n",
    "        f1_list.append(f1)\n",
    "        auc_list.append(auc)\n",
    "\n",
    "    local_testing[\"loss\"].append(sum(loss_list)/len(loss_list))\n",
    "    local_testing[\"acc\"].append(sum(acc_list)/len(acc_list))\n",
    "    local_testing[\"tpr\"].append(sum(tpr_list)/len(tpr_list))\n",
    "    local_testing[\"fpr\"].append(sum(fpr_list)/len(fpr_list))\n",
    "    local_testing[\"f1\"].append(sum(f1_list)/len(f1_list))\n",
    "    local_testing[\"auc\"].append(sum(auc_list)/len(auc_list))\n",
    "    print(\"Test =>                 \\tLoss: {:.10f} \\tAcc: {:.10f} \\tTPR:{:.10f} \\tFPR:{:.10f} \\tF1:{:.10f} \\tAUC:{:.10f}\".format(sum(loss_list)/len(loss_list), sum(acc_list)/len(acc_list), sum(tpr_list)/len(tpr_list), sum(fpr_list)/len(fpr_list), sum(f1_list)/len(f1_list), sum(auc_list)/len(auc_list)  ))\n",
    "\n",
    "\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "    print(\"-------------- FedServer: Federation process  -------------\")\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "    w_net_glob = FedAvg(w_locals_client)\n",
    "    net_glob.load_state_dict(w_net_glob)\n",
    "elapsed = format_time(time.time()-t0)\n",
    "print(\"Training and Test completed! total time cost: {:}\".format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Final Result =============\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.09030257900745499 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.11258057802915573398\n",
      "Client0 Test =>                 \tLoss: 0.2191743991 \tAcc: 0.9368990385 \tTPR:0.9414348881 \tFPR:0.1007936508 \tF1:0.9580695928 \tAUC:0.9203206186 \ttest cost: 0:00:00\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.0480001013216993 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.12074058825965039432\n",
      "Client1 Test =>                 \tLoss: 0.2373640380 \tAcc: 0.9405824830 \tTPR:0.9422011662 \tFPR:0.0603162390 \tF1:0.7251260089 \tAUC:0.9396054799 \ttest cost: 0:00:10\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.06108191821559797 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.06357105617115105245\n",
      "Client2 Test =>                 \tLoss: 0.1961861707 \tAcc: 0.9464597902 \tTPR:0.9495960051 \tFPR:0.0653291153 \tF1:0.9653622795 \tAUC:0.9421334449 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.056934118684086446 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.04919350198906613514\n",
      "Client3 Test =>                 \tLoss: 0.1904948581 \tAcc: 0.9522569444 \tTPR:0.9646709930 \tFPR:0.0583054314 \tF1:0.9451406035 \tAUC:0.9531827808 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.04252709100668911 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.08291732387758952993\n",
      "Client4 Test =>                 \tLoss: 0.2210591642 \tAcc: 0.9455808081 \tTPR:0.9471900308 \tFPR:0.0578355031 \tF1:0.9558556964 \tAUC:0.9446238125 \ttest cost: 0:00:17\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.06454186168098872 \tALA epochs: 3\n",
      "Client 5: Local Initial ALA epochs: 3 Loss: 0.12515765736129003116\n",
      "Client5 Test =>                 \tLoss: 0.2402477615 \tAcc: 0.9400922483 \tTPR:0.9441359080 \tFPR:0.0590280854 \tF1:0.7978307658 \tAUC:0.9423689308 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.036114557890706216 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.05566194143853839954\n",
      "Client6 Test =>                 \tLoss: 0.2269634757 \tAcc: 0.9451513639 \tTPR:0.9500545840 \tFPR:0.0602153020 \tF1:0.9420264306 \tAUC:0.9449196410 \ttest cost: 0:00:06\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.020662201374471792 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.02562515891622751951\n",
      "Client7 Test =>                 \tLoss: 0.1760731248 \tAcc: 0.9583333333 \tTPR:0.9506751535 \tFPR:0.0280094633 \tF1:0.9665206519 \tAUC:0.9613328451 \ttest cost: 0:00:01\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.09576643887889212 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.06755692681381061937\n",
      "Client8 Test =>                 \tLoss: 0.1985048992 \tAcc: 0.9485109718 \tTPR:0.9516843064 \tFPR:0.0625339603 \tF1:0.9647446343 \tAUC:0.9445751731 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.07666370912082004 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.12513294282623313447\n",
      "Client9 Test =>                 \tLoss: 0.2001783912 \tAcc: 0.9435096154 \tTPR:0.9464125846 \tFPR:0.0659090909 \tF1:0.9686233103 \tAUC:0.9382210727 \ttest cost: 0:00:01\n"
     ]
    }
   ],
   "source": [
    "idx_collect = [i for i in range(num_users)]\n",
    "print(\"============= Final Result =============\")\n",
    "for idx in idx_collect:\n",
    "    loss_test_collect[idx] = []\n",
    "    acc_test_collect[idx] = []\n",
    "    TPR_test_collect[idx] = []\n",
    "    FPR_test_collect[idx] = []\n",
    "    f1_test_collect[idx] = []\n",
    "    AUC_test_collect[idx] = []\n",
    "    local = Client(device, idx, lr, local_epochs, batch_size, dataset_train, dict_user_train[idx], dict_user_test[idx])\n",
    "    local.local_initialization(net = copy.deepcopy(net_glob).to(device))\n",
    "    loss, acc, tpr, fpr, f1, auc = local.evaluate(net = copy.deepcopy(net_local[idx]).to(device), ell=0)\n",
    "    loss_test_collect[idx].append(loss)\n",
    "    acc_test_collect[idx].append(acc)\n",
    "    TPR_test_collect[idx].append(tpr)\n",
    "    FPR_test_collect[idx].append(fpr)\n",
    "    f1_test_collect[idx].append(f1)\n",
    "    AUC_test_collect[idx].append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import xlwt\n",
    "f = xlwt.Workbook('encoding = utf-8')\n",
    "sheet1 = f.add_sheet('sheet1',cell_overwrite_ok=True)\n",
    "for i in range(len(loss_collect)):\n",
    "    sheet1.write(i+1,0,loss_collect[i])\n",
    "for i in range(len(acc_collect)):\n",
    "    sheet1.write(i+1,1,acc_collect[i])\n",
    "for i in range(len(TPR_collect)):\n",
    "    sheet1.write(i+1,2,TPR_collect[i])\n",
    "for i in range(len(FPR_collect)):\n",
    "    sheet1.write(i+1,3,FPR_collect[i])\n",
    "for i in range(len(F1_collect)):\n",
    "    sheet1.write(i+1,4,F1_collect[i])\n",
    "for i in range(len(AUC_collect)):\n",
    "    sheet1.write(i+1,5,AUC_collect[i])\n",
    "\n",
    "f.save('result.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(num_users):\n",
    "    f = xlwt.Workbook('encoding = utf-8')\n",
    "    sheet1 = f.add_sheet('sheet1', cell_overwrite_ok=True)\n",
    "    for j in range(len(loss_train_collect[i])):\n",
    "        sheet1.write(j+1, 0, loss_train_collect[i][j])\n",
    "    for j in range(len(acc_train_collect[i])):\n",
    "        sheet1.write(j+1, 1, acc_train_collect[i][j])\n",
    "    for j in range(len(TPR_train_collect[i])):\n",
    "        sheet1.write(j+1, 2, TPR_train_collect[i][j])\n",
    "    for j in range(len(FPR_train_collect[i])):\n",
    "        sheet1.write(j+1, 3, FPR_train_collect[i][j])\n",
    "    for j in range(len(f1_train_collect[i])):\n",
    "        sheet1.write(j+1, 4, f1_train_collect[i][j])\n",
    "    for j in range(len(AUC_train_collect[i])):\n",
    "        sheet1.write(j+1, 5, AUC_train_collect[i][j])\n",
    "\n",
    "    f.save('result_client{:}.xls'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(num_users):\n",
    "    f = xlwt.Workbook('encoding = utf-8')\n",
    "    sheet1 = f.add_sheet('sheet1', cell_overwrite_ok=True)\n",
    "    for j in range(len(loss_test_collect[i])):\n",
    "        sheet1.write(j+1, 0, loss_test_collect[i][j])\n",
    "    for j in range(len(acc_test_collect[i])):\n",
    "        sheet1.write(j+1, 1, acc_test_collect[i][j])\n",
    "    for j in range(len(TPR_test_collect[i])):\n",
    "        sheet1.write(j+1, 2, TPR_test_collect[i][j])\n",
    "    for j in range(len(FPR_test_collect[i])):\n",
    "        sheet1.write(j+1, 3, FPR_test_collect[i][j])\n",
    "    for j in range(len(f1_test_collect[i])):\n",
    "        sheet1.write(j+1, 4, f1_test_collect[i][j])\n",
    "    for j in range(len(AUC_test_collect[i])):\n",
    "        sheet1.write(j+1, 5, AUC_test_collect[i][j])\n",
    "\n",
    "    f.save('result_test_client{:}.xls'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import xlwt\n",
    "f = xlwt.Workbook('encoding = utf-8')\n",
    "sheet1 = f.add_sheet('sheet1',cell_overwrite_ok=True)\n",
    "for i in range(len(local_test[\"loss\"])):\n",
    "    sheet1.write(i+1,0,local_test[\"loss\"][i])\n",
    "for i in range(len(local_test[\"acc\"])):\n",
    "    sheet1.write(i+1,1,local_test[\"acc\"][i])\n",
    "for i in range(len(local_test[\"tpr\"])):\n",
    "    sheet1.write(i+1,2,local_test[\"tpr\"][i])\n",
    "for i in range(len(local_test[\"fpr\"])):\n",
    "    sheet1.write(i+1,3,local_test[\"fpr\"][i])\n",
    "for i in range(len(local_test[\"f1\"])):\n",
    "    sheet1.write(i+1,4,local_test[\"f1\"][i])\n",
    "for i in range(len(local_test[\"auc\"])):\n",
    "    sheet1.write(i+1,5,local_test[\"auc\"][i])\n",
    "\n",
    "f.save('Local_Test.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import xlwt\n",
    "f = xlwt.Workbook('encoding = utf-8')\n",
    "sheet1 = f.add_sheet('sheet1',cell_overwrite_ok=True)\n",
    "for i in range(len(local_testing[\"loss\"])):\n",
    "    sheet1.write(i+1,0,local_testing[\"loss\"][i])\n",
    "for i in range(len(local_testing[\"acc\"])):\n",
    "    sheet1.write(i+1,1,local_testing[\"acc\"][i])\n",
    "for i in range(len(local_testing[\"tpr\"])):\n",
    "    sheet1.write(i+1,2,local_testing[\"tpr\"][i])\n",
    "for i in range(len(local_testing[\"fpr\"])):\n",
    "    sheet1.write(i+1,3,local_testing[\"fpr\"][i])\n",
    "for i in range(len(local_testing[\"f1\"])):\n",
    "    sheet1.write(i+1,4,local_testing[\"f1\"][i])\n",
    "for i in range(len(local_testing[\"auc\"])):\n",
    "    sheet1.write(i+1,5,local_testing[\"auc\"][i])\n",
    "\n",
    "f.save('Local_Testing.xls')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
