{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "df_train = pd.read_csv(\"./fine_tuning.csv\")\n",
    "\n",
    "train_data_domain = df_train.domain.values\n",
    "train_data_label = df_train.label.values\n",
    "train_data_label = train_data_label.tolist()\n",
    "train_data_label = [0 if item == 2 else 1 for item in train_data_label]\n",
    "train_data_label = np.array(train_data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer(vocab_file=\"./bert_tokenizer/vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "input_ids_train = []\n",
    "attention_masks_train = []\n",
    "\n",
    "for sent in train_data_domain:\n",
    "\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        sent,                      # Sentence to encode.\n",
    "        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "        max_length = 64,           # Pad & truncate all sentences.\n",
    "        pad_to_max_length = True,\n",
    "        return_attention_mask = True,   # Construct attn. masks.\n",
    "        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "    )\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_train.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks_train.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_train = torch.cat(input_ids_train, dim=0)\n",
    "attention_masks_train = torch.cat(attention_masks_train, dim=0)\n",
    "labels_train = torch.tensor(train_data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111,998 training samples\n",
      "48,000 test samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train) # 打包处理，所以数据第一维必须相等\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.7 * len(dataset_train))\n",
    "test_size = len(dataset_train) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset_train, [train_size, test_size])\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} test samples'.format(test_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "构造MyModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "EmbeddingPath = \"./FedBert/FedTransformer.pt\"\n",
    "TransformerPath = \"./FedBert/FedEmbedding.pt\"\n",
    "num_users = 10\n",
    "frac = 0.5\n",
    "local_epochs = 5\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_name_or_path\": \"./bert-base-uncased-model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.2,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.34.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 1000\n",
      "}\n",
      "\n",
      "BertPooler(\n",
      "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (activation): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoTokenizer,DataCollatorForLanguageModeling,HfArgumentParser,Trainer,TrainingArguments,set_seed,\n",
    ")\n",
    "# 自己修改部分配置参数\n",
    "config_kwargs = {\n",
    "    \"cache_dir\": None,\n",
    "    \"revision\": 'main',\n",
    "    \"use_auth_token\": None,\n",
    "    #      \"hidden_size\": 512,\n",
    "    #     \"num_attention_heads\": 4,\n",
    "    \"hidden_dropout_prob\": 0.2,\n",
    "    \"vocab_size\": 1000 # 自己设置词汇大小\n",
    "}\n",
    "# 将模型的配置参数载入\n",
    "config = AutoConfig.from_pretrained('./bert-base-uncased-model/', **config_kwargs)\n",
    "print(config)\n",
    "# 载入预训练模型\n",
    "model = AutoModelForMaskedLM.from_config(\n",
    "    config=config,\n",
    ")\n",
    "model.resize_token_embeddings(config_kwargs[\"vocab_size\"])\n",
    "\n",
    "embedding = model.bert.embeddings\n",
    "\n",
    "class Bert_Embedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Bert_Embedding, self).__init__()\n",
    "        self.embeddings = copy.deepcopy(embedding)\n",
    "\n",
    "    def forward(self, input_ids, attn_mask):\n",
    "        embedding_output = self.embeddings(input_ids, attn_mask)\n",
    "        return embedding_output\n",
    "\n",
    "embedding_model = Bert_Embedding()\n",
    "embedding_model.load_state_dict(torch.load(EmbeddingPath))\n",
    "\n",
    "encoder = model.bert.encoder\n",
    "cls = model.cls\n",
    "\n",
    "class Bert_Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Bert_Encoder, self).__init__()\n",
    "        self.encoder = copy.deepcopy(encoder)\n",
    "        self.cls = copy.deepcopy(cls)\n",
    "\n",
    "    def forward(self, embedding_output):\n",
    "        output_encoder = self.encoder(embedding_output).last_hidden_state\n",
    "        return output_encoder\n",
    "encoder_model = Bert_Encoder()\n",
    "encoder_model.load_state_dict(torch.load(TransformerPath))\n",
    "\n",
    "from transformers.models.bert.modeling_bert import BertPooler\n",
    "class Pooler_Config:\n",
    "    def __init__(self, entries: dict={}):\n",
    "        for k, v in entries.items():\n",
    "            if isinstance(v, dict):\n",
    "                self.__dict__[k] = Pooler_Config(v)\n",
    "            else:\n",
    "                self.__dict__[k] = v\n",
    "\n",
    "config_pooler = {\"hidden_size\": 768}\n",
    "config_pooler = Pooler_Config(config_pooler)\n",
    "pooler = BertPooler(config_pooler)\n",
    "print(pooler)\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, hidden_size=768, num_classes=2, freeze_bert=False):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.embedding = Bert_Embedding()\n",
    "        self.encoder = Bert_Encoder()\n",
    "        self.pooler = copy.deepcopy(pooler)\n",
    "        if freeze_bert:\n",
    "            for p in self.embedding.parameters():\n",
    "                p.requires_grad = False\n",
    "            for p in self.encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(hidden_size, num_classes, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attn_mask):\n",
    "        embedding_outputs = self.embedding(input_ids, attn_mask)\n",
    "        encoder_outputs = self.encoder(embedding_outputs)\n",
    "        pooler_outputs = self.pooler(encoder_outputs)\n",
    "        #它代表了一句话的embedding\n",
    "        logits = self.fc(pooler_outputs)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "iid数据分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def dataset_iid(dataset, num_users):\n",
    "\n",
    "    num_items = int(len(dataset)/num_users)\n",
    "    dict_users, all_idxs = {}, [i for i in range(len(dataset))]\n",
    "    for i in range(num_users):\n",
    "        dict_users[i] = set(np.random.choice(all_idxs, num_items, replace = False))\n",
    "        all_idxs = list(set(all_idxs) - dict_users[i])\n",
    "    return dict_users\n",
    "\n",
    "# train_dataset[:][:][1]\n",
    "def dirichlet_split_noniid(train_labels, num_users):\n",
    "    '''\n",
    "    按照参数为alpha的Dirichlet分布将样本索引集合划分为n_clients个子集\n",
    "    '''\n",
    "    alpha = 0.7\n",
    "    n_classes = 2\n",
    "    # (K, N) 类别标签分布矩阵X，记录每个类别划分到每个client去的比例\n",
    "    label_distribution = np.random.dirichlet([alpha]*num_users, n_classes)\n",
    "    # (K, ...) 记录K个类别对应的样本索引集合\n",
    "    class_idcs = [np.argwhere(train_labels == y).flatten()\n",
    "                  for y in range(n_classes)]\n",
    "\n",
    "    # 记录N个client分别对应的样本索引集合\n",
    "    client_idcs = [[] for _ in range(num_users)]\n",
    "    for k_idcs, fracs in zip(class_idcs, label_distribution):\n",
    "        # np.split按照比例fracs将类别为k的样本索引k_idcs划分为了N个子集\n",
    "        # i表示第i个client，idcs表示其对应的样本索引集合idcs\n",
    "        for i, idcs in enumerate(np.split(k_idcs,\n",
    "                                          (np.cumsum(fracs)[:-1]*len(k_idcs)).\n",
    "                                                  astype(int))):\n",
    "            client_idcs[i] += [idcs]\n",
    "\n",
    "    dict_users = [np.concatenate(idcs) for idcs in client_idcs]\n",
    "\n",
    "    return dict_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "dict_user_train = dirichlet_split_noniid(train_dataset[:][:][:][2], num_users)\n",
    "dict_user_test = dataset_iid(test_dataset, num_users)\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it\n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch\n",
    "# size of 16 or 32.\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (embedding): Bert_Embedding(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(1000, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (encoder): Bert_Encoder(\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cls): Sequential()\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=768, out_features=2, bias=False)\n",
      "    (2): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net_glob = MyModel()\n",
    "net_glob.encoder.cls = nn.Sequential()\n",
    "print(net_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 训练loss记录\n",
    "loss_train_collect = {}\n",
    "# 训练acc记录\n",
    "acc_train_collect = {}\n",
    "loss_test_collect = {}\n",
    "# 测试acc记录\n",
    "acc_test_collect = {}\n",
    "# 训练TPR记录\n",
    "TPR_train_collect = {}\n",
    "# 测试TPR记录\n",
    "TPR_test_collect = {}\n",
    "# 训练FPR记录\n",
    "FPR_train_collect = {}\n",
    "# 测试FPR记录\n",
    "FPR_test_collect = {}\n",
    "# 训练测试F1-score记录\n",
    "f1_train_collect = {}\n",
    "f1_test_collect = {}\n",
    "# 训练测试AUC记录\n",
    "AUC_train_collect = {}\n",
    "AUC_test_collect = {}\n",
    "# 训练测试ROC曲线记录\n",
    "ROC_train_collect = {}\n",
    "ROC_test_collect = {}\n",
    "\n",
    "local_test = {}\n",
    "local_testing = {}\n",
    "\n",
    "loss_collect = []\n",
    "acc_collect = []\n",
    "TPR_collect = []\n",
    "FPR_collect = []\n",
    "F1_collect = []\n",
    "AUC_collect = []\n",
    "\n",
    "count1 = 0\n",
    "count2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def FedAvg(w):\n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    for k in w_avg.keys():\n",
    "        for i in range(1, len(w)):\n",
    "            w_avg[k] += w[i][k]\n",
    "        w_avg[k] = torch.div(w_avg[k], len(w))\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "idx_collect = []\n",
    "l_epoch_check = False\n",
    "fed_check = False\n",
    "# Initialization of net_model_server and net_server (server-side model)\n",
    "net_model = [net_glob for i in range(num_users)]\n",
    "net_server = copy.deepcopy(net_model[0]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "class DatasetSplit(Dataset):\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = list(idxs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        domain, mask, label = self.dataset[self.idxs[item]]\n",
    "        return domain, mask, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    return np.sum(preds == labels) / len(labels)\n",
    "\n",
    "def tpr_calculate(preds, labels):\n",
    "    return recall_score(labels, preds,zero_division=1)\n",
    "\n",
    "def fpr_calculate(preds, labels):\n",
    "    conf_matrix = confusion_matrix(labels, preds)\n",
    "    #print(conf_matrix)\n",
    "    fp = conf_matrix[0, 1]  # 0 表示负类别，1 表示正类别\n",
    "    tn = conf_matrix[0, 0]\n",
    "    fpr = fp / (fp + tn)\n",
    "    return fpr\n",
    "\n",
    "def f1_score_calculate(preds, labels):\n",
    "    return f1_score(labels, preds, zero_division=1)\n",
    "\n",
    "def AUC_calculate(preds, labels):\n",
    "    return roc_auc_score(labels, preds)\n",
    "\n",
    "def roc_curve_calculate(preds, labels):\n",
    "    return roc_curve(labels, preds)\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Client(object):\n",
    "    def __init__(self, device, idx, lr, local_epochs, batch_size, dataset_train = None, dataset_test = None, idxs = None, idxs_test = None):\n",
    "        self.device = device\n",
    "        self.lr = lr\n",
    "        self.idx = idx\n",
    "        self.local_ep = local_epochs\n",
    "        self.ldr_train = DataLoader(DatasetSplit(dataset_train, idxs), batch_size = batch_size, shuffle = True)\n",
    "        self.ldr_test = DataLoader(DatasetSplit(dataset_test, idxs_test), batch_size = batch_size, shuffle= True)\n",
    "        self.ala = ALA(idx, idxs, criterion, dataset_train, batch_size, 20, 0, lr*4, self.device, 0.1, 10)\n",
    "\n",
    "    def local_initialization(self, net):\n",
    "        print(\"local_initialization!\")\n",
    "        local_model = net_local[self.idx].to(self.device)\n",
    "        self.ala.adaptive_local_aggregation(net, local_model)\n",
    "\n",
    "    def train(self, net):\n",
    "        net.train()\n",
    "        optimizer_client = torch.optim.Adam(net.parameters(), lr = self.lr)\n",
    "\n",
    "        TPR_train_collect[self.idx] = []\n",
    "        FPR_train_collect[self.idx] = []\n",
    "        f1_train_collect[self.idx] = []\n",
    "        AUC_train_collect[self.idx] = []\n",
    "        loss_train_collect[self.idx] = []\n",
    "        acc_train_collect[self.idx] = []\n",
    "\n",
    "        epoch_loss = []\n",
    "        epoch_accuracy = []\n",
    "        for iter in range(self.local_ep):\n",
    "            tmp_t0 = time.time()\n",
    "            batch_loss_train = []\n",
    "            batch_acc_train = []\n",
    "            batch_tpr_train = []\n",
    "            batch_fpr_train = []\n",
    "            batch_f1_train = []\n",
    "            batch_auc_train = []\n",
    "            for batch_idx, (ids, attn_mask, b_labels) in enumerate(self.ldr_train):\n",
    "                ids, attn_mask, b_labels = ids.to(self.device), attn_mask.to(self.device), b_labels.to(self.device)\n",
    "                optimizer_client.zero_grad()\n",
    "                b_labels = b_labels.unsqueeze(1)\n",
    "                b_labels = b_labels.repeat(1,2)\n",
    "                for i in range(len(b_labels)):\n",
    "                    b_labels[i][1] = 1-b_labels[i][0]\n",
    "                logits = net(ids, attn_mask)\n",
    "                BCEloss = criterion(logits, b_labels.float())\n",
    "                BCEloss.backward()\n",
    "                optimizer_client.step()\n",
    "                batch_loss_train.append(BCEloss.item())\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                label_ids = b_labels.to('cpu').numpy()\n",
    "                logits = np.argmax(logits, axis=1).flatten()\n",
    "                label_ids = np.argmax(label_ids,axis=1).flatten()\n",
    "                accuracy = flat_accuracy(logits, label_ids)\n",
    "                tpr = tpr_calculate(logits, label_ids)\n",
    "                if len(set(label_ids)) == 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    fpr = fpr_calculate(logits, label_ids)\n",
    "                    batch_fpr_train.append(fpr)\n",
    "                f1 = f1_score_calculate(logits, label_ids)\n",
    "                if len(set(label_ids)) == 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    auc = AUC_calculate(logits, label_ids)\n",
    "                    batch_auc_train.append(auc)\n",
    "                batch_acc_train.append(accuracy)\n",
    "                batch_tpr_train.append(tpr)\n",
    "                batch_f1_train.append(f1)\n",
    "            elapsed = format_time(time.time()-tmp_t0)\n",
    "            epoch_avg_loss = sum(batch_loss_train)/len(batch_loss_train)\n",
    "            epoch_avg_acc = sum(batch_acc_train)/len(batch_acc_train)\n",
    "            epoch_avg_tpr = sum(batch_tpr_train)/len(batch_tpr_train)\n",
    "            epoch_avg_fpr = sum(batch_fpr_train)/len(batch_fpr_train)\n",
    "            epoch_avg_f1 = sum(batch_f1_train)/len(batch_f1_train)\n",
    "            epoch_avg_auc = sum(batch_auc_train)/len(batch_auc_train)\n",
    "            epoch_loss.append(sum(batch_loss_train)/len(batch_loss_train))\n",
    "            epoch_accuracy.append(sum(batch_acc_train)/len(batch_acc_train))\n",
    "            loss_train_collect[self.idx].append(epoch_avg_loss)\n",
    "            acc_train_collect[self.idx].append(epoch_avg_acc)\n",
    "            TPR_train_collect[self.idx].append(epoch_avg_tpr)\n",
    "            FPR_train_collect[self.idx].append(epoch_avg_fpr)\n",
    "            f1_train_collect[self.idx].append(epoch_avg_f1)\n",
    "            AUC_train_collect[self.idx].append(epoch_avg_auc)\n",
    "            loss_collect.append(epoch_avg_loss)\n",
    "            acc_collect.append(epoch_avg_acc)\n",
    "            TPR_collect.append(epoch_avg_tpr)\n",
    "            FPR_collect.append(epoch_avg_fpr)\n",
    "            F1_collect.append(epoch_avg_f1)\n",
    "            AUC_collect.append(epoch_avg_auc)\n",
    "\n",
    "            print('Client{} Local Train => Local Epoch: {} \\tLoss: {:.10f} \\tAcc: {:.10f} \\tTPR:{:.10f} \\tFPR:{:.10f} \\tF1:{:.10f} \\t AUC:{:.10f}\\tTrain cost: {:}'.format(self.idx, iter, epoch_avg_loss, \\\n",
    "                                                                                                                                                                           epoch_avg_acc, epoch_avg_tpr, epoch_avg_fpr, epoch_avg_f1, epoch_avg_auc, elapsed))\n",
    "        net_glob.load_state_dict(net.state_dict())\n",
    "        return net.state_dict(), sum(epoch_loss) / len(epoch_loss), sum(epoch_accuracy) / len(epoch_accuracy)\n",
    "\n",
    "    def evaluate(self, net, ell):\n",
    "        net.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tmp_t0 = time.time()\n",
    "            len_batch = len(self.ldr_test)\n",
    "\n",
    "            batch_acc_test = []\n",
    "            batch_loss_test = []\n",
    "            batch_tpr_test = []\n",
    "            batch_fpr_test = []\n",
    "            batch_f1_test = []\n",
    "            batch_auc_test = []\n",
    "            for batch_idx, (ids, attn_mask, b_labels) in enumerate(self.ldr_test):\n",
    "                ids, attn_mask, b_labels = ids.to(self.device), attn_mask.to(self.device), b_labels.to(self.device)\n",
    "                b_labels = b_labels.unsqueeze(1)\n",
    "                b_labels = b_labels.repeat(1,2)\n",
    "                for i in range(len(b_labels)):\n",
    "                    b_labels[i][1] = 1-b_labels[i][0]\n",
    "                logits = net(ids, attn_mask)\n",
    "                BCEloss = criterion(logits, b_labels.float())\n",
    "                batch_loss_test.append(BCEloss.item())\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                label_ids = b_labels.to('cpu').numpy()\n",
    "                logits = np.argmax(logits, axis=1).flatten()\n",
    "                label_ids = np.argmax(label_ids,axis=1).flatten()\n",
    "                accuracy = flat_accuracy(logits, label_ids)\n",
    "                tpr = tpr_calculate(logits, label_ids)\n",
    "                if len(set(label_ids)) == 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    fpr = fpr_calculate(logits, label_ids)\n",
    "                    batch_fpr_test.append(fpr)\n",
    "                f1 = f1_score_calculate(logits, label_ids)\n",
    "                if len(set(label_ids)) == 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    auc = AUC_calculate(logits, label_ids)\n",
    "                    batch_auc_test.append(auc)\n",
    "                batch_acc_test.append(accuracy)\n",
    "                batch_tpr_test.append(tpr)\n",
    "                batch_f1_test.append(f1)\n",
    "            elapsed = format_time(time.time()-tmp_t0)\n",
    "            test_avg_loss = sum(batch_loss_test) / len(batch_loss_test)\n",
    "            test_avg_acc = sum(batch_acc_test) / len(batch_acc_test)\n",
    "            test_avg_tpr = sum(batch_tpr_test)/len(batch_tpr_test)\n",
    "            test_avg_fpr = sum(batch_fpr_test) / len(batch_fpr_test)\n",
    "            test_avg_f1 = sum(batch_f1_test)/len(batch_f1_test)\n",
    "            test_avg_auc = sum(batch_auc_test)/len(batch_auc_test)\n",
    "            local_test[\"loss\"].append(test_avg_loss)\n",
    "            local_test[\"acc\"].append(test_avg_acc)\n",
    "            local_test[\"tpr\"].append(test_avg_tpr)\n",
    "            local_test[\"fpr\"].append(test_avg_fpr)\n",
    "            local_test[\"f1\"].append(test_avg_f1)\n",
    "            local_test[\"auc\"].append(test_avg_auc)\n",
    "            print('Client{} Test =>                 \\tLoss: {:.10f} \\tAcc: {:.10f} \\tTPR:{:.10f} \\tFPR:{:.10f} \\tF1:{:.10f} \\tAUC:{:.10f} \\ttest cost: {:}'.format(self.idx, test_avg_loss, test_avg_acc, test_avg_tpr, test_avg_fpr, test_avg_f1, test_avg_auc, elapsed))\n",
    "\n",
    "        return test_avg_loss, test_avg_acc, test_avg_tpr, test_avg_fpr, test_avg_f1, test_avg_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class ALA:\n",
    "    def __init__(self,\n",
    "                 cid: int,\n",
    "                 idxs,\n",
    "                 loss,\n",
    "                 train_data: TensorDataset,\n",
    "                 batch_size: int,\n",
    "                 rand_percent: int,\n",
    "                 layer_idx: int = 0,\n",
    "                 eta: float = 1.0,\n",
    "                 device: str = 'cpu',\n",
    "                 threshold: float = 0.1,\n",
    "                 num_pre_loss: int = 10) -> None:\n",
    "        \"\"\"\n",
    "        Initialize ALA module\n",
    "\n",
    "        Args:\n",
    "            cid: Client ID.\n",
    "            loss: The loss function.\n",
    "            train_data: The reference of the local training data.\n",
    "            batch_size: Weight learning batch size.\n",
    "            rand_percent: The percent of the local training data to sample.\n",
    "            layer_idx: Control the weight range. By default, all the layers are selected. Default: 0\n",
    "            eta: Weight learning rate. Default: 1.0\n",
    "            device: Using cuda or cpu. Default: 'cpu'\n",
    "            threshold: Train the weight until the standard deviation of the recorded losses is less than a given threshold. Default: 0.1\n",
    "            num_pre_loss: The number of the recorded losses to be considered to calculate the standard deviation. Default: 10\n",
    "\n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "\n",
    "        self.cid = cid\n",
    "        self.idxs = idxs\n",
    "        self.loss = loss\n",
    "        self.train_data = train_data\n",
    "        self.batch_size = batch_size\n",
    "        self.rand_percent = rand_percent\n",
    "        self.layer_idx = layer_idx\n",
    "        self.eta = eta\n",
    "        self.threshold = threshold\n",
    "        self.num_pre_loss = num_pre_loss\n",
    "        self.device = device\n",
    "\n",
    "        self.weights = None # Learnable local aggregation weights.\n",
    "        self.start_phase = True\n",
    "\n",
    "\n",
    "    def adaptive_local_aggregation(self,\n",
    "                                   global_model: nn.Module,\n",
    "                                   local_model: nn.Module) -> None:\n",
    "        \"\"\"\n",
    "        Generates the Dataloader for the randomly sampled local training data and\n",
    "        preserves the lower layers of the update.\n",
    "\n",
    "        Args:\n",
    "            global_model: The received global/aggregated model.\n",
    "            local_model: The trained local model.\n",
    "\n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "\n",
    "        # randomly sample partial local training data\n",
    "        rand_ratio = self.rand_percent / 100\n",
    "        rand_loader = DataLoader(DatasetSplit(self.train_data, self.idxs), self.batch_size, drop_last=True, shuffle=True)\n",
    "        rand_num = int(rand_ratio*len(rand_loader))\n",
    "\n",
    "\n",
    "        # obtain the references of the parameters\n",
    "        params_g = list(global_model.parameters())\n",
    "        params = list(local_model.parameters())\n",
    "\n",
    "        # deactivate ALA at the 1st communication iteration\n",
    "        if torch.sum(params_g[-1] - params[-1]) == 0:\n",
    "            print(\"deactivate ALA\")\n",
    "            return\n",
    "\n",
    "        # preserve all the updates in the lower layers\n",
    "        for param, param_g in zip(params[:-self.layer_idx], params_g[:-self.layer_idx]):\n",
    "            param.data = param_g.data.clone()\n",
    "\n",
    "\n",
    "        # temp local model only for weight learning\n",
    "        model_t = copy.deepcopy(local_model)\n",
    "        params_t = list(model_t.parameters())\n",
    "        params_t[-1].requires_grad_()\n",
    "\n",
    "        # only consider higher layers\n",
    "        params_p = params[-self.layer_idx:]\n",
    "        params_gp = params_g[-self.layer_idx:]\n",
    "        params_tp = params_t[-self.layer_idx:]\n",
    "\n",
    "\n",
    "        # used to obtain the gradient of higher layers\n",
    "        # no need to use optimizer.step(), so lr=0\n",
    "        optimizer = torch.optim.Adam(params_tp, lr = lr)\n",
    "\n",
    "        # initialize the weight to all ones in the beginning\n",
    "        if self.weights == None:\n",
    "            self.weights = [torch.ones_like(param.data).to(self.device) for param in params_p]\n",
    "\n",
    "        # initialize the higher layers in the temp local model\n",
    "        for param_t, param, param_g, weight in zip(params_tp, params_p, params_gp,\n",
    "                                                   self.weights):\n",
    "            param_t.data = param + (param_g - param) * weight\n",
    "\n",
    "        # weight learning\n",
    "        losses = []  # record losses\n",
    "        losses_round = []\n",
    "        cnt = 0  # weight training iteration counter\n",
    "        while True:\n",
    "            for batch_idx, (x, m , y) in enumerate(rand_loader):\n",
    "                if batch_idx >= rand_num:\n",
    "                    break\n",
    "                x = x.to(self.device)\n",
    "                m = m.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                y = y.unsqueeze(1)\n",
    "                y = y.repeat(1,2)\n",
    "                for i in range(len(y)):\n",
    "                    y[i][1] = 1-y[i][0]\n",
    "                optimizer.zero_grad()\n",
    "                output = model_t(x, m)\n",
    "                loss_value = self.loss(output, y.float()) # modify according to the local objective\n",
    "                losses.append(loss_value.item())\n",
    "                loss_value.backward()\n",
    "\n",
    "                # update weight in this batch\n",
    "                for param_t, param, param_g, weight in zip(params_tp, params_p,\n",
    "                                                           params_gp, self.weights):\n",
    "                    #print(\"param_t.grad:\",param_t.requires_grad)\n",
    "                    #print(\"param_g - param:\",type(param_g - param))\n",
    "                    weight.data = torch.clamp(weight - self.eta * (param_t.grad * (param_g - param)), 0, 1)\n",
    "\n",
    "                # update temp local model in this batch\n",
    "                for param_t, param, param_g, weight in zip(params_tp, params_p,\n",
    "                                                           params_gp, self.weights):\n",
    "                    param_t.data = param + (param_g - param) * weight\n",
    "\n",
    "            losses_round.append(sum(losses) / len(losses))\n",
    "            cnt += 1\n",
    "\n",
    "            # only train one epoch in the subsequent iterations\n",
    "            if not self.start_phase:\n",
    "                break\n",
    "\n",
    "            # train the weight until convergence\n",
    "            if len(losses_round) > self.num_pre_loss or np.std(losses[-self.num_pre_loss:]) < self.threshold:\n",
    "                print('Client:', self.cid, '\\tStd:', np.std(losses[-self.num_pre_loss:]),\n",
    "                      '\\tALA epochs:', cnt)\n",
    "                break\n",
    "\n",
    "        self.start_phase = False\n",
    "\n",
    "        # obtain initialized local model\n",
    "        for param, param_t in zip(params_p, params_tp):\n",
    "            param.data = param_t.data.clone()\n",
    "        print(\"Client {}: Local Initial ALA epochs: {} Loss: {:.20f}\".format(self.cid, cnt, losses_round[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test Begin!\n",
      "============== Round 0:  =============\n",
      "local_initialization!\n",
      "deactivate ALA\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.4946515006 \tAcc: 0.7845784024 \tTPR:0.9554121697 \tFPR:0.7764274251 \tF1:0.8689496695 \t AUC:0.5893596704\tTrain cost: 0:00:32\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.4707483554 \tAcc: 0.8028846154 \tTPR:0.9532991431 \tFPR:0.7089138277 \tF1:0.8795974830 \t AUC:0.6221233686\tTrain cost: 0:00:32\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.4134785727 \tAcc: 0.8381102071 \tTPR:0.9658915116 \tFPR:0.5922620782 \tF1:0.9000396764 \t AUC:0.6867597063\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.3652202301 \tAcc: 0.8578032544 \tTPR:0.9597872379 \tFPR:0.4843348959 \tF1:0.9104992223 \t AUC:0.7377261710\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.3129755075 \tAcc: 0.8798076923 \tTPR:0.9617996245 \tFPR:0.3984608616 \tF1:0.9233734644 \t AUC:0.7816127044\tTrain cost: 0:00:34\n",
      "Client8 Test =>                 \tLoss: 0.3871208485 \tAcc: 0.8304166667 \tTPR:0.8959629931 \tFPR:0.2333625660 \tF1:0.8328517191 \tAUC:0.8313002136 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.0828822791027451 \tALA epochs: 8\n",
      "Client 3: Local Initial ALA epochs: 8 Loss: 0.42271091265138238668\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.3979624995 \tAcc: 0.8169762383 \tTPR:0.8185724919 \tFPR:0.1816849165 \tF1:0.7926894210 \t AUC:0.8184437877\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.3959713672 \tAcc: 0.8132530120 \tTPR:0.8024364199 \tFPR:0.1810986142 \tF1:0.7843515744 \t AUC:0.8106689029\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.3748397089 \tAcc: 0.8278530790 \tTPR:0.8340018724 \tFPR:0.1732918513 \tF1:0.8033043674 \t AUC:0.8303550106\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.3719796359 \tAcc: 0.8307396252 \tTPR:0.8231622747 \tFPR:0.1608126100 \tF1:0.8054924297 \t AUC:0.8311748324\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.3511644918 \tAcc: 0.8454233601 \tTPR:0.8508842566 \tFPR:0.1557062404 \tF1:0.8221893133 \t AUC:0.8475890081\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.3879234677 \tAcc: 0.8214583333 \tTPR:0.7225129663 \tFPR:0.0825977371 \tF1:0.7929584752 \tAUC:0.8199576146 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.04091863980656081 \tALA epochs: 2\n",
      "Client 1: Local Initial ALA epochs: 2 Loss: 0.27560459795024466745\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.2098776653 \tAcc: 0.9176169591 \tTPR:0.4460992549 \tFPR:0.0223062338 \tF1:0.4725249937 \t AUC:0.7044113653\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1980150077 \tAcc: 0.9194353070 \tTPR:0.4811351295 \tFPR:0.0248011585 \tF1:0.5068988151 \t AUC:0.7235342634\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1856646967 \tAcc: 0.9261604532 \tTPR:0.5262696409 \tFPR:0.0241635154 \tF1:0.5498596192 \t AUC:0.7442854862\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1780010433 \tAcc: 0.9274945175 \tTPR:0.5474734289 \tFPR:0.0249439143 \tF1:0.5684005742 \t AUC:0.7554979270\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1704427507 \tAcc: 0.9317342836 \tTPR:0.5849802326 \tFPR:0.0241469474 \tF1:0.5956505974 \t AUC:0.7757639546\tTrain cost: 0:01:11\n",
      "Client1 Test =>                 \tLoss: 0.6878347080 \tAcc: 0.7445833333 \tTPR:0.4878818324 \tFPR:0.0107374393 \tF1:0.6398782593 \tAUC:0.7385721966 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.19166954952465903 \tALA epochs: 11\n",
      "Client 0: Local Initial ALA epochs: 11 Loss: 0.98920407186854963921\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.3391216387 \tAcc: 0.8740152311 \tTPR:0.9481061399 \tFPR:0.3973884251 \tF1:0.9200249482 \t AUC:0.7753588574\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.2744472628 \tAcc: 0.9020483193 \tTPR:0.9669752338 \tFPR:0.3443516801 \tF1:0.9389704676 \t AUC:0.8113117768\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.2732277167 \tAcc: 0.8910189076 \tTPR:0.9670921585 \tFPR:0.3636801690 \tF1:0.9325302082 \t AUC:0.8017059947\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.2563571552 \tAcc: 0.9030330882 \tTPR:0.9781904406 \tFPR:0.3667375283 \tF1:0.9397882467 \t AUC:0.8057264561\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.2640556605 \tAcc: 0.9032956933 \tTPR:0.9744922406 \tFPR:0.3490697794 \tF1:0.9398401758 \t AUC:0.8127112306\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.3563645271 \tAcc: 0.8481250000 \tTPR:0.9790745663 \tFPR:0.2883706656 \tF1:0.8619804432 \tAUC:0.8453519503 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.08911997691029411 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.29246497992426156998\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.2803947941 \tAcc: 0.8859126984 \tTPR:0.9460674989 \tFPR:0.2446789322 \tF1:0.9167678762 \t AUC:0.8506942834\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.2637083765 \tAcc: 0.8981894841 \tTPR:0.9543759214 \tFPR:0.2202733405 \tF1:0.9256075913 \t AUC:0.8670512904\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.2701971888 \tAcc: 0.8892609127 \tTPR:0.9435178592 \tFPR:0.2240755111 \tF1:0.9187621580 \t AUC:0.8597211740\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.2612647395 \tAcc: 0.8990575397 \tTPR:0.9523460173 \tFPR:0.2086349002 \tF1:0.9260897346 \t AUC:0.8718555586\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.2628855562 \tAcc: 0.8957093254 \tTPR:0.9492772900 \tFPR:0.2223459741 \tF1:0.9234734843 \t AUC:0.8634656579\tTrain cost: 0:00:08\n",
      "Client7 Test =>                 \tLoss: 0.2760420119 \tAcc: 0.8891666667 \tTPR:0.9344056809 \tFPR:0.1587277617 \tF1:0.8917920449 \tAUC:0.8878389596 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.4190571126 \tAcc: 0.8267500000 \tTPR:0.8039676078 \tFPR:0.1547592339 \tF1:0.8038921883 \tAUC:0.8246041869\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 1:  =============\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.0969329838310051 \tALA epochs: 2\n",
      "Client 3: Local Initial ALA epochs: 2 Loss: 0.29882396920584142208\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.3142668630 \tAcc: 0.8572205489 \tTPR:0.8671630405 \tFPR:0.1553873300 \tF1:0.8417310180 \t AUC:0.8558878552\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.3038613911 \tAcc: 0.8746234940 \tTPR:0.8813231517 \tFPR:0.1302597708 \tF1:0.8568284668 \t AUC:0.8755316904\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.2932707543 \tAcc: 0.8725317938 \tTPR:0.8616413531 \tFPR:0.1206597807 \tF1:0.8504025059 \t AUC:0.8704907862\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.2875618161 \tAcc: 0.8811914324 \tTPR:0.8791830896 \tFPR:0.1196272059 \tF1:0.8656540371 \t AUC:0.8797779419\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.2917390247 \tAcc: 0.8765060241 \tTPR:0.8783760198 \tFPR:0.1226968949 \tF1:0.8583604172 \t AUC:0.8778395625\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.2714651472 \tAcc: 0.8904166667 \tTPR:0.9159203073 \tFPR:0.1367437495 \tF1:0.8879036239 \tAUC:0.8895882789 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.07454333391562983 \tALA epochs: 5\n",
      "Client 5: Local Initial ALA epochs: 5 Loss: 0.36582693321364267991\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.2179502165 \tAcc: 0.9049081921 \tTPR:0.6115793732 \tFPR:0.0426797359 \tF1:0.6210611907 \t AUC:0.7827899014\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.2101470128 \tAcc: 0.9079978814 \tTPR:0.6156510627 \tFPR:0.0412070000 \tF1:0.6255977985 \t AUC:0.7866776278\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.2046790232 \tAcc: 0.9121998588 \tTPR:0.6642302769 \tFPR:0.0419285416 \tF1:0.6673358580 \t AUC:0.8111508677\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1945031926 \tAcc: 0.9189442090 \tTPR:0.6762524356 \tFPR:0.0375215953 \tF1:0.6846463150 \t AUC:0.8193654201\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1853320139 \tAcc: 0.9209039548 \tTPR:0.6911727240 \tFPR:0.0384410527 \tF1:0.6888315953 \t AUC:0.8254884854\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.6847941847 \tAcc: 0.7575000000 \tTPR:0.5194720446 \tFPR:0.0084410781 \tF1:0.6697628882 \tAUC:0.7555154832 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.04346239152745872 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.16750778823488338132\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1570612689 \tAcc: 0.9358552632 \tTPR:0.6420385454 \tFPR:0.0256254495 \tF1:0.6384428262 \t AUC:0.8028155622\tTrain cost: 0:01:05\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1462402031 \tAcc: 0.9433022661 \tTPR:0.6736111111 \tFPR:0.0229521011 \tF1:0.6812870299 \t AUC:0.8231535791\tTrain cost: 0:01:08\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1419271892 \tAcc: 0.9426991959 \tTPR:0.6663539636 \tFPR:0.0228941250 \tF1:0.6676227558 \t AUC:0.8197556824\tTrain cost: 0:01:09\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1353174648 \tAcc: 0.9473135965 \tTPR:0.6924980275 \tFPR:0.0213264901 \tF1:0.6946762784 \t AUC:0.8314303366\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1307556468 \tAcc: 0.9471856725 \tTPR:0.7010628423 \tFPR:0.0226059194 \tF1:0.6991263657 \t AUC:0.8356483757\tTrain cost: 0:01:12\n",
      "Client1 Test =>                 \tLoss: 0.8081242170 \tAcc: 0.7366666667 \tTPR:0.4668353155 \tFPR:0.0040901626 \tF1:0.6258868757 \tAUC:0.7313725765 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.2045220543693132 \tALA epochs: 11\n",
      "Client 0: Local Initial ALA epochs: 11 Loss: 1.02676613547585238173\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.3782742146 \tAcc: 0.8595063025 \tTPR:0.9376566917 \tFPR:0.3711592971 \tF1:0.9074943320 \t AUC:0.7832486973\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.2268550686 \tAcc: 0.9153098739 \tTPR:0.9691600959 \tFPR:0.3033652855 \tF1:0.9466855343 \t AUC:0.8328974052\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.2109445022 \tAcc: 0.9274553571 \tTPR:0.9751233607 \tFPR:0.2213021106 \tF1:0.9539092319 \t AUC:0.8769106251\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.2242831654 \tAcc: 0.9164259454 \tTPR:0.9732629117 \tFPR:0.3016362606 \tF1:0.9479765245 \t AUC:0.8358133256\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1970649669 \tAcc: 0.9229910714 \tTPR:0.9683360319 \tFPR:0.2642290249 \tF1:0.9516065112 \t AUC:0.8520535035\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.2473136453 \tAcc: 0.8979166667 \tTPR:0.9595712518 \tFPR:0.1660247171 \tF1:0.9027595478 \tAUC:0.8967732673 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.04976954362849604 \tALA epochs: 2\n",
      "Client 7: Local Initial ALA epochs: 2 Loss: 0.23128502967301756144\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.2284419633 \tAcc: 0.9150545635 \tTPR:0.9589078826 \tFPR:0.1771473236 \tF1:0.9376967037 \t AUC:0.8908802795\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.2175107801 \tAcc: 0.9123263889 \tTPR:0.9540655227 \tFPR:0.1710261960 \tF1:0.9356543793 \t AUC:0.8915196633\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.2124027495 \tAcc: 0.9190228175 \tTPR:0.9581028484 \tFPR:0.1617897480 \tF1:0.9392269116 \t AUC:0.8981565502\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.2052397383 \tAcc: 0.9205109127 \tTPR:0.9584199006 \tFPR:0.1619121289 \tF1:0.9409262731 \t AUC:0.8982538858\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1988412914 \tAcc: 0.9270833333 \tTPR:0.9610548551 \tFPR:0.1449088279 \tF1:0.9460154957 \t AUC:0.9080730136\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2389656297 \tAcc: 0.9077083333 \tTPR:0.8835452606 \tFPR:0.0689741427 \tF1:0.9029385217 \tAUC:0.9072855590 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.4501325648 \tAcc: 0.8380416667 \tTPR:0.7490688359 \tFPR:0.0768547700 \tF1:0.7978502914 \tAUC:0.8361070330\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 2:  =============\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.060029513085124754 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.21211825124919414520\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.2398811452 \tAcc: 0.9079233601 \tTPR:0.9046560840 \tFPR:0.0863231694 \tF1:0.8933957819 \t AUC:0.9091664573\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.2281302080 \tAcc: 0.9039909639 \tTPR:0.9093216194 \tFPR:0.1024666061 \tF1:0.8895300005 \t AUC:0.9034275067\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.2196670547 \tAcc: 0.9039491299 \tTPR:0.9020914585 \tFPR:0.0938895312 \tF1:0.8900579081 \t AUC:0.9041009636\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.2086621952 \tAcc: 0.9162064926 \tTPR:0.9168050975 \tFPR:0.0844792654 \tF1:0.9040684253 \t AUC:0.9161629160\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.2078004599 \tAcc: 0.9143239625 \tTPR:0.9161390132 \tFPR:0.0846331094 \tF1:0.9030800100 \t AUC:0.9157529519\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.2503730656 \tAcc: 0.9008333333 \tTPR:0.8556373503 \tFPR:0.0577112098 \tF1:0.8906634815 \tAUC:0.8989630702 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.07643476040438128 \tALA epochs: 2\n",
      "Client 4: Local Initial ALA epochs: 2 Loss: 0.24518890198644088807\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.2289900590 \tAcc: 0.9102848787 \tTPR:0.9494916537 \tFPR:0.1608000969 \tF1:0.9303270491 \t AUC:0.8943457784\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.2124410832 \tAcc: 0.9174485069 \tTPR:0.9527940846 \tFPR:0.1473615757 \tF1:0.9357524476 \t AUC:0.9027162545\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.2043287712 \tAcc: 0.9216062858 \tTPR:0.9536372065 \tFPR:0.1360024616 \tF1:0.9385768097 \t AUC:0.9088173725\tTrain cost: 0:01:59\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1949424387 \tAcc: 0.9252599653 \tTPR:0.9577213138 \tFPR:0.1337776649 \tF1:0.9414352818 \t AUC:0.9119718244\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1872863734 \tAcc: 0.9268035095 \tTPR:0.9580873694 \tFPR:0.1317008237 \tF1:0.9427916488 \t AUC:0.9131932728\tTrain cost: 0:02:01\n",
      "Client4 Test =>                 \tLoss: 0.2334791873 \tAcc: 0.9139583333 \tTPR:0.9156471937 \tFPR:0.0854742366 \tF1:0.9114068515 \tAUC:0.9150864786 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.06993716273163242 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.16205689961563296553\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1637448504 \tAcc: 0.9399963018 \tTPR:0.9745635093 \tFPR:0.1725849919 \tF1:0.9605988351 \t AUC:0.9009135549\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1595990125 \tAcc: 0.9432322485 \tTPR:0.9761536119 \tFPR:0.1676637383 \tF1:0.9631496904 \t AUC:0.9042449368\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1559047688 \tAcc: 0.9412906805 \tTPR:0.9759313869 \tFPR:0.1757315904 \tF1:0.9618083487 \t AUC:0.9000998982\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1531438853 \tAcc: 0.9424926036 \tTPR:0.9744188087 \tFPR:0.1651391223 \tF1:0.9622920565 \t AUC:0.9046018889\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1494175397 \tAcc: 0.9443417160 \tTPR:0.9756619447 \tFPR:0.1571580085 \tF1:0.9635340820 \t AUC:0.9092158582\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.2106938272 \tAcc: 0.9233333333 \tTPR:0.9432920595 \tFPR:0.0960203670 \tF1:0.9208380382 \tAUC:0.9236358462 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.06629461219979194 \tALA epochs: 2\n",
      "Client 7: Local Initial ALA epochs: 2 Loss: 0.19680861523374915123\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1867168407 \tAcc: 0.9284474206 \tTPR:0.9609402495 \tFPR:0.1441160196 \tF1:0.9463736078 \t AUC:0.9084121150\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1728185844 \tAcc: 0.9341517857 \tTPR:0.9645626937 \tFPR:0.1246814198 \tF1:0.9509265417 \t AUC:0.9199406370\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1665231169 \tAcc: 0.9367559524 \tTPR:0.9680526630 \tFPR:0.1334684539 \tF1:0.9532513587 \t AUC:0.9172921046\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1686821213 \tAcc: 0.9365079365 \tTPR:0.9664448329 \tFPR:0.1239781315 \tF1:0.9529746977 \t AUC:0.9212333507\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1588018881 \tAcc: 0.9394841270 \tTPR:0.9679204852 \tFPR:0.1193488866 \tF1:0.9540759517 \t AUC:0.9242857993\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2157207236 \tAcc: 0.9185416667 \tTPR:0.9197234092 \tFPR:0.0842920693 \tF1:0.9158469124 \tAUC:0.9177156699 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.08833871130952502 \tALA epochs: 2\n",
      "Client 6: Local Initial ALA epochs: 2 Loss: 0.24555960466915910390\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.2108101739 \tAcc: 0.9135625889 \tTPR:0.9264551008 \tFPR:0.0990351894 \tF1:0.9076900608 \t AUC:0.9137099557\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.2051473766 \tAcc: 0.9166064922 \tTPR:0.9258978073 \tFPR:0.0929206762 \tF1:0.9100224600 \t AUC:0.9164885656\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.2027739022 \tAcc: 0.9165092872 \tTPR:0.9286145154 \tFPR:0.0931624393 \tF1:0.9107693684 \t AUC:0.9177260381\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1972591850 \tAcc: 0.9195309723 \tTPR:0.9316768230 \tFPR:0.0917634812 \tF1:0.9137998247 \t AUC:0.9199566709\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1900144811 \tAcc: 0.9225582119 \tTPR:0.9325231562 \tFPR:0.0858580012 \tF1:0.9165430509 \t AUC:0.9233325775\tTrain cost: 0:00:41\n",
      "Client6 Test =>                 \tLoss: 0.1872396760 \tAcc: 0.9281250000 \tTPR:0.9127676519 \tFPR:0.0590109216 \tF1:0.9235041169 \tAUC:0.9268783652 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2195012959 \tAcc: 0.9169583333 \tTPR:0.9094135329 \tFPR:0.0765017609 \tF1:0.9124518801 \tAUC:0.9164558860\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 3:  =============\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.060536021851584694 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.09923842481591484133\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0890680988 \tAcc: 0.9675595238 \tTPR:0.9905226541 \tFPR:0.2939393939 \tF1:0.9824510478 \t AUC:0.8481449326\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0860784643 \tAcc: 0.9659970238 \tTPR:0.9878459915 \tFPR:0.3206060606 \tF1:0.9814336362 \t AUC:0.8333516014\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0773994434 \tAcc: 0.9739583333 \tTPR:0.9928130437 \tFPR:0.2983660131 \tF1:0.9859459846 \t AUC:0.8472021172\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0688061601 \tAcc: 0.9739583333 \tTPR:0.9912684115 \tFPR:0.2428104575 \tF1:0.9856376877 \t AUC:0.8740712878\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0717790535 \tAcc: 0.9744791667 \tTPR:0.9910473277 \tFPR:0.2580357143 \tF1:0.9861353838 \t AUC:0.8661860684\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.2653056574 \tAcc: 0.9135416667 \tTPR:0.9758070479 \tFPR:0.1497153954 \tF1:0.9177674777 \tAUC:0.9130458263 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.09654100306026707 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.12714173054943481156\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1395429746 \tAcc: 0.9521837349 \tTPR:0.9814807267 \tFPR:0.1750940575 \tF1:0.9701328908 \t AUC:0.9031933346\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1335130762 \tAcc: 0.9526543675 \tTPR:0.9809745342 \tFPR:0.1598647241 \tF1:0.9703028914 \t AUC:0.9105261657\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.1289131686 \tAcc: 0.9541603916 \tTPR:0.9817758629 \tFPR:0.1539201762 \tF1:0.9710776240 \t AUC:0.9139278433\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.1234101688 \tAcc: 0.9566076807 \tTPR:0.9812630201 \tFPR:0.1535113314 \tF1:0.9728692099 \t AUC:0.9138758444\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.1284004934 \tAcc: 0.9537838855 \tTPR:0.9802536271 \tFPR:0.1516314843 \tF1:0.9709616606 \t AUC:0.9143110714\tTrain cost: 0:00:35\n",
      "Client2 Test =>                 \tLoss: 0.1835291233 \tAcc: 0.9289583333 \tTPR:0.9438610408 \tFPR:0.0887104083 \tF1:0.9294251446 \tAUC:0.9275753163 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.07261261825997345 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.14396378495243947193\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1562546530 \tAcc: 0.9430473373 \tTPR:0.9753571380 \tFPR:0.1665721684 \tF1:0.9628389595 \t AUC:0.9043559227\tTrain cost: 0:00:32\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1460056964 \tAcc: 0.9448964497 \tTPR:0.9740101075 \tFPR:0.1576955425 \tF1:0.9635669956 \t AUC:0.9081572825\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1544778592 \tAcc: 0.9460983728 \tTPR:0.9794146077 \tFPR:0.1622760950 \tF1:0.9647839930 \t AUC:0.9085692563\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1432005225 \tAcc: 0.9481323964 \tTPR:0.9783065140 \tFPR:0.1516447614 \tF1:0.9659735849 \t AUC:0.9132986901\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1371495167 \tAcc: 0.9487795858 \tTPR:0.9785352601 \tFPR:0.1507741681 \tF1:0.9664279690 \t AUC:0.9138486992\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.2100005453 \tAcc: 0.9243750000 \tTPR:0.9416629824 \tFPR:0.0915184723 \tF1:0.9209669256 \tAUC:0.9250722550 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.08034710163528412 \tALA epochs: 6\n",
      "Client 6: Local Initial ALA epochs: 6 Loss: 0.26769146566718687863\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.2110211811 \tAcc: 0.9111380199 \tTPR:0.9208541550 \tFPR:0.0983542545 \tF1:0.9052317570 \t AUC:0.9112499502\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.2003112274 \tAcc: 0.9195865180 \tTPR:0.9320692481 \tFPR:0.0926770477 \tF1:0.9140332512 \t AUC:0.9196961002\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1929513138 \tAcc: 0.9206418859 \tTPR:0.9326754657 \tFPR:0.0906955336 \tF1:0.9166565302 \t AUC:0.9209899661\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1912943661 \tAcc: 0.9238885309 \tTPR:0.9362118033 \tFPR:0.0866205309 \tF1:0.9181606199 \t AUC:0.9247956362\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1859175628 \tAcc: 0.9242745734 \tTPR:0.9341183710 \tFPR:0.0855485629 \tF1:0.9197217262 \t AUC:0.9242849040\tTrain cost: 0:00:41\n",
      "Client6 Test =>                 \tLoss: 0.2003582811 \tAcc: 0.9233333333 \tTPR:0.8900662535 \tFPR:0.0433202922 \tF1:0.9178083736 \tAUC:0.9233729807 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.0513326051299803 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.20425620069727301598\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1732154088 \tAcc: 0.9336557540 \tTPR:0.9639260872 \tFPR:0.1308815737 \tF1:0.9509199049 \t AUC:0.9165222567\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1563352114 \tAcc: 0.9484126984 \tTPR:0.9770420248 \tFPR:0.1140530105 \tF1:0.9616959068 \t AUC:0.9314945072\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1560512056 \tAcc: 0.9432043651 \tTPR:0.9748084563 \tFPR:0.1209831670 \tF1:0.9580646923 \t AUC:0.9269126447\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1498844688 \tAcc: 0.9468005952 \tTPR:0.9729414166 \tFPR:0.1098913963 \tF1:0.9598569810 \t AUC:0.9315250101\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1504303075 \tAcc: 0.9469246032 \tTPR:0.9727919256 \tFPR:0.1124232745 \tF1:0.9605862005 \t AUC:0.9301843256\tTrain cost: 0:00:08\n",
      "Client7 Test =>                 \tLoss: 0.2228148367 \tAcc: 0.9187500000 \tTPR:0.8924937315 \tFPR:0.0565213009 \tF1:0.9125942702 \tAUC:0.9179862153 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2164016887 \tAcc: 0.9217916667 \tTPR:0.9287782112 \tFPR:0.0859571738 \tF1:0.9197124383 \tAUC:0.9214105187\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 4:  =============\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.09485082635738042 \tALA epochs: 2\n",
      "Client 1: Local Initial ALA epochs: 2 Loss: 0.31131166390910308683\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1186766322 \tAcc: 0.9525310673 \tTPR:0.7348527569 \tFPR:0.0206799099 \tF1:0.7307542756 \t AUC:0.8547190374\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1142090701 \tAcc: 0.9528965643 \tTPR:0.7418743618 \tFPR:0.0205834255 \tF1:0.7348068884 \t AUC:0.8575541432\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1099960614 \tAcc: 0.9553362573 \tTPR:0.7534681611 \tFPR:0.0190042979 \tF1:0.7385250960 \t AUC:0.8644681218\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1083271586 \tAcc: 0.9566885965 \tTPR:0.7641888286 \tFPR:0.0182642594 \tF1:0.7573124447 \t AUC:0.8694109115\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1076461411 \tAcc: 0.9565515351 \tTPR:0.7724785448 \tFPR:0.0186765898 \tF1:0.7548422338 \t AUC:0.8713176289\tTrain cost: 0:01:11\n",
      "Client1 Test =>                 \tLoss: 0.4204809592 \tAcc: 0.8531250000 \tTPR:0.7096360523 \tFPR:0.0123675487 \tF1:0.8179379384 \tAUC:0.8486342518 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.06503877109862759 \tALA epochs: 2\n",
      "Client 3: Local Initial ALA epochs: 2 Loss: 0.22651149972807615995\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1747729208 \tAcc: 0.9359939759 \tTPR:0.9376259632 \tFPR:0.0676070858 \tF1:0.9260303609 \t AUC:0.9350094387\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1629254805 \tAcc: 0.9363704819 \tTPR:0.9403902145 \tFPR:0.0672145124 \tF1:0.9264329412 \t AUC:0.9365878511\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1548768411 \tAcc: 0.9395498661 \tTPR:0.9497549885 \tFPR:0.0718161877 \tF1:0.9323786786 \t AUC:0.9389694004\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1601221229 \tAcc: 0.9337349398 \tTPR:0.9350366688 \tFPR:0.0687634589 \tF1:0.9242561140 \t AUC:0.9331366050\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1503526983 \tAcc: 0.9423945783 \tTPR:0.9538236495 \tFPR:0.0652922522 \tF1:0.9364224006 \t AUC:0.9442656987\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.3081707563 \tAcc: 0.8908333333 \tTPR:0.8078863153 \tFPR:0.0252537764 \tF1:0.8772230044 \tAUC:0.8913162694 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.057866372104541854 \tALA epochs: 2\n",
      "Client 6: Local Initial ALA epochs: 2 Loss: 0.21209874042829909846\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1932614353 \tAcc: 0.9218750000 \tTPR:0.9297782397 \tFPR:0.0858885099 \tF1:0.9161290832 \t AUC:0.9219448649\tTrain cost: 0:00:37\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1905965021 \tAcc: 0.9239357448 \tTPR:0.9310485788 \tFPR:0.0818921240 \tF1:0.9171187894 \t AUC:0.9245782274\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1852676579 \tAcc: 0.9238885309 \tTPR:0.9317654267 \tFPR:0.0848873527 \tF1:0.9192850573 \t AUC:0.9234390370\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1808876412 \tAcc: 0.9249189033 \tTPR:0.9339456420 \tFPR:0.0827152993 \tF1:0.9198663874 \t AUC:0.9256151714\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1730848810 \tAcc: 0.9315954941 \tTPR:0.9407232101 \tFPR:0.0772988910 \tF1:0.9264209482 \t AUC:0.9317121596\tTrain cost: 0:00:40\n",
      "Client6 Test =>                 \tLoss: 0.2702909626 \tAcc: 0.9016666667 \tTPR:0.8249251166 \tFPR:0.0250465843 \tF1:0.8871896738 \tAUC:0.8999392661 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.04388458830883635 \tALA epochs: 2\n",
      "Client 9: Local Initial ALA epochs: 2 Loss: 0.23669986528429118322\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0828046354 \tAcc: 0.9703125000 \tTPR:0.9882466679 \tFPR:0.2617724868 \tF1:0.9837325115 \t AUC:0.8637415351\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0680484748 \tAcc: 0.9748511905 \tTPR:0.9901605199 \tFPR:0.2197454844 \tF1:0.9861872961 \t AUC:0.8850378715\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0671384094 \tAcc: 0.9812500000 \tTPR:0.9964359784 \tFPR:0.2352201258 \tF1:0.9897236132 \t AUC:0.8803725664\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0602773858 \tAcc: 0.9786458333 \tTPR:0.9916746837 \tFPR:0.1747835498 \tF1:0.9882827605 \t AUC:0.9083512344\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0583982529 \tAcc: 0.9791666667 \tTPR:0.9920587966 \tFPR:0.1775757576 \tF1:0.9885935423 \t AUC:0.9071646466\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.2959615489 \tAcc: 0.9070833333 \tTPR:0.9808262863 \tFPR:0.1696395482 \tF1:0.9125054663 \tAUC:0.9055933691 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.189725091348967 \tALA epochs: 11\n",
      "Client 5: Local Initial ALA epochs: 11 Loss: 0.76211797560190230882\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1416750502 \tAcc: 0.9397775424 \tTPR:0.7788671623 \tFPR:0.0323232686 \tF1:0.7760258606 \t AUC:0.8729587275\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1284295865 \tAcc: 0.9469456215 \tTPR:0.8003309936 \tFPR:0.0276376571 \tF1:0.7974245890 \t AUC:0.8863466682\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1292385008 \tAcc: 0.9464159605 \tTPR:0.7958955044 \tFPR:0.0275871823 \tF1:0.7961612292 \t AUC:0.8841541610\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1237591115 \tAcc: 0.9491525424 \tTPR:0.8164248495 \tFPR:0.0263151114 \tF1:0.8002258508 \t AUC:0.8934723246\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1220647539 \tAcc: 0.9492408192 \tTPR:0.8064568200 \tFPR:0.0260360076 \tF1:0.8062841773 \t AUC:0.8896605676\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.3652111657 \tAcc: 0.8675000000 \tTPR:0.7508393312 \tFPR:0.0179267475 \tF1:0.8430520782 \tAUC:0.8664562919 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.3320230785 \tAcc: 0.8840416667 \tTPR:0.8148226203 \tFPR:0.0500468410 \tF1:0.8675816322 \tAUC:0.8823878897\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 5:  =============\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.06585078681996054 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.24854123294353486218\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1812594211 \tAcc: 0.9320509454 \tTPR:0.9667201790 \tFPR:0.1991664090 \tF1:0.9546629190 \t AUC:0.8837768850\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1731736756 \tAcc: 0.9408482143 \tTPR:0.9758011367 \tFPR:0.1911564626 \tF1:0.9623959875 \t AUC:0.8923223371\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1643778176 \tAcc: 0.9367778361 \tTPR:0.9837834579 \tFPR:0.2209428468 \tF1:0.9591736279 \t AUC:0.8814203055\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1622351785 \tAcc: 0.9411108193 \tTPR:0.9771950927 \tFPR:0.1857477840 \tF1:0.9622855510 \t AUC:0.8957236543\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1577107062 \tAcc: 0.9366465336 \tTPR:0.9770785536 \tFPR:0.2158485364 \tF1:0.9594579955 \t AUC:0.8806150086\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.1823310717 \tAcc: 0.9297916667 \tTPR:0.9527516280 \tFPR:0.0927319629 \tF1:0.9290238921 \tAUC:0.9300098326 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.07435476253897778 \tALA epochs: 2\n",
      "Client 4: Local Initial ALA epochs: 2 Loss: 0.19334627208097474038\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1711757287 \tAcc: 0.9342775130 \tTPR:0.9641879383 \tFPR:0.1207130032 \tF1:0.9488187522 \t AUC:0.9217374676\tTrain cost: 0:02:01\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1652864580 \tAcc: 0.9357543994 \tTPR:0.9651353250 \tFPR:0.1172564914 \tF1:0.9499672781 \t AUC:0.9239394168\tTrain cost: 0:02:01\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1612153535 \tAcc: 0.9372292028 \tTPR:0.9652777123 \tFPR:0.1137742414 \tF1:0.9504908713 \t AUC:0.9257517354\tTrain cost: 0:01:56\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1564364087 \tAcc: 0.9400871550 \tTPR:0.9674930859 \tFPR:0.1090440750 \tF1:0.9531260599 \t AUC:0.9292245055\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1526817895 \tAcc: 0.9414140615 \tTPR:0.9682717665 \tFPR:0.1067847159 \tF1:0.9541573105 \t AUC:0.9307435253\tTrain cost: 0:01:58\n",
      "Client4 Test =>                 \tLoss: 0.2030322020 \tAcc: 0.9247916667 \tTPR:0.9308796301 \tFPR:0.0828983668 \tF1:0.9225873911 \tAUC:0.9239906317 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.08347587306442283 \tALA epochs: 2\n",
      "Client 6: Local Initial ALA epochs: 2 Loss: 0.20235545224473847070\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1798923615 \tAcc: 0.9268602248 \tTPR:0.9384645940 \tFPR:0.0829852478 \tF1:0.9217539539 \t AUC:0.9277396731\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1731661792 \tAcc: 0.9294292126 \tTPR:0.9404666168 \tFPR:0.0810615473 \tF1:0.9241435534 \t AUC:0.9297025348\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1729654100 \tAcc: 0.9308956186 \tTPR:0.9424578084 \tFPR:0.0792054497 \tF1:0.9260480857 \t AUC:0.9316261793\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1683506580 \tAcc: 0.9335451475 \tTPR:0.9429755747 \tFPR:0.0754191650 \tF1:0.9282644344 \t AUC:0.9337782048\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1615603978 \tAcc: 0.9357114291 \tTPR:0.9438276919 \tFPR:0.0708268611 \tF1:0.9311012770 \t AUC:0.9365004154\tTrain cost: 0:00:40\n",
      "Client6 Test =>                 \tLoss: 0.2046403777 \tAcc: 0.9283333333 \tTPR:0.8927258689 \tFPR:0.0367223345 \tF1:0.9224327890 \tAUC:0.9280017672 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.06748199202316146 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.16864055097924873783\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1057170367 \tAcc: 0.9563961988 \tTPR:0.7561009004 \tFPR:0.0195103402 \tF1:0.7491568294 \t AUC:0.8663020482\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1013334654 \tAcc: 0.9591831140 \tTPR:0.7842000835 \tFPR:0.0180936709 \tF1:0.7742494742 \t AUC:0.8796355606\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0960629563 \tAcc: 0.9608826754 \tTPR:0.7920379653 \tFPR:0.0177515923 \tF1:0.7808685875 \t AUC:0.8849704488\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0956428577 \tAcc: 0.9619426170 \tTPR:0.7824770259 \tFPR:0.0161811047 \tF1:0.7859107579 \t AUC:0.8807093622\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0904467288 \tAcc: 0.9636695906 \tTPR:0.8081766917 \tFPR:0.0173703427 \tF1:0.7995578049 \t AUC:0.8926628416\tTrain cost: 0:01:12\n",
      "Client1 Test =>                 \tLoss: 0.4562351729 \tAcc: 0.8512500000 \tTPR:0.7097552255 \tFPR:0.0106188228 \tF1:0.8194843859 \tAUC:0.8495682014 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.06652956752893917 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.13503450921603610269\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1275282958 \tAcc: 0.9469103107 \tTPR:0.8087050896 \tFPR:0.0273008500 \tF1:0.7970929454 \t AUC:0.8887726322\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1189036974 \tAcc: 0.9515713277 \tTPR:0.8134916323 \tFPR:0.0237864411 \tF1:0.8083622941 \t AUC:0.8943227423\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1160884922 \tAcc: 0.9525953390 \tTPR:0.8268436993 \tFPR:0.0245128610 \tF1:0.8235953299 \t AUC:0.9009201553\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1113874546 \tAcc: 0.9559322034 \tTPR:0.8365527755 \tFPR:0.0233551572 \tF1:0.8337764857 \t AUC:0.9059003167\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1072791706 \tAcc: 0.9567443503 \tTPR:0.8431784553 \tFPR:0.0227177126 \tF1:0.8393453034 \t AUC:0.9097848556\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.3422084565 \tAcc: 0.8822916667 \tTPR:0.7786520973 \tFPR:0.0149451416 \tF1:0.8632315855 \tAUC:0.8818534779 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2776894562 \tAcc: 0.9032916667 \tTPR:0.8529528900 \tFPR:0.0475833257 \tF1:0.8913520087 \tAUC:0.9026847821\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 6:  =============\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.05694824768432122 \tALA epochs: 2\n",
      "Client 8: Local Initial ALA epochs: 2 Loss: 0.18538477246774665019\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1413330897 \tAcc: 0.9497041420 \tTPR:0.9795380505 \tFPR:0.1458463299 \tF1:0.9671803084 \t AUC:0.9168458603\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1347393999 \tAcc: 0.9525702663 \tTPR:0.9801500402 \tFPR:0.1396500079 \tF1:0.9688072036 \t AUC:0.9202205652\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1286316416 \tAcc: 0.9535872781 \tTPR:0.9806447692 \tFPR:0.1380436712 \tF1:0.9694474230 \t AUC:0.9212718320\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1229923897 \tAcc: 0.9559911243 \tTPR:0.9825648022 \tFPR:0.1355331653 \tF1:0.9710287558 \t AUC:0.9234899502\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1218919760 \tAcc: 0.9554363905 \tTPR:0.9816679641 \tFPR:0.1327830043 \tF1:0.9708558084 \t AUC:0.9244424799\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.2062810192 \tAcc: 0.9256250000 \tTPR:0.9410881594 \tFPR:0.0892567319 \tF1:0.9245348144 \tAUC:0.9259157137 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.08856535526114412 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.15790242587580630151\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1546870208 \tAcc: 0.9399913345 \tTPR:0.9679918378 \tFPR:0.1104270633 \tF1:0.9529611425 \t AUC:0.9287823873\tTrain cost: 0:02:01\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1490969262 \tAcc: 0.9430117651 \tTPR:0.9694922559 \tFPR:0.1046717017 \tF1:0.9551788057 \t AUC:0.9324102771\tTrain cost: 0:01:59\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1447210291 \tAcc: 0.9447177876 \tTPR:0.9711400218 \tFPR:0.1021025110 \tF1:0.9566856796 \t AUC:0.9345187554\tTrain cost: 0:01:59\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1426719111 \tAcc: 0.9450698240 \tTPR:0.9711359729 \tFPR:0.1013099253 \tF1:0.9570550737 \t AUC:0.9349130238\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1381648231 \tAcc: 0.9480340121 \tTPR:0.9723232843 \tFPR:0.0966830154 \tF1:0.9592757315 \t AUC:0.9378201344\tTrain cost: 0:02:00\n",
      "Client4 Test =>                 \tLoss: 0.2067843900 \tAcc: 0.9275000000 \tTPR:0.9168981656 \tFPR:0.0639656968 \tF1:0.9240757607 \tAUC:0.9264662344 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.09013949079200274 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.21878880488553217876\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1219683104 \tAcc: 0.9496822034 \tTPR:0.8232878625 \tFPR:0.0277831707 \tF1:0.8069481529 \t AUC:0.8967425622\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1182287820 \tAcc: 0.9516066384 \tTPR:0.8236185503 \tFPR:0.0269821487 \tF1:0.8171139977 \t AUC:0.8980683687\tTrain cost: 0:00:35\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1110534768 \tAcc: 0.9542196328 \tTPR:0.8334608188 \tFPR:0.0233620611 \tF1:0.8272662836 \t AUC:0.9050493789\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1097323462 \tAcc: 0.9539194915 \tTPR:0.8375285339 \tFPR:0.0246390598 \tF1:0.8260563607 \t AUC:0.9057504145\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1034801979 \tAcc: 0.9579802260 \tTPR:0.8517773579 \tFPR:0.0221228510 \tF1:0.8443081712 \t AUC:0.9141938234\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.3960151410 \tAcc: 0.8764583333 \tTPR:0.7666170662 \tFPR:0.0178149485 \tF1:0.8556781129 \tAUC:0.8744010589 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.07376065240992014 \tALA epochs: 9\n",
      "Client 7: Local Initial ALA epochs: 9 Loss: 0.33038546589927542119\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1575479760 \tAcc: 0.9375000000 \tTPR:0.9645973768 \tFPR:0.1190993861 \tF1:0.9525333604 \t AUC:0.9227489954\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1499757760 \tAcc: 0.9433283730 \tTPR:0.9758688878 \tFPR:0.1246386550 \tF1:0.9582522582 \t AUC:0.9256151164\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1414496811 \tAcc: 0.9471726190 \tTPR:0.9721085882 \tFPR:0.1032089273 \tF1:0.9605407283 \t AUC:0.9344498305\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1353993863 \tAcc: 0.9506448413 \tTPR:0.9761808041 \tFPR:0.1057650828 \tF1:0.9635256805 \t AUC:0.9352078606\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1362317578 \tAcc: 0.9495287698 \tTPR:0.9721295611 \tFPR:0.1007536445 \tF1:0.9628604769 \t AUC:0.9356879583\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2040033959 \tAcc: 0.9256250000 \tTPR:0.9527348635 \tFPR:0.1023190829 \tF1:0.9268912147 \tAUC:0.9252078903 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.07079310763830585 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.11077803927897052205\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1148055097 \tAcc: 0.9582078313 \tTPR:0.9832789405 \tFPR:0.1411074200 \tF1:0.9737747121 \t AUC:0.9210857603\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1100286434 \tAcc: 0.9602786145 \tTPR:0.9851441797 \tFPR:0.1415527197 \tF1:0.9748728038 \t AUC:0.9218204946\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0992380400 \tAcc: 0.9644201807 \tTPR:0.9864773435 \tFPR:0.1294114771 \tF1:0.9776787797 \t AUC:0.9285329332\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0985958354 \tAcc: 0.9643260542 \tTPR:0.9859424928 \tFPR:0.1268458730 \tF1:0.9775507752 \t AUC:0.9295057114\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0975231710 \tAcc: 0.9633847892 \tTPR:0.9855700535 \tFPR:0.1303332711 \tF1:0.9768884389 \t AUC:0.9276183912\tTrain cost: 0:00:35\n",
      "Client2 Test =>                 \tLoss: 0.1669025766 \tAcc: 0.9404166667 \tTPR:0.9696043897 \tFPR:0.0890971333 \tF1:0.9412584093 \tAUC:0.9402536282 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2359973046 \tAcc: 0.9191250000 \tTPR:0.9093885289 \tFPR:0.0724907187 \tF1:0.9144876624 \tAUC:0.9184489051\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 7:  =============\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.07469930816785796 \tALA epochs: 2\n",
      "Client 4: Local Initial ALA epochs: 2 Loss: 0.13774101106126024341\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1391221406 \tAcc: 0.9460842721 \tTPR:0.9698218710 \tFPR:0.0971911266 \tF1:0.9578282141 \t AUC:0.9363153722\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1389456812 \tAcc: 0.9456259999 \tTPR:0.9712165581 \tFPR:0.1005029005 \tF1:0.9574173354 \t AUC:0.9353568288\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1337622443 \tAcc: 0.9491984402 \tTPR:0.9723226860 \tFPR:0.0930681022 \tF1:0.9600139700 \t AUC:0.9396272919\tTrain cost: 0:01:57\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1297298835 \tAcc: 0.9501462305 \tTPR:0.9728111076 \tFPR:0.0916762461 \tF1:0.9607753631 \t AUC:0.9405674308\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1304633633 \tAcc: 0.9509857019 \tTPR:0.9737278608 \tFPR:0.0901801952 \tF1:0.9617409081 \t AUC:0.9417738328\tTrain cost: 0:01:59\n",
      "Client4 Test =>                 \tLoss: 0.2143025693 \tAcc: 0.9250000000 \tTPR:0.8993940394 \tFPR:0.0513587029 \tF1:0.9192242059 \tAUC:0.9240176682 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.09019560294262964 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.13654054189100861549\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1459976773 \tAcc: 0.9456845238 \tTPR:0.9753345710 \tFPR:0.1215640785 \tF1:0.9599368757 \t AUC:0.9267366593\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1382182189 \tAcc: 0.9456845238 \tTPR:0.9760217266 \tFPR:0.1191754178 \tF1:0.9598020529 \t AUC:0.9284231544\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1327134102 \tAcc: 0.9505208333 \tTPR:0.9769107052 \tFPR:0.1039769093 \tF1:0.9633747683 \t AUC:0.9364668979\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1241145905 \tAcc: 0.9569692460 \tTPR:0.9800147378 \tFPR:0.0964491031 \tF1:0.9688129073 \t AUC:0.9417828173\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1272280657 \tAcc: 0.9517609127 \tTPR:0.9795702315 \tFPR:0.1083220681 \tF1:0.9647720535 \t AUC:0.9356240817\tTrain cost: 0:00:08\n",
      "Client7 Test =>                 \tLoss: 0.2353615567 \tAcc: 0.9212500000 \tTPR:0.8871521913 \tFPR:0.0440609639 \tF1:0.9165226482 \tAUC:0.9215456137 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.06800277607380278 \tALA epochs: 2\n",
      "Client 3: Local Initial ALA epochs: 2 Loss: 0.15143975103273987770\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1467538121 \tAcc: 0.9461596386 \tTPR:0.9544571393 \tFPR:0.0621331364 \tF1:0.9388234018 \t AUC:0.9461620014\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1411864507 \tAcc: 0.9476656627 \tTPR:0.9520800700 \tFPR:0.0540108371 \tF1:0.9395421732 \t AUC:0.9490346165\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1390831151 \tAcc: 0.9497155288 \tTPR:0.9502524043 \tFPR:0.0533685623 \tF1:0.9418001295 \t AUC:0.9484419210\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1331199490 \tAcc: 0.9510123829 \tTPR:0.9562028670 \tFPR:0.0494621382 \tF1:0.9341746254 \t AUC:0.9531033087\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1217446527 \tAcc: 0.9555722892 \tTPR:0.9587008029 \tFPR:0.0480185972 \tF1:0.9486803708 \t AUC:0.9553411029\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.1966056382 \tAcc: 0.9356250000 \tTPR:0.9082815378 \tFPR:0.0374947811 \tF1:0.9306037072 \tAUC:0.9353933784 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.05771669714653846 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.15241152579103833808\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1274875317 \tAcc: 0.9532174556 \tTPR:0.9808193300 \tFPR:0.1384802389 \tF1:0.9691806721 \t AUC:0.9211410876\tTrain cost: 0:00:32\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1224840212 \tAcc: 0.9565458580 \tTPR:0.9823989920 \tFPR:0.1289275100 \tF1:0.9714927545 \t AUC:0.9267096268\tTrain cost: 0:00:32\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1156057527 \tAcc: 0.9583025148 \tTPR:0.9834594831 \tFPR:0.1286364851 \tF1:0.9726059511 \t AUC:0.9274114990\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1096839754 \tAcc: 0.9597818047 \tTPR:0.9832020631 \tFPR:0.1133725495 \tF1:0.9737193704 \t AUC:0.9349147568\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1098508595 \tAcc: 0.9599667160 \tTPR:0.9834240711 \tFPR:0.1202554617 \tF1:0.9738004584 \t AUC:0.9315597114\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.1980841955 \tAcc: 0.9339583333 \tTPR:0.9543991065 \tFPR:0.0848465327 \tF1:0.9320244456 \tAUC:0.9347762869 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.07297599647201757 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.22132239452043137029\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1684898659 \tAcc: 0.9320870734 \tTPR:0.9437698034 \tFPR:0.0770895196 \tF1:0.9271484006 \t AUC:0.9333401419\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1606570732 \tAcc: 0.9336173569 \tTPR:0.9456223182 \tFPR:0.0768517656 \tF1:0.9291883919 \t AUC:0.9343852763\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1553116758 \tAcc: 0.9366057145 \tTPR:0.9468951093 \tFPR:0.0724067888 \tF1:0.9317823158 \t AUC:0.9372441603\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1467399385 \tAcc: 0.9417603537 \tTPR:0.9518897484 \tFPR:0.0666699567 \tF1:0.9377479595 \t AUC:0.9426098958\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1438893175 \tAcc: 0.9435155972 \tTPR:0.9525074133 \tFPR:0.0648009038 \tF1:0.9397376509 \t AUC:0.9438532548\tTrain cost: 0:00:40\n",
      "Client6 Test =>                 \tLoss: 0.2016394292 \tAcc: 0.9306250000 \tTPR:0.8986394578 \tFPR:0.0381128064 \tF1:0.9250293741 \tAUC:0.9302633257 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2091986778 \tAcc: 0.9292916667 \tTPR:0.9095732666 \tFPR:0.0511747574 \tF1:0.9246808762 \tAUC:0.9291992546\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 8:  =============\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.07990653363000423 \tALA epochs: 4\n",
      "Client 5: Local Initial ALA epochs: 4 Loss: 0.18931318685811546199\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1152405932 \tAcc: 0.9525953390 \tTPR:0.8292548161 \tFPR:0.0257600260 \tF1:0.8191711648 \t AUC:0.9010177148\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1080214012 \tAcc: 0.9552436441 \tTPR:0.8475908194 \tFPR:0.0237876842 \tF1:0.8238390992 \t AUC:0.9108098113\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1036920872 \tAcc: 0.9563912429 \tTPR:0.8362545960 \tFPR:0.0225211887 \tF1:0.8367379134 \t AUC:0.9068667036\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0983471518 \tAcc: 0.9580155367 \tTPR:0.8514387997 \tFPR:0.0221518945 \tF1:0.8382548283 \t AUC:0.9140085757\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0953133193 \tAcc: 0.9604872881 \tTPR:0.8642997774 \tFPR:0.0215410929 \tF1:0.8537829786 \t AUC:0.9213793423\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.3335666898 \tAcc: 0.8970833333 \tTPR:0.8100207174 \tFPR:0.0199240695 \tF1:0.8824125340 \tAUC:0.8950483240 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.08518722374056222 \tALA epochs: 2\n",
      "Client 2: Local Initial ALA epochs: 2 Loss: 0.30774598094550048577\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1094798100 \tAcc: 0.9599021084 \tTPR:0.9839660763 \tFPR:0.1432365827 \tF1:0.9748415380 \t AUC:0.9203647468\tTrain cost: 0:00:32\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1011252810 \tAcc: 0.9637612952 \tTPR:0.9856829627 \tFPR:0.1308738868 \tF1:0.9773226025 \t AUC:0.9274045379\tTrain cost: 0:00:32\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0990721168 \tAcc: 0.9633847892 \tTPR:0.9854244006 \tFPR:0.1236275522 \tF1:0.9770060163 \t AUC:0.9308984242\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0943775793 \tAcc: 0.9647966867 \tTPR:0.9861275697 \tFPR:0.1221703439 \tF1:0.9778673104 \t AUC:0.9319576576\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0915576581 \tAcc: 0.9665850904 \tTPR:0.9884625329 \tFPR:0.1185534680 \tF1:0.9790297574 \t AUC:0.9349545325\tTrain cost: 0:00:35\n",
      "Client2 Test =>                 \tLoss: 0.1768141010 \tAcc: 0.9389583333 \tTPR:0.9569718188 \tFPR:0.0805566180 \tF1:0.9393540650 \tAUC:0.9382076004 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.09521418776851917 \tALA epochs: 2\n",
      "Client 3: Local Initial ALA epochs: 2 Loss: 0.21232749463524669409\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1461917883 \tAcc: 0.9451974565 \tTPR:0.9432804818 \tFPR:0.0551057555 \tF1:0.9342328952 \t AUC:0.9440873631\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1335626894 \tAcc: 0.9469126506 \tTPR:0.9450390741 \tFPR:0.0536594508 \tF1:0.9379168663 \t AUC:0.9456898116\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1297250933 \tAcc: 0.9487951807 \tTPR:0.9549846431 \tFPR:0.0535911710 \tF1:0.9416792043 \t AUC:0.9506967360\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1223286450 \tAcc: 0.9517653949 \tTPR:0.9525977643 \tFPR:0.0490931359 \tF1:0.9462966065 \t AUC:0.9517523142\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1179893442 \tAcc: 0.9527275770 \tTPR:0.9557291454 \tFPR:0.0517234116 \tF1:0.9424044818 \t AUC:0.9520028669\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.1906961393 \tAcc: 0.9327083333 \tTPR:0.9014079274 \tFPR:0.0386312765 \tF1:0.9268380021 \tAUC:0.9313883255 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.06623713617203432 \tALA epochs: 2\n",
      "Client 1: Local Initial ALA epochs: 2 Loss: 0.17925759814405703430\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0960487770 \tAcc: 0.9612573099 \tTPR:0.7995323958 \tFPR:0.0176035621 \tF1:0.7869988652 \t AUC:0.8873195513\tTrain cost: 0:01:05\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0917757073 \tAcc: 0.9609740497 \tTPR:0.7983825304 \tFPR:0.0177854726 \tF1:0.7868288565 \t AUC:0.8875739685\tTrain cost: 0:01:05\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0874056751 \tAcc: 0.9637701023 \tTPR:0.8101074445 \tFPR:0.0162733284 \tF1:0.7948558078 \t AUC:0.8946428957\tTrain cost: 0:01:09\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0856557832 \tAcc: 0.9649579678 \tTPR:0.8174376915 \tFPR:0.0165452709 \tF1:0.8082021472 \t AUC:0.8986777229\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0823787023 \tAcc: 0.9666027047 \tTPR:0.8216803583 \tFPR:0.0145417180 \tF1:0.8147013456 \t AUC:0.9018419316\tTrain cost: 0:01:11\n",
      "Client1 Test =>                 \tLoss: 0.3347223227 \tAcc: 0.8750000000 \tTPR:0.7611734157 \tFPR:0.0176323559 \tF1:0.8503345275 \tAUC:0.8717705299 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.08675225941956691 \tALA epochs: 2\n",
      "Client 8: Local Initial ALA epochs: 2 Loss: 0.35575611411190743993\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1226510068 \tAcc: 0.9543269231 \tTPR:0.9780141884 \tFPR:0.1277857744 \tF1:0.9699895239 \t AUC:0.9251142070\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1149642171 \tAcc: 0.9577477811 \tTPR:0.9821047233 \tFPR:0.1259535911 \tF1:0.9721653482 \t AUC:0.9280755661\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1073458421 \tAcc: 0.9595968935 \tTPR:0.9815575154 \tFPR:0.1162727887 \tF1:0.9736927735 \t AUC:0.9326423634\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1030977248 \tAcc: 0.9620007396 \tTPR:0.9843377669 \tFPR:0.1136404026 \tF1:0.9748453950 \t AUC:0.9353254444\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1032929268 \tAcc: 0.9607063609 \tTPR:0.9845651072 \tFPR:0.1145570406 \tF1:0.9741479528 \t AUC:0.9350040333\tTrain cost: 0:00:34\n",
      "Client8 Test =>                 \tLoss: 0.1988362947 \tAcc: 0.9339583333 \tTPR:0.9307752335 \tFPR:0.0615260776 \tF1:0.9306166392 \tAUC:0.9346245779 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2469271095 \tAcc: 0.9155416667 \tTPR:0.8720698226 \tFPR:0.0436540795 \tF1:0.9059111536 \tAUC:0.9142078715\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 9:  =============\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.05211752061256923 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.10390623542480170727\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1236890366 \tAcc: 0.9521837349 \tTPR:0.9516146200 \tFPR:0.0479816304 \tF1:0.9450549460 \t AUC:0.9518164948\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1189300691 \tAcc: 0.9531040830 \tTPR:0.9575108614 \tFPR:0.0482284592 \tF1:0.9449196255 \t AUC:0.9546412011\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1161288938 \tAcc: 0.9534805890 \tTPR:0.9581841734 \tFPR:0.0494482093 \tF1:0.9465399699 \t AUC:0.9543679820\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1103927419 \tAcc: 0.9559069612 \tTPR:0.9583773150 \tFPR:0.0449720465 \tF1:0.9483015718 \t AUC:0.9567026343\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1039399352 \tAcc: 0.9612198795 \tTPR:0.9616064777 \tFPR:0.0394252564 \tF1:0.9560528505 \t AUC:0.9610906106\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.2306582180 \tAcc: 0.9260416667 \tTPR:0.8793349176 \tFPR:0.0304974953 \tF1:0.9180240072 \tAUC:0.9244187112 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.040682342949792415 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.13773004345433867424\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1298445822 \tAcc: 0.9496192174 \tTPR:0.9733214797 \tFPR:0.0921489594 \tF1:0.9605292040 \t AUC:0.9405862602\tTrain cost: 0:01:59\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1236225651 \tAcc: 0.9520834722 \tTPR:0.9748666166 \tFPR:0.0896208392 \tF1:0.9623366890 \t AUC:0.9426228887\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1194126130 \tAcc: 0.9528271231 \tTPR:0.9743487224 \tFPR:0.0864925568 \tF1:0.9628343173 \t AUC:0.9439280828\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1175179389 \tAcc: 0.9545206472 \tTPR:0.9765192273 \tFPR:0.0852867188 \tF1:0.9643592581 \t AUC:0.9456162542\tTrain cost: 0:02:01\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1157441124 \tAcc: 0.9556434142 \tTPR:0.9767753709 \tFPR:0.0822132597 \tF1:0.9650670164 \t AUC:0.9472810556\tTrain cost: 0:01:59\n",
      "Client4 Test =>                 \tLoss: 0.2335731698 \tAcc: 0.9237500000 \tTPR:0.8909716159 \tFPR:0.0448087448 \tF1:0.9174996393 \tAUC:0.9230814355 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.05198076186045316 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.16093188872585048599\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1592068522 \tAcc: 0.9366945876 \tTPR:0.9466499530 \tFPR:0.0733533682 \tF1:0.9316973804 \t AUC:0.9366482924\tTrain cost: 0:00:37\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1552855457 \tAcc: 0.9377805057 \tTPR:0.9484308250 \tFPR:0.0720162034 \tF1:0.9340107705 \t AUC:0.9382073108\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1443695044 \tAcc: 0.9431212229 \tTPR:0.9527093754 \tFPR:0.0667982002 \tF1:0.9389531811 \t AUC:0.9429555876\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1410978163 \tAcc: 0.9427185167 \tTPR:0.9504936315 \tFPR:0.0650937383 \tF1:0.9382268550 \t AUC:0.9426999466\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1379539682 \tAcc: 0.9447320476 \tTPR:0.9542610431 \tFPR:0.0637747314 \tF1:0.9410908976 \t AUC:0.9452431558\tTrain cost: 0:00:41\n",
      "Client6 Test =>                 \tLoss: 0.1870417318 \tAcc: 0.9395833333 \tTPR:0.9281256400 \tFPR:0.0496091798 \tF1:0.9360395593 \tAUC:0.9392582301 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.07090344258513372 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.12713567656464874744\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1378201920 \tAcc: 0.9480406746 \tTPR:0.9749583018 \tFPR:0.1155135374 \tF1:0.9612228671 \t AUC:0.9297223822\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1258484523 \tAcc: 0.9501488095 \tTPR:0.9739953542 \tFPR:0.0998635624 \tF1:0.9628436716 \t AUC:0.9370658959\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1194408852 \tAcc: 0.9536210317 \tTPR:0.9778222329 \tFPR:0.0972202731 \tF1:0.9654509599 \t AUC:0.9403009799\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1168914657 \tAcc: 0.9532490079 \tTPR:0.9770174236 \tFPR:0.0912027651 \tF1:0.9647644473 \t AUC:0.9429073292\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1103796638 \tAcc: 0.9606894841 \tTPR:0.9842411651 \tFPR:0.0850655132 \tF1:0.9703498027 \t AUC:0.9495878260\tTrain cost: 0:00:08\n",
      "Client7 Test =>                 \tLoss: 0.2194620518 \tAcc: 0.9297916667 \tTPR:0.9248552369 \tFPR:0.0678490657 \tF1:0.9267317682 \tAUC:0.9285030856 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.04392728311426873 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.05988623252646489703\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0543417492 \tAcc: 0.9807291667 \tTPR:0.9926807476 \tFPR:0.1730158730 \tF1:0.9894182794 \t AUC:0.9096398254\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0550340337 \tAcc: 0.9812500000 \tTPR:0.9943726795 \tFPR:0.2021604938 \tF1:0.9898165430 \t AUC:0.8960828158\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0431194106 \tAcc: 0.9848958333 \tTPR:0.9956943286 \tFPR:0.1654545455 \tF1:0.9919011554 \t AUC:0.9157764519\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0384672332 \tAcc: 0.9859375000 \tTPR:0.9960960897 \tFPR:0.1304761905 \tF1:0.9922807335 \t AUC:0.9326324991\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0360824132 \tAcc: 0.9869791667 \tTPR:0.9943790082 \tFPR:0.1224242424 \tF1:0.9929256878 \t AUC:0.9357218833\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.2581216636 \tAcc: 0.9308333333 \tTPR:0.9820604427 \tFPR:0.1186317158 \tF1:0.9330239130 \tAUC:0.9317143634 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2257713670 \tAcc: 0.9300000000 \tTPR:0.9210695706 \tFPR:0.0622792403 \tF1:0.9262637774 \tAUC:0.9293951652\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 10:  =============\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.053041080640935746 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.10015365989370779431\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0575812407 \tAcc: 0.9833333333 \tTPR:0.9939749027 \tFPR:0.1789308176 \tF1:0.9910205562 \t AUC:0.9074189701\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0452824587 \tAcc: 0.9796875000 \tTPR:0.9938917886 \tFPR:0.1963636364 \tF1:0.9889200428 \t AUC:0.8984864301\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0422658602 \tAcc: 0.9861607143 \tTPR:0.9966796275 \tFPR:0.1003267974 \tF1:0.9923783828 \t AUC:0.9481898136\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0352316485 \tAcc: 0.9864583333 \tTPR:0.9965214485 \tFPR:0.1339622642 \tF1:0.9925103367 \t AUC:0.9310498765\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0330880870 \tAcc: 0.9899553571 \tTPR:0.9954168657 \tFPR:0.0580128205 \tF1:0.9944121111 \t AUC:0.9686499546\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.2597357970 \tAcc: 0.9345833333 \tTPR:0.9706651280 \tFPR:0.1046873415 \tF1:0.9364795338 \tAUC:0.9329888933 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.07177199326518946 \tALA epochs: 5\n",
      "Client 0: Local Initial ALA epochs: 5 Loss: 0.16112232871353626695\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1629364988 \tAcc: 0.9464285714 \tTPR:0.9753527596 \tFPR:0.1556422744 \tF1:0.9660833577 \t AUC:0.9098552426\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1426163183 \tAcc: 0.9487920168 \tTPR:0.9712733720 \tFPR:0.1322991493 \tF1:0.9667431620 \t AUC:0.9194871114\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1425367526 \tAcc: 0.9568671218 \tTPR:0.9863409937 \tFPR:0.1447137188 \tF1:0.9710758641 \t AUC:0.9208136374\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1241441348 \tAcc: 0.9510241597 \tTPR:0.9811147847 \tFPR:0.1687074830 \tF1:0.9688665425 \t AUC:0.9062036508\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1201627184 \tAcc: 0.9546349790 \tTPR:0.9817591411 \tFPR:0.1423933210 \tF1:0.9708546241 \t AUC:0.9196829101\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.1797579149 \tAcc: 0.9370833333 \tTPR:0.9444313955 \tFPR:0.0718738851 \tF1:0.9378816028 \tAUC:0.9362787552 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.04111031853544163 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.11137298956068593381\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1138508370 \tAcc: 0.9587647929 \tTPR:0.9838541676 \tFPR:0.1330290190 \tF1:0.9729839836 \t AUC:0.9254125743\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1106731739 \tAcc: 0.9590421598 \tTPR:0.9819626916 \tFPR:0.1137497517 \tF1:0.9731132359 \t AUC:0.9340797084\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1038588234 \tAcc: 0.9629252959 \tTPR:0.9858015976 \tFPR:0.1160059854 \tF1:0.9758252330 \t AUC:0.9348767402\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0990771547 \tAcc: 0.9634800296 \tTPR:0.9841145974 \tFPR:0.1040297474 \tF1:0.9760773205 \t AUC:0.9400424250\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0996709865 \tAcc: 0.9628328402 \tTPR:0.9841740857 \tFPR:0.1133337652 \tF1:0.9758361115 \t AUC:0.9354201603\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.1995978087 \tAcc: 0.9339583333 \tTPR:0.9305238073 \tFPR:0.0636163494 \tF1:0.9299992430 \tAUC:0.9334537290 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.08072762575169655 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.12697078182827681303\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1232332360 \tAcc: 0.9523809524 \tTPR:0.9767989920 \tFPR:0.0994105101 \tF1:0.9644244999 \t AUC:0.9386942410\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1196610450 \tAcc: 0.9549851190 \tTPR:0.9778266526 \tFPR:0.0903113421 \tF1:0.9666717962 \t AUC:0.9437576552\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1130959151 \tAcc: 0.9580853175 \tTPR:0.9786868836 \tFPR:0.0823891318 \tF1:0.9683758837 \t AUC:0.9481488759\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1047925758 \tAcc: 0.9614335317 \tTPR:0.9786872907 \tFPR:0.0763844951 \tF1:0.9710820931 \t AUC:0.9511513978\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0965019173 \tAcc: 0.9657738095 \tTPR:0.9839796386 \tFPR:0.0750440367 \tF1:0.9743865646 \t AUC:0.9544678010\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2348183314 \tAcc: 0.9266666667 \tTPR:0.9225285085 \tFPR:0.0680833518 \tF1:0.9245172734 \tAUC:0.9272225784 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.08358495225223266 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.13157596166205146049\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1193595700 \tAcc: 0.9533957972 \tTPR:0.9742691160 \tFPR:0.0854919246 \tF1:0.9632156778 \t AUC:0.9443885957\tTrain cost: 0:01:55\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1141564455 \tAcc: 0.9558600520 \tTPR:0.9762161559 \tFPR:0.0816657416 \tF1:0.9652712530 \t AUC:0.9472752071\tTrain cost: 0:01:59\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1113210576 \tAcc: 0.9568349220 \tTPR:0.9772403349 \tFPR:0.0785302741 \tF1:0.9661295053 \t AUC:0.9493550304\tTrain cost: 0:02:01\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1092120394 \tAcc: 0.9581889081 \tTPR:0.9779136309 \tFPR:0.0777404031 \tF1:0.9670839479 \t AUC:0.9500866139\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1063184299 \tAcc: 0.9579597720 \tTPR:0.9771001716 \tFPR:0.0768940914 \tF1:0.9668104786 \t AUC:0.9501030401\tTrain cost: 0:01:58\n",
      "Client4 Test =>                 \tLoss: 0.2318162581 \tAcc: 0.9245833333 \tTPR:0.9069213224 \tFPR:0.0578612035 \tF1:0.9215162447 \tAUC:0.9245300594 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2211452220 \tAcc: 0.9313750000 \tTPR:0.9350140323 \tFPR:0.0732244263 \tF1:0.9300787795 \tAUC:0.9308948030\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 11:  =============\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.08688366675561764 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.27148470271910940532\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1007003090 \tAcc: 0.9596574859 \tTPR:0.8665559958 \tFPR:0.0229987857 \tF1:0.8468734047 \t AUC:0.9213995028\tTrain cost: 0:00:35\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0959670442 \tAcc: 0.9598340395 \tTPR:0.8561270493 \tFPR:0.0212015550 \tF1:0.8451654533 \t AUC:0.9170540172\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0894710786 \tAcc: 0.9643714689 \tTPR:0.8704956139 \tFPR:0.0192250626 \tF1:0.8636993276 \t AUC:0.9256352757\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0833888972 \tAcc: 0.9656603107 \tTPR:0.8776768900 \tFPR:0.0188970693 \tF1:0.8698459406 \t AUC:0.9290424015\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0811025355 \tAcc: 0.9667196328 \tTPR:0.8845761897 \tFPR:0.0176661054 \tF1:0.8754310028 \t AUC:0.9331271336\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.3680052629 \tAcc: 0.8935416667 \tTPR:0.7999847036 \tFPR:0.0143260535 \tF1:0.8756549489 \tAUC:0.8928293250 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.07247321833119605 \tALA epochs: 3\n",
      "Client 7: Local Initial ALA epochs: 3 Loss: 0.27670087556665140527\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1300028440 \tAcc: 0.9508928571 \tTPR:0.9729173017 \tFPR:0.0914440601 \tF1:0.9631087200 \t AUC:0.9407366208\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1184228846 \tAcc: 0.9562251984 \tTPR:0.9765337667 \tFPR:0.0866730025 \tF1:0.9674008562 \t AUC:0.9449303821\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1109160111 \tAcc: 0.9580853175 \tTPR:0.9775726342 \tFPR:0.0836434773 \tF1:0.9686882349 \t AUC:0.9469645785\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1049158530 \tAcc: 0.9605654762 \tTPR:0.9792339107 \tFPR:0.0789689030 \tF1:0.9710162710 \t AUC:0.9501325038\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1075108271 \tAcc: 0.9598214286 \tTPR:0.9794089000 \tFPR:0.0877655083 \tF1:0.9696531622 \t AUC:0.9458216958\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2070475203 \tAcc: 0.9308333333 \tTPR:0.9276735248 \tFPR:0.0648126476 \tF1:0.9288142517 \tAUC:0.9314304386 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.06133297765966423 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.14988256478682160378\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1232678905 \tAcc: 0.9503012048 \tTPR:0.9531972824 \tFPR:0.0501856437 \tF1:0.9438128305 \t AUC:0.9515058194\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1114611502 \tAcc: 0.9559487952 \tTPR:0.9580632932 \tFPR:0.0462302837 \tF1:0.9480522161 \t AUC:0.9559165048\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1087991477 \tAcc: 0.9563253012 \tTPR:0.9617770459 \tFPR:0.0467943333 \tF1:0.9504552082 \t AUC:0.9574913563\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1084285992 \tAcc: 0.9591281794 \tTPR:0.9672858996 \tFPR:0.0477822409 \tF1:0.9529632910 \t AUC:0.9597518294\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1033028824 \tAcc: 0.9557396252 \tTPR:0.9583692569 \tFPR:0.0458492248 \tF1:0.9491785525 \t AUC:0.9562600161\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.2402706035 \tAcc: 0.9229166667 \tTPR:0.8698573140 \tFPR:0.0258595469 \tF1:0.9143615527 \tAUC:0.9219988835 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.07205751407997593 \tALA epochs: 5\n",
      "Client 1: Local Initial ALA epochs: 5 Loss: 0.13070738957783975542\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0904746120 \tAcc: 0.9632035819 \tTPR:0.8096235960 \tFPR:0.0178953480 \tF1:0.7969085285 \t AUC:0.8932914699\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0845817486 \tAcc: 0.9648209064 \tTPR:0.8140664160 \tFPR:0.0154559739 \tF1:0.8022167774 \t AUC:0.8965050165\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0801223785 \tAcc: 0.9682017544 \tTPR:0.8318707649 \tFPR:0.0143141232 \tF1:0.8251980638 \t AUC:0.9066357444\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0774452684 \tAcc: 0.9671509503 \tTPR:0.8233709273 \tFPR:0.0150981217 \tF1:0.8142897133 \t AUC:0.9024253909\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0748531434 \tAcc: 0.9701206140 \tTPR:0.8354967279 \tFPR:0.0136151456 \tF1:0.8303865322 \t AUC:0.9090965841\tTrain cost: 0:01:11\n",
      "Client1 Test =>                 \tLoss: 0.4641431473 \tAcc: 0.8591666667 \tTPR:0.7247515523 \tFPR:0.0110783092 \tF1:0.8305209762 \tAUC:0.8568366216 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.08157708835599779 \tALA epochs: 11\n",
      "Client 2: Local Initial ALA epochs: 11 Loss: 0.43119767032173711430\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1022125524 \tAcc: 0.9638554217 \tTPR:0.9848341310 \tFPR:0.1288919078 \tF1:0.9772583604 \t AUC:0.9279725029\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0916692812 \tAcc: 0.9672439759 \tTPR:0.9873564337 \tFPR:0.1119808237 \tF1:0.9794484030 \t AUC:0.9376878050\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0878111400 \tAcc: 0.9680911145 \tTPR:0.9881848305 \tFPR:0.1186280838 \tF1:0.9799201732 \t AUC:0.9347783734\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0860034867 \tAcc: 0.9687500000 \tTPR:0.9889591860 \tFPR:0.1150425271 \tF1:0.9803887164 \t AUC:0.9369416515\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0801795631 \tAcc: 0.9697853916 \tTPR:0.9883328460 \tFPR:0.1083098925 \tF1:0.9809886284 \t AUC:0.9399938526\tTrain cost: 0:00:35\n",
      "Client2 Test =>                 \tLoss: 0.1785534215 \tAcc: 0.9416666667 \tTPR:0.9743780261 \tFPR:0.0930739119 \tF1:0.9433169847 \tAUC:0.9406520571 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2916039911 \tAcc: 0.9096250000 \tTPR:0.8593290242 \tFPR:0.0418300938 \tF1:0.8985337429 \tAUC:0.9087494652\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 12:  =============\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.07497324240428956 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.13544605115277910667\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0829906526 \tAcc: 0.9671052632 \tTPR:0.8281599938 \tFPR:0.0156382827 \tF1:0.8174025214 \t AUC:0.9047265698\tTrain cost: 0:01:08\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0793420959 \tAcc: 0.9679733187 \tTPR:0.8244331895 \tFPR:0.0144219814 \tF1:0.8168766171 \t AUC:0.9033048823\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0742698083 \tAcc: 0.9700749269 \tTPR:0.8466583124 \tFPR:0.0146039253 \tF1:0.8353875552 \t AUC:0.9145417674\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0729875068 \tAcc: 0.9708059211 \tTPR:0.8469609419 \tFPR:0.0134330937 \tF1:0.8381089594 \t AUC:0.9142209791\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0702365768 \tAcc: 0.9720303363 \tTPR:0.8589320524 \tFPR:0.0130682935 \tF1:0.8410779295 \t AUC:0.9201448227\tTrain cost: 0:01:12\n",
      "Client1 Test =>                 \tLoss: 0.4847166732 \tAcc: 0.8612500000 \tTPR:0.7295822416 \tFPR:0.0127457121 \tF1:0.8325376731 \tAUC:0.8584182648 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.059101676631363405 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.08189691270568541515\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0879767726 \tAcc: 0.9641066384 \tTPR:0.8715483120 \tFPR:0.0198633221 \tF1:0.8619981512 \t AUC:0.9256605520\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0797517047 \tAcc: 0.9666137006 \tTPR:0.8847891750 \tFPR:0.0184511028 \tF1:0.8756178544 \t AUC:0.9330058480\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0776031934 \tAcc: 0.9698446328 \tTPR:0.8878262039 \tFPR:0.0150440517 \tF1:0.8863818318 \t AUC:0.9360724005\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0738595110 \tAcc: 0.9691031073 \tTPR:0.8963674273 \tFPR:0.0172098117 \tF1:0.8841854751 \t AUC:0.9389866217\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0685089066 \tAcc: 0.9721398305 \tTPR:0.9109137880 \tFPR:0.0158530485 \tF1:0.9004001452 \t AUC:0.9470213057\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.5227690791 \tAcc: 0.8631250000 \tTPR:0.7353511942 \tFPR:0.0104305974 \tF1:0.8366472329 \tAUC:0.8624602984 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.16322668137966614 \tALA epochs: 11\n",
      "Client 6: Local Initial ALA epochs: 11 Loss: 0.32838316862234995241\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1533892504 \tAcc: 0.9369362113 \tTPR:0.9466145182 \tFPR:0.0718830119 \tF1:0.9324899522 \t AUC:0.9373657532\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1424102490 \tAcc: 0.9419853137 \tTPR:0.9482711892 \tFPR:0.0642534225 \tF1:0.9377888711 \t AUC:0.9420088833\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1374469164 \tAcc: 0.9465039549 \tTPR:0.9557904076 \tFPR:0.0623446618 \tF1:0.9424935488 \t AUC:0.9467228729\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1294080647 \tAcc: 0.9475593228 \tTPR:0.9531555377 \tFPR:0.0581104087 \tF1:0.9437044572 \t AUC:0.9475225645\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1306637360 \tAcc: 0.9477120734 \tTPR:0.9531032997 \tFPR:0.0583622268 \tF1:0.9427423895 \t AUC:0.9473705364\tTrain cost: 0:00:40\n",
      "Client6 Test =>                 \tLoss: 0.2184412527 \tAcc: 0.9310416667 \tTPR:0.8958315567 \tFPR:0.0323947769 \tF1:0.9258128104 \tAUC:0.9317183899 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.041577829497496055 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.12898123314353956981\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1135590094 \tAcc: 0.9553439349 \tTPR:0.9815095069 \tFPR:0.1342450859 \tF1:0.9706826312 \t AUC:0.9236322105\tTrain cost: 0:00:32\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1048713561 \tAcc: 0.9615384615 \tTPR:0.9840466029 \tFPR:0.1119114777 \tF1:0.9747425513 \t AUC:0.9360675626\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0964164901 \tAcc: 0.9636649408 \tTPR:0.9835929004 \tFPR:0.1036983562 \tF1:0.9762665827 \t AUC:0.9399472721\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0943104723 \tAcc: 0.9656065089 \tTPR:0.9862506580 \tFPR:0.1013103309 \tF1:0.9775933674 \t AUC:0.9424701636\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0899065917 \tAcc: 0.9672707101 \tTPR:0.9858655650 \tFPR:0.0966002922 \tF1:0.9784752930 \t AUC:0.9446116654\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.1985281764 \tAcc: 0.9352083333 \tTPR:0.9523581504 \tFPR:0.0827639728 \tF1:0.9339480980 \tAUC:0.9347970888 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.07158937960854335 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.09196157783100550320\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0947902686 \tAcc: 0.9643260542 \tTPR:0.9861838114 \tFPR:0.1227855478 \tF1:0.9774490992 \t AUC:0.9316991318\tTrain cost: 0:00:32\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0885987139 \tAcc: 0.9663027108 \tTPR:0.9862495776 \tFPR:0.1119906445 \tF1:0.9788228435 \t AUC:0.9371086956\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0817074175 \tAcc: 0.9704442771 \tTPR:0.9891766463 \tFPR:0.1066031820 \tF1:0.9812636989 \t AUC:0.9412703827\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0784604214 \tAcc: 0.9706325301 \tTPR:0.9882468357 \tFPR:0.1025607742 \tF1:0.9814772961 \t AUC:0.9428252767\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0749394685 \tAcc: 0.9729856928 \tTPR:0.9898479666 \tFPR:0.0985124225 \tF1:0.9829726154 \t AUC:0.9456524367\tTrain cost: 0:00:35\n",
      "Client2 Test =>                 \tLoss: 0.1796955135 \tAcc: 0.9425000000 \tTPR:0.9600574059 \tFPR:0.0742861952 \tF1:0.9416886150 \tAUC:0.9428856054 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.3208301390 \tAcc: 0.9066250000 \tTPR:0.8546361098 \tFPR:0.0425242509 \tF1:0.8941268859 \tAUC:0.9060559294\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 13:  =============\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.07158624793644958 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.14729035747322169470\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0452023687 \tAcc: 0.9828125000 \tTPR:0.9927265383 \tFPR:0.1278735632 \tF1:0.9906141146 \t AUC:0.9325704796\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0398327541 \tAcc: 0.9857886905 \tTPR:0.9966807476 \tFPR:0.1558479532 \tF1:0.9923085477 \t AUC:0.9203290484\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0318532057 \tAcc: 0.9869791667 \tTPR:0.9955864375 \tFPR:0.1125000000 \tF1:0.9928950088 \t AUC:0.9416646094\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0311686461 \tAcc: 0.9890625000 \tTPR:0.9961648746 \tFPR:0.0841346154 \tF1:0.9939833452 \t AUC:0.9557201199\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0253303396 \tAcc: 0.9927083333 \tTPR:0.9983074472 \tFPR:0.0730994152 \tF1:0.9960165524 \t AUC:0.9625594752\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.2596013236 \tAcc: 0.9350000000 \tTPR:0.9721013625 \tFPR:0.1030123898 \tF1:0.9364109101 \tAUC:0.9345444863 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.23448767433437684 \tALA epochs: 11\n",
      "Client 5: Local Initial ALA epochs: 11 Loss: 0.54716089633958675531\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0843091423 \tAcc: 0.9670197740 \tTPR:0.8891357466 \tFPR:0.0197837629 \tF1:0.8766798477 \t AUC:0.9345189603\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0712980972 \tAcc: 0.9698093220 \tTPR:0.9002443727 \tFPR:0.0173204281 \tF1:0.8902639236 \t AUC:0.9411785756\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0664015405 \tAcc: 0.9751412429 \tTPR:0.9191681749 \tFPR:0.0147756521 \tF1:0.9070926210 \t AUC:0.9520817687\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0632813369 \tAcc: 0.9750882768 \tTPR:0.9198386203 \tFPR:0.0148532430 \tF1:0.9082633121 \t AUC:0.9523791456\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0582458021 \tAcc: 0.9765183616 \tTPR:0.9147854656 \tFPR:0.0120630386 \tF1:0.9148079418 \t AUC:0.9509970489\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.4558479909 \tAcc: 0.8935416667 \tTPR:0.7989781248 \tFPR:0.0124014506 \tF1:0.8786261055 \tAUC:0.8932883371 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.0857342729257949 \tALA epochs: 6\n",
      "Client 2: Local Initial ALA epochs: 6 Loss: 0.35088678187634231298\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0973157219 \tAcc: 0.9638554217 \tTPR:0.9859578894 \tFPR:0.1245234183 \tF1:0.9772966481 \t AUC:0.9307172355\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0846250754 \tAcc: 0.9686558735 \tTPR:0.9889420424 \tFPR:0.1141468471 \tF1:0.9804170054 \t AUC:0.9373975976\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0817411403 \tAcc: 0.9697853916 \tTPR:0.9889541110 \tFPR:0.1096586145 \tF1:0.9809098001 \t AUC:0.9396477482\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0802323352 \tAcc: 0.9700677711 \tTPR:0.9893975540 \tFPR:0.1101645334 \tF1:0.9811714833 \t AUC:0.9396004945\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0725288456 \tAcc: 0.9728915663 \tTPR:0.9906009059 \tFPR:0.0984493167 \tF1:0.9829340118 \t AUC:0.9460757946\tTrain cost: 0:00:34\n",
      "Client2 Test =>                 \tLoss: 0.1766544550 \tAcc: 0.9420833333 \tTPR:0.9447966645 \tFPR:0.0596684925 \tF1:0.9405185172 \tAUC:0.9425640860 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.07706645958319686 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.18009284734725952704\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1647320775 \tAcc: 0.9420955882 \tTPR:0.9747314722 \tFPR:0.1825435477 \tF1:0.9627738535 \t AUC:0.8960939623\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1393597566 \tAcc: 0.9510241597 \tTPR:0.9858410618 \tFPR:0.1796737213 \tF1:0.9687157796 \t AUC:0.9039788751\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1242957185 \tAcc: 0.9575892857 \tTPR:0.9827442002 \tFPR:0.1262471655 \tF1:0.9723917246 \t AUC:0.9282485174\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1363603476 \tAcc: 0.9486607143 \tTPR:0.9836593117 \tFPR:0.1748041641 \tF1:0.9667471680 \t AUC:0.9044275738\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1145087363 \tAcc: 0.9600840336 \tTPR:0.9861309649 \tFPR:0.1176445578 \tF1:0.9736333876 \t AUC:0.9342432035\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.1747996993 \tAcc: 0.9362500000 \tTPR:0.9232900137 \tFPR:0.0522174361 \tF1:0.9343163951 \tAUC:0.9355362888 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.0769712422250304 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.10262443847022950649\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1147370172 \tAcc: 0.9521329365 \tTPR:0.9750085580 \tFPR:0.0897577349 \tF1:0.9637298538 \t AUC:0.9426254116\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1050211977 \tAcc: 0.9583333333 \tTPR:0.9781137303 \tFPR:0.0808088059 \tF1:0.9684853465 \t AUC:0.9486524622\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1033105033 \tAcc: 0.9623015873 \tTPR:0.9763086359 \tFPR:0.0632208215 \tF1:0.9715731413 \t AUC:0.9565439072\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0975322618 \tAcc: 0.9621775794 \tTPR:0.9827156512 \tFPR:0.0791159733 \tF1:0.9715032520 \t AUC:0.9517998390\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0922761161 \tAcc: 0.9619295635 \tTPR:0.9800402344 \tFPR:0.0717500899 \tF1:0.9713660409 \t AUC:0.9541450722\tTrain cost: 0:00:08\n",
      "Client7 Test =>                 \tLoss: 0.2200653739 \tAcc: 0.9277083333 \tTPR:0.9040872449 \tFPR:0.0500644367 \tF1:0.9235543959 \tAUC:0.9270114041 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2573937685 \tAcc: 0.9269166667 \tTPR:0.9086506821 \tFPR:0.0554728411 \tF1:0.9226852648 \tAUC:0.9265889205\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 14:  =============\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.07379153734235154 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.15382783676727446176\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1392761701 \tAcc: 0.9434350560 \tTPR:0.9493829977 \tFPR:0.0614085062 \tF1:0.9385768162 \t AUC:0.9439872457\tTrain cost: 0:00:37\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1308531132 \tAcc: 0.9448209207 \tTPR:0.9488143672 \tFPR:0.0600593506 \tF1:0.9403358845 \t AUC:0.9443775083\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1256251640 \tAcc: 0.9515141753 \tTPR:0.9601778887 \tFPR:0.0574355033 \tF1:0.9483476930 \t AUC:0.9513711927\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1229569453 \tAcc: 0.9514975116 \tTPR:0.9587667805 \tFPR:0.0567382853 \tF1:0.9481962710 \t AUC:0.9510142476\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1215741403 \tAcc: 0.9499588962 \tTPR:0.9566686580 \tFPR:0.0545160394 \tF1:0.9462489047 \t AUC:0.9510763093\tTrain cost: 0:00:40\n",
      "Client6 Test =>                 \tLoss: 0.2196899536 \tAcc: 0.9337500000 \tTPR:0.8961083815 \tFPR:0.0318632088 \tF1:0.9274672663 \tAUC:0.9321225864 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.07546678060172311 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.11903271707040923022\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0719996766 \tAcc: 0.9707274011 \tTPR:0.9077369743 \tFPR:0.0172049873 \tF1:0.8959275484 \t AUC:0.9451353093\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0647042521 \tAcc: 0.9724929379 \tTPR:0.9057479557 \tFPR:0.0156823117 \tF1:0.8943392169 \t AUC:0.9446300355\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0568883008 \tAcc: 0.9762535311 \tTPR:0.9217961496 \tFPR:0.0139860010 \tF1:0.9166852294 \t AUC:0.9537943039\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0551966944 \tAcc: 0.9769950565 \tTPR:0.9198327606 \tFPR:0.0132095868 \tF1:0.9133875315 \t AUC:0.9533115869\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0506428052 \tAcc: 0.9796080508 \tTPR:0.9244774215 \tFPR:0.0116239414 \tF1:0.9140302509 \t AUC:0.9562121873\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.5811623256 \tAcc: 0.8762500000 \tTPR:0.7619828188 \tFPR:0.0114929373 \tF1:0.8546319474 \tAUC:0.8752449408 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.28040199620034456 \tALA epochs: 11\n",
      "Client 7: Local Initial ALA epochs: 11 Loss: 0.45361914868805219836\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1409808535 \tAcc: 0.9468005952 \tTPR:0.9686364654 \tFPR:0.1020541958 \tF1:0.9600367238 \t AUC:0.9332911348\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1120121923 \tAcc: 0.9582093254 \tTPR:0.9774270733 \tFPR:0.0851927999 \tF1:0.9688593043 \t AUC:0.9461171367\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1037436173 \tAcc: 0.9605654762 \tTPR:0.9791678655 \tFPR:0.0760218765 \tF1:0.9702834883 \t AUC:0.9515729945\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1018468945 \tAcc: 0.9629216270 \tTPR:0.9789119842 \tFPR:0.0701520371 \tF1:0.9726253167 \t AUC:0.9543799735\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0921385969 \tAcc: 0.9642857143 \tTPR:0.9805646444 \tFPR:0.0690904334 \tF1:0.9736183206 \t AUC:0.9557371055\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2167203745 \tAcc: 0.9285416667 \tTPR:0.9145179670 \tFPR:0.0549515502 \tF1:0.9247786447 \tAUC:0.9297832084 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.08459295476410604 \tALA epochs: 2\n",
      "Client 4: Local Initial ALA epochs: 2 Loss: 0.12167635642842429544\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1199682294 \tAcc: 0.9530041828 \tTPR:0.9748672109 \tFPR:0.0863578549 \tF1:0.9631070795 \t AUC:0.9442546780\tTrain cost: 0:01:59\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1124557801 \tAcc: 0.9560100320 \tTPR:0.9759713088 \tFPR:0.0799246083 \tF1:0.9653681652 \t AUC:0.9480233502\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1083497517 \tAcc: 0.9579597720 \tTPR:0.9772947651 \tFPR:0.0776595466 \tF1:0.9668601425 \t AUC:0.9498176093\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1052520291 \tAcc: 0.9593137582 \tTPR:0.9788145692 \tFPR:0.0762567910 \tF1:0.9681625529 \t AUC:0.9512788891\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1002052783 \tAcc: 0.9619134115 \tTPR:0.9806417174 \tFPR:0.0718144848 \tF1:0.9701645523 \t AUC:0.9544136163\tTrain cost: 0:02:00\n",
      "Client4 Test =>                 \tLoss: 0.2094235982 \tAcc: 0.9343750000 \tTPR:0.9265170328 \tFPR:0.0591460995 \tF1:0.9299927508 \tAUC:0.9336854667 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.1878743831977522 \tALA epochs: 11\n",
      "Client 1: Local Initial ALA epochs: 11 Loss: 0.21701611391328434753\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0787193152 \tAcc: 0.9682474415 \tTPR:0.8409907872 \tFPR:0.0159280224 \tF1:0.8234711076 \t AUC:0.9109910547\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0711404709 \tAcc: 0.9711714181 \tTPR:0.8526762508 \tFPR:0.0138116849 \tF1:0.8458319296 \t AUC:0.9177806714\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0672367786 \tAcc: 0.9725877193 \tTPR:0.8621959993 \tFPR:0.0133017898 \tF1:0.8500770700 \t AUC:0.9217245333\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0650033522 \tAcc: 0.9732273392 \tTPR:0.8566067948 \tFPR:0.0124867978 \tF1:0.8435227760 \t AUC:0.9206709436\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0614040205 \tAcc: 0.9740405702 \tTPR:0.8673007751 \tFPR:0.0123683132 \tF1:0.8544152653 \t AUC:0.9260798211\tTrain cost: 0:01:11\n",
      "Client1 Test =>                 \tLoss: 0.4643428013 \tAcc: 0.8716666667 \tTPR:0.7542097911 \tFPR:0.0120425711 \tF1:0.8485564315 \tAUC:0.8710836100 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.3382678106 \tAcc: 0.9089166667 \tTPR:0.8506671982 \tFPR:0.0338992734 \tF1:0.8970854081 \tAUC:0.9083839624\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 15:  =============\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.0928784820921299 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.14742993616053592931\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1091712292 \tAcc: 0.9583513865 \tTPR:0.9768947235 \tFPR:0.0758198289 \tF1:0.9671923934 \t AUC:0.9505374473\tTrain cost: 0:01:57\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1055492756 \tAcc: 0.9591637782 \tTPR:0.9785740426 \tFPR:0.0770041699 \tF1:0.9680394816 \t AUC:0.9507849364\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1014066194 \tAcc: 0.9607885615 \tTPR:0.9784829939 \tFPR:0.0700369036 \tF1:0.9690296825 \t AUC:0.9542230452\tTrain cost: 0:01:59\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0969710666 \tAcc: 0.9630090988 \tTPR:0.9807757569 \tFPR:0.0687133981 \tF1:0.9709802376 \t AUC:0.9560311794\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0939257908 \tAcc: 0.9637819124 \tTPR:0.9804646144 \tFPR:0.0665641840 \tF1:0.9713129706 \t AUC:0.9569502152\tTrain cost: 0:01:59\n",
      "Client4 Test =>                 \tLoss: 0.1904636011 \tAcc: 0.9370833333 \tTPR:0.9373661878 \tFPR:0.0651108697 \tF1:0.9336661473 \tAUC:0.9361276590 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.02504748530757573 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.05661361529068513476\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0446684060 \tAcc: 0.9822916667 \tTPR:0.9954750870 \tFPR:0.2115646259 \tF1:0.9902560116 \t AUC:0.8914473322\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0338788843 \tAcc: 0.9880208333 \tTPR:0.9956081989 \tFPR:0.1228070175 \tF1:0.9935922088 \t AUC:0.9365591398\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0258596573 \tAcc: 0.9890625000 \tTPR:0.9971775794 \tFPR:0.1057575758 \tF1:0.9939982484 \t AUC:0.9458658009\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0221030952 \tAcc: 0.9932291667 \tTPR:0.9966271165 \tFPR:0.0393081761 \tF1:0.9962543969 \t AUC:0.9784367326\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0330350165 \tAcc: 0.9875000000 \tTPR:0.9961589266 \tFPR:0.1123456790 \tF1:0.9932486251 \t AUC:0.9422719345\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.2293411076 \tAcc: 0.9397916667 \tTPR:0.9735182874 \tFPR:0.0930630384 \tF1:0.9404940664 \tAUC:0.9402276245 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.08864338032952572 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.16720695677213370800\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1241892425 \tAcc: 0.9532490079 \tTPR:0.9761401993 \tFPR:0.0945640717 \tF1:0.9651863042 \t AUC:0.9407880638\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1042233008 \tAcc: 0.9590773810 \tTPR:0.9818520814 \tFPR:0.0909290445 \tF1:0.9695491088 \t AUC:0.9454615184\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0982768030 \tAcc: 0.9635416667 \tTPR:0.9847098794 \tFPR:0.0854870658 \tF1:0.9739957002 \t AUC:0.9496114068\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0939041918 \tAcc: 0.9662698413 \tTPR:0.9841943307 \tFPR:0.0672749374 \tF1:0.9744527789 \t AUC:0.9584596967\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0902259593 \tAcc: 0.9655257937 \tTPR:0.9802781012 \tFPR:0.0691913245 \tF1:0.9739517774 \t AUC:0.9555433883\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2128810251 \tAcc: 0.9339583333 \tTPR:0.9243877758 \tFPR:0.0570851392 \tF1:0.9313372493 \tAUC:0.9336513183 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.0656205669963807 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.15016514730530899913\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1271658272 \tAcc: 0.9502893930 \tTPR:0.9585224342 \tFPR:0.0564644327 \tF1:0.9459672835 \t AUC:0.9510290007\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1195747139 \tAcc: 0.9506198898 \tTPR:0.9556326375 \tFPR:0.0540226199 \tF1:0.9459920372 \t AUC:0.9508050088\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1146496499 \tAcc: 0.9540914948 \tTPR:0.9596882815 \tFPR:0.0507561024 \tF1:0.9510139239 \t AUC:0.9544660895\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1088521048 \tAcc: 0.9576186456 \tTPR:0.9637524217 \tFPR:0.0490949576 \tF1:0.9537702277 \t AUC:0.9573287320\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1021620953 \tAcc: 0.9596405084 \tTPR:0.9656693534 \tFPR:0.0458333953 \tF1:0.9557117522 \t AUC:0.9599179791\tTrain cost: 0:00:39\n",
      "Client6 Test =>                 \tLoss: 0.2197293124 \tAcc: 0.9385416667 \tTPR:0.9168865434 \tFPR:0.0386819231 \tF1:0.9343618595 \tAUC:0.9391023101 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.09895594688615814 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.15931380606215336804\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0765417354 \tAcc: 0.9685215643 \tTPR:0.8467476562 \tFPR:0.0155564403 \tF1:0.8255706084 \t AUC:0.9134062887\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0680060505 \tAcc: 0.9723958333 \tTPR:0.8526408614 \tFPR:0.0123762176 \tF1:0.8402991936 \t AUC:0.9177985799\tTrain cost: 0:01:09\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0657841876 \tAcc: 0.9727704678 \tTPR:0.8609646486 \tFPR:0.0132110877 \tF1:0.8488530676 \t AUC:0.9213488650\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0619387019 \tAcc: 0.9743695175 \tTPR:0.8594054581 \tFPR:0.0119501120 \tF1:0.8477861768 \t AUC:0.9220439061\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0589715057 \tAcc: 0.9753746345 \tTPR:0.8719831987 \tFPR:0.0116258665 \tF1:0.8632205817 \t AUC:0.9289385630\tTrain cost: 0:01:10\n",
      "Client1 Test =>                 \tLoss: 0.4114400831 \tAcc: 0.8795833333 \tTPR:0.7718833880 \tFPR:0.0146445047 \tF1:0.8585876263 \tAUC:0.8786194417 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2527710259 \tAcc: 0.9257916667 \tTPR:0.9048084365 \tFPR:0.0537170950 \tF1:0.9196893898 \tAUC:0.9255456707\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 16:  =============\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.03776483016103001 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.08558254573268420096\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0840282237 \tAcc: 0.9687500000 \tTPR:0.9875559637 \tFPR:0.1060107647 \tF1:0.9802691548 \t AUC:0.9407725995\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0768644924 \tAcc: 0.9726091867 \tTPR:0.9893316914 \tFPR:0.0944503298 \tF1:0.9827464288 \t AUC:0.9474245655\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0741369501 \tAcc: 0.9732680723 \tTPR:0.9903280913 \tFPR:0.0955557077 \tF1:0.9832855749 \t AUC:0.9473861918\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0687188422 \tAcc: 0.9755271084 \tTPR:0.9896579508 \tFPR:0.0867202911 \tF1:0.9846272193 \t AUC:0.9514688299\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0657276033 \tAcc: 0.9759036145 \tTPR:0.9905460422 \tFPR:0.0859700958 \tF1:0.9847258331 \t AUC:0.9522879732\tTrain cost: 0:00:35\n",
      "Client2 Test =>                 \tLoss: 0.1983553505 \tAcc: 0.9445833333 \tTPR:0.9659714117 \tFPR:0.0770994847 \tF1:0.9444883233 \tAUC:0.9444359635 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.0974896017325592 \tALA epochs: 4\n",
      "Client 4: Local Initial ALA epochs: 4 Loss: 0.13549782469977483812\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0989358422 \tAcc: 0.9625216638 \tTPR:0.9787260179 \tFPR:0.0664797204 \tF1:0.9703664266 \t AUC:0.9561231488\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0902624853 \tAcc: 0.9666377816 \tTPR:0.9827339772 \tFPR:0.0622520990 \tF1:0.9735753252 \t AUC:0.9602409391\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0905621052 \tAcc: 0.9646609619 \tTPR:0.9813510612 \tFPR:0.0656926801 \tF1:0.9722509732 \t AUC:0.9578291905\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0854453910 \tAcc: 0.9667731802 \tTPR:0.9817244146 \tFPR:0.0599467926 \tF1:0.9737723818 \t AUC:0.9608888110\tTrain cost: 0:02:02\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0807195692 \tAcc: 0.9681959072 \tTPR:0.9833246395 \tFPR:0.0591608153 \tF1:0.9748583884 \t AUC:0.9620819121\tTrain cost: 0:02:00\n",
      "Client4 Test =>                 \tLoss: 0.2278428292 \tAcc: 0.9312500000 \tTPR:0.9089495920 \tFPR:0.0490708124 \tF1:0.9260251154 \tAUC:0.9299393898 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.0791989124393584 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.11089550811448134482\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1136303779 \tAcc: 0.9585843373 \tTPR:0.9637876868 \tFPR:0.0461729063 \tF1:0.9519023479 \t AUC:0.9588073903\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1093348579 \tAcc: 0.9562834672 \tTPR:0.9622894526 \tFPR:0.0490743941 \tF1:0.9494269407 \t AUC:0.9566075293\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1001554254 \tAcc: 0.9623493976 \tTPR:0.9709516147 \tFPR:0.0441325503 \tF1:0.9558409889 \t AUC:0.9634095322\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0914765807 \tAcc: 0.9662817938 \tTPR:0.9742934585 \tFPR:0.0398714928 \tF1:0.9628662451 \t AUC:0.9672109828\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0842217719 \tAcc: 0.9674113119 \tTPR:0.9764644190 \tFPR:0.0398162011 \tF1:0.9642724835 \t AUC:0.9683241089\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.2301091594 \tAcc: 0.9350000000 \tTPR:0.8994647978 \tFPR:0.0303122719 \tF1:0.9291323184 \tAUC:0.9345762630 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.054914115804846356 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.11516227287439895210\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0772031123 \tAcc: 0.9698093220 \tTPR:0.9049186375 \tFPR:0.0182108846 \tF1:0.8900652539 \t AUC:0.9432192003\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0662361601 \tAcc: 0.9738700565 \tTPR:0.9070901713 \tFPR:0.0144236318 \tF1:0.8989116829 \t AUC:0.9459362192\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0576974423 \tAcc: 0.9766949153 \tTPR:0.9185991269 \tFPR:0.0127007903 \tF1:0.9096372644 \t AUC:0.9527179158\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0556716860 \tAcc: 0.9770833333 \tTPR:0.9303479712 \tFPR:0.0137484040 \tF1:0.9198550625 \t AUC:0.9579017720\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0452238724 \tAcc: 0.9822563559 \tTPR:0.9403763217 \tFPR:0.0106776197 \tF1:0.9271800364 \t AUC:0.9646799656\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.3928249092 \tAcc: 0.9131250000 \tTPR:0.8410143240 \tFPR:0.0174082912 \tF1:0.9024651864 \tAUC:0.9118030164 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.09935484096990557 \tALA epochs: 6\n",
      "Client 6: Local Initial ALA epochs: 6 Loss: 0.21217301586497719357\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1252249153 \tAcc: 0.9498061456 \tTPR:0.9571517123 \tFPR:0.0574953711 \tF1:0.9450352131 \t AUC:0.9498281706\tTrain cost: 0:00:38\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1165375157 \tAcc: 0.9536082474 \tTPR:0.9612327739 \tFPR:0.0521476500 \tF1:0.9492458700 \t AUC:0.9545425619\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1091822379 \tAcc: 0.9570548569 \tTPR:0.9637553319 \tFPR:0.0503085263 \tF1:0.9533355525 \t AUC:0.9567234028\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1044046867 \tAcc: 0.9585212629 \tTPR:0.9650422487 \tFPR:0.0484464391 \tF1:0.9552139781 \t AUC:0.9582979048\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0984524872 \tAcc: 0.9607680857 \tTPR:0.9668827329 \tFPR:0.0462233329 \tF1:0.9577030233 \t AUC:0.9603297000\tTrain cost: 0:00:40\n",
      "Client6 Test =>                 \tLoss: 0.2204920276 \tAcc: 0.9325000000 \tTPR:0.8983171330 \tFPR:0.0322739311 \tF1:0.9272350660 \tAUC:0.9330216009 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2539248552 \tAcc: 0.9312916667 \tTPR:0.9027434517 \tFPR:0.0412329582 \tF1:0.9258692019 \tAUC:0.9307552467\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 17:  =============\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.04169040025829077 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.10345612261776945817\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0591026389 \tAcc: 0.9761652542 \tTPR:0.9163144765 \tFPR:0.0133304160 \tF1:0.9093992208 \t AUC:0.9510138272\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0524842861 \tAcc: 0.9783192090 \tTPR:0.9233039638 \tFPR:0.0123765138 \tF1:0.9138373549 \t AUC:0.9553550904\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0473947258 \tAcc: 0.9811087571 \tTPR:0.9345574388 \tFPR:0.0104898383 \tF1:0.9259741226 \t AUC:0.9616598428\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0426413601 \tAcc: 0.9832627119 \tTPR:0.9504865035 \tFPR:0.0103901787 \tF1:0.9377376188 \t AUC:0.9699074990\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0432258323 \tAcc: 0.9823446328 \tTPR:0.9467019876 \tFPR:0.0113287942 \tF1:0.9353043113 \t AUC:0.9676111038\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.4665851971 \tAcc: 0.8950000000 \tTPR:0.8022275231 \tFPR:0.0136905616 \tF1:0.8787171279 \tAUC:0.8942684808 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.21806550139433215 \tALA epochs: 11\n",
      "Client 8: Local Initial ALA epochs: 11 Loss: 0.41067690830020642245\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1101694896 \tAcc: 0.9607988166 \tTPR:0.9832388611 \tFPR:0.1144952516 \tF1:0.9743023564 \t AUC:0.9343718048\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0998614553 \tAcc: 0.9644970414 \tTPR:0.9860033435 \tFPR:0.1093535792 \tF1:0.9767199065 \t AUC:0.9383041156\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0898752484 \tAcc: 0.9660687870 \tTPR:0.9861694360 \tFPR:0.0993100701 \tF1:0.9778794628 \t AUC:0.9434091628\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0845389964 \tAcc: 0.9681028107 \tTPR:0.9865594796 \tFPR:0.0902976104 \tF1:0.9788116378 \t AUC:0.9481309346\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0802541521 \tAcc: 0.9678254438 \tTPR:0.9864676382 \tFPR:0.0963950902 \tF1:0.9789388168 \t AUC:0.9450161963\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.2002905337 \tAcc: 0.9366666667 \tTPR:0.9322504645 \tFPR:0.0590629336 \tF1:0.9333487601 \tAUC:0.9365937654 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.08963784373081256 \tALA epochs: 4\n",
      "Client 1: Local Initial ALA epochs: 4 Loss: 0.19536898189471685328\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0778356078 \tAcc: 0.9689236111 \tTPR:0.8352716281 \tFPR:0.0148914571 \tF1:0.8280106188 \t AUC:0.9074529071\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0681425198 \tAcc: 0.9711257310 \tTPR:0.8584057471 \tFPR:0.0139594522 \tF1:0.8460182675 \t AUC:0.9204187229\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0625492847 \tAcc: 0.9745522661 \tTPR:0.8649389678 \tFPR:0.0114625462 \tF1:0.8537363587 \t AUC:0.9253271254\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0576802201 \tAcc: 0.9769279971 \tTPR:0.8851033835 \tFPR:0.0109748799 \tF1:0.8754472854 \t AUC:0.9358638394\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0554761017 \tAcc: 0.9773848684 \tTPR:0.8885872088 \tFPR:0.0112491084 \tF1:0.8737546531 \t AUC:0.9369911467\tTrain cost: 0:01:11\n",
      "Client1 Test =>                 \tLoss: 0.3398231083 \tAcc: 0.9027083333 \tTPR:0.8243354626 \tFPR:0.0222617475 \tF1:0.8895729537 \tAUC:0.9010368576 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.08187553092826479 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.21446398599073290825\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1237920344 \tAcc: 0.9520089286 \tTPR:0.9728629644 \tFPR:0.0912019858 \tF1:0.9637526181 \t AUC:0.9408304893\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0986665019 \tAcc: 0.9624255952 \tTPR:0.9823259491 \tFPR:0.0771524111 \tF1:0.9723955314 \t AUC:0.9525867690\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0848943814 \tAcc: 0.9691220238 \tTPR:0.9843439782 \tFPR:0.0675437492 \tF1:0.9774468087 \t AUC:0.9584001145\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0859781938 \tAcc: 0.9706101190 \tTPR:0.9857145346 \tFPR:0.0573833292 \tF1:0.9774234237 \t AUC:0.9641656027\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0770447051 \tAcc: 0.9694940476 \tTPR:0.9820291242 \tFPR:0.0580498468 \tF1:0.9766960531 \t AUC:0.9619896387\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2235478196 \tAcc: 0.9360416667 \tTPR:0.9349713288 \tFPR:0.0612908271 \tF1:0.9332110801 \tAUC:0.9368402508 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.06786962613620794 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.09888233380589747656\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0794538715 \tAcc: 0.9716679217 \tTPR:0.9893827752 \tFPR:0.1007993011 \tF1:0.9822482318 \t AUC:0.9442917371\tTrain cost: 0:00:32\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0680926337 \tAcc: 0.9742093373 \tTPR:0.9890917088 \tFPR:0.0891552474 \tF1:0.9837699233 \t AUC:0.9499682307\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0643204809 \tAcc: 0.9757153614 \tTPR:0.9903864718 \tFPR:0.0828238278 \tF1:0.9847397394 \t AUC:0.9537813220\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0565219488 \tAcc: 0.9770331325 \tTPR:0.9898096097 \tFPR:0.0774229619 \tF1:0.9855513602 \t AUC:0.9561933239\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0553932020 \tAcc: 0.9801393072 \tTPR:0.9925753873 \tFPR:0.0733654314 \tF1:0.9876071929 \t AUC:0.9596049779\tTrain cost: 0:00:33\n",
      "Client2 Test =>                 \tLoss: 0.1815635963 \tAcc: 0.9418750000 \tTPR:0.9422249510 \tFPR:0.0568055440 \tF1:0.9405799367 \tAUC:0.9427097035 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2823620510 \tAcc: 0.9224583333 \tTPR:0.8872019460 \tFPR:0.0426223227 \tF1:0.9150859717 \tAUC:0.9222898116\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 18:  =============\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.07396991595501383 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.13512538759404738031\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0671637250 \tAcc: 0.9742093373 \tTPR:0.9892861976 \tFPR:0.0924881344 \tF1:0.9838177172 \t AUC:0.9483990316\tTrain cost: 0:00:32\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0595288163 \tAcc: 0.9788215361 \tTPR:0.9920605640 \tFPR:0.0773672529 \tF1:0.9866180044 \t AUC:0.9573466555\tTrain cost: 0:00:32\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0577952470 \tAcc: 0.9779743976 \tTPR:0.9914062406 \tFPR:0.0797750566 \tF1:0.9860904568 \t AUC:0.9557895503\tTrain cost: 0:00:32\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0519676425 \tAcc: 0.9797628012 \tTPR:0.9921015202 \tFPR:0.0709961391 \tF1:0.9873535876 \t AUC:0.9605526905\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0493347279 \tAcc: 0.9820218373 \tTPR:0.9918846554 \tFPR:0.0580323793 \tF1:0.9885932313 \t AUC:0.9669261381\tTrain cost: 0:00:34\n",
      "Client2 Test =>                 \tLoss: 0.1861353366 \tAcc: 0.9460416667 \tTPR:0.9550671367 \tFPR:0.0621787728 \tF1:0.9451716995 \tAUC:0.9464441819 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.09560954254988223 \tALA epochs: 2\n",
      "Client 6: Local Initial ALA epochs: 2 Loss: 0.22000952758644889973\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1227991447 \tAcc: 0.9523834652 \tTPR:0.9604365786 \tFPR:0.0543966201 \tF1:0.9489876862 \t AUC:0.9530199793\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1137380602 \tAcc: 0.9548885754 \tTPR:0.9623613375 \tFPR:0.0520437897 \tF1:0.9509915190 \t AUC:0.9551587739\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1019949830 \tAcc: 0.9593988846 \tTPR:0.9666757088 \tFPR:0.0467063954 \tF1:0.9569616907 \t AUC:0.9599846567\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1036422486 \tAcc: 0.9579408105 \tTPR:0.9657097882 \tFPR:0.0489575093 \tF1:0.9548899830 \t AUC:0.9583761394\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0907226524 \tAcc: 0.9643757776 \tTPR:0.9705043855 \tFPR:0.0407630164 \tF1:0.9613596233 \t AUC:0.9648706845\tTrain cost: 0:00:40\n",
      "Client6 Test =>                 \tLoss: 0.2635129743 \tAcc: 0.9333333333 \tTPR:0.8924348120 \tFPR:0.0244261212 \tF1:0.9279668734 \tAUC:0.9340043454 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.05211467359213742 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.11714495712487191237\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0661832793 \tAcc: 0.9738212719 \tTPR:0.8661020185 \tFPR:0.0130661217 \tF1:0.8483825578 \t AUC:0.9247085162\tTrain cost: 0:01:08\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0582208514 \tAcc: 0.9757858187 \tTPR:0.8699932702 \tFPR:0.0115300901 \tF1:0.8656175307 \t AUC:0.9282671484\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0563558935 \tAcc: 0.9766081871 \tTPR:0.8833170890 \tFPR:0.0118501429 \tF1:0.8728458678 \t AUC:0.9342465094\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0529244615 \tAcc: 0.9778874269 \tTPR:0.8915970482 \tFPR:0.0113799836 \tF1:0.8770090225 \t AUC:0.9385599187\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0492298601 \tAcc: 0.9803088450 \tTPR:0.9038307574 \tFPR:0.0100184631 \tF1:0.8952193632 \t AUC:0.9461927255\tTrain cost: 0:01:10\n",
      "Client1 Test =>                 \tLoss: 0.5168688233 \tAcc: 0.8566666667 \tTPR:0.7173625927 \tFPR:0.0100043653 \tF1:0.8253697850 \tAUC:0.8536791137 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.09589366715521 \tALA epochs: 6\n",
      "Client 3: Local Initial ALA epochs: 6 Loss: 0.25691907635822036626\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1253334898 \tAcc: 0.9529367470 \tTPR:0.9488255364 \tFPR:0.0402692989 \tF1:0.9471259989 \t AUC:0.9542781188\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1017591186 \tAcc: 0.9564926372 \tTPR:0.9556347757 \tFPR:0.0425874262 \tF1:0.9469092880 \t AUC:0.9565236748\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0921356570 \tAcc: 0.9670348059 \tTPR:0.9695551525 \tFPR:0.0369380728 \tF1:0.9631831744 \t AUC:0.9663085399\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0916339697 \tAcc: 0.9638554217 \tTPR:0.9661214470 \tFPR:0.0385177546 \tF1:0.9586689786 \t AUC:0.9638018462\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0802972942 \tAcc: 0.9672439759 \tTPR:0.9718964878 \tFPR:0.0364935210 \tF1:0.9616265423 \t AUC:0.9677014834\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.2286632740 \tAcc: 0.9316666667 \tTPR:0.8887068803 \tFPR:0.0277613263 \tF1:0.9240786091 \tAUC:0.9304727770 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.08767914475025967 \tALA epochs: 2\n",
      "Client 9: Local Initial ALA epochs: 2 Loss: 0.21350043029947715634\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0516812299 \tAcc: 0.9821428571 \tTPR:0.9931114382 \tFPR:0.1527272727 \tF1:0.9902377515 \t AUC:0.9201630572\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0346783605 \tAcc: 0.9875000000 \tTPR:0.9961228360 \tFPR:0.1098214286 \tF1:0.9932311152 \t AUC:0.9432912514\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0316787912 \tAcc: 0.9868303571 \tTPR:0.9948784805 \tFPR:0.1443396226 \tF1:0.9929120246 \t AUC:0.9256050698\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0253828677 \tAcc: 0.9927083333 \tTPR:0.9982950192 \tFPR:0.0800595238 \tF1:0.9960196156 \t AUC:0.9590568555\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0207617230 \tAcc: 0.9920386905 \tTPR:0.9982744937 \tFPR:0.0803571429 \tF1:0.9956552983 \t AUC:0.9588970502\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.3342881318 \tAcc: 0.9231250000 \tTPR:0.9835235073 \tFPR:0.1381175288 \tF1:0.9257970669 \tAUC:0.9227029892 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.3058937080 \tAcc: 0.9181666667 \tTPR:0.8874189858 \tFPR:0.0524976229 \tF1:0.9096768068 \tAUC:0.9174606814\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 19:  =============\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.07951955398691994 \tALA epochs: 2\n",
      "Client 1: Local Initial ALA epochs: 2 Loss: 0.13411943773612353126\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0523519706 \tAcc: 0.9787554825 \tTPR:0.8940290541 \tFPR:0.0105978998 \tF1:0.8782179758 \t AUC:0.9402835373\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0497017616 \tAcc: 0.9795778509 \tTPR:0.9038359788 \tFPR:0.0104581555 \tF1:0.8874790337 \t AUC:0.9454634331\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0476444018 \tAcc: 0.9799890351 \tTPR:0.9034553978 \tFPR:0.0102411194 \tF1:0.8941056862 \t AUC:0.9453768107\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0449785910 \tAcc: 0.9814510234 \tTPR:0.9019928293 \tFPR:0.0091540696 \tF1:0.8939377673 \t AUC:0.9453954244\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0406648947 \tAcc: 0.9838724415 \tTPR:0.9181089297 \tFPR:0.0080116551 \tF1:0.9108279880 \t AUC:0.9538153381\tTrain cost: 0:01:11\n",
      "Client1 Test =>                 \tLoss: 0.4502751532 \tAcc: 0.8845833333 \tTPR:0.7799074017 \tFPR:0.0145282613 \tF1:0.8631636650 \tAUC:0.8826895702 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.09115934130304779 \tALA epochs: 5\n",
      "Client 7: Local Initial ALA epochs: 5 Loss: 0.30426549338735642269\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1128004371 \tAcc: 0.9583333333 \tTPR:0.9740917898 \tFPR:0.0750488599 \tF1:0.9686872211 \t AUC:0.9495214650\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0954623155 \tAcc: 0.9654017857 \tTPR:0.9825474209 \tFPR:0.0653903072 \tF1:0.9734199516 \t AUC:0.9585785568\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0838877980 \tAcc: 0.9713541667 \tTPR:0.9866067935 \tFPR:0.0590912394 \tF1:0.9785876150 \t AUC:0.9637577770\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0813359579 \tAcc: 0.9702380952 \tTPR:0.9833521149 \tFPR:0.0561883057 \tF1:0.9773602546 \t AUC:0.9635819046\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0808074087 \tAcc: 0.9697420635 \tTPR:0.9833986491 \tFPR:0.0573487077 \tF1:0.9770116695 \t AUC:0.9630249707\tTrain cost: 0:00:08\n",
      "Client7 Test =>                 \tLoss: 0.2126025794 \tAcc: 0.9385416667 \tTPR:0.9361386395 \tFPR:0.0603252015 \tF1:0.9354684318 \tAUC:0.9379067190 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.04551627598651358 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.10737874648019449242\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0966600656 \tAcc: 0.9636649408 \tTPR:0.9840059974 \tFPR:0.1003826375 \tF1:0.9760028207 \t AUC:0.9417879500\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0879687978 \tAcc: 0.9668084320 \tTPR:0.9858681610 \tFPR:0.0934802581 \tF1:0.9779878188 \t AUC:0.9461729843\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0827026310 \tAcc: 0.9688424556 \tTPR:0.9869432172 \tFPR:0.0929220384 \tF1:0.9795369290 \t AUC:0.9469912173\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0782329965 \tAcc: 0.9706915680 \tTPR:0.9886991621 \tFPR:0.0886208212 \tF1:0.9806203120 \t AUC:0.9500224036\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0716509374 \tAcc: 0.9733727811 \tTPR:0.9886506259 \tFPR:0.0780461790 \tF1:0.9824980516 \t AUC:0.9552853846\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.1903614742 \tAcc: 0.9408333333 \tTPR:0.9659097827 \tFPR:0.0829286372 \tF1:0.9397675308 \tAUC:0.9414905727 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.04210401723823082 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.12037607713136821985\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1086066896 \tAcc: 0.9579986613 \tTPR:0.9651708654 \tFPR:0.0476908511 \tF1:0.9515260974 \t AUC:0.9587400072\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.0959014069 \tAcc: 0.9642319277 \tTPR:0.9673135388 \tFPR:0.0392593868 \tF1:0.9563686152 \t AUC:0.9640270760\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0854884671 \tAcc: 0.9668674699 \tTPR:0.9710980799 \tFPR:0.0376076854 \tF1:0.9605400443 \t AUC:0.9667451973\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0796645710 \tAcc: 0.9700468541 \tTPR:0.9735679012 \tFPR:0.0322602343 \tF1:0.9644620985 \t AUC:0.9706538334\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0780552941 \tAcc: 0.9702560241 \tTPR:0.9731198906 \tFPR:0.0313297047 \tF1:0.9645396206 \t AUC:0.9708950930\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.2421858095 \tAcc: 0.9347916667 \tTPR:0.8970480960 \tFPR:0.0271591790 \tF1:0.9297160735 \tAUC:0.9349444585 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.08156084500806167 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.21890365779399872936\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1571958324 \tAcc: 0.9420955882 \tTPR:0.9660997648 \tFPR:0.1492090214 \tF1:0.9628545632 \t AUC:0.9089069142\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1255152976 \tAcc: 0.9533876050 \tTPR:0.9900177534 \tFPR:0.1587094453 \tF1:0.9695864834 \t AUC:0.9156541540\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1231279929 \tAcc: 0.9588366597 \tTPR:0.9793035067 \tFPR:0.1251417234 \tF1:0.9740204206 \t AUC:0.9270808916\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1123320881 \tAcc: 0.9564732143 \tTPR:0.9894062974 \tFPR:0.1635031635 \tF1:0.9723065527 \t AUC:0.9129515670\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0944732814 \tAcc: 0.9633009454 \tTPR:0.9838976090 \tFPR:0.0977607710 \tF1:0.9765637660 \t AUC:0.9430684190\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.1745744113 \tAcc: 0.9389583333 \tTPR:0.9742936683 \tFPR:0.0993455868 \tF1:0.9403824372 \tAUC:0.9374740407 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2539998855 \tAcc: 0.9275416667 \tTPR:0.9106595176 \tFPR:0.0568573731 \tF1:0.9216996277 \tAUC:0.9269010722\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 20:  =============\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.059143128303273895 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.12189589434835527981\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0582162792 \tAcc: 0.9761122881 \tTPR:0.9157918980 \tFPR:0.0140674583 \tF1:0.9095947948 \t AUC:0.9507429449\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0527821320 \tAcc: 0.9793432203 \tTPR:0.9358050847 \tFPR:0.0122466678 \tF1:0.9285981437 \t AUC:0.9616882808\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0433902451 \tAcc: 0.9823446328 \tTPR:0.9384887006 \tFPR:0.0105664927 \tF1:0.9297353662 \t AUC:0.9637863559\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0391172366 \tAcc: 0.9849046610 \tTPR:0.9545085643 \tFPR:0.0097865183 \tF1:0.9486775920 \t AUC:0.9722317859\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0377176225 \tAcc: 0.9837570621 \tTPR:0.9433996951 \tFPR:0.0095506817 \tF1:0.9374694957 \t AUC:0.9669245067\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.3803100721 \tAcc: 0.9127083333 \tTPR:0.8441759094 \tFPR:0.0187487985 \tF1:0.9028362791 \tAUC:0.9127135555 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.1355058226710774 \tALA epochs: 11\n",
      "Client 0: Local Initial ALA epochs: 11 Loss: 0.34707284315743230918\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1675428117 \tAcc: 0.9478072479 \tTPR:0.9678829372 \tFPR:0.1329059829 \tF1:0.9669652563 \t AUC:0.9174884772\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1239470693 \tAcc: 0.9521402311 \tTPR:0.9797752942 \tFPR:0.1564342404 \tF1:0.9697543791 \t AUC:0.9116705269\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1125561477 \tAcc: 0.9556197479 \tTPR:0.9781250047 \tFPR:0.1376017831 \tF1:0.9723224768 \t AUC:0.9202616108\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0953058541 \tAcc: 0.9666491597 \tTPR:0.9900511698 \tFPR:0.1101757370 \tF1:0.9786413418 \t AUC:0.9399377164\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0979141417 \tAcc: 0.9587053571 \tTPR:0.9814611355 \tFPR:0.1250000000 \tF1:0.9737026913 \t AUC:0.9282305677\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.1769205965 \tAcc: 0.9356250000 \tTPR:0.9525384959 \tFPR:0.0840941983 \tF1:0.9359480866 \tAUC:0.9342221488 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.07819984280440574 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.10705538178709420039\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0448699738 \tAcc: 0.9817708333 \tTPR:0.9945062084 \tFPR:0.1812121212 \tF1:0.9901845928 \t AUC:0.9069655076\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0313330977 \tAcc: 0.9901041667 \tTPR:0.9959055329 \tFPR:0.0696969697 \tF1:0.9943981828 \t AUC:0.9629181695\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0291712750 \tAcc: 0.9906250000 \tTPR:0.9977956989 \tFPR:0.1193452381 \tF1:0.9949646519 \t AUC:0.9391465054\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0237991333 \tAcc: 0.9932291667 \tTPR:0.9972401434 \tFPR:0.0575757576 \tF1:0.9963225768 \t AUC:0.9697067449\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0192689000 \tAcc: 0.9927083333 \tTPR:0.9988697318 \tFPR:0.1148484848 \tF1:0.9960555487 \t AUC:0.9419592476\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.3038125497 \tAcc: 0.9325000000 \tTPR:0.9770789527 \tFPR:0.1137398036 \tF1:0.9351293786 \tAUC:0.9316695745 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.09740116875655859 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.09770353715231810954\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0660323583 \tAcc: 0.9768448795 \tTPR:0.9903025153 \tFPR:0.0833279003 \tF1:0.9855328296 \t AUC:0.9534873075\tTrain cost: 0:00:32\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0543993723 \tAcc: 0.9807040663 \tTPR:0.9922716314 \tFPR:0.0678886739 \tF1:0.9878253158 \t AUC:0.9621798044\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0507192426 \tAcc: 0.9823042169 \tTPR:0.9937270779 \tFPR:0.0638636798 \tF1:0.9888221281 \t AUC:0.9649316990\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0450992699 \tAcc: 0.9826807229 \tTPR:0.9931156252 \tFPR:0.0617003004 \tF1:0.9890460664 \t AUC:0.9657444685\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0429989022 \tAcc: 0.9835278614 \tTPR:0.9927173304 \tFPR:0.0525008375 \tF1:0.9895899886 \t AUC:0.9701082464\tTrain cost: 0:00:34\n",
      "Client2 Test =>                 \tLoss: 0.2243834045 \tAcc: 0.9435416667 \tTPR:0.9632454344 \tFPR:0.0779736240 \tF1:0.9443741824 \tAUC:0.9426359052 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.09292319085470335 \tALA epochs: 2\n",
      "Client 4: Local Initial ALA epochs: 2 Loss: 0.13108526483664045825\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0994746737 \tAcc: 0.9613718171 \tTPR:0.9779958329 \tFPR:0.0691414201 \tF1:0.9694437163 \t AUC:0.9544272064\tTrain cost: 0:01:59\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0876044854 \tAcc: 0.9659066291 \tTPR:0.9822234774 \tFPR:0.0639548650 \tF1:0.9733106994 \t AUC:0.9591343062\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0842809303 \tAcc: 0.9668690008 \tTPR:0.9820581563 \tFPR:0.0599908234 \tF1:0.9738782553 \t AUC:0.9610336665\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0786405168 \tAcc: 0.9698061092 \tTPR:0.9845360943 \tFPR:0.0571151202 \tF1:0.9761667819 \t AUC:0.9637104871\tTrain cost: 0:01:59\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0757430080 \tAcc: 0.9706455806 \tTPR:0.9846230825 \tFPR:0.0542962788 \tF1:0.9769048698 \t AUC:0.9651634019\tTrain cost: 0:01:58\n",
      "Client4 Test =>                 \tLoss: 0.2048840535 \tAcc: 0.9393750000 \tTPR:0.9544919040 \tFPR:0.0757380327 \tF1:0.9382036895 \tAUC:0.9393769357 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2580621353 \tAcc: 0.9327500000 \tTPR:0.9383061393 \tFPR:0.0740588914 \tF1:0.9312983232 \tAUC:0.9321236239\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 21:  =============\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.0837653165840826 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.11558003060054033995\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.0998592747 \tAcc: 0.9634789157 \tTPR:0.9641902628 \tFPR:0.0375016466 \tF1:0.9560924613 \t AUC:0.9633443081\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.0817354148 \tAcc: 0.9728915663 \tTPR:0.9771688436 \tFPR:0.0304611035 \tF1:0.9688117131 \t AUC:0.9733538701\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0765152824 \tAcc: 0.9721385542 \tTPR:0.9742340454 \tFPR:0.0305857534 \tF1:0.9680376796 \t AUC:0.9718241460\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0730205135 \tAcc: 0.9740210843 \tTPR:0.9811392937 \tFPR:0.0330403113 \tF1:0.9708181980 \t AUC:0.9740494912\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0756425213 \tAcc: 0.9725150602 \tTPR:0.9782812136 \tFPR:0.0332485823 \tF1:0.9683852379 \t AUC:0.9725163157\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.1776114891 \tAcc: 0.9477083333 \tTPR:0.9396967463 \tFPR:0.0436509244 \tF1:0.9454212378 \tAUC:0.9480229109 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.09295588905852616 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.10325426134196194483\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0325220617 \tAcc: 0.9885416667 \tTPR:0.9948343888 \tFPR:0.1000000000 \tF1:0.9937308550 \t AUC:0.9471823939\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0261635310 \tAcc: 0.9901041667 \tTPR:0.9967168382 \tFPR:0.0875000000 \tF1:0.9945976844 \t AUC:0.9547701812\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0236041887 \tAcc: 0.9921875000 \tTPR:0.9977177022 \tFPR:0.0621794872 \tF1:0.9956810367 \t AUC:0.9675935461\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0218115817 \tAcc: 0.9921875000 \tTPR:0.9966065911 \tFPR:0.0773809524 \tF1:0.9957762168 \t AUC:0.9594916262\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0146024575 \tAcc: 0.9958333333 \tTPR:0.9988300493 \tFPR:0.0439393939 \tF1:0.9976978570 \t AUC:0.9773921481\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.2926654708 \tAcc: 0.9350000000 \tTPR:0.9858619522 \tFPR:0.1153900695 \tF1:0.9379219126 \tAUC:0.9352359414 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.34074595158466625 \tALA epochs: 11\n",
      "Client 5: Local Initial ALA epochs: 11 Loss: 0.69108538231872895796\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0528571261 \tAcc: 0.9789371469 \tTPR:0.9399647198 \tFPR:0.0137251089 \tF1:0.9286741447 \t AUC:0.9628632445\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0335483076 \tAcc: 0.9867584746 \tTPR:0.9634817709 \tFPR:0.0084165171 \tF1:0.9522397518 \t AUC:0.9773765661\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0311046678 \tAcc: 0.9869350282 \tTPR:0.9577089499 \tFPR:0.0084539612 \tF1:0.9498862487 \t AUC:0.9745675920\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0287811462 \tAcc: 0.9876412429 \tTPR:0.9587413685 \tFPR:0.0071173337 \tF1:0.9558741333 \t AUC:0.9756948054\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0283232053 \tAcc: 0.9881709040 \tTPR:0.9626814962 \tFPR:0.0077002395 \tF1:0.9536747371 \t AUC:0.9774906283\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.4002173082 \tAcc: 0.9168750000 \tTPR:0.8546334974 \tFPR:0.0225930013 \tF1:0.9075998676 \tAUC:0.9160202480 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.09953599268467214 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.21139058990815243200\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1174403013 \tAcc: 0.9535832519 \tTPR:0.9603267735 \tFPR:0.0517447431 \tF1:0.9507004626 \t AUC:0.9542910152\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1044815353 \tAcc: 0.9596238446 \tTPR:0.9665812077 \tFPR:0.0464829349 \tF1:0.9565783590 \t AUC:0.9600491364\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0953152857 \tAcc: 0.9620400818 \tTPR:0.9699105541 \tFPR:0.0444964034 \tF1:0.9595709089 \t AUC:0.9627070753\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0914257535 \tAcc: 0.9634259465 \tTPR:0.9686946164 \tFPR:0.0416431778 \tF1:0.9601856259 \t AUC:0.9635257193\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0881656133 \tAcc: 0.9667281372 \tTPR:0.9720163763 \tFPR:0.0385622145 \tF1:0.9638849510 \t AUC:0.9667270809\tTrain cost: 0:00:41\n",
      "Client6 Test =>                 \tLoss: 0.2071120620 \tAcc: 0.9427083333 \tTPR:0.9215334455 \tFPR:0.0372689583 \tF1:0.9382526542 \tAUC:0.9421322436 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.09601143073915003 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.09911683007426884406\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0930786425 \tAcc: 0.9638089921 \tTPR:0.9808150481 \tFPR:0.0665569892 \tF1:0.9715358232 \t AUC:0.9571290294\tTrain cost: 0:02:02\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0843341084 \tAcc: 0.9676001533 \tTPR:0.9823145123 \tFPR:0.0589110469 \tF1:0.9743273203 \t AUC:0.9617017327\tTrain cost: 0:01:59\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0809613457 \tAcc: 0.9686687608 \tTPR:0.9838108316 \tFPR:0.0586123880 \tF1:0.9754615425 \t AUC:0.9625992218\tTrain cost: 0:02:01\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0747439293 \tAcc: 0.9710121984 \tTPR:0.9833478526 \tFPR:0.0516609547 \tF1:0.9770663462 \t AUC:0.9658434489\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0728042983 \tAcc: 0.9720141481 \tTPR:0.9844154952 \tFPR:0.0495836773 \tF1:0.9776038931 \t AUC:0.9674159090\tTrain cost: 0:01:59\n",
      "Client4 Test =>                 \tLoss: 0.2074503496 \tAcc: 0.9379166667 \tTPR:0.9443601272 \tFPR:0.0671355077 \tF1:0.9372531991 \tAUC:0.9386123098 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2570113359 \tAcc: 0.9360416667 \tTPR:0.9292171537 \tFPR:0.0572076922 \tF1:0.9332897742 \tAUC:0.9360047307\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 22:  =============\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.0802033836241162 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.11733342349180020392\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0881902532 \tAcc: 0.9672619048 \tTPR:0.9841003916 \tFPR:0.0673724735 \tF1:0.9747268886 \t AUC:0.9583639591\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0824565336 \tAcc: 0.9683779762 \tTPR:0.9851091828 \tFPR:0.0679894510 \tF1:0.9758416387 \t AUC:0.9585598659\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0696721185 \tAcc: 0.9748263889 \tTPR:0.9903734664 \tFPR:0.0554564483 \tF1:0.9813076384 \t AUC:0.9674585091\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0663414209 \tAcc: 0.9758184524 \tTPR:0.9870536313 \tFPR:0.0468294767 \tF1:0.9816045682 \t AUC:0.9701120773\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0574999184 \tAcc: 0.9773065476 \tTPR:0.9870484906 \tFPR:0.0442442809 \tF1:0.9832611940 \t AUC:0.9714021049\tTrain cost: 0:00:08\n",
      "Client7 Test =>                 \tLoss: 0.2529689130 \tAcc: 0.9314583333 \tTPR:0.9303550515 \tFPR:0.0680419315 \tF1:0.9295951948 \tAUC:0.9311565600 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.06948670437456204 \tALA epochs: 11\n",
      "Client 0: Local Initial ALA epochs: 11 Loss: 0.14798058425499635571\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1315696038 \tAcc: 0.9567358193 \tTPR:0.9792595911 \tFPR:0.1382253659 \tF1:0.9726437039 \t AUC:0.9205171126\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1057616374 \tAcc: 0.9575892857 \tTPR:0.9858282194 \tFPR:0.1505886970 \tF1:0.9730269186 \t AUC:0.9176197612\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0988151676 \tAcc: 0.9655330882 \tTPR:0.9839551659 \tFPR:0.1016749124 \tF1:0.9782165025 \t AUC:0.9411401268\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0964529676 \tAcc: 0.9642857143 \tTPR:0.9881322533 \tFPR:0.1126146671 \tF1:0.9773027235 \t AUC:0.9377587931\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0799263600 \tAcc: 0.9776785714 \tTPR:0.9916992267 \tFPR:0.0695745723 \tF1:0.9857419795 \t AUC:0.9610623272\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.1687699028 \tAcc: 0.9437500000 \tTPR:0.9530559773 \tFPR:0.0662531617 \tF1:0.9441788826 \tAUC:0.9434014078 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.07789780122108729 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.09717773622833192348\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.0758892240 \tAcc: 0.9736445783 \tTPR:0.9738420517 \tFPR:0.0292071604 \tF1:0.9683483997 \t AUC:0.9723174457\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.0703619090 \tAcc: 0.9740210843 \tTPR:0.9771116645 \tFPR:0.0289834299 \tF1:0.9703609065 \t AUC:0.9740641173\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0516954082 \tAcc: 0.9815512048 \tTPR:0.9828910071 \tFPR:0.0189715968 \tF1:0.9787355224 \t AUC:0.9819597051\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0544851812 \tAcc: 0.9789156627 \tTPR:0.9842706348 \tFPR:0.0258166335 \tF1:0.9763326814 \t AUC:0.9792270007\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0468925584 \tAcc: 0.9838102410 \tTPR:0.9873816061 \tFPR:0.0197649454 \tF1:0.9809812044 \t AUC:0.9838083304\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.2392999533 \tAcc: 0.9406250000 \tTPR:0.9119474407 \tFPR:0.0314666417 \tF1:0.9348240348 \tAUC:0.9402403995 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.09623074376922443 \tALA epochs: 4\n",
      "Client 1: Local Initial ALA epochs: 4 Loss: 0.12892596138231859904\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0523249882 \tAcc: 0.9794864766 \tTPR:0.8908614128 \tFPR:0.0104510541 \tF1:0.8773038098 \t AUC:0.9391479501\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0455741756 \tAcc: 0.9815789474 \tTPR:0.9033851464 \tFPR:0.0090024362 \tF1:0.8945715961 \t AUC:0.9460342910\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0410085321 \tAcc: 0.9831871345 \tTPR:0.9208744715 \tFPR:0.0087494718 \tF1:0.9071441838 \t AUC:0.9549932360\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0377262599 \tAcc: 0.9852887427 \tTPR:0.9288214750 \tFPR:0.0073450125 \tF1:0.9190984686 \t AUC:0.9598857938\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0339913210 \tAcc: 0.9858826754 \tTPR:0.9319061543 \tFPR:0.0077513524 \tF1:0.9193112376 \t AUC:0.9611572138\tTrain cost: 0:01:12\n",
      "Client1 Test =>                 \tLoss: 0.5101150649 \tAcc: 0.8818750000 \tTPR:0.7743301226 \tFPR:0.0150751364 \tF1:0.8605271531 \tAUC:0.8796274931 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.07152846117182265 \tALA epochs: 9\n",
      "Client 6: Local Initial ALA epochs: 9 Loss: 0.27985362506177258179\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1124002663 \tAcc: 0.9555329053 \tTPR:0.9597182196 \tFPR:0.0484005468 \tF1:0.9515570639 \t AUC:0.9556588364\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1008880266 \tAcc: 0.9601154239 \tTPR:0.9665595566 \tFPR:0.0458169530 \tF1:0.9570054899 \t AUC:0.9603713018\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0933189102 \tAcc: 0.9631121134 \tTPR:0.9685913771 \tFPR:0.0414483630 \tF1:0.9600037879 \t AUC:0.9635715070\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0878707478 \tAcc: 0.9659227248 \tTPR:0.9714394411 \tFPR:0.0389703586 \tF1:0.9627153764 \t AUC:0.9662345412\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0808532909 \tAcc: 0.9680001333 \tTPR:0.9750813433 \tFPR:0.0388468584 \tF1:0.9653831332 \t AUC:0.9681172424\tTrain cost: 0:00:41\n",
      "Client6 Test =>                 \tLoss: 0.2062614651 \tAcc: 0.9414583333 \tTPR:0.9185145701 \tFPR:0.0358546322 \tF1:0.9378673178 \tAUC:0.9413299690 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2754830598 \tAcc: 0.9278333333 \tTPR:0.8976406324 \tFPR:0.0433383007 \tF1:0.9213985166 \tAUC:0.9271511659\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 23:  =============\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.024476342810161464 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.04232364322524517775\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0641607240 \tAcc: 0.9785466270 \tTPR:0.9896643717 \tFPR:0.0474203240 \tF1:0.9836823666 \t AUC:0.9711220239\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0537021925 \tAcc: 0.9806547619 \tTPR:0.9911609939 \tFPR:0.0410812169 \tF1:0.9852831733 \t AUC:0.9750398885\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0439540209 \tAcc: 0.9851190476 \tTPR:0.9924442695 \tFPR:0.0290338795 \tF1:0.9888977950 \t AUC:0.9817051950\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0463881175 \tAcc: 0.9884672619 \tTPR:0.9956574955 \tFPR:0.0275101766 \tF1:0.9914911300 \t AUC:0.9840736595\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0459608805 \tAcc: 0.9836309524 \tTPR:0.9917515315 \tFPR:0.0330515384 \tF1:0.9874683620 \t AUC:0.9793499966\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2712791857 \tAcc: 0.9335416667 \tTPR:0.9236605426 \tFPR:0.0581831503 \tF1:0.9304395934 \tAUC:0.9327386961 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.09233585972888433 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.07515747024974023249\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0634794738 \tAcc: 0.9757153614 \tTPR:0.9898431257 \tFPR:0.0788771971 \tF1:0.9846836510 \t AUC:0.9554829643\tTrain cost: 0:00:32\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0492914310 \tAcc: 0.9819277108 \tTPR:0.9930603420 \tFPR:0.0613411438 \tF1:0.9885992981 \t AUC:0.9658595991\tTrain cost: 0:00:32\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0470448623 \tAcc: 0.9818335843 \tTPR:0.9923432448 \tFPR:0.0601638154 \tF1:0.9885309699 \t AUC:0.9660897147\tTrain cost: 0:00:32\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0426705765 \tAcc: 0.9857868976 \tTPR:0.9947035954 \tFPR:0.0522235378 \tF1:0.9910307456 \t AUC:0.9712400288\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0367783942 \tAcc: 0.9861634036 \tTPR:0.9940219152 \tFPR:0.0453844599 \tF1:0.9912868919 \t AUC:0.9743187277\tTrain cost: 0:00:35\n",
      "Client2 Test =>                 \tLoss: 0.2391664651 \tAcc: 0.9414583333 \tTPR:0.9331446178 \tFPR:0.0518586274 \tF1:0.9389000719 \tAUC:0.9406429952 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.07881709557591218 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.17183787375688552856\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1369544463 \tAcc: 0.9564732143 \tTPR:0.9770786914 \tFPR:0.1204081633 \tF1:0.9719454529 \t AUC:0.9283352641\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1046028351 \tAcc: 0.9631696429 \tTPR:0.9874231563 \tFPR:0.1252409297 \tF1:0.9763535867 \t AUC:0.9310911133\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0878482584 \tAcc: 0.9676339286 \tTPR:0.9911140950 \tFPR:0.1237270666 \tF1:0.9792918727 \t AUC:0.9336935142\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0707808635 \tAcc: 0.9787946429 \tTPR:0.9929995045 \tFPR:0.0748441043 \tF1:0.9866670016 \t AUC:0.9590777001\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0615688909 \tAcc: 0.9766938025 \tTPR:0.9871452397 \tFPR:0.0589143991 \tF1:0.9845230961 \t AUC:0.9641154203\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.1880156321 \tAcc: 0.9439583333 \tTPR:0.9617427183 \tFPR:0.0740427572 \tF1:0.9436827412 \tAUC:0.9438499805 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.09143994598564441 \tALA epochs: 3\n",
      "Client 6: Local Initial ALA epochs: 3 Loss: 0.16668116509636210498\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1088132258 \tAcc: 0.9566688144 \tTPR:0.9624945405 \tFPR:0.0478085675 \tF1:0.9533156184 \t AUC:0.9573429865\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.0939074783 \tAcc: 0.9617345805 \tTPR:0.9655016088 \tFPR:0.0415871549 \tF1:0.9587604360 \t AUC:0.9619572269\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0888896700 \tAcc: 0.9650284394 \tTPR:0.9713950423 \tFPR:0.0403712216 \tF1:0.9619777181 \t AUC:0.9655119104\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0817646556 \tAcc: 0.9689916237 \tTPR:0.9747629905 \tFPR:0.0367018768 \tF1:0.9659805662 \t AUC:0.9690305569\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0745952902 \tAcc: 0.9714884021 \tTPR:0.9770810163 \tFPR:0.0338096863 \tF1:0.9696981877 \t AUC:0.9716356650\tTrain cost: 0:00:40\n",
      "Client6 Test =>                 \tLoss: 0.2027191735 \tAcc: 0.9441666667 \tTPR:0.9326613624 \tFPR:0.0434452779 \tF1:0.9419374105 \tAUC:0.9446080422 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.06966522241570729 \tALA epochs: 2\n",
      "Client 5: Local Initial ALA epochs: 2 Loss: 0.10988842322091971204\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0443809375 \tAcc: 0.9811970339 \tTPR:0.9346715745 \tFPR:0.0109653905 \tF1:0.9297643232 \t AUC:0.9615739107\tTrain cost: 0:00:35\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0343028258 \tAcc: 0.9863524011 \tTPR:0.9536263564 \tFPR:0.0075930203 \tF1:0.9497660983 \t AUC:0.9728849247\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0339465379 \tAcc: 0.9867584746 \tTPR:0.9610942965 \tFPR:0.0083732693 \tF1:0.9545482051 \t AUC:0.9763054063\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0327985525 \tAcc: 0.9859639831 \tTPR:0.9555732874 \tFPR:0.0089471810 \tF1:0.9481470099 \t AUC:0.9732501258\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0281622000 \tAcc: 0.9891419492 \tTPR:0.9662283652 \tFPR:0.0066125028 \tF1:0.9592912588 \t AUC:0.9797600960\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.4221512299 \tAcc: 0.9106250000 \tTPR:0.8403884488 \tFPR:0.0185660959 \tF1:0.9006535628 \tAUC:0.9109111764 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2646663372 \tAcc: 0.9347500000 \tTPR:0.9183195380 \tFPR:0.0492191818 \tF1:0.9311226760 \tAUC:0.9345501781\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 24:  =============\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.09926035366027056 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.09915331499651074132\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0381324420 \tAcc: 0.9852048023 \tTPR:0.9571707796 \tFPR:0.0093730104 \tF1:0.9520200609 \t AUC:0.9737158538\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0311928682 \tAcc: 0.9875529661 \tTPR:0.9594923203 \tFPR:0.0070219567 \tF1:0.9561618530 \t AUC:0.9761778055\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0271475091 \tAcc: 0.9877295198 \tTPR:0.9579544435 \tFPR:0.0075323387 \tF1:0.9521354273 \t AUC:0.9751514978\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0239286261 \tAcc: 0.9908192090 \tTPR:0.9714016680 \tFPR:0.0057348887 \tF1:0.9654262889 \t AUC:0.9826285305\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0254887467 \tAcc: 0.9904131356 \tTPR:0.9680241682 \tFPR:0.0053231739 \tF1:0.9644210838 \t AUC:0.9811677781\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.4002177103 \tAcc: 0.9191666667 \tTPR:0.8576481793 \tFPR:0.0209566813 \tF1:0.9106809670 \tAUC:0.9183457490 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.13140158464011994 \tALA epochs: 11\n",
      "Client 0: Local Initial ALA epochs: 11 Loss: 0.34431188946420493435\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1372427205 \tAcc: 0.9564732143 \tTPR:0.9701359216 \tFPR:0.0916950113 \tF1:0.9711367220 \t AUC:0.9392204551\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0809644079 \tAcc: 0.9699973739 \tTPR:0.9848676984 \tFPR:0.0712481962 \tF1:0.9803274902 \t AUC:0.9568097511\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0830872975 \tAcc: 0.9654017857 \tTPR:0.9808092753 \tFPR:0.0952406720 \tF1:0.9774790732 \t AUC:0.9427843017\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0730859861 \tAcc: 0.9676339286 \tTPR:0.9841093232 \tFPR:0.0918521954 \tF1:0.9789574287 \t AUC:0.9461285639\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0689941075 \tAcc: 0.9722295168 \tTPR:0.9881572706 \tFPR:0.0865246856 \tF1:0.9828125269 \t AUC:0.9508162925\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.1892323244 \tAcc: 0.9437500000 \tTPR:0.9588214760 \tFPR:0.0705789290 \tF1:0.9435986487 \tAUC:0.9441212735 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.06275393063171376 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.06301315140444785357\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0650457294 \tAcc: 0.9758184524 \tTPR:0.9873169644 \tFPR:0.0490704333 \tF1:0.9815199193 \t AUC:0.9691232655\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0482677594 \tAcc: 0.9828869048 \tTPR:0.9903011962 \tFPR:0.0336240479 \tF1:0.9871489537 \t AUC:0.9783385741\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0498240729 \tAcc: 0.9818948413 \tTPR:0.9881042939 \tFPR:0.0316112294 \tF1:0.9864426695 \t AUC:0.9782465322\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0383696209 \tAcc: 0.9848710317 \tTPR:0.9913728872 \tFPR:0.0277781742 \tF1:0.9882517891 \t AUC:0.9817973565\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0321817098 \tAcc: 0.9888392857 \tTPR:0.9929693766 \tFPR:0.0196336732 \tF1:0.9917274433 \t AUC:0.9866678517\tTrain cost: 0:00:08\n",
      "Client7 Test =>                 \tLoss: 0.3103312799 \tAcc: 0.9295833333 \tTPR:0.9173129656 \tFPR:0.0574646402 \tF1:0.9254781242 \tAUC:0.9299241627 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.09153208271496528 \tALA epochs: 3\n",
      "Client 4: Local Initial ALA epochs: 3 Loss: 0.11790474929308612795\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0933160482 \tAcc: 0.9653650347 \tTPR:0.9804466249 \tFPR:0.0617274226 \tF1:0.9725644309 \t AUC:0.9593596012\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0850055422 \tAcc: 0.9675043328 \tTPR:0.9828264142 \tFPR:0.0607997782 \tF1:0.9743746553 \t AUC:0.9610133180\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0780101333 \tAcc: 0.9711600953 \tTPR:0.9855464095 \tFPR:0.0540258114 \tF1:0.9771416542 \t AUC:0.9657602990\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0737266698 \tAcc: 0.9712288362 \tTPR:0.9843338111 \tFPR:0.0536403908 \tF1:0.9774082753 \t AUC:0.9653467102\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0735829352 \tAcc: 0.9719995667 \tTPR:0.9856126322 \tFPR:0.0526425024 \tF1:0.9778128048 \t AUC:0.9664850649\tTrain cost: 0:01:59\n",
      "Client4 Test =>                 \tLoss: 0.2205708608 \tAcc: 0.9360416667 \tTPR:0.9240556728 \tFPR:0.0520739496 \tF1:0.9338309402 \tAUC:0.9359908616 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.09474699151053134 \tALA epochs: 3\n",
      "Client 1: Local Initial ALA epochs: 3 Loss: 0.13001064526022174106\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0533604748 \tAcc: 0.9782986111 \tTPR:0.8908810853 \tFPR:0.0114268945 \tF1:0.8762881849 \t AUC:0.9385037892\tTrain cost: 0:01:08\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0461173366 \tAcc: 0.9819535819 \tTPR:0.9083797457 \tFPR:0.0086487951 \tF1:0.9009173766 \t AUC:0.9485566145\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0411331824 \tAcc: 0.9828673246 \tTPR:0.9128277871 \tFPR:0.0083830549 \tF1:0.9041395795 \t AUC:0.9508418106\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0372441059 \tAcc: 0.9859192251 \tTPR:0.9356104381 \tFPR:0.0075852939 \tF1:0.9186809538 \t AUC:0.9630428498\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0330054454 \tAcc: 0.9864766082 \tTPR:0.9261881028 \tFPR:0.0065958610 \tF1:0.9202555716 \t AUC:0.9588554895\tTrain cost: 0:01:11\n",
      "Client1 Test =>                 \tLoss: 0.5490166286 \tAcc: 0.8754166667 \tTPR:0.7596901855 \tFPR:0.0112630314 \tF1:0.8529848074 \tAUC:0.8742135770 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.3338737608 \tAcc: 0.9207916667 \tTPR:0.8835056958 \tFPR:0.0424674463 \tF1:0.9133146975 \tAUC:0.9205191248\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 25:  =============\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.06170311630731567 \tALA epochs: 4\n",
      "Client 6: Local Initial ALA epochs: 4 Loss: 0.10269426833800426868\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.0941780391 \tAcc: 0.9629343672 \tTPR:0.9692535977 \tFPR:0.0428459654 \tF1:0.9601094471 \t AUC:0.9632038162\tTrain cost: 0:00:37\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.0878601485 \tAcc: 0.9662365579 \tTPR:0.9703579931 \tFPR:0.0376090055 \tF1:0.9640487922 \t AUC:0.9663744938\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0756761262 \tAcc: 0.9718105670 \tTPR:0.9763003783 \tFPR:0.0318723655 \tF1:0.9689135177 \t AUC:0.9722140064\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0752351741 \tAcc: 0.9705135754 \tTPR:0.9752503009 \tFPR:0.0345724720 \tF1:0.9685247531 \t AUC:0.9703389145\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0733000026 \tAcc: 0.9717216939 \tTPR:0.9778301857 \tFPR:0.0330886885 \tF1:0.9695920982 \t AUC:0.9723707486\tTrain cost: 0:00:41\n",
      "Client6 Test =>                 \tLoss: 0.2180816100 \tAcc: 0.9420833333 \tTPR:0.9273147727 \tFPR:0.0415991874 \tF1:0.9392238209 \tAUC:0.9428577927 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.04293289404530508 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.10118062634220613416\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0367845269 \tAcc: 0.9844632768 \tTPR:0.9476235315 \tFPR:0.0093098670 \tF1:0.9378716926 \t AUC:0.9690826446\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0289130048 \tAcc: 0.9881179379 \tTPR:0.9652161241 \tFPR:0.0075689641 \tF1:0.9499408374 \t AUC:0.9786248150\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0205188819 \tAcc: 0.9919668079 \tTPR:0.9765189221 \tFPR:0.0052321511 \tF1:0.9672712388 \t AUC:0.9856101262\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0224431612 \tAcc: 0.9919668079 \tTPR:0.9704578065 \tFPR:0.0049999805 \tF1:0.9650779980 \t AUC:0.9826449863\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0191341192 \tAcc: 0.9922669492 \tTPR:0.9769202314 \tFPR:0.0050272463 \tF1:0.9716083334 \t AUC:0.9859138016\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.4253433501 \tAcc: 0.9204166667 \tTPR:0.8630172959 \tFPR:0.0224029618 \tF1:0.9123537526 \tAUC:0.9203071670 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.36670195209188644 \tALA epochs: 11\n",
      "Client 9: Local Initial ALA epochs: 11 Loss: 0.57480575175078452155\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0736562892 \tAcc: 0.9776041667 \tTPR:0.9834684966 \tFPR:0.0867673993 \tF1:0.9871886795 \t AUC:0.9479803369\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0270733869 \tAcc: 0.9901041667 \tTPR:0.9971994732 \tFPR:0.0892156863 \tF1:0.9945206454 \t AUC:0.9540511607\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0307462595 \tAcc: 0.9880208333 \tTPR:0.9954928757 \tFPR:0.1071428571 \tF1:0.9934122525 \t AUC:0.9440140405\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0253889867 \tAcc: 0.9906250000 \tTPR:0.9967359952 \tFPR:0.0721088435 \tF1:0.9948808064 \t AUC:0.9622660855\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0144397316 \tAcc: 0.9947916667 \tTPR:0.9994252874 \tFPR:0.0590909091 \tF1:0.9971605398 \t AUC:0.9701410658\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.3269559787 \tAcc: 0.9304166667 \tTPR:0.9884971007 \tFPR:0.1306677431 \tF1:0.9333888822 \tAUC:0.9289146788 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.18992316643257598 \tALA epochs: 11\n",
      "Client 3: Local Initial ALA epochs: 11 Loss: 0.46366477747539069920\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1025355787 \tAcc: 0.9634789157 \tTPR:0.9727740144 \tFPR:0.0417801725 \tF1:0.9576354594 \t AUC:0.9654969210\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.0829660947 \tAcc: 0.9696703481 \tTPR:0.9709193176 \tFPR:0.0302152828 \tF1:0.9636515096 \t AUC:0.9703520174\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0744108184 \tAcc: 0.9702560241 \tTPR:0.9766869300 \tFPR:0.0341859392 \tF1:0.9673323011 \t AUC:0.9712504954\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0619623665 \tAcc: 0.9781626506 \tTPR:0.9823397555 \tFPR:0.0239802308 \tF1:0.9750073987 \t AUC:0.9791797624\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0600583432 \tAcc: 0.9770331325 \tTPR:0.9836844902 \tFPR:0.0299491280 \tF1:0.9741759733 \t AUC:0.9768676811\tTrain cost: 0:00:09\n",
      "Client3 Test =>                 \tLoss: 0.2526983547 \tAcc: 0.9335416667 \tTPR:0.9000557367 \tFPR:0.0322482440 \tF1:0.9284272391 \tAUC:0.9339037464 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.07892504689974889 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.17017950415611265980\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1039664072 \tAcc: 0.9598214286 \tTPR:0.9789528733 \tFPR:0.1173611111 \tF1:0.9742655570 \t AUC:0.9307958811\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0852876900 \tAcc: 0.9709821429 \tTPR:0.9929461015 \tFPR:0.1181264172 \tF1:0.9818899911 \t AUC:0.9374098421\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0701925084 \tAcc: 0.9744616597 \tTPR:0.9866193515 \tFPR:0.0968692022 \tF1:0.9827914545 \t AUC:0.9448750746\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0668569297 \tAcc: 0.9776785714 \tTPR:0.9943694970 \tFPR:0.0832766440 \tF1:0.9859200641 \t AUC:0.9555464265\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0625269891 \tAcc: 0.9744616597 \tTPR:0.9900550145 \tFPR:0.0888502371 \tF1:0.9837474428 \t AUC:0.9506023887\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.1945210378 \tAcc: 0.9458333333 \tTPR:0.9607485132 \tFPR:0.0696332194 \tF1:0.9464987988 \tAUC:0.9455576469 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2835200663 \tAcc: 0.9344583333 \tTPR:0.9279266838 \tFPR:0.0593102711 \tF1:0.9319784987 \tAUC:0.9343082064\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 26:  =============\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.046312290878690425 \tALA epochs: 2\n",
      "Client 8: Local Initial ALA epochs: 2 Loss: 0.11914815942308545904\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0930104086 \tAcc: 0.9677329882 \tTPR:0.9868795914 \tFPR:0.0966206724 \tF1:0.9787448080 \t AUC:0.9451099930\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0775954901 \tAcc: 0.9711538462 \tTPR:0.9883146253 \tFPR:0.0865779456 \tF1:0.9810495818 \t AUC:0.9508510025\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0766159589 \tAcc: 0.9711538462 \tTPR:0.9877125104 \tFPR:0.0846856655 \tF1:0.9810795351 \t AUC:0.9514951918\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0705718769 \tAcc: 0.9746671598 \tTPR:0.9895308312 \tFPR:0.0752218846 \tF1:0.9832771065 \t AUC:0.9571698180\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0639776792 \tAcc: 0.9757766272 \tTPR:0.9896790558 \tFPR:0.0719041642 \tF1:0.9840196944 \t AUC:0.9588874458\tTrain cost: 0:00:34\n",
      "Client8 Test =>                 \tLoss: 0.1915217235 \tAcc: 0.9439583333 \tTPR:0.9673522661 \tFPR:0.0790235573 \tF1:0.9430143018 \tAUC:0.9441643544 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.0703788286926442 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.11909166164696216583\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.0958619511 \tAcc: 0.9554884454 \tTPR:0.9802574972 \tFPR:0.1391362606 \tF1:0.9714601045 \t AUC:0.9205606183\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0721064547 \tAcc: 0.9743303571 \tTPR:0.9875524601 \tFPR:0.0686507937 \tF1:0.9836144247 \t AUC:0.9594508332\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0649481312 \tAcc: 0.9743303571 \tTPR:0.9881803646 \tFPR:0.0909464543 \tF1:0.9834722125 \t AUC:0.9486169551\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0543194793 \tAcc: 0.9765625000 \tTPR:0.9959662751 \tFPR:0.0962043908 \tF1:0.9850706791 \t AUC:0.9498809421\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0520313196 \tAcc: 0.9833902311 \tTPR:0.9945054945 \tFPR:0.0609126984 \tF1:0.9895981658 \t AUC:0.9667963980\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.2048649383 \tAcc: 0.9427083333 \tTPR:0.9575945726 \tFPR:0.0756090185 \tF1:0.9429689723 \tAUC:0.9409927770 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.048081285159820256 \tALA epochs: 2\n",
      "Client 7: Local Initial ALA epochs: 2 Loss: 0.07319610317790647969\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0652205070 \tAcc: 0.9780505952 \tTPR:0.9865938823 \tFPR:0.0396042168 \tF1:0.9832971880 \t AUC:0.9734948328\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0574146824 \tAcc: 0.9796626984 \tTPR:0.9872071760 \tFPR:0.0357018691 \tF1:0.9845547739 \t AUC:0.9757526534\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0496030923 \tAcc: 0.9804067460 \tTPR:0.9886648020 \tFPR:0.0359646306 \tF1:0.9852893146 \t AUC:0.9763500857\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0434318862 \tAcc: 0.9843750000 \tTPR:0.9914114789 \tFPR:0.0287249396 \tF1:0.9881475272 \t AUC:0.9813432697\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0370684084 \tAcc: 0.9866071429 \tTPR:0.9913078185 \tFPR:0.0207984806 \tF1:0.9898127822 \t AUC:0.9852546689\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2649034070 \tAcc: 0.9368750000 \tTPR:0.9367104066 \tFPR:0.0647382546 \tF1:0.9353457503 \tAUC:0.9359860760 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.0808191328106265 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.12166615133211561295\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.0833105408 \tAcc: 0.9678557145 \tTPR:0.9720686807 \tFPR:0.0363747172 \tF1:0.9648033984 \t AUC:0.9678469818\tTrain cost: 0:00:37\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.0713002169 \tAcc: 0.9726159794 \tTPR:0.9780721817 \tFPR:0.0325657526 \tF1:0.9701836679 \t AUC:0.9727532145\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0702307549 \tAcc: 0.9730908950 \tTPR:0.9761620337 \tFPR:0.0295847878 \tF1:0.9703025606 \t AUC:0.9732886229\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0633774368 \tAcc: 0.9759181701 \tTPR:0.9785621484 \tFPR:0.0264459195 \tF1:0.9733805028 \t AUC:0.9760581145\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0600716089 \tAcc: 0.9770374156 \tTPR:0.9802415205 \tFPR:0.0261449349 \tF1:0.9752100262 \t AUC:0.9770482928\tTrain cost: 0:00:40\n",
      "Client6 Test =>                 \tLoss: 0.2518243277 \tAcc: 0.9372916667 \tTPR:0.9138727695 \tFPR:0.0414514585 \tF1:0.9328487568 \tAUC:0.9362106555 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.07498581753748434 \tALA epochs: 8\n",
      "Client 1: Local Initial ALA epochs: 8 Loss: 0.13866908273613423597\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0509660696 \tAcc: 0.9795778509 \tTPR:0.8962817924 \tFPR:0.0099056254 \tF1:0.8845492906 \t AUC:0.9416260623\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0443011036 \tAcc: 0.9814053363 \tTPR:0.9059790680 \tFPR:0.0094455048 \tF1:0.8896455319 \t AUC:0.9469962285\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0389807357 \tAcc: 0.9845577485 \tTPR:0.9253637566 \tFPR:0.0075385611 \tF1:0.9209412935 \t AUC:0.9576724185\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0348088199 \tAcc: 0.9861567982 \tTPR:0.9338577926 \tFPR:0.0073722078 \tF1:0.9240614407 \t AUC:0.9625517544\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0311518225 \tAcc: 0.9874360380 \tTPR:0.9413794904 \tFPR:0.0064991841 \tF1:0.9318615176 \t AUC:0.9668722943\tTrain cost: 0:01:11\n",
      "Client1 Test =>                 \tLoss: 0.5226528753 \tAcc: 0.8812500000 \tTPR:0.7724482364 \tFPR:0.0126821045 \tF1:0.8605249891 \tAUC:0.8798830660 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2871534543 \tAcc: 0.9284166667 \tTPR:0.9095956502 \tFPR:0.0547008787 \tF1:0.9229405540 \tAUC:0.9274473858\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 27:  =============\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.07994980561416015 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.12762393117522793928\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0451717211 \tAcc: 0.9807200292 \tTPR:0.9082521118 \tFPR:0.0100537117 \tF1:0.8972613820 \t AUC:0.9480004229\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0390653616 \tAcc: 0.9847861842 \tTPR:0.9216762972 \tFPR:0.0073532423 \tF1:0.9147734847 \t AUC:0.9561633993\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0355113850 \tAcc: 0.9852430556 \tTPR:0.9295513088 \tFPR:0.0077706289 \tF1:0.9110870600 \t AUC:0.9593868618\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0317745659 \tAcc: 0.9867507310 \tTPR:0.9322838346 \tFPR:0.0063548458 \tF1:0.9271582115 \t AUC:0.9620494111\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0310995231 \tAcc: 0.9882584064 \tTPR:0.9464761441 \tFPR:0.0063520739 \tF1:0.9348304192 \t AUC:0.9692559529\tTrain cost: 0:01:11\n",
      "Client1 Test =>                 \tLoss: 0.4154980062 \tAcc: 0.8985416667 \tTPR:0.8156319913 \tFPR:0.0202185153 \tF1:0.8849224815 \tAUC:0.8977067380 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.09605123768177828 \tALA epochs: 5\n",
      "Client 4: Local Initial ALA epochs: 5 Loss: 0.28690574950012176503\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0893832344 \tAcc: 0.9655275130 \tTPR:0.9812377195 \tFPR:0.0620176337 \tF1:0.9728677966 \t AUC:0.9596100429\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0816029601 \tAcc: 0.9683438042 \tTPR:0.9827306136 \tFPR:0.0570089623 \tF1:0.9750917920 \t AUC:0.9628608256\tTrain cost: 0:01:59\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0742831495 \tAcc: 0.9722703640 \tTPR:0.9854796381 \tFPR:0.0516000648 \tF1:0.9781344159 \t AUC:0.9669397867\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0705133327 \tAcc: 0.9736243501 \tTPR:0.9860385705 \tFPR:0.0482650071 \tF1:0.9791312590 \t AUC:0.9688867817\tTrain cost: 0:01:59\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0676370426 \tAcc: 0.9735431109 \tTPR:0.9860677271 \tFPR:0.0489386808 \tF1:0.9791674026 \t AUC:0.9685645231\tTrain cost: 0:01:58\n",
      "Client4 Test =>                 \tLoss: 0.2266115854 \tAcc: 0.9408333333 \tTPR:0.9304298112 \tFPR:0.0496292252 \tF1:0.9385068787 \tAUC:0.9404002930 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.06942915045234554 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.06638304985244758427\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0626057324 \tAcc: 0.9750744048 \tTPR:0.9870546514 \tFPR:0.0453425873 \tF1:0.9812329403 \t AUC:0.9708560321\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0544499358 \tAcc: 0.9802827381 \tTPR:0.9910154905 \tFPR:0.0449141632 \tF1:0.9851381688 \t AUC:0.9730506637\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0496110500 \tAcc: 0.9832589286 \tTPR:0.9920725553 \tFPR:0.0346181266 \tF1:0.9874896016 \t AUC:0.9787272144\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0434601717 \tAcc: 0.9862351190 \tTPR:0.9913661092 \tFPR:0.0258170615 \tF1:0.9894142903 \t AUC:0.9827745238\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0399884266 \tAcc: 0.9866071429 \tTPR:0.9931882590 \tFPR:0.0269301135 \tF1:0.9900815443 \t AUC:0.9831290727\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2680996302 \tAcc: 0.9368750000 \tTPR:0.9385823367 \tFPR:0.0664516659 \tF1:0.9351832718 \tAUC:0.9360653354 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.07280124711253008 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.09253625937024921588\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0616124456 \tAcc: 0.9769390060 \tTPR:0.9905253478 \tFPR:0.0769306809 \tF1:0.9854318868 \t AUC:0.9567830213\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0523274307 \tAcc: 0.9806099398 \tTPR:0.9925691315 \tFPR:0.0689538039 \tF1:0.9877712535 \t AUC:0.9618076638\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0452445790 \tAcc: 0.9828689759 \tTPR:0.9926697733 \tFPR:0.0578175506 \tF1:0.9892553919 \t AUC:0.9674261113\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0379320523 \tAcc: 0.9861634036 \tTPR:0.9939613681 \tFPR:0.0428077027 \tF1:0.9911527892 \t AUC:0.9755768327\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0353922800 \tAcc: 0.9866340361 \tTPR:0.9934069927 \tFPR:0.0397691415 \tF1:0.9914869758 \t AUC:0.9768189256\tTrain cost: 0:00:34\n",
      "Client2 Test =>                 \tLoss: 0.2286948540 \tAcc: 0.9437500000 \tTPR:0.9627308220 \tFPR:0.0754702419 \tF1:0.9428220755 \tAUC:0.9436302901 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.08571828924564782 \tALA epochs: 8\n",
      "Client 5: Local Initial ALA epochs: 8 Loss: 0.28340845388676305650\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0435443221 \tAcc: 0.9822033898 \tTPR:0.9448502376 \tFPR:0.0104291312 \tF1:0.9370391283 \t AUC:0.9672105532\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0306585713 \tAcc: 0.9859639831 \tTPR:0.9522687529 \tFPR:0.0080350667 \tF1:0.9449110313 \t AUC:0.9718440931\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0268308016 \tAcc: 0.9903248588 \tTPR:0.9615840609 \tFPR:0.0047916102 \tF1:0.9609445588 \t AUC:0.9783962254\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0217254617 \tAcc: 0.9915254237 \tTPR:0.9716156725 \tFPR:0.0045007301 \tF1:0.9653836541 \t AUC:0.9835172668\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0186809091 \tAcc: 0.9926730226 \tTPR:0.9775647924 \tFPR:0.0044816082 \tF1:0.9703873972 \t AUC:0.9864778557\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.4821796344 \tAcc: 0.9072916667 \tTPR:0.8286529106 \tFPR:0.0152612138 \tF1:0.8948139311 \tAUC:0.9066958484 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.3242167420 \tAcc: 0.9254583333 \tTPR:0.8952055744 \tFPR:0.0454061724 \tF1:0.9192497277 \tAUC:0.9248997010\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 28:  =============\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.08297385127059574 \tALA epochs: 2\n",
      "Client 8: Local Initial ALA epochs: 2 Loss: 0.14452937339891247515\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0726184149 \tAcc: 0.9741124260 \tTPR:0.9895700695 \tFPR:0.0756339276 \tF1:0.9830159045 \t AUC:0.9569525963\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0653540721 \tAcc: 0.9760539941 \tTPR:0.9900456858 \tFPR:0.0713958602 \tF1:0.9842311149 \t AUC:0.9593565088\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0583181834 \tAcc: 0.9781804734 \tTPR:0.9909634481 \tFPR:0.0640996697 \tF1:0.9854465966 \t AUC:0.9634184819\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0559557623 \tAcc: 0.9789201183 \tTPR:0.9905518716 \tFPR:0.0628275247 \tF1:0.9860980982 \t AUC:0.9638340540\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0496850090 \tAcc: 0.9810465976 \tTPR:0.9918334135 \tFPR:0.0534379657 \tF1:0.9874110653 \t AUC:0.9691977239\tTrain cost: 0:00:34\n",
      "Client8 Test =>                 \tLoss: 0.1990116544 \tAcc: 0.9454166667 \tTPR:0.9631226542 \tFPR:0.0709822693 \tF1:0.9432565285 \tAUC:0.9460701925 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.05340911625792592 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.07616078992090795363\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0737367437 \tAcc: 0.9715537928 \tTPR:0.9841359020 \tFPR:0.0506494249 \tF1:0.9774597750 \t AUC:0.9667432385\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0675299671 \tAcc: 0.9753574523 \tTPR:0.9871351643 \tFPR:0.0461703995 \tF1:0.9805823703 \t AUC:0.9704823824\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0620488429 \tAcc: 0.9766031196 \tTPR:0.9869462042 \tFPR:0.0429832414 \tF1:0.9814103979 \t AUC:0.9719814814\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0611207885 \tAcc: 0.9773759332 \tTPR:0.9880879091 \tFPR:0.0418131662 \tF1:0.9819715640 \t AUC:0.9731373714\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0572286283 \tAcc: 0.9784445407 \tTPR:0.9881240813 \tFPR:0.0396983029 \tF1:0.9829740446 \t AUC:0.9742128892\tTrain cost: 0:01:58\n",
      "Client4 Test =>                 \tLoss: 0.2437503782 \tAcc: 0.9400000000 \tTPR:0.9446159867 \tFPR:0.0677171294 \tF1:0.9373874876 \tAUC:0.9384494287 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.08188546255963973 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.05955951694737781493\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0367962140 \tAcc: 0.9901041667 \tTPR:0.9954712302 \tFPR:0.0597484277 \tF1:0.9945076038 \t AUC:0.9678571429\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0259197508 \tAcc: 0.9885416667 \tTPR:0.9966796275 \tFPR:0.1191823899 \tF1:0.9938145787 \t AUC:0.9388241602\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0190634418 \tAcc: 0.9927083333 \tTPR:0.9983092159 \tFPR:0.0698717949 \tF1:0.9959594340 \t AUC:0.9643891310\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0200762085 \tAcc: 0.9942708333 \tTPR:0.9972904307 \tFPR:0.0503144654 \tF1:0.9969552284 \t AUC:0.9738986715\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0154342545 \tAcc: 0.9958333333 \tTPR:0.9989236111 \tFPR:0.0351851852 \tF1:0.9977036582 \t AUC:0.9820987654\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.3027742012 \tAcc: 0.9372916667 \tTPR:0.9871135617 \tFPR:0.1108927583 \tF1:0.9383281338 \tAUC:0.9381104017 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.17425963089847038 \tALA epochs: 11\n",
      "Client 6: Local Initial ALA epochs: 11 Loss: 0.35138831807161902132\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.0950671213 \tAcc: 0.9647951475 \tTPR:0.9740575936 \tFPR:0.0423475833 \tF1:0.9625231297 \t AUC:0.9658550051\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.0819476704 \tAcc: 0.9684278351 \tTPR:0.9718283834 \tFPR:0.0353036173 \tF1:0.9664040352 \t AUC:0.9682623831\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0728640509 \tAcc: 0.9719716495 \tTPR:0.9774755556 \tFPR:0.0323969535 \tF1:0.9695823484 \t AUC:0.9725393011\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0695667555 \tAcc: 0.9722938144 \tTPR:0.9779362334 \tFPR:0.0328024866 \tF1:0.9698419498 \t AUC:0.9725668734\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0638258265 \tAcc: 0.9742990135 \tTPR:0.9798741196 \tFPR:0.0308414981 \tF1:0.9723620841 \t AUC:0.9745163108\tTrain cost: 0:00:40\n",
      "Client6 Test =>                 \tLoss: 0.2277542469 \tAcc: 0.9406250000 \tTPR:0.9186163304 \tFPR:0.0377866399 \tF1:0.9362512706 \tAUC:0.9404148453 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.04583674960016608 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.08061406773049384356\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0620544135 \tAcc: 0.9761904762 \tTPR:0.9866762077 \tFPR:0.0479821766 \tF1:0.9822699532 \t AUC:0.9693470156\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0532802777 \tAcc: 0.9792906746 \tTPR:0.9874985753 \tFPR:0.0392815518 \tF1:0.9844685850 \t AUC:0.9741085118\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0388508602 \tAcc: 0.9869791667 \tTPR:0.9933932233 \tFPR:0.0262918959 \tF1:0.9900856012 \t AUC:0.9835506637\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0409148780 \tAcc: 0.9846230159 \tTPR:0.9924977501 \tFPR:0.0283924739 \tF1:0.9877750229 \t AUC:0.9820526381\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0418414783 \tAcc: 0.9863591270 \tTPR:0.9903663034 \tFPR:0.0228875010 \tF1:0.9897823547 \t AUC:0.9837394012\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2757106405 \tAcc: 0.9393750000 \tTPR:0.9462732024 \tFPR:0.0682904166 \tF1:0.9381210253 \tAUC:0.9389913929 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2498002242 \tAcc: 0.9405416667 \tTPR:0.9519483471 \tFPR:0.0711338427 \tF1:0.9386688891 \tAUC:0.9404072522\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 29:  =============\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.07006051096682327 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.05668927695571809172\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0571970196 \tAcc: 0.9780925043 \tTPR:0.9882964967 \tFPR:0.0390131755 \tF1:0.9826197252 \t AUC:0.9746416606\tTrain cost: 0:01:59\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0558455952 \tAcc: 0.9786757599 \tTPR:0.9890095737 \tFPR:0.0402323355 \tF1:0.9832405328 \t AUC:0.9743886191\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0512373584 \tAcc: 0.9806796594 \tTPR:0.9893102737 \tFPR:0.0357462400 \tF1:0.9847429220 \t AUC:0.9767820169\tTrain cost: 0:01:59\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0511205781 \tAcc: 0.9808817158 \tTPR:0.9904951134 \tFPR:0.0358321877 \tF1:0.9850004106 \t AUC:0.9773314628\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0474491759 \tAcc: 0.9821003033 \tTPR:0.9908273315 \tFPR:0.0337755769 \tF1:0.9859047137 \t AUC:0.9785258773\tTrain cost: 0:01:58\n",
      "Client4 Test =>                 \tLoss: 0.2379573429 \tAcc: 0.9435416667 \tTPR:0.9431809693 \tFPR:0.0540034593 \tF1:0.9414862921 \tAUC:0.9445887550 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.057268233092748144 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.06594795588171109557\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0661646585 \tAcc: 0.9747023810 \tTPR:0.9845615681 \tFPR:0.0485190900 \tF1:0.9807217669 \t AUC:0.9680212390\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0515251041 \tAcc: 0.9817708333 \tTPR:0.9915018430 \tFPR:0.0385337760 \tF1:0.9865049890 \t AUC:0.9764840335\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0442471745 \tAcc: 0.9847470238 \tTPR:0.9915596669 \tFPR:0.0282387751 \tF1:0.9882696154 \t AUC:0.9816604459\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0358956339 \tAcc: 0.9884672619 \tTPR:0.9950961043 \tFPR:0.0242810430 \tF1:0.9913213909 \t AUC:0.9854075306\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0341021130 \tAcc: 0.9869791667 \tTPR:0.9929282699 \tFPR:0.0261947378 \tF1:0.9904698328 \t AUC:0.9833667660\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2866223881 \tAcc: 0.9381250000 \tTPR:0.9366788142 \tFPR:0.0587790714 \tF1:0.9360221884 \tAUC:0.9389498714 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.059159309367994045 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.10148835014030277435\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.0873221882 \tAcc: 0.9667364691 \tTPR:0.9704286926 \tFPR:0.0361019527 \tF1:0.9639193077 \t AUC:0.9671633699\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.0731991481 \tAcc: 0.9704330341 \tTPR:0.9748966397 \tFPR:0.0341670892 \tF1:0.9684216155 \t AUC:0.9703647753\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0658726680 \tAcc: 0.9755960052 \tTPR:0.9798362645 \tFPR:0.0278774316 \tF1:0.9732025670 \t AUC:0.9759794164\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0612729821 \tAcc: 0.9762320032 \tTPR:0.9798566790 \tFPR:0.0269453679 \tF1:0.9744431172 \t AUC:0.9764556556\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0607343929 \tAcc: 0.9767957919 \tTPR:0.9804306048 \tFPR:0.0265489043 \tF1:0.9744316815 \t AUC:0.9769408502\tTrain cost: 0:00:41\n",
      "Client6 Test =>                 \tLoss: 0.2371320039 \tAcc: 0.9433333333 \tTPR:0.9245459537 \tFPR:0.0405347963 \tF1:0.9400640551 \tAUC:0.9420055787 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.08721861913430728 \tALA epochs: 4\n",
      "Client 0: Local Initial ALA epochs: 4 Loss: 0.17712196565698831718\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1187469851 \tAcc: 0.9587053571 \tTPR:0.9756905040 \tFPR:0.1229733560 \tF1:0.9734984852 \t AUC:0.9263585740\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0774828332 \tAcc: 0.9709821429 \tTPR:0.9899036692 \tFPR:0.0976332200 \tF1:0.9813745803 \t AUC:0.9461352246\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0685629403 \tAcc: 0.9743303571 \tTPR:0.9863575115 \tFPR:0.0630836425 \tF1:0.9826213968 \t AUC:0.9616369345\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0619430642 \tAcc: 0.9720982143 \tTPR:0.9891235699 \tFPR:0.0893298060 \tF1:0.9821133037 \t AUC:0.9502741703\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0552415013 \tAcc: 0.9789259454 \tTPR:0.9926218967 \tFPR:0.0651515152 \tF1:0.9860663313 \t AUC:0.9637351908\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.2025641914 \tAcc: 0.9437500000 \tTPR:0.9733966101 \tFPR:0.0850024360 \tF1:0.9440222871 \tAUC:0.9441970870 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.050840769859259435 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.06140469120634691608\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0678498845 \tAcc: 0.9764238166 \tTPR:0.9909943618 \tFPR:0.0735227022 \tF1:0.9844812920 \t AUC:0.9587224683\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0569063136 \tAcc: 0.9784578402 \tTPR:0.9916569902 \tFPR:0.0674479576 \tF1:0.9857643758 \t AUC:0.9620921380\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0514150940 \tAcc: 0.9813239645 \tTPR:0.9921953598 \tFPR:0.0560302945 \tF1:0.9876882753 \t AUC:0.9680825326\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0474630680 \tAcc: 0.9828032544 \tTPR:0.9927668406 \tFPR:0.0495275599 \tF1:0.9886579109 \t AUC:0.9716196404\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0423069306 \tAcc: 0.9845599112 \tTPR:0.9932051165 \tFPR:0.0465923460 \tF1:0.9898734005 \t AUC:0.9732963038\tTrain cost: 0:00:36\n",
      "Client8 Test =>                 \tLoss: 0.2275295463 \tAcc: 0.9383333333 \tTPR:0.9722783417 \tFPR:0.0944477126 \tF1:0.9371211536 \tAUC:0.9389153146 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2383610945 \tAcc: 0.9414166667 \tTPR:0.9500161378 \tFPR:0.0665534951 \tF1:0.9397431952 \tAUC:0.9417313213\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "Training and Test completed! total time cost: 8:36:58\n"
     ]
    }
   ],
   "source": [
    "print(\"Train and Test Begin!\")\n",
    "net_glob.train()\n",
    "w_net_glob = net_glob.state_dict()\n",
    "t0 = time.time()\n",
    "net_local = [copy.deepcopy(net_glob) for i in range(num_users)]\n",
    "\n",
    "lr = 2e-6\n",
    "\n",
    "local_test[\"loss\"] = []\n",
    "local_test[\"acc\"] = []\n",
    "local_test[\"tpr\"] = []\n",
    "local_test[\"fpr\"] = []\n",
    "local_test[\"f1\"] = []\n",
    "local_test[\"auc\"] = []\n",
    "\n",
    "local_testing[\"loss\"] = []\n",
    "local_testing[\"acc\"] = []\n",
    "local_testing[\"tpr\"] = []\n",
    "local_testing[\"fpr\"] = []\n",
    "local_testing[\"f1\"] = []\n",
    "local_testing[\"auc\"] = []\n",
    "\n",
    "for iter in range(epochs):\n",
    "    print(\"============== Round {}:  =============\".format(iter))\n",
    "    idx_collect = []\n",
    "    m = max(int(frac * num_users) ,1)\n",
    "    idxs_users = np.random.choice(range(num_users), m, replace = False)\n",
    "    w_locals_client = []\n",
    "\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    tpr_list = []\n",
    "    fpr_list = []\n",
    "    f1_list = []\n",
    "    auc_list = []\n",
    "\n",
    "    for idx in idxs_users:\n",
    "        local = Client(device, idx, lr, local_epochs, batch_size, train_dataset, test_dataset, dict_user_train[idx], dict_user_test[idx])\n",
    "        local.local_initialization(net = copy.deepcopy(net_glob).to(device))\n",
    "        w_client, client_loss, client_acc = local.train(net = copy.deepcopy(net_local[idx]).to(device))\n",
    "        w_locals_client.append(copy.deepcopy(w_client))\n",
    "        loss, acc, tpr, fpr, f1, auc = local.evaluate(net = copy.deepcopy(net_glob).to(device), ell=iter)\n",
    "\n",
    "        loss_list.append(loss)\n",
    "        acc_list.append(acc)\n",
    "        tpr_list.append(tpr)\n",
    "        fpr_list.append(fpr)\n",
    "        f1_list.append(f1)\n",
    "        auc_list.append(auc)\n",
    "\n",
    "    local_testing[\"loss\"].append(sum(loss_list)/len(loss_list))\n",
    "    local_testing[\"acc\"].append(sum(acc_list)/len(acc_list))\n",
    "    local_testing[\"tpr\"].append(sum(tpr_list)/len(tpr_list))\n",
    "    local_testing[\"fpr\"].append(sum(fpr_list)/len(fpr_list))\n",
    "    local_testing[\"f1\"].append(sum(f1_list)/len(f1_list))\n",
    "    local_testing[\"auc\"].append(sum(auc_list)/len(auc_list))\n",
    "    print(\"Test =>                 \\tLoss: {:.10f} \\tAcc: {:.10f} \\tTPR:{:.10f} \\tFPR:{:.10f} \\tF1:{:.10f} \\tAUC:{:.10f}\".format(sum(loss_list)/len(loss_list), sum(acc_list)/len(acc_list), sum(tpr_list)/len(tpr_list), sum(fpr_list)/len(fpr_list), sum(f1_list)/len(f1_list), sum(auc_list)/len(auc_list)  ))\n",
    "\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "    print(\"-------------- FedServer: Federation process  -------------\")\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "    w_net_glob = FedAvg(w_locals_client)\n",
    "    net_glob.load_state_dict(w_net_glob)\n",
    "elapsed = format_time(time.time()-t0)\n",
    "print(\"Training and Test completed! total time cost: {:}\".format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Final Result =============\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.026846555985805546 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.02836113898083567758\n",
      "Client0 Test =>                 \tLoss: 0.1971132714 \tAcc: 0.9500000000 \tTPR:0.9522314099 \tFPR:0.0534716299 \tF1:0.9497142165 \tAUC:0.9493798900 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.09939059847416308 \tALA epochs: 6\n",
      "Client 1: Local Initial ALA epochs: 6 Loss: 0.18544305231854177340\n",
      "Client1 Test =>                 \tLoss: 0.2159932375 \tAcc: 0.9487500000 \tTPR:0.9461497630 \tFPR:0.0514951208 \tF1:0.9448570736 \tAUC:0.9473273211 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.03564530824012863 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.05153172613813005593\n",
      "Client2 Test =>                 \tLoss: 0.2127031225 \tAcc: 0.9456250000 \tTPR:0.9546251588 \tFPR:0.0635646367 \tF1:0.9442100739 \tAUC:0.9455302610 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.056419750788617475 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.08025036139588337392\n",
      "Client3 Test =>                 \tLoss: 0.2024559251 \tAcc: 0.9510416667 \tTPR:0.9535781493 \tFPR:0.0530361138 \tF1:0.9479279505 \tAUC:0.9502710178 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.046984061576920685 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.04516686475835740566\n",
      "Client4 Test =>                 \tLoss: 0.2270757118 \tAcc: 0.9445833333 \tTPR:0.9492646478 \tFPR:0.0609196709 \tF1:0.9425186804 \tAUC:0.9441724885 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.08545846784626736 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.15175188692436286653\n",
      "Client5 Test =>                 \tLoss: 0.2043707859 \tAcc: 0.9510416667 \tTPR:0.9553638566 \tFPR:0.0548848631 \tF1:0.9486258549 \tAUC:0.9502394967 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.05057996077227 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.08773165138123871498\n",
      "Client6 Test =>                 \tLoss: 0.2107246768 \tAcc: 0.9464583333 \tTPR:0.9466310668 \tFPR:0.0530611786 \tF1:0.9443050255 \tAUC:0.9467849441 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.0740926339699431 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.03737267348333261907\n",
      "Client7 Test =>                 \tLoss: 0.2448205623 \tAcc: 0.9391666667 \tTPR:0.9478215508 \tFPR:0.0694896105 \tF1:0.9372682136 \tAUC:0.9391659702 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.0714138098554122 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.06454229515754798807\n",
      "Client8 Test =>                 \tLoss: 0.2090752864 \tAcc: 0.9479166667 \tTPR:0.9571712412 \tFPR:0.0587741260 \tF1:0.9443318785 \tAUC:0.9491985576 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.03343995992945693 \tALA epochs: 2\n",
      "Client 9: Local Initial ALA epochs: 2 Loss: 0.05937411752529442310\n",
      "Client9 Test =>                 \tLoss: 0.2002124801 \tAcc: 0.9493750000 \tTPR:0.9573942808 \tFPR:0.0598516946 \tF1:0.9499407276 \tAUC:0.9487712931 \ttest cost: 0:00:05\n"
     ]
    }
   ],
   "source": [
    "idx_collect = [i for i in range(num_users)]\n",
    "print(\"============= Final Result =============\")\n",
    "for idx in idx_collect:\n",
    "    loss_test_collect[idx] = []\n",
    "    acc_test_collect[idx] = []\n",
    "    TPR_test_collect[idx] = []\n",
    "    FPR_test_collect[idx] = []\n",
    "    f1_test_collect[idx] = []\n",
    "    AUC_test_collect[idx] = []\n",
    "    local = Client(device, idx, lr, local_epochs, batch_size, train_dataset, test_dataset, dict_user_train[idx], dict_user_test[idx])\n",
    "    local.local_initialization(net = copy.deepcopy(net_glob).to(device))\n",
    "    loss, acc, tpr, fpr, f1, auc = local.evaluate(net = copy.deepcopy(net_local[idx]).to(device), ell=0)\n",
    "    loss_test_collect[idx].append(loss)\n",
    "    acc_test_collect[idx].append(acc)\n",
    "    TPR_test_collect[idx].append(tpr)\n",
    "    FPR_test_collect[idx].append(fpr)\n",
    "    f1_test_collect[idx].append(f1)\n",
    "    AUC_test_collect[idx].append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import xlwt\n",
    "f = xlwt.Workbook('encoding = utf-8')\n",
    "sheet1 = f.add_sheet('sheet1',cell_overwrite_ok=True)\n",
    "for i in range(len(loss_collect)):\n",
    "    sheet1.write(i+1,0,loss_collect[i]) #写入数据参数对应 行, 列, 值\n",
    "for i in range(len(acc_collect)):\n",
    "    sheet1.write(i+1,1,acc_collect[i])\n",
    "for i in range(len(TPR_collect)):\n",
    "    sheet1.write(i+1,2,TPR_collect[i])\n",
    "for i in range(len(FPR_collect)):\n",
    "    sheet1.write(i+1,3,FPR_collect[i])\n",
    "for i in range(len(F1_collect)):\n",
    "    sheet1.write(i+1,4,F1_collect[i])\n",
    "for i in range(len(AUC_collect)):\n",
    "    sheet1.write(i+1,5,AUC_collect[i])\n",
    "\n",
    "f.save('result.xls')#保存.xls到当前工作目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(num_users):\n",
    "    f = xlwt.Workbook('encoding = utf-8')\n",
    "    sheet1 = f.add_sheet('sheet1', cell_overwrite_ok=True)\n",
    "    for j in range(len(loss_train_collect[i])):\n",
    "        sheet1.write(j+1, 0, loss_train_collect[i][j])\n",
    "    for j in range(len(acc_train_collect[i])):\n",
    "        sheet1.write(j+1, 1, acc_train_collect[i][j])\n",
    "    for j in range(len(TPR_train_collect[i])):\n",
    "        sheet1.write(j+1, 2, TPR_train_collect[i][j])\n",
    "    for j in range(len(FPR_train_collect[i])):\n",
    "        sheet1.write(j+1, 3, FPR_train_collect[i][j])\n",
    "    for j in range(len(f1_train_collect[i])):\n",
    "        sheet1.write(j+1, 4, f1_train_collect[i][j])\n",
    "    for j in range(len(AUC_train_collect[i])):\n",
    "        sheet1.write(j+1, 5, AUC_train_collect[i][j])\n",
    "\n",
    "    f.save('result_client{:}.xls'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(num_users):\n",
    "    f = xlwt.Workbook('encoding = utf-8')\n",
    "    sheet1 = f.add_sheet('sheet1', cell_overwrite_ok=True)\n",
    "    for j in range(len(loss_test_collect[i])):\n",
    "        sheet1.write(j+1, 0, loss_test_collect[i][j])\n",
    "    for j in range(len(acc_test_collect[i])):\n",
    "        sheet1.write(j+1, 1, acc_test_collect[i][j])\n",
    "    for j in range(len(TPR_test_collect[i])):\n",
    "        sheet1.write(j+1, 2, TPR_test_collect[i][j])\n",
    "    for j in range(len(FPR_test_collect[i])):\n",
    "        sheet1.write(j+1, 3, FPR_test_collect[i][j])\n",
    "    for j in range(len(f1_test_collect[i])):\n",
    "        sheet1.write(j+1, 4, f1_test_collect[i][j])\n",
    "    for j in range(len(AUC_test_collect[i])):\n",
    "        sheet1.write(j+1, 5, AUC_test_collect[i][j])\n",
    "\n",
    "    f.save('result_test_client{:}.xls'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import xlwt\n",
    "f = xlwt.Workbook('encoding = utf-8')\n",
    "sheet1 = f.add_sheet('sheet1',cell_overwrite_ok=True)\n",
    "for i in range(len(local_test[\"loss\"])):\n",
    "    sheet1.write(i+1,0,local_test[\"loss\"][i])\n",
    "for i in range(len(local_test[\"acc\"])):\n",
    "    sheet1.write(i+1,1,local_test[\"acc\"][i])\n",
    "for i in range(len(local_test[\"tpr\"])):\n",
    "    sheet1.write(i+1,2,local_test[\"tpr\"][i])\n",
    "for i in range(len(local_test[\"fpr\"])):\n",
    "    sheet1.write(i+1,3,local_test[\"fpr\"][i])\n",
    "for i in range(len(local_test[\"f1\"])):\n",
    "    sheet1.write(i+1,4,local_test[\"f1\"][i])\n",
    "for i in range(len(local_test[\"auc\"])):\n",
    "    sheet1.write(i+1,5,local_test[\"auc\"][i])\n",
    "\n",
    "f.save('Local_Test.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import xlwt\n",
    "f = xlwt.Workbook('encoding = utf-8')\n",
    "sheet1 = f.add_sheet('sheet1',cell_overwrite_ok=True)\n",
    "for i in range(len(local_testing[\"loss\"])):\n",
    "    sheet1.write(i+1,0,local_testing[\"loss\"][i])\n",
    "for i in range(len(local_testing[\"acc\"])):\n",
    "    sheet1.write(i+1,1,local_testing[\"acc\"][i])\n",
    "for i in range(len(local_testing[\"tpr\"])):\n",
    "    sheet1.write(i+1,2,local_testing[\"tpr\"][i])\n",
    "for i in range(len(local_testing[\"fpr\"])):\n",
    "    sheet1.write(i+1,3,local_testing[\"fpr\"][i])\n",
    "for i in range(len(local_testing[\"f1\"])):\n",
    "    sheet1.write(i+1,4,local_testing[\"f1\"][i])\n",
    "for i in range(len(local_testing[\"auc\"])):\n",
    "    sheet1.write(i+1,5,local_testing[\"auc\"][i])\n",
    "\n",
    "f.save('Local_Testing.xls')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
