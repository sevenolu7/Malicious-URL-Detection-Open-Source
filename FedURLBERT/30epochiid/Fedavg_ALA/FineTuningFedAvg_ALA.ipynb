{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "df_train = pd.read_csv(\"./fine_tuning.csv\")\n",
    "\n",
    "train_data_domain = df_train.domain.values\n",
    "train_data_label = df_train.label.values\n",
    "train_data_label = train_data_label.tolist()\n",
    "train_data_label = [0 if item == 2 else 1 for item in train_data_label]\n",
    "train_data_label = np.array(train_data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer(vocab_file=\"./bert_tokenizer/vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "input_ids_train = []\n",
    "attention_masks_train = []\n",
    "\n",
    "for sent in train_data_domain:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        sent,                      # Sentence to encode.\n",
    "        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "        max_length = 64,           # Pad & truncate all sentences.\n",
    "        pad_to_max_length = True,\n",
    "        return_attention_mask = True,   # Construct attn. masks.\n",
    "        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "    )\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_train.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks_train.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_train = torch.cat(input_ids_train, dim=0)\n",
    "attention_masks_train = torch.cat(attention_masks_train, dim=0)\n",
    "labels_train = torch.tensor(train_data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111,998 training samples\n",
      "48,000 test samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.7 * len(dataset_train))\n",
    "test_size = len(dataset_train) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset_train, [train_size, test_size])\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} test samples'.format(test_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "构造MyModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "EmbeddingPath = \"./FedBert/FedTransformer.pt\"\n",
    "TransformerPath = \"./FedBert/FedEmbedding.pt\"\n",
    "num_users = 10\n",
    "frac = 0.5\n",
    "local_epochs = 5\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_name_or_path\": \"./bert-base-uncased-model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.2,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.34.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 1000\n",
      "}\n",
      "\n",
      "BertPooler(\n",
      "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (activation): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoTokenizer,DataCollatorForLanguageModeling,HfArgumentParser,Trainer,TrainingArguments,set_seed,\n",
    ")\n",
    "# 自己修改部分配置参数\n",
    "config_kwargs = {\n",
    "    \"cache_dir\": None,\n",
    "    \"revision\": 'main',\n",
    "    \"use_auth_token\": None,\n",
    "    #      \"hidden_size\": 512,\n",
    "    #     \"num_attention_heads\": 4,\n",
    "    \"hidden_dropout_prob\": 0.2,\n",
    "    \"vocab_size\": 1000 # 自己设置词汇大小\n",
    "}\n",
    "# 将模型的配置参数载入\n",
    "config = AutoConfig.from_pretrained('./bert-base-uncased-model/', **config_kwargs)\n",
    "print(config)\n",
    "# 载入预训练模型\n",
    "model = AutoModelForMaskedLM.from_config(\n",
    "    config=config,\n",
    ")\n",
    "model.resize_token_embeddings(config_kwargs[\"vocab_size\"])\n",
    "\n",
    "embedding = model.bert.embeddings\n",
    "\n",
    "class Bert_Embedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Bert_Embedding, self).__init__()\n",
    "        self.embeddings = copy.deepcopy(embedding)\n",
    "\n",
    "    def forward(self, input_ids, attn_mask):\n",
    "        embedding_output = self.embeddings(input_ids, attn_mask)\n",
    "        return embedding_output\n",
    "\n",
    "embedding_model = Bert_Embedding()\n",
    "embedding_model.load_state_dict(torch.load(EmbeddingPath))\n",
    "\n",
    "encoder = model.bert.encoder\n",
    "cls = model.cls\n",
    "\n",
    "class Bert_Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Bert_Encoder, self).__init__()\n",
    "        self.encoder = copy.deepcopy(encoder)\n",
    "        self.cls = copy.deepcopy(cls)\n",
    "\n",
    "    def forward(self, embedding_output):\n",
    "        output_encoder = self.encoder(embedding_output).last_hidden_state\n",
    "        return output_encoder\n",
    "encoder_model = Bert_Encoder()\n",
    "encoder_model.load_state_dict(torch.load(TransformerPath))\n",
    "\n",
    "from transformers.models.bert.modeling_bert import BertPooler\n",
    "class Pooler_Config:\n",
    "    def __init__(self, entries: dict={}):\n",
    "        for k, v in entries.items():\n",
    "            if isinstance(v, dict):\n",
    "                self.__dict__[k] = Pooler_Config(v)\n",
    "            else:\n",
    "                self.__dict__[k] = v\n",
    "\n",
    "config_pooler = {\"hidden_size\": 768}\n",
    "config_pooler = Pooler_Config(config_pooler)\n",
    "pooler = BertPooler(config_pooler)\n",
    "print(pooler)\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, hidden_size=768, num_classes=2, freeze_bert=False):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.embedding = Bert_Embedding()\n",
    "        self.encoder = Bert_Encoder()\n",
    "        self.pooler = copy.deepcopy(pooler)\n",
    "        if freeze_bert:\n",
    "            for p in self.embedding.parameters():\n",
    "                p.requires_grad = False\n",
    "            for p in self.encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(hidden_size, num_classes, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attn_mask):\n",
    "        embedding_outputs = self.embedding(input_ids, attn_mask)\n",
    "        encoder_outputs = self.encoder(embedding_outputs)\n",
    "        pooler_outputs = self.pooler(encoder_outputs)\n",
    "        #它代表了一句话的embedding\n",
    "        logits = self.fc(pooler_outputs)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "iid数据分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def dataset_iid(dataset, num_users):\n",
    "\n",
    "    num_items = int(len(dataset)/num_users)\n",
    "    dict_users, all_idxs = {}, [i for i in range(len(dataset))]\n",
    "    for i in range(num_users):\n",
    "        dict_users[i] = set(np.random.choice(all_idxs, num_items, replace = False))\n",
    "        all_idxs = list(set(all_idxs) - dict_users[i])\n",
    "    return dict_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "dict_user_train = dataset_iid(train_dataset, num_users)\n",
    "dict_user_test = dataset_iid(test_dataset, num_users)\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it\n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch\n",
    "# size of 16 or 32.\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (embedding): Bert_Embedding(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(1000, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (encoder): Bert_Encoder(\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cls): Sequential()\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=768, out_features=2, bias=False)\n",
      "    (2): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net_glob = MyModel()\n",
    "net_glob.encoder.cls = nn.Sequential()\n",
    "print(net_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 训练loss记录\n",
    "loss_train_collect = {}\n",
    "# 训练acc记录\n",
    "acc_train_collect = {}\n",
    "loss_test_collect = {}\n",
    "# 测试acc记录\n",
    "acc_test_collect = {}\n",
    "# 训练TPR记录\n",
    "TPR_train_collect = {}\n",
    "# 测试TPR记录\n",
    "TPR_test_collect = {}\n",
    "# 训练FPR记录\n",
    "FPR_train_collect = {}\n",
    "# 测试FPR记录\n",
    "FPR_test_collect = {}\n",
    "# 训练测试F1-score记录\n",
    "f1_train_collect = {}\n",
    "f1_test_collect = {}\n",
    "# 训练测试AUC记录\n",
    "AUC_train_collect = {}\n",
    "AUC_test_collect = {}\n",
    "# 训练测试ROC曲线记录\n",
    "ROC_train_collect = {}\n",
    "ROC_test_collect = {}\n",
    "\n",
    "local_test = {}\n",
    "local_testing = {}\n",
    "\n",
    "loss_collect = []\n",
    "acc_collect = []\n",
    "TPR_collect = []\n",
    "FPR_collect = []\n",
    "F1_collect = []\n",
    "AUC_collect = []\n",
    "\n",
    "count1 = 0\n",
    "count2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def FedAvg(w):\n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    for k in w_avg.keys():\n",
    "        for i in range(1, len(w)):\n",
    "            w_avg[k] += w[i][k]\n",
    "        w_avg[k] = torch.div(w_avg[k], len(w))\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "idx_collect = []\n",
    "l_epoch_check = False\n",
    "fed_check = False\n",
    "# Initialization of net_model_server and net_server (server-side model)\n",
    "net_model = [net_glob for i in range(num_users)]\n",
    "net_server = copy.deepcopy(net_model[0]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "class DatasetSplit(Dataset):\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = list(idxs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        domain, attn_mask, label = self.dataset[self.idxs[item]]\n",
    "        return domain, attn_mask, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    return np.sum(preds == labels) / len(labels)\n",
    "\n",
    "def tpr_calculate(preds, labels):\n",
    "    return recall_score(labels, preds)\n",
    "\n",
    "def fpr_calculate(preds, labels):\n",
    "    conf_matrix = confusion_matrix(labels, preds)\n",
    "    fp = conf_matrix[0, 1]  # 0 表示负类别，1 表示正类别\n",
    "    tn = conf_matrix[0, 0]\n",
    "    fpr = fp / (fp + tn)\n",
    "    return fpr\n",
    "\n",
    "def f1_score_calculate(preds, labels):\n",
    "    return f1_score(labels, preds)\n",
    "\n",
    "def AUC_calculate(preds, labels):\n",
    "    return roc_auc_score(labels, preds)\n",
    "\n",
    "def roc_curve_calculate(preds, labels):\n",
    "    return roc_curve(labels, preds)\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Client(object):\n",
    "    def __init__(self, device, idx, lr, local_epochs, batch_size, dataset_train = None, dataset_test = None, idxs = None, idxs_test = None):\n",
    "        self.device = device\n",
    "        self.lr = lr\n",
    "        self.idx = idx\n",
    "        self.local_ep = local_epochs\n",
    "        self.ldr_train = DataLoader(DatasetSplit(dataset_train, idxs), batch_size = batch_size, shuffle = True)\n",
    "        self.ldr_test = DataLoader(DatasetSplit(dataset_test, idxs_test), batch_size = batch_size, shuffle= True)\n",
    "        self.ala = ALA(idx, idxs, criterion, dataset_train, batch_size, 20, 0, lr*4, self.device, 0.1, 10)\n",
    "\n",
    "    def local_initialization(self, net):\n",
    "        print(\"local_initialization!\")\n",
    "        local_model = net_local[self.idx].to(self.device)\n",
    "        self.ala.adaptive_local_aggregation(net, local_model)\n",
    "\n",
    "    def train(self, net):\n",
    "        net.train()\n",
    "        optimizer_client = torch.optim.Adam(net.parameters(), lr = self.lr)\n",
    "\n",
    "        TPR_train_collect[self.idx] = []\n",
    "        FPR_train_collect[self.idx] = []\n",
    "        f1_train_collect[self.idx] = []\n",
    "        AUC_train_collect[self.idx] = []\n",
    "        loss_train_collect[self.idx] = []\n",
    "        acc_train_collect[self.idx] = []\n",
    "\n",
    "        epoch_loss = []\n",
    "        epoch_accuracy = []\n",
    "        for iter in range(self.local_ep):\n",
    "            tmp_t0 = time.time()\n",
    "            batch_loss_train = []\n",
    "            batch_acc_train = []\n",
    "            batch_tpr_train = []\n",
    "            batch_fpr_train = []\n",
    "            batch_f1_train = []\n",
    "            batch_auc_train = []\n",
    "            for batch_idx, (ids, attn_mask, b_labels) in enumerate(self.ldr_train):\n",
    "                ids, attn_mask, b_labels = ids.to(self.device), attn_mask.to(self.device) , b_labels.to(self.device)\n",
    "                optimizer_client.zero_grad()\n",
    "                b_labels = b_labels.unsqueeze(1)\n",
    "                b_labels = b_labels.repeat(1,2)\n",
    "                for i in range(len(b_labels)):\n",
    "                    b_labels[i][1] = 1-b_labels[i][0]\n",
    "                logits = net(ids, attn_mask)\n",
    "                BCEloss = criterion(logits, b_labels.float())\n",
    "                BCEloss.backward()\n",
    "                optimizer_client.step()\n",
    "                batch_loss_train.append(BCEloss.item())\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                label_ids = b_labels.to('cpu').numpy()\n",
    "                logits = np.argmax(logits, axis=1).flatten()\n",
    "                label_ids = np.argmax(label_ids,axis=1).flatten()\n",
    "                accuracy = flat_accuracy(logits, label_ids)\n",
    "                tpr = tpr_calculate(logits, label_ids)\n",
    "                fpr = fpr_calculate(logits, label_ids)\n",
    "                f1 = f1_score_calculate(logits, label_ids)\n",
    "                auc = AUC_calculate(logits, label_ids)\n",
    "                batch_acc_train.append(accuracy)\n",
    "                batch_tpr_train.append(tpr)\n",
    "                batch_fpr_train.append(fpr)\n",
    "                batch_f1_train.append(f1)\n",
    "                batch_auc_train.append(auc)\n",
    "            elapsed = format_time(time.time()-tmp_t0)\n",
    "            epoch_avg_loss = sum(batch_loss_train)/len(batch_loss_train)\n",
    "            epoch_avg_acc = sum(batch_acc_train)/len(batch_acc_train)\n",
    "            epoch_avg_tpr = sum(batch_tpr_train)/len(batch_tpr_train)\n",
    "            epoch_avg_fpr = sum(batch_fpr_train)/len(batch_fpr_train)\n",
    "            epoch_avg_f1 = sum(batch_f1_train)/len(batch_f1_train)\n",
    "            epoch_avg_auc = sum(batch_auc_train)/len(batch_auc_train)\n",
    "            epoch_loss.append(sum(batch_loss_train)/len(batch_loss_train))\n",
    "            epoch_accuracy.append(sum(batch_acc_train)/len(batch_acc_train))\n",
    "            loss_train_collect[self.idx].append(epoch_avg_loss)\n",
    "            acc_train_collect[self.idx].append(epoch_avg_acc)\n",
    "            TPR_train_collect[self.idx].append(epoch_avg_tpr)\n",
    "            FPR_train_collect[self.idx].append(epoch_avg_fpr)\n",
    "            f1_train_collect[self.idx].append(epoch_avg_f1)\n",
    "            AUC_train_collect[self.idx].append(epoch_avg_auc)\n",
    "            loss_collect.append(epoch_avg_loss)\n",
    "            acc_collect.append(epoch_avg_acc)\n",
    "            TPR_collect.append(epoch_avg_tpr)\n",
    "            FPR_collect.append(epoch_avg_fpr)\n",
    "            F1_collect.append(epoch_avg_f1)\n",
    "            AUC_collect.append(epoch_avg_auc)\n",
    "\n",
    "            print('Client{} Local Train => Local Epoch: {} \\tLoss: {:.10f} \\tAcc: {:.10f} \\tTPR:{:.10f} \\tFPR:{:.10f} \\tF1:{:.10f} \\t AUC:{:.10f}\\tTrain cost: {:}'.format(self.idx, iter, epoch_avg_loss, \\\n",
    "                                                                                                                                                                           epoch_avg_acc, epoch_avg_tpr, epoch_avg_fpr, epoch_avg_f1, epoch_avg_auc, elapsed))\n",
    "\n",
    "        net_glob.load_state_dict(net.state_dict())\n",
    "        return net.state_dict(), sum(epoch_loss) / len(epoch_loss), sum(epoch_accuracy) / len(epoch_accuracy)\n",
    "\n",
    "    def evaluate(self, net, ell):\n",
    "        net.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tmp_t0 = time.time()\n",
    "            len_batch = len(self.ldr_test)\n",
    "\n",
    "            batch_acc_test = []\n",
    "            batch_loss_test = []\n",
    "            batch_tpr_test = []\n",
    "            batch_fpr_test = []\n",
    "            batch_f1_test = []\n",
    "            batch_auc_test = []\n",
    "            for batch_idx, (ids, attn_mask, b_labels) in enumerate(self.ldr_test):\n",
    "                ids, attn_mask, b_labels = ids.to(self.device), attn_mask.to(self.device) , b_labels.to(self.device)\n",
    "                b_labels = b_labels.unsqueeze(1)\n",
    "                b_labels = b_labels.repeat(1,2)\n",
    "                for i in range(len(b_labels)):\n",
    "                    b_labels[i][1] = 1-b_labels[i][0]\n",
    "                logits = net(ids, attn_mask)\n",
    "                BCEloss = criterion(logits, b_labels.float())\n",
    "                batch_loss_test.append(BCEloss.item())\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                label_ids = b_labels.to('cpu').numpy()\n",
    "                logits = np.argmax(logits, axis=1).flatten()\n",
    "                label_ids = np.argmax(label_ids,axis=1).flatten()\n",
    "                accuracy = flat_accuracy(logits, label_ids)\n",
    "                tpr = tpr_calculate(logits, label_ids)\n",
    "                if len(set(label_ids)) == 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    fpr = fpr_calculate(logits, label_ids)\n",
    "                    batch_fpr_test.append(fpr)\n",
    "                f1 = f1_score_calculate(logits, label_ids)\n",
    "                if len(set(label_ids)) == 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    auc = AUC_calculate(logits, label_ids)\n",
    "                    batch_auc_test.append(auc)\n",
    "                batch_acc_test.append(accuracy)\n",
    "                batch_tpr_test.append(tpr)\n",
    "                batch_f1_test.append(f1)\n",
    "            elapsed = format_time(time.time()-tmp_t0)\n",
    "            test_avg_loss = sum(batch_loss_test) / len(batch_loss_test)\n",
    "            test_avg_acc = sum(batch_acc_test) / len(batch_acc_test)\n",
    "            test_avg_tpr = sum(batch_tpr_test)/len(batch_tpr_test)\n",
    "            test_avg_fpr = sum(batch_fpr_test) / len(batch_fpr_test)\n",
    "            test_avg_f1 = sum(batch_f1_test)/len(batch_f1_test)\n",
    "            test_avg_auc = sum(batch_auc_test)/len(batch_auc_test)\n",
    "            local_test[\"loss\"].append(test_avg_loss)\n",
    "            local_test[\"acc\"].append(test_avg_acc)\n",
    "            local_test[\"tpr\"].append(test_avg_tpr)\n",
    "            local_test[\"fpr\"].append(test_avg_fpr)\n",
    "            local_test[\"f1\"].append(test_avg_f1)\n",
    "            local_test[\"auc\"].append(test_avg_auc)\n",
    "            print('Client{} Test =>                 \\tLoss: {:.10f} \\tAcc: {:.10f} \\tTPR:{:.10f} \\tFPR:{:.10f} \\tF1:{:.10f} \\tAUC:{:.10f} \\ttest cost: {:}'.format(self.idx, test_avg_loss, test_avg_acc, test_avg_tpr, test_avg_fpr, test_avg_f1, test_avg_auc, elapsed))\n",
    "\n",
    "        return test_avg_loss, test_avg_acc, test_avg_tpr, test_avg_fpr, test_avg_f1, test_avg_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class ALA:\n",
    "    def __init__(self,\n",
    "                 cid: int,\n",
    "                 idxs,\n",
    "                 loss,\n",
    "                 train_data: TensorDataset,\n",
    "                 batch_size: int,\n",
    "                 rand_percent: int,\n",
    "                 layer_idx: int = 0,\n",
    "                 eta: float = 1.0,\n",
    "                 device: str = 'cpu',\n",
    "                 threshold: float = 0.1,\n",
    "                 num_pre_loss: int = 10) -> None:\n",
    "        \"\"\"\n",
    "        Initialize ALA module\n",
    "\n",
    "        Args:\n",
    "            cid: Client ID.\n",
    "            loss: The loss function.\n",
    "            train_data: The reference of the local training data.\n",
    "            batch_size: Weight learning batch size.\n",
    "            rand_percent: The percent of the local training data to sample.\n",
    "            layer_idx: Control the weight range. By default, all the layers are selected. Default: 0\n",
    "            eta: Weight learning rate. Default: 1.0\n",
    "            device: Using cuda or cpu. Default: 'cpu'\n",
    "            threshold: Train the weight until the standard deviation of the recorded losses is less than a given threshold. Default: 0.1\n",
    "            num_pre_loss: The number of the recorded losses to be considered to calculate the standard deviation. Default: 10\n",
    "\n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "\n",
    "        self.cid = cid\n",
    "        self.idxs = idxs\n",
    "        self.loss = loss\n",
    "        self.train_data = train_data\n",
    "        self.batch_size = batch_size\n",
    "        self.rand_percent = rand_percent\n",
    "        self.layer_idx = layer_idx\n",
    "        self.eta = eta\n",
    "        self.threshold = threshold\n",
    "        self.num_pre_loss = num_pre_loss\n",
    "        self.device = device\n",
    "\n",
    "        self.weights = None # Learnable local aggregation weights.\n",
    "        self.start_phase = True\n",
    "\n",
    "\n",
    "    def adaptive_local_aggregation(self,\n",
    "                                   global_model: nn.Module,\n",
    "                                   local_model: nn.Module) -> None:\n",
    "        \"\"\"\n",
    "        Generates the Dataloader for the randomly sampled local training data and\n",
    "        preserves the lower layers of the update.\n",
    "\n",
    "        Args:\n",
    "            global_model: The received global/aggregated model.\n",
    "            local_model: The trained local model.\n",
    "\n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "\n",
    "        # randomly sample partial local training data\n",
    "        rand_ratio = self.rand_percent / 100\n",
    "        rand_loader = DataLoader(DatasetSplit(self.train_data, self.idxs), self.batch_size, drop_last=True, shuffle=True)\n",
    "        rand_num = int(rand_ratio*len(rand_loader))\n",
    "\n",
    "\n",
    "        # obtain the references of the parameters\n",
    "        params_g = list(global_model.parameters())\n",
    "        params = list(local_model.parameters())\n",
    "\n",
    "        # deactivate ALA at the 1st communication iteration\n",
    "        if torch.sum(params_g[-1] - params[-1]) == 0:\n",
    "            print(\"deactivate ALA\")\n",
    "            return\n",
    "\n",
    "        # preserve all the updates in the lower layers\n",
    "        for param, param_g in zip(params[:-self.layer_idx], params_g[:-self.layer_idx]):\n",
    "            param.data = param_g.data.clone()\n",
    "\n",
    "\n",
    "        # temp local model only for weight learning\n",
    "        model_t = copy.deepcopy(local_model)\n",
    "        params_t = list(model_t.parameters())\n",
    "        params_t[-1].requires_grad_()\n",
    "\n",
    "        # only consider higher layers\n",
    "        params_p = params[-self.layer_idx:]\n",
    "        params_gp = params_g[-self.layer_idx:]\n",
    "        params_tp = params_t[-self.layer_idx:]\n",
    "\n",
    "\n",
    "        # used to obtain the gradient of higher layers\n",
    "        # no need to use optimizer.step(), so lr=0\n",
    "        optimizer = torch.optim.Adam(params_tp, lr = lr)\n",
    "\n",
    "        # initialize the weight to all ones in the beginning\n",
    "        if self.weights == None:\n",
    "            self.weights = [torch.ones_like(param.data).to(self.device) for param in params_p]\n",
    "\n",
    "        # initialize the higher layers in the temp local model\n",
    "        for param_t, param, param_g, weight in zip(params_tp, params_p, params_gp,\n",
    "                                                   self.weights):\n",
    "            param_t.data = param + (param_g - param) * weight\n",
    "\n",
    "        # weight learning\n",
    "        losses = []  # record losses\n",
    "        losses_round = []\n",
    "        cnt = 0  # weight training iteration counter\n",
    "        while True:\n",
    "            for batch_idx, (x, m, y) in enumerate(rand_loader):\n",
    "                if batch_idx >= rand_num:\n",
    "                    break\n",
    "                x = x.to(self.device)\n",
    "                m = m.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                y = y.unsqueeze(1)\n",
    "                y = y.repeat(1,2)\n",
    "                for i in range(len(y)):\n",
    "                    y[i][1] = 1-y[i][0]\n",
    "                optimizer.zero_grad()\n",
    "                output = model_t(x, m)\n",
    "                loss_value = self.loss(output, y.float()) # modify according to the local objective\n",
    "                losses.append(loss_value.item())\n",
    "                loss_value.backward()\n",
    "\n",
    "                # update weight in this batch\n",
    "                for param_t, param, param_g, weight in zip(params_tp, params_p,\n",
    "                                                           params_gp, self.weights):\n",
    "                    #print(\"param_t.grad:\",param_t.requires_grad)\n",
    "                    #print(\"param_g - param:\",type(param_g - param))\n",
    "                    weight.data = torch.clamp(weight - self.eta * (param_t.grad * (param_g - param)), 0, 1)\n",
    "\n",
    "                # update temp local model in this batch\n",
    "                for param_t, param, param_g, weight in zip(params_tp, params_p,\n",
    "                                                           params_gp, self.weights):\n",
    "                    param_t.data = param + (param_g - param) * weight\n",
    "\n",
    "            losses_round.append(sum(losses) / len(losses))\n",
    "            cnt += 1\n",
    "\n",
    "            # only train one epoch in the subsequent iterations\n",
    "            if not self.start_phase:\n",
    "                break\n",
    "\n",
    "            # train the weight until convergence\n",
    "            if len(losses_round) > self.num_pre_loss or np.std(losses[-self.num_pre_loss:]) < self.threshold:\n",
    "                print('Client:', self.cid, '\\tStd:', np.std(losses[-self.num_pre_loss:]),\n",
    "                      '\\tALA epochs:', cnt)\n",
    "                break\n",
    "\n",
    "        self.start_phase = False\n",
    "\n",
    "        # obtain initialized local model\n",
    "        for param, param_t in zip(params_p, params_tp):\n",
    "            param.data = param_t.data.clone()\n",
    "        print(\"Client {}: Local Initial ALA epochs: {} Loss: {:.20f}\".format(self.cid, cnt, losses_round[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test Begin!\n",
      "============== Round 0:  =============\n",
      "local_initialization!\n",
      "deactivate ALA\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.6272902027 \tAcc: 0.6537240783 \tTPR:0.7593991838 \tFPR:0.4528384268 \tF1:0.6838900180 \t AUC:0.6532803785\tTrain cost: 0:00:34\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.5961614575 \tAcc: 0.6848934332 \tTPR:0.7949938600 \tFPR:0.4271178049 \tF1:0.7120313939 \t AUC:0.6839380275\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.5019100147 \tAcc: 0.7570391705 \tTPR:0.8340190530 \tFPR:0.3251060476 \tF1:0.7700943178 \t AUC:0.7544565027\tTrain cost: 0:00:36\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.4176253469 \tAcc: 0.8094527650 \tTPR:0.8529519031 \tFPR:0.2381832702 \tF1:0.8148396144 \t AUC:0.8073843165\tTrain cost: 0:00:36\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.3759440225 \tAcc: 0.8287269585 \tTPR:0.8656580617 \tFPR:0.2100626500 \tF1:0.8317424047 \t AUC:0.8277977058\tTrain cost: 0:00:36\n",
      "Client6 Test =>                 \tLoss: 0.3389969882 \tAcc: 0.8475000000 \tTPR:0.8605162146 \tFPR:0.1682922419 \tF1:0.8437775864 \tAUC:0.8461119864 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.0622382933328889 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.37021620809168054311\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.3665351338 \tAcc: 0.8384706221 \tTPR:0.8778302215 \tFPR:0.2032726267 \tF1:0.8403974383 \t AUC:0.8372787974\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.3575103771 \tAcc: 0.8408669355 \tTPR:0.8768977416 \tFPR:0.1951810737 \tF1:0.8405609576 \t AUC:0.8408583339\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.3459469956 \tAcc: 0.8490927419 \tTPR:0.8848394944 \tFPR:0.1867149241 \tF1:0.8496525040 \t AUC:0.8490622852\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.3306706718 \tAcc: 0.8575748848 \tTPR:0.8922018552 \tFPR:0.1764256449 \tF1:0.8582515592 \t AUC:0.8578881051\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.3132909939 \tAcc: 0.8668721198 \tTPR:0.9004132288 \tFPR:0.1646702711 \tF1:0.8670048688 \t AUC:0.8678714789\tTrain cost: 0:00:36\n",
      "Client8 Test =>                 \tLoss: 0.2943995510 \tAcc: 0.8802083333 \tTPR:0.9224359587 \tFPR:0.1616484684 \tF1:0.8811645623 \tAUC:0.8803937451 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.09997284218250856 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.32897012270447134608\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.3054730250 \tAcc: 0.8695449309 \tTPR:0.8981429771 \tFPR:0.1607567115 \tF1:0.8693556617 \t AUC:0.8686931328\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.3036125440 \tAcc: 0.8710627880 \tTPR:0.8951975917 \tFPR:0.1573526223 \tF1:0.8703459410 \t AUC:0.8689224847\tTrain cost: 0:00:35\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.2932682722 \tAcc: 0.8758899770 \tTPR:0.9026384990 \tFPR:0.1520182057 \tF1:0.8754584766 \t AUC:0.8753101466\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.2838788997 \tAcc: 0.8791013825 \tTPR:0.9071842066 \tFPR:0.1492721715 \tF1:0.8795894347 \t AUC:0.8789560176\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.2737807226 \tAcc: 0.8865120968 \tTPR:0.9096536186 \tFPR:0.1356009802 \tF1:0.8867245895 \t AUC:0.8870263192\tTrain cost: 0:00:37\n",
      "Client1 Test =>                 \tLoss: 0.2418908312 \tAcc: 0.9027083333 \tTPR:0.8955137319 \tFPR:0.0910557137 \tF1:0.8958847639 \tAUC:0.9022290091 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.08720774889045198 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.26917453790488449217\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.2788601851 \tAcc: 0.8840120968 \tTPR:0.9097007941 \tFPR:0.1426781789 \tF1:0.8848155632 \t AUC:0.8835113076\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.2695409950 \tAcc: 0.8867770737 \tTPR:0.9115817642 \tFPR:0.1380697063 \tF1:0.8889054974 \t AUC:0.8867560289\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.2606423080 \tAcc: 0.8926756912 \tTPR:0.9146890981 \tFPR:0.1285442625 \tF1:0.8939778868 \t AUC:0.8930724178\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.2480058276 \tAcc: 0.9004349078 \tTPR:0.9175637335 \tFPR:0.1184034000 \tF1:0.9016006435 \t AUC:0.8995801668\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.2397737573 \tAcc: 0.9029406682 \tTPR:0.9200518088 \tFPR:0.1168956729 \tF1:0.9035983382 \t AUC:0.9015780680\tTrain cost: 0:00:33\n",
      "Client7 Test =>                 \tLoss: 0.2265995464 \tAcc: 0.9112500000 \tTPR:0.8842058982 \tFPR:0.0612857457 \tF1:0.9066992476 \tAUC:0.9114600762 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.08416395591521114 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.23299438992272253346\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.2538073586 \tAcc: 0.8942741935 \tTPR:0.9076844157 \tFPR:0.1197066740 \tF1:0.8900257878 \t AUC:0.8939888708\tTrain cost: 0:00:35\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.2468041972 \tAcc: 0.9008755760 \tTPR:0.9160330165 \tFPR:0.1138575755 \tF1:0.8980773288 \t AUC:0.9010877205\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.2344871374 \tAcc: 0.9055328341 \tTPR:0.9186996586 \tFPR:0.1089805025 \tF1:0.9024896600 \t AUC:0.9048595780\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.2292272502 \tAcc: 0.9051756912 \tTPR:0.9190516043 \tFPR:0.1090298500 \tF1:0.9020090495 \t AUC:0.9050108771\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.2249242299 \tAcc: 0.9082056452 \tTPR:0.9246004697 \tFPR:0.1071061965 \tF1:0.9047014846 \t AUC:0.9087471366\tTrain cost: 0:00:36\n",
      "Client0 Test =>                 \tLoss: 0.2497231733 \tAcc: 0.8972916667 \tTPR:0.8496509296 \tFPR:0.0520403461 \tF1:0.8913923227 \tAUC:0.8988052917 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2703220180 \tAcc: 0.8877916667 \tTPR:0.8824645466 \tFPR:0.1068645032 \tF1:0.8837836966 \tAUC:0.8878000217\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 1:  =============\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.09160993717605934 \tALA epochs: 2\n",
      "Client 3: Local Initial ALA epochs: 2 Loss: 0.28237819126334745556\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.2781830130 \tAcc: 0.8861520737 \tTPR:0.9103251090 \tFPR:0.1382870477 \tF1:0.8845321215 \t AUC:0.8860190307\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.2586701350 \tAcc: 0.8955299539 \tTPR:0.9164177763 \tFPR:0.1250004283 \tF1:0.8939993731 \t AUC:0.8957086740\tTrain cost: 0:00:34\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.2557287040 \tAcc: 0.8952563364 \tTPR:0.9139184995 \tFPR:0.1223231857 \tF1:0.8923656360 \t AUC:0.8957976569\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.2475071286 \tAcc: 0.8985656682 \tTPR:0.9170296035 \tFPR:0.1192744493 \tF1:0.8971470884 \t AUC:0.8988775771\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.2387095158 \tAcc: 0.9036520737 \tTPR:0.9195840796 \tFPR:0.1144515594 \tF1:0.9014735199 \t AUC:0.9025662601\tTrain cost: 0:00:37\n",
      "Client3 Test =>                 \tLoss: 0.2436211622 \tAcc: 0.9081250000 \tTPR:0.9473060952 \tFPR:0.1306634412 \tF1:0.9091369445 \tAUC:0.9083213270 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.05381854111248207 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.27931577388359152270\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.2452607439 \tAcc: 0.8995478111 \tTPR:0.9174524983 \tFPR:0.1187342222 \tF1:0.8983462752 \t AUC:0.8993591381\tTrain cost: 0:00:35\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.2403165655 \tAcc: 0.9045506912 \tTPR:0.9186620465 \tFPR:0.1099455517 \tF1:0.9028329429 \t AUC:0.9043582474\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.2302700449 \tAcc: 0.9085570276 \tTPR:0.9242943158 \tFPR:0.1067921421 \tF1:0.9070348777 \t AUC:0.9087510868\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.2314152372 \tAcc: 0.9068548387 \tTPR:0.9234394490 \tFPR:0.1098156371 \tF1:0.9055080523 \t AUC:0.9068119059\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.2240293262 \tAcc: 0.9112471198 \tTPR:0.9248074660 \tFPR:0.1028124625 \tF1:0.9093761505 \t AUC:0.9109975018\tTrain cost: 0:00:36\n",
      "Client9 Test =>                 \tLoss: 0.2474505012 \tAcc: 0.9039583333 \tTPR:0.8579139998 \tFPR:0.0488575620 \tF1:0.8973406781 \tAUC:0.9045282189 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.05538086162534215 \tALA epochs: 2\n",
      "Client 4: Local Initial ALA epochs: 2 Loss: 0.24131354495235110558\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.2344617179 \tAcc: 0.9026670507 \tTPR:0.9152833642 \tFPR:0.1102273280 \tF1:0.9010731167 \t AUC:0.9025280181\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.2251594774 \tAcc: 0.9076641705 \tTPR:0.9230735692 \tFPR:0.1074199980 \tF1:0.9065705925 \t AUC:0.9078267856\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.2170984250 \tAcc: 0.9096370968 \tTPR:0.9203841641 \tFPR:0.1012635376 \tF1:0.9073252525 \t AUC:0.9095603132\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.2122706238 \tAcc: 0.9135541475 \tTPR:0.9291739945 \tFPR:0.1023001417 \tF1:0.9120656878 \t AUC:0.9134369264\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.2081298855 \tAcc: 0.9157862903 \tTPR:0.9305891106 \tFPR:0.0987299487 \tF1:0.9147244381 \t AUC:0.9159295810\tTrain cost: 0:00:36\n",
      "Client4 Test =>                 \tLoss: 0.2193085935 \tAcc: 0.9143750000 \tTPR:0.8986277235 \tFPR:0.0697683790 \tF1:0.9110530665 \tAUC:0.9144296723 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.07676620577411258 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.21738837810530178829\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.2269776569 \tAcc: 0.9073963134 \tTPR:0.9255826546 \tFPR:0.1081432896 \tF1:0.9073770760 \t AUC:0.9087196825\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.2234052632 \tAcc: 0.9062413594 \tTPR:0.9249175786 \tFPR:0.1108275524 \tF1:0.9053627115 \t AUC:0.9070450131\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.2170831512 \tAcc: 0.9113306452 \tTPR:0.9280045631 \tFPR:0.1029716675 \tF1:0.9101194912 \t AUC:0.9125164478\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.2123545700 \tAcc: 0.9158899770 \tTPR:0.9298766423 \tFPR:0.0985843679 \tF1:0.9136564573 \t AUC:0.9156461372\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.2062650268 \tAcc: 0.9174884793 \tTPR:0.9335576156 \tFPR:0.0997818986 \tF1:0.9160695494 \t AUC:0.9168878585\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.2044824526 \tAcc: 0.9195833333 \tTPR:0.8868274365 \tFPR:0.0469554937 \tF1:0.9146860834 \tAUC:0.9199359714 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.08850729474981939 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.19763516148795251537\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.2042132755 \tAcc: 0.9204435484 \tTPR:0.9376998180 \tFPR:0.0970430365 \tF1:0.9210349990 \t AUC:0.9203283907\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.2012570998 \tAcc: 0.9211520737 \tTPR:0.9362124816 \tFPR:0.0953588495 \tF1:0.9213942131 \t AUC:0.9204268160\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1920565841 \tAcc: 0.9244585253 \tTPR:0.9381423490 \tFPR:0.0903098594 \tF1:0.9253865365 \t AUC:0.9239162448\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1916533036 \tAcc: 0.9235685484 \tTPR:0.9374023976 \tFPR:0.0902313650 \tF1:0.9236697191 \t AUC:0.9235855163\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1867009169 \tAcc: 0.9249020737 \tTPR:0.9384119588 \tFPR:0.0890471690 \tF1:0.9247631689 \t AUC:0.9246823949\tTrain cost: 0:00:36\n",
      "Client7 Test =>                 \tLoss: 0.2358717034 \tAcc: 0.9027083333 \tTPR:0.8413443563 \tFPR:0.0373472387 \tF1:0.8917733089 \tAUC:0.9019985588 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2301468826 \tAcc: 0.9097500000 \tTPR:0.8864039223 \tFPR:0.0667184229 \tF1:0.9047980163 \tAUC:0.9098427497\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 2:  =============\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.06749108508910341 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.19832812438624491946\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.2174415280 \tAcc: 0.9144585253 \tTPR:0.9306573772 \tFPR:0.1008425706 \tF1:0.9134024678 \t AUC:0.9149074033\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.2068563486 \tAcc: 0.9165927419 \tTPR:0.9286882970 \tFPR:0.0945564472 \tF1:0.9149514019 \t AUC:0.9170659249\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.2042433188 \tAcc: 0.9159763825 \tTPR:0.9297282939 \tFPR:0.0972805658 \tF1:0.9146261223 \t AUC:0.9162238640\tTrain cost: 0:00:34\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1911443702 \tAcc: 0.9241877880 \tTPR:0.9389539013 \tFPR:0.0900611053 \tF1:0.9239436823 \t AUC:0.9244463980\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1960125387 \tAcc: 0.9207891705 \tTPR:0.9351861475 \tFPR:0.0941256511 \tF1:0.9187111439 \t AUC:0.9205302482\tTrain cost: 0:00:37\n",
      "Client4 Test =>                 \tLoss: 0.2453556705 \tAcc: 0.9083333333 \tTPR:0.8611625569 \tFPR:0.0452427325 \tF1:0.9002620381 \tAUC:0.9079599122 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.07717702861511154 \tALA epochs: 2\n",
      "Client 5: Local Initial ALA epochs: 2 Loss: 0.21029038171189418094\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.2207280255 \tAcc: 0.9095506912 \tTPR:0.9270675883 \tFPR:0.1074035081 \tF1:0.9076541039 \t AUC:0.9098320401\tTrain cost: 0:00:35\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.2076311754 \tAcc: 0.9174913594 \tTPR:0.9351857633 \tFPR:0.1000216077 \tF1:0.9162894437 \t AUC:0.9175820778\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.2076332741 \tAcc: 0.9152620968 \tTPR:0.9304334491 \tFPR:0.1004802535 \tF1:0.9144690727 \t AUC:0.9149765978\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1987227664 \tAcc: 0.9207949309 \tTPR:0.9355957390 \tFPR:0.0951518166 \tF1:0.9204556776 \t AUC:0.9202219612\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1980238138 \tAcc: 0.9207978111 \tTPR:0.9374945101 \tFPR:0.0945093473 \tF1:0.9202226362 \t AUC:0.9214925814\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.1931153657 \tAcc: 0.9200000000 \tTPR:0.8977631436 \tFPR:0.0577622728 \tF1:0.9166990520 \tAUC:0.9200004354 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.06652476429140063 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.19342647222937017770\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1950609318 \tAcc: 0.9226699309 \tTPR:0.9341452396 \tFPR:0.0892527316 \tF1:0.9207609590 \t AUC:0.9224462540\tTrain cost: 0:00:37\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1867889745 \tAcc: 0.9264256912 \tTPR:0.9371512325 \tFPR:0.0840608178 \tF1:0.9242247322 \t AUC:0.9265452073\tTrain cost: 0:00:37\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1827677904 \tAcc: 0.9289199309 \tTPR:0.9419176470 \tFPR:0.0841263796 \tF1:0.9259450207 \t AUC:0.9288956337\tTrain cost: 0:00:37\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1805224519 \tAcc: 0.9285656682 \tTPR:0.9427725215 \tFPR:0.0855400090 \tF1:0.9271273069 \t AUC:0.9286162562\tTrain cost: 0:00:37\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1762542436 \tAcc: 0.9302620968 \tTPR:0.9443787888 \tFPR:0.0843035295 \tF1:0.9285994135 \t AUC:0.9300376297\tTrain cost: 0:00:37\n",
      "Client3 Test =>                 \tLoss: 0.2221702714 \tAcc: 0.9164583333 \tTPR:0.8797879291 \tFPR:0.0472840733 \tF1:0.9107897950 \tAUC:0.9162519279 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.08933878972368618 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.23285914406828259193\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.1994464688 \tAcc: 0.9186549539 \tTPR:0.9305046500 \tFPR:0.0962693451 \tF1:0.9162390369 \t AUC:0.9171176524\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.1959702608 \tAcc: 0.9218721198 \tTPR:0.9373791588 \tFPR:0.0923103881 \tF1:0.9207743286 \t AUC:0.9225343853\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.1879270934 \tAcc: 0.9246399770 \tTPR:0.9368084399 \tFPR:0.0857138959 \tF1:0.9228899889 \t AUC:0.9255472720\tTrain cost: 0:00:37\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.1834517285 \tAcc: 0.9259792627 \tTPR:0.9389025995 \tFPR:0.0867188181 \tF1:0.9239574807 \t AUC:0.9260918907\tTrain cost: 0:00:37\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.1796712394 \tAcc: 0.9272235023 \tTPR:0.9401178733 \tFPR:0.0869225107 \tF1:0.9262389994 \t AUC:0.9265976813\tTrain cost: 0:00:36\n",
      "Client9 Test =>                 \tLoss: 0.2226478151 \tAcc: 0.9141666667 \tTPR:0.8764854912 \tFPR:0.0476197128 \tF1:0.9091809322 \tAUC:0.9144328892 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.07806540476016365 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.20592694648582002270\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1971504037 \tAcc: 0.9206192396 \tTPR:0.9362760265 \tFPR:0.0963052868 \tF1:0.9198730996 \t AUC:0.9199853698\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1975947185 \tAcc: 0.9204377880 \tTPR:0.9400470579 \tFPR:0.0988172376 \tF1:0.9202883714 \t AUC:0.9206149102\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1872927459 \tAcc: 0.9243721198 \tTPR:0.9408415391 \tFPR:0.0913537696 \tF1:0.9240883202 \t AUC:0.9247438847\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1863203723 \tAcc: 0.9236520737 \tTPR:0.9422361456 \tFPR:0.0942696533 \tF1:0.9232102923 \t AUC:0.9239832462\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1803371709 \tAcc: 0.9283755760 \tTPR:0.9440785236 \tFPR:0.0871375559 \tF1:0.9279340557 \t AUC:0.9284704839\tTrain cost: 0:00:36\n",
      "Client1 Test =>                 \tLoss: 0.1953491871 \tAcc: 0.9243750000 \tTPR:0.8900955269 \tFPR:0.0426055815 \tF1:0.9169832110 \tAUC:0.9237449727 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2157276619 \tAcc: 0.9166666667 \tTPR:0.8810589295 \tFPR:0.0481028746 \tF1:0.9107830057 \tAUC:0.9164780275\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 3:  =============\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.057948948799271774 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.16650036020555358807\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1890519106 \tAcc: 0.9246284562 \tTPR:0.9420874646 \tFPR:0.0927737855 \tF1:0.9239931225 \t AUC:0.9246568395\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1828485376 \tAcc: 0.9253542627 \tTPR:0.9409162977 \tFPR:0.0912134807 \tF1:0.9241446221 \t AUC:0.9248514085\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1772577447 \tAcc: 0.9291013825 \tTPR:0.9439349859 \tFPR:0.0857681905 \tF1:0.9290268540 \t AUC:0.9290833977\tTrain cost: 0:00:35\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1754618900 \tAcc: 0.9299971198 \tTPR:0.9449257656 \tFPR:0.0848482270 \tF1:0.9303877940 \t AUC:0.9300387693\tTrain cost: 0:00:37\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1732643755 \tAcc: 0.9310685484 \tTPR:0.9481412210 \tFPR:0.0872267168 \tF1:0.9312030490 \t AUC:0.9304572521\tTrain cost: 0:00:36\n",
      "Client6 Test =>                 \tLoss: 0.2149668166 \tAcc: 0.9172916667 \tTPR:0.8896335857 \tFPR:0.0554291928 \tF1:0.9122030012 \tAUC:0.9171021965 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.07531530076607588 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.19512906999907631000\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1810704054 \tAcc: 0.9279349078 \tTPR:0.9407883326 \tFPR:0.0840678397 \tF1:0.9266162760 \t AUC:0.9283602465\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1752003967 \tAcc: 0.9317857143 \tTPR:0.9451994917 \tFPR:0.0791240516 \tF1:0.9307516362 \t AUC:0.9330377200\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1670829572 \tAcc: 0.9324049539 \tTPR:0.9438331097 \tFPR:0.0780831543 \tF1:0.9295380435 \t AUC:0.9328749777\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1682667721 \tAcc: 0.9324078341 \tTPR:0.9463332424 \tFPR:0.0803329881 \tF1:0.9300906556 \t AUC:0.9330001271\tTrain cost: 0:00:37\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1631119592 \tAcc: 0.9350777650 \tTPR:0.9479186952 \tFPR:0.0785557000 \tF1:0.9335967236 \t AUC:0.9346814976\tTrain cost: 0:00:37\n",
      "Client3 Test =>                 \tLoss: 0.2039255223 \tAcc: 0.9264583333 \tTPR:0.9144434262 \tFPR:0.0609544313 \tF1:0.9222878936 \tAUC:0.9267444975 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.050429316001529736 \tALA epochs: 2\n",
      "Client 7: Local Initial ALA epochs: 2 Loss: 0.19392527402986003970\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1913911917 \tAcc: 0.9237442396 \tTPR:0.9399875624 \tFPR:0.0936019492 \tF1:0.9245350203 \t AUC:0.9231928066\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1870663112 \tAcc: 0.9272235023 \tTPR:0.9414633019 \tFPR:0.0869884462 \tF1:0.9276084043 \t AUC:0.9272374278\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1786894310 \tAcc: 0.9288306452 \tTPR:0.9430056595 \tFPR:0.0866091316 \tF1:0.9293910184 \t AUC:0.9281982640\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1737638344 \tAcc: 0.9332114055 \tTPR:0.9463224374 \tFPR:0.0814811975 \tF1:0.9333601887 \t AUC:0.9324206199\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1738215148 \tAcc: 0.9335599078 \tTPR:0.9461502480 \tFPR:0.0795076995 \tF1:0.9335566182 \t AUC:0.9333212742\tTrain cost: 0:00:37\n",
      "Client7 Test =>                 \tLoss: 0.2326080467 \tAcc: 0.9118750000 \tTPR:0.8597969623 \tFPR:0.0356303583 \tF1:0.9047774943 \tAUC:0.9120833020 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.07476502224132509 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.20521843222820240760\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1847662233 \tAcc: 0.9250748848 \tTPR:0.9382803942 \tFPR:0.0885865431 \tF1:0.9234306386 \t AUC:0.9248469256\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1765252337 \tAcc: 0.9258928571 \tTPR:0.9389536927 \tFPR:0.0879524071 \tF1:0.9237636656 \t AUC:0.9255006428\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1771437476 \tAcc: 0.9273185484 \tTPR:0.9413253971 \tFPR:0.0864913283 \tF1:0.9262714826 \t AUC:0.9274170344\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1761059541 \tAcc: 0.9298127880 \tTPR:0.9445610145 \tFPR:0.0834518086 \tF1:0.9289633041 \t AUC:0.9305546029\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1667734756 \tAcc: 0.9335656682 \tTPR:0.9492288083 \tFPR:0.0810044106 \tF1:0.9324750291 \t AUC:0.9341121989\tTrain cost: 0:00:36\n",
      "Client8 Test =>                 \tLoss: 0.2830724943 \tAcc: 0.8981250000 \tTPR:0.8211795861 \tFPR:0.0287158307 \tF1:0.8857417376 \tAUC:0.8962318777 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.06306117852196588 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.21420075890162718069\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1823428288 \tAcc: 0.9235627880 \tTPR:0.9365688736 \tFPR:0.0884060349 \tF1:0.9225282334 \t AUC:0.9240814193\tTrain cost: 0:00:34\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1752302231 \tAcc: 0.9288364055 \tTPR:0.9441124268 \tFPR:0.0870649356 \tF1:0.9275424507 \t AUC:0.9285237456\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1703154980 \tAcc: 0.9301756912 \tTPR:0.9450554632 \tFPR:0.0833420839 \tF1:0.9287684598 \t AUC:0.9308566897\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1637056516 \tAcc: 0.9332085253 \tTPR:0.9472935373 \tFPR:0.0807440965 \tF1:0.9324868294 \t AUC:0.9332747204\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1612527296 \tAcc: 0.9326699309 \tTPR:0.9463278211 \tFPR:0.0814782687 \tF1:0.9312573231 \t AUC:0.9324247762\tTrain cost: 0:00:36\n",
      "Client4 Test =>                 \tLoss: 0.2685287146 \tAcc: 0.9064583333 \tTPR:0.8492037988 \tFPR:0.0357197552 \tF1:0.8980373745 \tAUC:0.9067420218 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2406203189 \tAcc: 0.9120416667 \tTPR:0.8668514718 \tFPR:0.0432899136 \tF1:0.9046095002 \tAUC:0.9117807791\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 4:  =============\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.07196028987867353 \tALA epochs: 2\n",
      "Client 8: Local Initial ALA epochs: 2 Loss: 0.17678831231550892755\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1786205701 \tAcc: 0.9294556452 \tTPR:0.9429302083 \tFPR:0.0847563211 \tF1:0.9291470004 \t AUC:0.9290869436\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1753000272 \tAcc: 0.9298156682 \tTPR:0.9436869319 \tFPR:0.0825780618 \tF1:0.9286758998 \t AUC:0.9305544350\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1726159519 \tAcc: 0.9303542627 \tTPR:0.9436446394 \tFPR:0.0815834605 \tF1:0.9291201657 \t AUC:0.9310305895\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1683030702 \tAcc: 0.9319614055 \tTPR:0.9458614300 \tFPR:0.0831678311 \tF1:0.9307407921 \t AUC:0.9313467994\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1647683102 \tAcc: 0.9337413594 \tTPR:0.9448191375 \tFPR:0.0777207258 \tF1:0.9328506758 \t AUC:0.9335492058\tTrain cost: 0:00:37\n",
      "Client8 Test =>                 \tLoss: 0.2301686898 \tAcc: 0.9181250000 \tTPR:0.8737796805 \tFPR:0.0378941461 \tF1:0.9113815402 \tAUC:0.9179427672 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.09706616085674968 \tALA epochs: 2\n",
      "Client 6: Local Initial ALA epochs: 2 Loss: 0.17590416243056888890\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1686525360 \tAcc: 0.9324942396 \tTPR:0.9502242797 \tFPR:0.0855167270 \tF1:0.9321545864 \t AUC:0.9323537763\tTrain cost: 0:00:37\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1625931788 \tAcc: 0.9344527650 \tTPR:0.9510684477 \tFPR:0.0831601466 \tF1:0.9351299654 \t AUC:0.9339541505\tTrain cost: 0:00:36\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1601239679 \tAcc: 0.9360656682 \tTPR:0.9522477767 \tFPR:0.0793745847 \tF1:0.9369047177 \t AUC:0.9364365960\tTrain cost: 0:00:36\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1560151292 \tAcc: 0.9367828341 \tTPR:0.9503198399 \tFPR:0.0779962281 \tF1:0.9365566819 \t AUC:0.9361618059\tTrain cost: 0:00:37\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1500362548 \tAcc: 0.9413335253 \tTPR:0.9545060110 \tFPR:0.0720207143 \tF1:0.9410909631 \t AUC:0.9412426484\tTrain cost: 0:00:37\n",
      "Client6 Test =>                 \tLoss: 0.2209180052 \tAcc: 0.9187500000 \tTPR:0.8912910918 \tFPR:0.0585317687 \tF1:0.9137213691 \tAUC:0.9163796616 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.08452166389761663 \tALA epochs: 4\n",
      "Client 1: Local Initial ALA epochs: 4 Loss: 0.18774325393842181131\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1820401612 \tAcc: 0.9269585253 \tTPR:0.9440057050 \tFPR:0.0910449128 \tF1:0.9262976873 \t AUC:0.9264803961\tTrain cost: 0:00:35\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1799673475 \tAcc: 0.9285685484 \tTPR:0.9454158425 \tFPR:0.0889574131 \tF1:0.9273301280 \t AUC:0.9282292147\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1749457293 \tAcc: 0.9307978111 \tTPR:0.9450408132 \tFPR:0.0841227677 \tF1:0.9300048871 \t AUC:0.9304590227\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1718280671 \tAcc: 0.9305299539 \tTPR:0.9465512470 \tFPR:0.0864787662 \tF1:0.9294558587 \t AUC:0.9300362404\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1663340466 \tAcc: 0.9325864055 \tTPR:0.9488794443 \tFPR:0.0833424167 \tF1:0.9319694469 \t AUC:0.9327685138\tTrain cost: 0:00:36\n",
      "Client1 Test =>                 \tLoss: 0.1983664063 \tAcc: 0.9250000000 \tTPR:0.8885042785 \tFPR:0.0382592460 \tF1:0.9179743055 \tAUC:0.9251225163 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.07846480832705056 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.17312119247904722563\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1752788029 \tAcc: 0.9302620968 \tTPR:0.9463621777 \tFPR:0.0857073872 \tF1:0.9287297398 \t AUC:0.9303273953\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1677779663 \tAcc: 0.9310627880 \tTPR:0.9440166631 \tFPR:0.0816800983 \tF1:0.9292485640 \t AUC:0.9311682824\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1667971298 \tAcc: 0.9317770737 \tTPR:0.9485066698 \tFPR:0.0844502987 \tF1:0.9304763193 \t AUC:0.9320281855\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1608488861 \tAcc: 0.9342828341 \tTPR:0.9498384849 \tFPR:0.0803612203 \tF1:0.9337260755 \t AUC:0.9347386323\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1583962252 \tAcc: 0.9360685484 \tTPR:0.9494569003 \tFPR:0.0765957093 \tF1:0.9346182339 \t AUC:0.9364305955\tTrain cost: 0:00:37\n",
      "Client4 Test =>                 \tLoss: 0.2163242167 \tAcc: 0.9237500000 \tTPR:0.8999718530 \tFPR:0.0541150746 \tF1:0.9194190414 \tAUC:0.9229283892 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.08975983476183644 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.17643314092487527578\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1768845044 \tAcc: 0.9302620968 \tTPR:0.9467998819 \tFPR:0.0862977442 \tF1:0.9301964160 \t AUC:0.9302510689\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1656527114 \tAcc: 0.9335656682 \tTPR:0.9460596053 \tFPR:0.0810897194 \tF1:0.9328176264 \t AUC:0.9324849430\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.1642893456 \tAcc: 0.9349078341 \tTPR:0.9447311229 \tFPR:0.0733048807 \tF1:0.9338730169 \t AUC:0.9357131211\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.1643240617 \tAcc: 0.9349942396 \tTPR:0.9455959700 \tFPR:0.0766683108 \tF1:0.9334772373 \t AUC:0.9344638296\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.1586136861 \tAcc: 0.9356192396 \tTPR:0.9486388399 \tFPR:0.0760459785 \tF1:0.9349983550 \t AUC:0.9362964307\tTrain cost: 0:00:36\n",
      "Client2 Test =>                 \tLoss: 0.2150106029 \tAcc: 0.9210416667 \tTPR:0.8903270743 \tFPR:0.0471828340 \tF1:0.9164100243 \tAUC:0.9215721201 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2161575842 \tAcc: 0.9213333333 \tTPR:0.8887747956 \tFPR:0.0471966139 \tF1:0.9157812561 \tAUC:0.9207890909\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 5:  =============\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.07633445917628545 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.14923788828478343205\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1619298267 \tAcc: 0.9353542627 \tTPR:0.9492617528 \tFPR:0.0797240533 \tF1:0.9343676148 \t AUC:0.9347688497\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1568452517 \tAcc: 0.9364084101 \tTPR:0.9484797204 \tFPR:0.0750759137 \tF1:0.9346695200 \t AUC:0.9367019034\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1522607678 \tAcc: 0.9389228111 \tTPR:0.9512363290 \tFPR:0.0747045712 \tF1:0.9372674622 \t AUC:0.9382658789\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1471326380 \tAcc: 0.9410627880 \tTPR:0.9504561547 \tFPR:0.0701804803 \tF1:0.9405894436 \t AUC:0.9401378372\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1481600913 \tAcc: 0.9383870968 \tTPR:0.9507009438 \tFPR:0.0738673321 \tF1:0.9374343505 \t AUC:0.9384168059\tTrain cost: 0:00:37\n",
      "Client8 Test =>                 \tLoss: 0.2204624719 \tAcc: 0.9229166667 \tTPR:0.8885276304 \tFPR:0.0439391652 \tF1:0.9165661084 \tAUC:0.9222942326 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.06038344271510586 \tALA epochs: 2\n",
      "Client 7: Local Initial ALA epochs: 2 Loss: 0.16074447215035342351\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1754558284 \tAcc: 0.9339256912 \tTPR:0.9478024791 \tFPR:0.0797998412 \tF1:0.9343483749 \t AUC:0.9340013189\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1690789020 \tAcc: 0.9349078341 \tTPR:0.9483617991 \tFPR:0.0784173202 \tF1:0.9351090586 \t AUC:0.9349722395\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1661072357 \tAcc: 0.9333870968 \tTPR:0.9460688489 \tFPR:0.0786580564 \tF1:0.9332716463 \t AUC:0.9337053963\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1616365964 \tAcc: 0.9383899770 \tTPR:0.9488475715 \tFPR:0.0725067558 \tF1:0.9381581529 \t AUC:0.9381704079\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1572222236 \tAcc: 0.9391964286 \tTPR:0.9525624520 \tFPR:0.0744636339 \tF1:0.9399112597 \t AUC:0.9390494090\tTrain cost: 0:00:37\n",
      "Client7 Test =>                 \tLoss: 0.1916919540 \tAcc: 0.9306250000 \tTPR:0.9148075713 \tFPR:0.0542902871 \tF1:0.9264944517 \tAUC:0.9302586421 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.04573315249209015 \tALA epochs: 4\n",
      "Client 9: Local Initial ALA epochs: 4 Loss: 0.18474287854885493299\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.1790661020 \tAcc: 0.9285714286 \tTPR:0.9423350276 \tFPR:0.0847101072 \tF1:0.9282314425 \t AUC:0.9288124602\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.1735141577 \tAcc: 0.9315092166 \tTPR:0.9461764066 \tFPR:0.0823106707 \tF1:0.9309243295 \t AUC:0.9319328679\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.1656270026 \tAcc: 0.9354406682 \tTPR:0.9505652998 \tFPR:0.0808005775 \tF1:0.9347301282 \t AUC:0.9348823612\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.1680424908 \tAcc: 0.9335570276 \tTPR:0.9479391310 \tFPR:0.0807720554 \tF1:0.9315552140 \t AUC:0.9335835378\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.1562882191 \tAcc: 0.9394642857 \tTPR:0.9504972416 \tFPR:0.0728843271 \tF1:0.9383435411 \t AUC:0.9388064573\tTrain cost: 0:00:36\n",
      "Client9 Test =>                 \tLoss: 0.1784714319 \tAcc: 0.9362500000 \tTPR:0.9330060133 \tFPR:0.0604204129 \tF1:0.9342101571 \tAUC:0.9362928002 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.0618374974019361 \tALA epochs: 4\n",
      "Client 5: Local Initial ALA epochs: 4 Loss: 0.19130266710872884106\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1785833209 \tAcc: 0.9303485023 \tTPR:0.9473545371 \tFPR:0.0870634923 \tF1:0.9289087652 \t AUC:0.9301455224\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1715514675 \tAcc: 0.9337442396 \tTPR:0.9471369943 \tFPR:0.0800249315 \tF1:0.9326725175 \t AUC:0.9335560314\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1655448235 \tAcc: 0.9346342166 \tTPR:0.9482795511 \tFPR:0.0789368717 \tF1:0.9339429932 \t AUC:0.9346713397\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1642920091 \tAcc: 0.9347206221 \tTPR:0.9512477683 \tFPR:0.0810073071 \tF1:0.9345339819 \t AUC:0.9351202306\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1614412530 \tAcc: 0.9363364055 \tTPR:0.9472370827 \tFPR:0.0756164096 \tF1:0.9351849020 \t AUC:0.9358103366\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.1949506689 \tAcc: 0.9264583333 \tTPR:0.8918439160 \tFPR:0.0410606873 \tF1:0.9204913077 \tAUC:0.9253916144 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.08215298568869406 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.17278665730702705283\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1657298119 \tAcc: 0.9358899770 \tTPR:0.9503828196 \tFPR:0.0767633950 \tF1:0.9354027702 \t AUC:0.9368097123\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1648532414 \tAcc: 0.9346428571 \tTPR:0.9466094685 \tFPR:0.0777478976 \tF1:0.9336419890 \t AUC:0.9344307855\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.1565119721 \tAcc: 0.9366042627 \tTPR:0.9495724574 \tFPR:0.0772349776 \tF1:0.9352336960 \t AUC:0.9361687399\tTrain cost: 0:00:37\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.1510850703 \tAcc: 0.9419614055 \tTPR:0.9554323254 \tFPR:0.0715019184 \tF1:0.9411188509 \t AUC:0.9419652035\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.1489479007 \tAcc: 0.9410714286 \tTPR:0.9508912509 \tFPR:0.0698575896 \tF1:0.9396864879 \t AUC:0.9405168306\tTrain cost: 0:00:36\n",
      "Client2 Test =>                 \tLoss: 0.2170164610 \tAcc: 0.9252083333 \tTPR:0.8996589492 \tFPR:0.0504352609 \tF1:0.9199629187 \tAUC:0.9246118442 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2005185975 \tAcc: 0.9282916667 \tTPR:0.9055688161 \tFPR:0.0500291627 \tF1:0.9235449887 \tAUC:0.9277698267\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 6:  =============\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.07953549671565346 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.15848355697116989216\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1586364287 \tAcc: 0.9358813364 \tTPR:0.9466626908 \tFPR:0.0772612690 \tF1:0.9359815757 \t AUC:0.9347007109\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1519052134 \tAcc: 0.9399020737 \tTPR:0.9528518618 \tFPR:0.0738787233 \tF1:0.9407478318 \t AUC:0.9394865693\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1503077674 \tAcc: 0.9418663594 \tTPR:0.9540951908 \tFPR:0.0691909179 \tF1:0.9424311116 \t AUC:0.9424521365\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1460796469 \tAcc: 0.9407949309 \tTPR:0.9516224847 \tFPR:0.0703249510 \tF1:0.9401944982 \t AUC:0.9406487668\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1413425759 \tAcc: 0.9453571429 \tTPR:0.9547121814 \tFPR:0.0666146599 \tF1:0.9447007836 \t AUC:0.9440487607\tTrain cost: 0:00:37\n",
      "Client7 Test =>                 \tLoss: 0.2492960038 \tAcc: 0.9185416667 \tTPR:0.8711132639 \tFPR:0.0357061149 \tF1:0.9113882441 \tAUC:0.9177035745 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.08948863275851551 \tALA epochs: 2\n",
      "Client 5: Local Initial ALA epochs: 2 Loss: 0.17555393819170800329\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1689294900 \tAcc: 0.9344585253 \tTPR:0.9472235393 \tFPR:0.0759430407 \tF1:0.9332114791 \t AUC:0.9356402493\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1620742138 \tAcc: 0.9342799539 \tTPR:0.9496897371 \tFPR:0.0829735089 \tF1:0.9339007334 \t AUC:0.9333581141\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1602354059 \tAcc: 0.9341964286 \tTPR:0.9461983204 \tFPR:0.0790572404 \tF1:0.9336555982 \t AUC:0.9335705400\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1569284944 \tAcc: 0.9382978111 \tTPR:0.9510979887 \tFPR:0.0732749072 \tF1:0.9369348280 \t AUC:0.9389115408\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1515922447 \tAcc: 0.9408813364 \tTPR:0.9534630852 \tFPR:0.0728021301 \tF1:0.9405274854 \t AUC:0.9403304775\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.1848259883 \tAcc: 0.9291666667 \tTPR:0.9043519758 \tFPR:0.0453091673 \tF1:0.9259691575 \tAUC:0.9295214042 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.0861898467059451 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.19065668109966360522\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1801885536 \tAcc: 0.9276728111 \tTPR:0.9396736226 \tFPR:0.0850201271 \tF1:0.9246165366 \t AUC:0.9273267477\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1722027755 \tAcc: 0.9299107143 \tTPR:0.9405613075 \tFPR:0.0805065755 \tF1:0.9269338866 \t AUC:0.9300273660\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1692928403 \tAcc: 0.9331250000 \tTPR:0.9440188847 \tFPR:0.0770552476 \tF1:0.9311792765 \t AUC:0.9334818186\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1593153088 \tAcc: 0.9363306452 \tTPR:0.9485941922 \tFPR:0.0757638328 \tF1:0.9342012530 \t AUC:0.9364151797\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1581690897 \tAcc: 0.9352620968 \tTPR:0.9458427241 \tFPR:0.0753565318 \tF1:0.9329737147 \t AUC:0.9352430962\tTrain cost: 0:00:36\n",
      "Client0 Test =>                 \tLoss: 0.2223432330 \tAcc: 0.9183333333 \tTPR:0.8962577612 \tFPR:0.0598546148 \tF1:0.9163860220 \tAUC:0.9182015732 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.07865086913587699 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.17758726855011089385\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1722393064 \tAcc: 0.9300892857 \tTPR:0.9488728393 \tFPR:0.0881063108 \tF1:0.9301058221 \t AUC:0.9303832643\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1637084141 \tAcc: 0.9332891705 \tTPR:0.9478952758 \tFPR:0.0808034561 \tF1:0.9318991709 \t AUC:0.9335459098\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1559375653 \tAcc: 0.9349971198 \tTPR:0.9496481378 \tFPR:0.0793523652 \tF1:0.9343650621 \t AUC:0.9351478863\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1526078258 \tAcc: 0.9396284562 \tTPR:0.9536394471 \tFPR:0.0744112386 \tF1:0.9378739571 \t AUC:0.9396141043\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1479093350 \tAcc: 0.9408870968 \tTPR:0.9541152568 \tFPR:0.0730741473 \tF1:0.9404461356 \t AUC:0.9405205547\tTrain cost: 0:00:37\n",
      "Client1 Test =>                 \tLoss: 0.1864144110 \tAcc: 0.9325000000 \tTPR:0.9076197632 \tFPR:0.0436688958 \tF1:0.9262845564 \tAUC:0.9319754337 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.08023572986863851 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.15323551285310069159\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1572167182 \tAcc: 0.9387413594 \tTPR:0.9501969307 \tFPR:0.0736177077 \tF1:0.9375223064 \t AUC:0.9382896115\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1499512761 \tAcc: 0.9399049539 \tTPR:0.9554059383 \tFPR:0.0748754361 \tF1:0.9383434416 \t AUC:0.9402652511\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1425008235 \tAcc: 0.9440092166 \tTPR:0.9573582334 \tFPR:0.0693109097 \tF1:0.9424346458 \t AUC:0.9440236619\tTrain cost: 0:00:37\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1423465897 \tAcc: 0.9435599078 \tTPR:0.9540957566 \tFPR:0.0668296157 \tF1:0.9415298479 \t AUC:0.9436330705\tTrain cost: 0:00:37\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1371877216 \tAcc: 0.9488364055 \tTPR:0.9606405675 \tFPR:0.0614559440 \tF1:0.9480303842 \t AUC:0.9495923118\tTrain cost: 0:00:37\n",
      "Client3 Test =>                 \tLoss: 0.2025176071 \tAcc: 0.9277083333 \tTPR:0.8991965402 \tFPR:0.0440647011 \tF1:0.9220623769 \tAUC:0.9275659195 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2090794486 \tAcc: 0.9252500000 \tTPR:0.8957078609 \tFPR:0.0457206988 \tF1:0.9204180714 \tAUC:0.9249935810\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 7:  =============\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.052812344225268426 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.13579657522664553837\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1448083769 \tAcc: 0.9421370968 \tTPR:0.9529095261 \tFPR:0.0681821959 \tF1:0.9420095443 \t AUC:0.9423636651\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1385441723 \tAcc: 0.9453485023 \tTPR:0.9560031305 \tFPR:0.0654775803 \tF1:0.9453835680 \t AUC:0.9452627751\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1379862652 \tAcc: 0.9449078341 \tTPR:0.9576072345 \tFPR:0.0684580634 \tF1:0.9451144780 \t AUC:0.9445745856\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1318229618 \tAcc: 0.9455328341 \tTPR:0.9552954294 \tFPR:0.0652407038 \tF1:0.9454133198 \t AUC:0.9450273628\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1329826691 \tAcc: 0.9487442396 \tTPR:0.9562456988 \tFPR:0.0582134534 \tF1:0.9477167115 \t AUC:0.9490161227\tTrain cost: 0:00:36\n",
      "Client7 Test =>                 \tLoss: 0.2008038780 \tAcc: 0.9312500000 \tTPR:0.9024049834 \tFPR:0.0392633508 \tF1:0.9265748126 \tAUC:0.9315708163 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.07371797176242603 \tALA epochs: 2\n",
      "Client 0: Local Initial ALA epochs: 2 Loss: 0.17301593789074948271\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1685552550 \tAcc: 0.9315120968 \tTPR:0.9445818815 \tFPR:0.0805649277 \tF1:0.9290935155 \t AUC:0.9320084769\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1617467793 \tAcc: 0.9354377880 \tTPR:0.9466918502 \tFPR:0.0756195648 \tF1:0.9322070436 \t AUC:0.9355361427\tTrain cost: 0:00:35\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1564908773 \tAcc: 0.9379406682 \tTPR:0.9493805606 \tFPR:0.0748735905 \tF1:0.9358251516 \t AUC:0.9372534851\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1500937048 \tAcc: 0.9401699309 \tTPR:0.9510477389 \tFPR:0.0707144461 \tF1:0.9379917018 \t AUC:0.9401666464\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1463744803 \tAcc: 0.9401670507 \tTPR:0.9518761225 \tFPR:0.0709990703 \tF1:0.9385873384 \t AUC:0.9404385261\tTrain cost: 0:00:36\n",
      "Client0 Test =>                 \tLoss: 0.2054689835 \tAcc: 0.9314583333 \tTPR:0.9293337510 \tFPR:0.0643732666 \tF1:0.9297830964 \tAUC:0.9324802422 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.059755682771479815 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.18597980294430602188\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1656295982 \tAcc: 0.9326699309 \tTPR:0.9468151307 \tFPR:0.0822322912 \tF1:0.9323260902 \t AUC:0.9322914198\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1521377553 \tAcc: 0.9378542627 \tTPR:0.9472707817 \tFPR:0.0716304546 \tF1:0.9358686319 \t AUC:0.9378201636\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1482593282 \tAcc: 0.9402620968 \tTPR:0.9543003767 \tFPR:0.0737108481 \tF1:0.9401059266 \t AUC:0.9402947643\tTrain cost: 0:00:35\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1441483591 \tAcc: 0.9426699309 \tTPR:0.9537163900 \tFPR:0.0678739210 \tF1:0.9414158691 \t AUC:0.9429212345\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1407049697 \tAcc: 0.9419556452 \tTPR:0.9562276329 \tFPR:0.0718118593 \tF1:0.9417768286 \t AUC:0.9422078868\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.2552054079 \tAcc: 0.9122916667 \tTPR:0.8569173229 \tFPR:0.0313942697 \tF1:0.9037268305 \tAUC:0.9127615266 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.09718917316802639 \tALA epochs: 2\n",
      "Client 4: Local Initial ALA epochs: 2 Loss: 0.17088389348076737928\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1632728878 \tAcc: 0.9338364055 \tTPR:0.9480031704 \tFPR:0.0799641344 \tF1:0.9319359422 \t AUC:0.9340195180\tTrain cost: 0:00:35\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1543566376 \tAcc: 0.9373127880 \tTPR:0.9525630774 \tFPR:0.0760583631 \tF1:0.9366798205 \t AUC:0.9382523571\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1491348411 \tAcc: 0.9419556452 \tTPR:0.9553784505 \tFPR:0.0714338299 \tF1:0.9413382687 \t AUC:0.9419723103\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1447000389 \tAcc: 0.9407978111 \tTPR:0.9551431873 \tFPR:0.0737204535 \tF1:0.9396584015 \t AUC:0.9407113669\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1418833410 \tAcc: 0.9426756912 \tTPR:0.9533727061 \tFPR:0.0687227453 \tF1:0.9417255062 \t AUC:0.9423249804\tTrain cost: 0:00:37\n",
      "Client4 Test =>                 \tLoss: 0.1846112740 \tAcc: 0.9329166667 \tTPR:0.9443798276 \tFPR:0.0789244246 \tF1:0.9313102399 \tAUC:0.9327277015 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.06920705532274107 \tALA epochs: 2\n",
      "Client 1: Local Initial ALA epochs: 2 Loss: 0.17435096749576969866\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1608076505 \tAcc: 0.9360685484 \tTPR:0.9523789440 \tFPR:0.0797550389 \tF1:0.9355084528 \t AUC:0.9363119525\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1545370655 \tAcc: 0.9366906682 \tTPR:0.9491613899 \tFPR:0.0762421367 \tF1:0.9361172161 \t AUC:0.9364596266\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1490258726 \tAcc: 0.9385656682 \tTPR:0.9530272042 \tFPR:0.0781069477 \tF1:0.9386796455 \t AUC:0.9374601282\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1418656542 \tAcc: 0.9445478111 \tTPR:0.9543122306 \tFPR:0.0661854918 \tF1:0.9432852986 \t AUC:0.9440633694\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1433723896 \tAcc: 0.9437471198 \tTPR:0.9565310933 \tFPR:0.0693708700 \tF1:0.9425698604 \t AUC:0.9435801117\tTrain cost: 0:00:37\n",
      "Client1 Test =>                 \tLoss: 0.1971985802 \tAcc: 0.9291666667 \tTPR:0.8882075070 \tFPR:0.0329222844 \tF1:0.9204222896 \tAUC:0.9276426113 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2086576247 \tAcc: 0.9274166667 \tTPR:0.9042486784 \tFPR:0.0493755192 \tF1:0.9223634538 \tAUC:0.9274365796\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 8:  =============\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.07748793317754832 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.14382033101350499837\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1584534126 \tAcc: 0.9379406682 \tTPR:0.9487785823 \tFPR:0.0720342626 \tF1:0.9373071867 \t AUC:0.9383721598\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1516429997 \tAcc: 0.9405270737 \tTPR:0.9499431215 \tFPR:0.0690856148 \tF1:0.9401215086 \t AUC:0.9404287534\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.1477930287 \tAcc: 0.9417770737 \tTPR:0.9542993116 \tFPR:0.0706140496 \tF1:0.9401483192 \t AUC:0.9418426310\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.1441312543 \tAcc: 0.9432027650 \tTPR:0.9547876756 \tFPR:0.0687503266 \tF1:0.9418463093 \t AUC:0.9430186745\tTrain cost: 0:00:37\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.1396763438 \tAcc: 0.9450864055 \tTPR:0.9537192161 \tFPR:0.0640283911 \tF1:0.9439306408 \t AUC:0.9448454125\tTrain cost: 0:00:37\n",
      "Client2 Test =>                 \tLoss: 0.2063019422 \tAcc: 0.9293750000 \tTPR:0.9174412450 \tFPR:0.0559683088 \tF1:0.9263255408 \tAUC:0.9307364681 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.04498781854231751 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.11850314587354660034\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1361685707 \tAcc: 0.9466042627 \tTPR:0.9557940799 \tFPR:0.0641111831 \tF1:0.9464562235 \t AUC:0.9458414484\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1312381013 \tAcc: 0.9478485023 \tTPR:0.9592091415 \tFPR:0.0647730074 \tF1:0.9485670972 \t AUC:0.9472180671\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1237358162 \tAcc: 0.9496313364 \tTPR:0.9584756403 \tFPR:0.0590910516 \tF1:0.9498691145 \t AUC:0.9496922944\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1212890173 \tAcc: 0.9517828341 \tTPR:0.9615554876 \tFPR:0.0567951245 \tF1:0.9515665097 \t AUC:0.9523801815\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1208561742 \tAcc: 0.9517799539 \tTPR:0.9623720037 \tFPR:0.0586059781 \tF1:0.9515046815 \t AUC:0.9518830128\tTrain cost: 0:00:37\n",
      "Client7 Test =>                 \tLoss: 0.2410069704 \tAcc: 0.9183333333 \tTPR:0.8705414197 \tFPR:0.0326514240 \tF1:0.9122285930 \tAUC:0.9189449979 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.07969594266467724 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.16226432037850221923\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1531037465 \tAcc: 0.9399971198 \tTPR:0.9529767939 \tFPR:0.0712282072 \tF1:0.9389458105 \t AUC:0.9408742934\tTrain cost: 0:00:35\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1468800978 \tAcc: 0.9405270737 \tTPR:0.9543782870 \tFPR:0.0735482505 \tF1:0.9395944866 \t AUC:0.9404150182\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1417038121 \tAcc: 0.9431221198 \tTPR:0.9575071267 \tFPR:0.0713471339 \tF1:0.9420267439 \t AUC:0.9430799964\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1345679970 \tAcc: 0.9466935484 \tTPR:0.9574890387 \tFPR:0.0639724950 \tF1:0.9453324733 \t AUC:0.9467582718\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1315425216 \tAcc: 0.9487471198 \tTPR:0.9604697515 \tFPR:0.0625562218 \tF1:0.9480003338 \t AUC:0.9489567648\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.2183652609 \tAcc: 0.9247916667 \tTPR:0.8878198138 \tFPR:0.0379045506 \tF1:0.9195691421 \tAUC:0.9249576316 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.0738602433265841 \tALA epochs: 4\n",
      "Client 1: Local Initial ALA epochs: 4 Loss: 0.15904117268307702004\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1577467731 \tAcc: 0.9384735023 \tTPR:0.9547824808 \tFPR:0.0777291003 \tF1:0.9385669119 \t AUC:0.9385266903\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1528153397 \tAcc: 0.9379377880 \tTPR:0.9509532982 \tFPR:0.0759717996 \tF1:0.9370835935 \t AUC:0.9374907493\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1463623778 \tAcc: 0.9402620968 \tTPR:0.9521922888 \tFPR:0.0717721539 \tF1:0.9392358540 \t AUC:0.9402100675\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1434183273 \tAcc: 0.9427620968 \tTPR:0.9565393365 \tFPR:0.0707663357 \tF1:0.9417486138 \t AUC:0.9428865004\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1390347664 \tAcc: 0.9440149770 \tTPR:0.9564493993 \tFPR:0.0693897942 \tF1:0.9429677781 \t AUC:0.9435298025\tTrain cost: 0:00:36\n",
      "Client1 Test =>                 \tLoss: 0.2010776774 \tAcc: 0.9322916667 \tTPR:0.9029617425 \tFPR:0.0383937406 \tF1:0.9263611058 \tAUC:0.9322840010 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.07882294808521202 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.15932069505578366764\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1556745462 \tAcc: 0.9399942396 \tTPR:0.9522335373 \tFPR:0.0714204695 \tF1:0.9376852324 \t AUC:0.9404065339\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1522991846 \tAcc: 0.9384821429 \tTPR:0.9478920500 \tFPR:0.0699307362 \tF1:0.9356873152 \t AUC:0.9389806569\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1455568803 \tAcc: 0.9415149770 \tTPR:0.9545945530 \tFPR:0.0698855578 \tF1:0.9401162291 \t AUC:0.9423544976\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1386863656 \tAcc: 0.9422321429 \tTPR:0.9522735327 \tFPR:0.0681028604 \tF1:0.9397120587 \t AUC:0.9420853361\tTrain cost: 0:00:35\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1327481505 \tAcc: 0.9495506912 \tTPR:0.9600610335 \tFPR:0.0594275846 \tF1:0.9477133645 \t AUC:0.9503167245\tTrain cost: 0:00:36\n",
      "Client0 Test =>                 \tLoss: 0.1839205908 \tAcc: 0.9339583333 \tTPR:0.9193370022 \tFPR:0.0513443962 \tF1:0.9321515537 \tAUC:0.9339963030 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2101344883 \tAcc: 0.9277500000 \tTPR:0.8996202447 \tFPR:0.0432524840 \tF1:0.9233271871 \tAUC:0.9281838803\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 9:  =============\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.08435020001148337 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.12809228521866211636\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1389448513 \tAcc: 0.9442828341 \tTPR:0.9562764038 \tFPR:0.0664992230 \tF1:0.9437957025 \t AUC:0.9448885904\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1354178380 \tAcc: 0.9461491935 \tTPR:0.9560538275 \tFPR:0.0635698980 \tF1:0.9446350645 \t AUC:0.9462419648\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.1291976326 \tAcc: 0.9504435484 \tTPR:0.9594078449 \tFPR:0.0595302373 \tF1:0.9498081902 \t AUC:0.9499388038\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.1281579408 \tAcc: 0.9499942396 \tTPR:0.9608394640 \tFPR:0.0603314186 \tF1:0.9496279815 \t AUC:0.9502540227\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.1255387862 \tAcc: 0.9500864055 \tTPR:0.9597334456 \tFPR:0.0604713280 \tF1:0.9494535761 \t AUC:0.9496310588\tTrain cost: 0:00:36\n",
      "Client2 Test =>                 \tLoss: 0.2104077605 \tAcc: 0.9277083333 \tTPR:0.9027987519 \tFPR:0.0458564832 \tF1:0.9232449586 \tAUC:0.9284711344 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.06216616662199816 \tALA epochs: 3\n",
      "Client 6: Local Initial ALA epochs: 3 Loss: 0.14829873256745257359\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1467793954 \tAcc: 0.9408006912 \tTPR:0.9546343882 \tFPR:0.0721168506 \tF1:0.9399044227 \t AUC:0.9412587688\tTrain cost: 0:00:37\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1394658185 \tAcc: 0.9441042627 \tTPR:0.9585164454 \tFPR:0.0713741017 \tF1:0.9443992132 \t AUC:0.9435711719\tTrain cost: 0:00:37\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1370745323 \tAcc: 0.9446342166 \tTPR:0.9587685529 \tFPR:0.0698591878 \tF1:0.9442725079 \t AUC:0.9444546826\tTrain cost: 0:00:36\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1313719943 \tAcc: 0.9490120968 \tTPR:0.9608946631 \tFPR:0.0630717667 \tF1:0.9490410972 \t AUC:0.9489114482\tTrain cost: 0:00:36\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1252890691 \tAcc: 0.9508899770 \tTPR:0.9651488191 \tFPR:0.0646393540 \tF1:0.9506748998 \t AUC:0.9502547325\tTrain cost: 0:00:36\n",
      "Client6 Test =>                 \tLoss: 0.2370281868 \tAcc: 0.9237500000 \tTPR:0.8820534516 \tFPR:0.0384252837 \tF1:0.9169184848 \tAUC:0.9218140840 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.0744621345010534 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.16063753439896349962\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1503113469 \tAcc: 0.9393721198 \tTPR:0.9526685643 \tFPR:0.0732688277 \tF1:0.9382284449 \t AUC:0.9396998683\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1427552038 \tAcc: 0.9437500000 \tTPR:0.9570680992 \tFPR:0.0687560520 \tF1:0.9423533826 \t AUC:0.9441560236\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1337821974 \tAcc: 0.9475835253 \tTPR:0.9585204105 \tFPR:0.0645967253 \tF1:0.9468063640 \t AUC:0.9469618426\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1306551909 \tAcc: 0.9479349078 \tTPR:0.9588246020 \tFPR:0.0635507163 \tF1:0.9465216228 \t AUC:0.9476369428\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1259892621 \tAcc: 0.9504435484 \tTPR:0.9601613306 \tFPR:0.0590320439 \tF1:0.9491690495 \t AUC:0.9505646434\tTrain cost: 0:00:37\n",
      "Client8 Test =>                 \tLoss: 0.2267024775 \tAcc: 0.9275000000 \tTPR:0.8945727221 \tFPR:0.0377696940 \tF1:0.9236612104 \tAUC:0.9284015141 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.07595236436340451 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.14128691098396328751\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1486974511 \tAcc: 0.9424020737 \tTPR:0.9538541739 \tFPR:0.0684365986 \tF1:0.9405090598 \t AUC:0.9427087877\tTrain cost: 0:00:35\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1425954240 \tAcc: 0.9421370968 \tTPR:0.9548510921 \tFPR:0.0698199654 \tF1:0.9409147237 \t AUC:0.9425155633\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1353528105 \tAcc: 0.9474942396 \tTPR:0.9604009201 \tFPR:0.0651019141 \tF1:0.9466216944 \t AUC:0.9476495030\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1306099994 \tAcc: 0.9468692396 \tTPR:0.9585869991 \tFPR:0.0637123307 \tF1:0.9450542822 \t AUC:0.9474373342\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1269289631 \tAcc: 0.9510685484 \tTPR:0.9623728905 \tFPR:0.0595179187 \tF1:0.9488451334 \t AUC:0.9514274859\tTrain cost: 0:00:36\n",
      "Client3 Test =>                 \tLoss: 0.2152316660 \tAcc: 0.9250000000 \tTPR:0.9029903082 \tFPR:0.0521687768 \tF1:0.9205623924 \tAUC:0.9254107657 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.062819478610033 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.15303448120644991270\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1500126499 \tAcc: 0.9407978111 \tTPR:0.9537975256 \tFPR:0.0715667876 \tF1:0.9391890390 \t AUC:0.9411153690\tTrain cost: 0:00:35\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1437460632 \tAcc: 0.9419642857 \tTPR:0.9537807061 \tFPR:0.0699997399 \tF1:0.9408585760 \t AUC:0.9418904831\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1372742808 \tAcc: 0.9452592166 \tTPR:0.9573611080 \tFPR:0.0669273045 \tF1:0.9450525421 \t AUC:0.9452169018\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1322622042 \tAcc: 0.9486549539 \tTPR:0.9599479832 \tFPR:0.0627273604 \tF1:0.9478578219 \t AUC:0.9486103114\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1296100760 \tAcc: 0.9482949309 \tTPR:0.9580905114 \tFPR:0.0625041938 \tF1:0.9475035484 \t AUC:0.9477931588\tTrain cost: 0:00:36\n",
      "Client4 Test =>                 \tLoss: 0.1901059997 \tAcc: 0.9314583333 \tTPR:0.9247888933 \tFPR:0.0609160759 \tF1:0.9278803309 \tAUC:0.9319364087 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2158952181 \tAcc: 0.9270833333 \tTPR:0.9014408254 \tFPR:0.0470272627 \tF1:0.9224534754 \tAUC:0.9272067814\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 10:  =============\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.03830082964094228 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.12328921527723255003\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1334152022 \tAcc: 0.9483842166 \tTPR:0.9593024596 \tFPR:0.0631068954 \tF1:0.9470433959 \t AUC:0.9480977821\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1273913699 \tAcc: 0.9489256912 \tTPR:0.9600331062 \tFPR:0.0621257911 \tF1:0.9481546049 \t AUC:0.9489536575\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1258229120 \tAcc: 0.9489256912 \tTPR:0.9583018227 \tFPR:0.0614537253 \tF1:0.9476269578 \t AUC:0.9484240487\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1192295145 \tAcc: 0.9521370968 \tTPR:0.9611877747 \tFPR:0.0584419805 \tF1:0.9510104084 \t AUC:0.9513728971\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1175074324 \tAcc: 0.9527678571 \tTPR:0.9629736876 \tFPR:0.0568641572 \tF1:0.9520564286 \t AUC:0.9530547652\tTrain cost: 0:00:36\n",
      "Client8 Test =>                 \tLoss: 0.2486267099 \tAcc: 0.9225000000 \tTPR:0.8849800481 \tFPR:0.0395867940 \tF1:0.9172325980 \tAUC:0.9226966271 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.09647656904177443 \tALA epochs: 2\n",
      "Client 7: Local Initial ALA epochs: 2 Loss: 0.14089443225521539049\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1334814260 \tAcc: 0.9473156682 \tTPR:0.9590436595 \tFPR:0.0652881329 \tF1:0.9475535363 \t AUC:0.9468777633\tTrain cost: 0:00:35\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1252081775 \tAcc: 0.9490092166 \tTPR:0.9603905697 \tFPR:0.0623974277 \tF1:0.9490546811 \t AUC:0.9489965710\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1194559980 \tAcc: 0.9532114055 \tTPR:0.9607185137 \tFPR:0.0547999139 \tF1:0.9527924127 \t AUC:0.9529592999\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1143619470 \tAcc: 0.9524971198 \tTPR:0.9628168804 \tFPR:0.0576814481 \tF1:0.9530570678 \t AUC:0.9525677161\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1087772325 \tAcc: 0.9579464286 \tTPR:0.9676853914 \tFPR:0.0530983701 \tF1:0.9585184982 \t AUC:0.9572935106\tTrain cost: 0:00:36\n",
      "Client7 Test =>                 \tLoss: 0.2149250612 \tAcc: 0.9293750000 \tTPR:0.8949766050 \tFPR:0.0347665232 \tF1:0.9257218062 \tAUC:0.9301050409 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.061655102358735135 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.15965643958391054213\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1476052367 \tAcc: 0.9410714286 \tTPR:0.9525317738 \tFPR:0.0695328778 \tF1:0.9404227642 \t AUC:0.9414994480\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1420955146 \tAcc: 0.9424942396 \tTPR:0.9540286535 \tFPR:0.0699829570 \tF1:0.9419676266 \t AUC:0.9420228482\tTrain cost: 0:00:35\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1391855691 \tAcc: 0.9438392857 \tTPR:0.9554068745 \tFPR:0.0661081018 \tF1:0.9428013903 \t AUC:0.9446493864\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1296232886 \tAcc: 0.9481192396 \tTPR:0.9598543587 \tFPR:0.0613969709 \tF1:0.9465423359 \t AUC:0.9492286939\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1322677804 \tAcc: 0.9466906682 \tTPR:0.9610636978 \tFPR:0.0675572646 \tF1:0.9462708062 \t AUC:0.9467532166\tTrain cost: 0:00:37\n",
      "Client1 Test =>                 \tLoss: 0.1807471719 \tAcc: 0.9387500000 \tTPR:0.9264340550 \tFPR:0.0488494378 \tF1:0.9342144880 \tAUC:0.9387923086 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.059298288223306975 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.14688234493487339893\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1532142030 \tAcc: 0.9376728111 \tTPR:0.9483020268 \tFPR:0.0733395563 \tF1:0.9349717099 \t AUC:0.9374812352\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1425519225 \tAcc: 0.9430299539 \tTPR:0.9555281888 \tFPR:0.0687702464 \tF1:0.9413781269 \t AUC:0.9433789712\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1374455514 \tAcc: 0.9447206221 \tTPR:0.9546871600 \tFPR:0.0645469698 \tF1:0.9432679653 \t AUC:0.9450700951\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1314769608 \tAcc: 0.9452592166 \tTPR:0.9522282181 \tFPR:0.0608391683 \tF1:0.9426301540 \t AUC:0.9456945249\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1290755999 \tAcc: 0.9489285714 \tTPR:0.9584867553 \tFPR:0.0600791417 \tF1:0.9459130004 \t AUC:0.9492038068\tTrain cost: 0:00:36\n",
      "Client0 Test =>                 \tLoss: 0.2081774549 \tAcc: 0.9314583333 \tTPR:0.9090345251 \tFPR:0.0450197988 \tF1:0.9291458332 \tAUC:0.9320073631 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.0816111054141876 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.12505552715257459151\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1328919073 \tAcc: 0.9482114055 \tTPR:0.9576456177 \tFPR:0.0622099653 \tF1:0.9470262006 \t AUC:0.9477178262\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1268296428 \tAcc: 0.9500864055 \tTPR:0.9595817312 \tFPR:0.0591719994 \tF1:0.9490186706 \t AUC:0.9502048659\tTrain cost: 0:00:37\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.1155674609 \tAcc: 0.9524971198 \tTPR:0.9601159080 \tFPR:0.0548231303 \tF1:0.9510042519 \t AUC:0.9526463888\tTrain cost: 0:00:37\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.1159879603 \tAcc: 0.9533035714 \tTPR:0.9623043691 \tFPR:0.0566599302 \tF1:0.9527293311 \t AUC:0.9528222194\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.1131519548 \tAcc: 0.9559763825 \tTPR:0.9645206097 \tFPR:0.0511978030 \tF1:0.9546916178 \t AUC:0.9566614034\tTrain cost: 0:00:36\n",
      "Client2 Test =>                 \tLoss: 0.2123741967 \tAcc: 0.9295833333 \tTPR:0.9098927707 \tFPR:0.0510918522 \tF1:0.9249928239 \tAUC:0.9294004593 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2129701189 \tAcc: 0.9303333333 \tTPR:0.9050636008 \tFPR:0.0438628812 \tF1:0.9262615099 \tAUC:0.9306003598\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 11:  =============\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.07391334402327256 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.10880853756722333459\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1141032076 \tAcc: 0.9551756912 \tTPR:0.9649777657 \tFPR:0.0536243589 \tF1:0.9547540875 \t AUC:0.9556767034\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1051682154 \tAcc: 0.9600864055 \tTPR:0.9663716237 \tFPR:0.0462702730 \tF1:0.9594622949 \t AUC:0.9600506754\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1023425370 \tAcc: 0.9586578341 \tTPR:0.9667529376 \tFPR:0.0491415169 \tF1:0.9582780152 \t AUC:0.9588057104\tTrain cost: 0:00:35\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1005460214 \tAcc: 0.9596370968 \tTPR:0.9669144425 \tFPR:0.0477197738 \tF1:0.9593248387 \t AUC:0.9595973344\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0939163563 \tAcc: 0.9632142857 \tTPR:0.9704943749 \tFPR:0.0437850540 \tF1:0.9628715652 \t AUC:0.9633546605\tTrain cost: 0:00:36\n",
      "Client7 Test =>                 \tLoss: 0.2753524124 \tAcc: 0.9193750000 \tTPR:0.8752266124 \tFPR:0.0399308568 \tF1:0.9128832616 \tAUC:0.9176478778 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.06984711275571069 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.12795036193658260171\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1260335560 \tAcc: 0.9492799539 \tTPR:0.9612129910 \tFPR:0.0622647824 \tF1:0.9484592642 \t AUC:0.9494741043\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1170485907 \tAcc: 0.9524049539 \tTPR:0.9618592954 \tFPR:0.0581715409 \tF1:0.9510957952 \t AUC:0.9518438773\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1137904907 \tAcc: 0.9552649770 \tTPR:0.9635995482 \tFPR:0.0531226315 \tF1:0.9539849565 \t AUC:0.9552384584\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1127805173 \tAcc: 0.9559821429 \tTPR:0.9667237027 \tFPR:0.0547513997 \tF1:0.9547844806 \t AUC:0.9559861515\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1057029358 \tAcc: 0.9582114055 \tTPR:0.9653895579 \tFPR:0.0481949083 \tF1:0.9572072217 \t AUC:0.9585973248\tTrain cost: 0:00:36\n",
      "Client8 Test =>                 \tLoss: 0.2267026137 \tAcc: 0.9297916667 \tTPR:0.9066637176 \tFPR:0.0481512035 \tF1:0.9259433387 \tAUC:0.9292562570 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.051884459635785724 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.15989005241705023241\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1457704428 \tAcc: 0.9430328341 \tTPR:0.9558739399 \tFPR:0.0686239623 \tF1:0.9407680253 \t AUC:0.9436249888\tTrain cost: 0:00:35\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1381844730 \tAcc: 0.9438364055 \tTPR:0.9555436927 \tFPR:0.0677224977 \tF1:0.9421818777 \t AUC:0.9439105975\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1288717463 \tAcc: 0.9471342166 \tTPR:0.9576684079 \tFPR:0.0633756416 \tF1:0.9450711803 \t AUC:0.9471463832\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1281648621 \tAcc: 0.9485656682 \tTPR:0.9553359443 \tFPR:0.0589485698 \tF1:0.9466898012 \t AUC:0.9481936872\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1232178780 \tAcc: 0.9521313364 \tTPR:0.9600941875 \tFPR:0.0573463251 \tF1:0.9502717146 \t AUC:0.9513739312\tTrain cost: 0:00:37\n",
      "Client0 Test =>                 \tLoss: 0.2292147988 \tAcc: 0.9212500000 \tTPR:0.8833886383 \tFPR:0.0388422022 \tF1:0.9160719639 \tAUC:0.9222732181 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.08449024501883025 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.13823976464893505955\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1419195239 \tAcc: 0.9415092166 \tTPR:0.9538659540 \tFPR:0.0702047370 \tF1:0.9400232215 \t AUC:0.9418306085\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1346493360 \tAcc: 0.9459763825 \tTPR:0.9591331844 \tFPR:0.0662381089 \tF1:0.9460588922 \t AUC:0.9464475377\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1254438066 \tAcc: 0.9490092166 \tTPR:0.9618877166 \tFPR:0.0658437103 \tF1:0.9485597080 \t AUC:0.9480220032\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1227612221 \tAcc: 0.9499942396 \tTPR:0.9606290665 \tFPR:0.0614938291 \tF1:0.9491538890 \t AUC:0.9495676187\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1190804949 \tAcc: 0.9523156682 \tTPR:0.9639881540 \tFPR:0.0603356309 \tF1:0.9518079364 \t AUC:0.9518262615\tTrain cost: 0:00:37\n",
      "Client1 Test =>                 \tLoss: 0.1854159887 \tAcc: 0.9329166667 \tTPR:0.9062313130 \tFPR:0.0413294153 \tF1:0.9261104765 \tAUC:0.9324509488 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.09139027770838552 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.14367030196539734566\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1425687684 \tAcc: 0.9458006912 \tTPR:0.9571344718 \tFPR:0.0651751724 \tF1:0.9443804433 \t AUC:0.9459796497\tTrain cost: 0:00:34\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1321485953 \tAcc: 0.9465092166 \tTPR:0.9605452094 \tFPR:0.0669804039 \tF1:0.9456704092 \t AUC:0.9467824027\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1250528962 \tAcc: 0.9509792627 \tTPR:0.9618755135 \tFPR:0.0588968175 \tF1:0.9493514784 \t AUC:0.9514893480\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1197547325 \tAcc: 0.9535627880 \tTPR:0.9648876106 \tFPR:0.0570777439 \tF1:0.9519861581 \t AUC:0.9539049334\tTrain cost: 0:00:35\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1168160740 \tAcc: 0.9535685484 \tTPR:0.9621400933 \tFPR:0.0553252607 \tF1:0.9522125728 \t AUC:0.9534074163\tTrain cost: 0:00:36\n",
      "Client3 Test =>                 \tLoss: 0.2095277461 \tAcc: 0.9295833333 \tTPR:0.8907129015 \tFPR:0.0334972154 \tF1:0.9231865506 \tAUC:0.9286078431 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2252427120 \tAcc: 0.9265833333 \tTPR:0.8924446365 \tFPR:0.0403501786 \tF1:0.9208391182 \tAUC:0.9260472290\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 12:  =============\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.07062490928256362 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.16245205812426150027\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.1492923298 \tAcc: 0.9399913594 \tTPR:0.9520846671 \tFPR:0.0710119305 \tF1:0.9390792094 \t AUC:0.9405363683\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.1414745594 \tAcc: 0.9429377880 \tTPR:0.9539762520 \tFPR:0.0671745458 \tF1:0.9419505317 \t AUC:0.9434008531\tTrain cost: 0:00:37\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.1389035267 \tAcc: 0.9458899770 \tTPR:0.9552521860 \tFPR:0.0636071498 \tF1:0.9445305982 \t AUC:0.9458225181\tTrain cost: 0:00:37\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.1321576541 \tAcc: 0.9473214286 \tTPR:0.9570625126 \tFPR:0.0627260938 \tF1:0.9460635214 \t AUC:0.9471682094\tTrain cost: 0:00:37\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.1307698602 \tAcc: 0.9494642857 \tTPR:0.9569684500 \tFPR:0.0580910109 \tF1:0.9482448496 \t AUC:0.9494387196\tTrain cost: 0:00:37\n",
      "Client9 Test =>                 \tLoss: 0.1889380218 \tAcc: 0.9385416667 \tTPR:0.9331635978 \tFPR:0.0573562402 \tF1:0.9376299555 \tAUC:0.9379036788 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.08259219973990067 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.13267113370955854745\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1319243680 \tAcc: 0.9458928571 \tTPR:0.9581390251 \tFPR:0.0654063786 \tF1:0.9454550909 \t AUC:0.9463663232\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1247039583 \tAcc: 0.9504406682 \tTPR:0.9599407047 \tFPR:0.0598806820 \tF1:0.9498117963 \t AUC:0.9500300113\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1189420812 \tAcc: 0.9518692396 \tTPR:0.9636425864 \tFPR:0.0602685632 \tF1:0.9509597581 \t AUC:0.9516870116\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1137134320 \tAcc: 0.9556192396 \tTPR:0.9669592916 \tFPR:0.0554213771 \tF1:0.9551762782 \t AUC:0.9557689573\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1102089028 \tAcc: 0.9553542627 \tTPR:0.9638724409 \tFPR:0.0533316621 \tF1:0.9540274427 \t AUC:0.9552703894\tTrain cost: 0:00:37\n",
      "Client1 Test =>                 \tLoss: 0.2121331700 \tAcc: 0.9285416667 \tTPR:0.8872836967 \tFPR:0.0330509066 \tF1:0.9199190352 \tAUC:0.9271163951 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.08059903705697484 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.10854698447645574899\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1125267450 \tAcc: 0.9554435484 \tTPR:0.9664414708 \tFPR:0.0564132307 \tF1:0.9554713818 \t AUC:0.9550141200\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1018119583 \tAcc: 0.9588306452 \tTPR:0.9668610672 \tFPR:0.0502031973 \tF1:0.9584134929 \t AUC:0.9583289350\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0947512222 \tAcc: 0.9628571429 \tTPR:0.9719297094 \tFPR:0.0473115567 \tF1:0.9632273434 \t AUC:0.9623090763\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0931754765 \tAcc: 0.9624078341 \tTPR:0.9705135950 \tFPR:0.0461994448 \tF1:0.9626981007 \t AUC:0.9621570751\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0894984167 \tAcc: 0.9650892857 \tTPR:0.9724954747 \tFPR:0.0412806069 \tF1:0.9648719332 \t AUC:0.9656074339\tTrain cost: 0:00:37\n",
      "Client7 Test =>                 \tLoss: 0.2837699067 \tAcc: 0.9172916667 \tTPR:0.8564370428 \tFPR:0.0224327586 \tF1:0.9082442895 \tAUC:0.9170021421 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.0865732650074209 \tALA epochs: 4\n",
      "Client 4: Local Initial ALA epochs: 4 Loss: 0.15260986188777547756\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1437119353 \tAcc: 0.9433870968 \tTPR:0.9562576275 \tFPR:0.0680945971 \tF1:0.9421829284 \t AUC:0.9440815152\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1331117384 \tAcc: 0.9476670507 \tTPR:0.9613541406 \tFPR:0.0673150435 \tF1:0.9473511035 \t AUC:0.9470195485\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1286519489 \tAcc: 0.9482978111 \tTPR:0.9604500966 \tFPR:0.0641177024 \tF1:0.9472745621 \t AUC:0.9481661971\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1245746422 \tAcc: 0.9506221198 \tTPR:0.9639544261 \tFPR:0.0631443666 \tF1:0.9502420863 \t AUC:0.9504050298\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1193492306 \tAcc: 0.9527649770 \tTPR:0.9626505790 \tFPR:0.0572296458 \tF1:0.9503849006 \t AUC:0.9527104666\tTrain cost: 0:00:36\n",
      "Client4 Test =>                 \tLoss: 0.1866412391 \tAcc: 0.9360416667 \tTPR:0.9240164998 \tFPR:0.0525716278 \tF1:0.9320481132 \tAUC:0.9357224360 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.048627848898609834 \tALA epochs: 2\n",
      "Client 8: Local Initial ALA epochs: 2 Loss: 0.11530626202137142511\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1203212454 \tAcc: 0.9531250000 \tTPR:0.9633993161 \tFPR:0.0571119263 \tF1:0.9522757395 \t AUC:0.9531436949\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1115789725 \tAcc: 0.9558870968 \tTPR:0.9661425514 \tFPR:0.0539310216 \tF1:0.9552100102 \t AUC:0.9561057649\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1068048086 \tAcc: 0.9583006912 \tTPR:0.9670996988 \tFPR:0.0508538235 \tF1:0.9570945385 \t AUC:0.9581229376\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1023200549 \tAcc: 0.9591071429 \tTPR:0.9677449991 \tFPR:0.0499346450 \tF1:0.9577778023 \t AUC:0.9589051771\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0944229343 \tAcc: 0.9636549539 \tTPR:0.9716459803 \tFPR:0.0444904826 \tF1:0.9631939623 \t AUC:0.9635777489\tTrain cost: 0:00:36\n",
      "Client8 Test =>                 \tLoss: 0.2541016034 \tAcc: 0.9266666667 \tTPR:0.8873898013 \tFPR:0.0371541021 \tF1:0.9200631346 \tAUC:0.9251178496 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2251167882 \tAcc: 0.9294166667 \tTPR:0.8976581277 \tFPR:0.0405131271 \tF1:0.9235809056 \tAUC:0.9285725003\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 13:  =============\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.09887604860352811 \tALA epochs: 2\n",
      "Client 0: Local Initial ALA epochs: 2 Loss: 0.13598297192526143107\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1349112540 \tAcc: 0.9457978111 \tTPR:0.9561511231 \tFPR:0.0640441513 \tF1:0.9429402244 \t AUC:0.9460534859\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1255081870 \tAcc: 0.9511549539 \tTPR:0.9585475445 \tFPR:0.0565337067 \tF1:0.9486653624 \t AUC:0.9510069189\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1185245142 \tAcc: 0.9551641705 \tTPR:0.9638743397 \tFPR:0.0529558131 \tF1:0.9527219936 \t AUC:0.9554592633\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1148099150 \tAcc: 0.9540120968 \tTPR:0.9634161796 \tFPR:0.0549725526 \tF1:0.9518057231 \t AUC:0.9542218135\tTrain cost: 0:00:37\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1108780958 \tAcc: 0.9577678571 \tTPR:0.9669691217 \tFPR:0.0504025257 \tF1:0.9553182874 \t AUC:0.9582832980\tTrain cost: 0:00:37\n",
      "Client0 Test =>                 \tLoss: 0.2401182286 \tAcc: 0.9252083333 \tTPR:0.8949301755 \tFPR:0.0433793727 \tF1:0.9219943879 \tAUC:0.9257754014 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.08628483878857493 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.12992490471705145372\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1420491556 \tAcc: 0.9440927419 \tTPR:0.9560515599 \tFPR:0.0669556489 \tF1:0.9430417712 \t AUC:0.9445479555\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1289024177 \tAcc: 0.9516935484 \tTPR:0.9654906225 \tFPR:0.0613212587 \tF1:0.9507416906 \t AUC:0.9520846819\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1286205531 \tAcc: 0.9487500000 \tTPR:0.9603577667 \tFPR:0.0630362358 \tF1:0.9482268421 \t AUC:0.9486607655\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1174278790 \tAcc: 0.9528542627 \tTPR:0.9624272442 \tFPR:0.0577649634 \tF1:0.9518850616 \t AUC:0.9523311404\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1156953097 \tAcc: 0.9535685484 \tTPR:0.9643594314 \tFPR:0.0569322988 \tF1:0.9531990156 \t AUC:0.9537135663\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.1612373732 \tAcc: 0.9439583333 \tTPR:0.9425347891 \tFPR:0.0540871468 \tF1:0.9429396647 \tAUC:0.9442238212 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.0587963316986329 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.13924570122490759205\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.1361485604 \tAcc: 0.9471399770 \tTPR:0.9581126765 \tFPR:0.0632471980 \tF1:0.9459267482 \t AUC:0.9474327393\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.1246149988 \tAcc: 0.9524078341 \tTPR:0.9626974240 \tFPR:0.0567124327 \tF1:0.9515111419 \t AUC:0.9529924956\tTrain cost: 0:00:35\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.1197093332 \tAcc: 0.9546399770 \tTPR:0.9627655465 \tFPR:0.0537834773 \tF1:0.9538350129 \t AUC:0.9544910346\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.1178845023 \tAcc: 0.9516042627 \tTPR:0.9617518220 \tFPR:0.0589052690 \tF1:0.9513439954 \t AUC:0.9514232765\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.1108709762 \tAcc: 0.9571428571 \tTPR:0.9620840857 \tFPR:0.0493683541 \tF1:0.9550747040 \t AUC:0.9563578658\tTrain cost: 0:00:37\n",
      "Client9 Test =>                 \tLoss: 0.1890066944 \tAcc: 0.9391666667 \tTPR:0.9363878268 \tFPR:0.0594943889 \tF1:0.9347058663 \tAUC:0.9384467190 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.09769311940704507 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.13455632998459582383\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1247125767 \tAcc: 0.9496399770 \tTPR:0.9607631858 \tFPR:0.0627224131 \tF1:0.9486267618 \t AUC:0.9490203863\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1151030475 \tAcc: 0.9550835253 \tTPR:0.9646353848 \tFPR:0.0542748624 \tF1:0.9544829958 \t AUC:0.9551802612\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1096640887 \tAcc: 0.9574107143 \tTPR:0.9677041208 \tFPR:0.0524244869 \tF1:0.9566990433 \t AUC:0.9576398170\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1060614678 \tAcc: 0.9571370968 \tTPR:0.9662719565 \tFPR:0.0512438772 \tF1:0.9566934596 \t AUC:0.9575140397\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0978700618 \tAcc: 0.9599971198 \tTPR:0.9693239853 \tFPR:0.0494824986 \tF1:0.9593758477 \t AUC:0.9599207434\tTrain cost: 0:00:35\n",
      "Client1 Test =>                 \tLoss: 0.1982542703 \tAcc: 0.9383333333 \tTPR:0.9111437799 \tFPR:0.0381860802 \tF1:0.9332656274 \tAUC:0.9364788499 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.06792091923760368 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.09231829053411881592\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1065109815 \tAcc: 0.9572235023 \tTPR:0.9686544158 \tFPR:0.0532325024 \tF1:0.9575352155 \t AUC:0.9577109567\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0976027856 \tAcc: 0.9587500000 \tTPR:0.9654831522 \tFPR:0.0478578167 \tF1:0.9587516212 \t AUC:0.9588126678\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0913681226 \tAcc: 0.9645478111 \tTPR:0.9724684875 \tFPR:0.0421017559 \tF1:0.9644649573 \t AUC:0.9651833658\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0892288916 \tAcc: 0.9649913594 \tTPR:0.9720059689 \tFPR:0.0417597779 \tF1:0.9650009300 \t AUC:0.9651230955\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0826064207 \tAcc: 0.9683899770 \tTPR:0.9762219654 \tFPR:0.0395301704 \tF1:0.9680598295 \t AUC:0.9683458975\tTrain cost: 0:00:37\n",
      "Client7 Test =>                 \tLoss: 0.1892009741 \tAcc: 0.9404166667 \tTPR:0.9297632143 \tFPR:0.0486109505 \tF1:0.9386601371 \tAUC:0.9405761319 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.1955635081 \tAcc: 0.9374166667 \tTPR:0.9229519571 \tFPR:0.0487515878 \tF1:0.9343131367 \tAUC:0.9371001847\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 14:  =============\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.054604115947540534 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.09613486419877280420\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1092028823 \tAcc: 0.9560714286 \tTPR:0.9676293854 \tFPR:0.0546573669 \tF1:0.9556565629 \t AUC:0.9564860093\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1041102348 \tAcc: 0.9574078341 \tTPR:0.9675433208 \tFPR:0.0534389099 \tF1:0.9569252820 \t AUC:0.9570522054\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0986740131 \tAcc: 0.9588335253 \tTPR:0.9682046857 \tFPR:0.0506062782 \tF1:0.9581146974 \t AUC:0.9587992038\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0971341298 \tAcc: 0.9608035714 \tTPR:0.9699006226 \tFPR:0.0478990587 \tF1:0.9598422085 \t AUC:0.9610007820\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0927585056 \tAcc: 0.9638392857 \tTPR:0.9718086177 \tFPR:0.0442918319 \tF1:0.9633057767 \t AUC:0.9637583929\tTrain cost: 0:00:36\n",
      "Client1 Test =>                 \tLoss: 0.1838725893 \tAcc: 0.9414583333 \tTPR:0.9288913773 \tFPR:0.0435077772 \tF1:0.9373403944 \tAUC:0.9426918000 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.042327704018176024 \tALA epochs: 2\n",
      "Client 5: Local Initial ALA epochs: 2 Loss: 0.13548151098623656408\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1274016460 \tAcc: 0.9493721198 \tTPR:0.9614211674 \tFPR:0.0625236894 \tF1:0.9485286948 \t AUC:0.9494487390\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1204694295 \tAcc: 0.9530299539 \tTPR:0.9623884364 \tFPR:0.0571250316 \tF1:0.9519292007 \t AUC:0.9526317024\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1139376093 \tAcc: 0.9563335253 \tTPR:0.9680246867 \tFPR:0.0543493622 \tF1:0.9554042015 \t AUC:0.9568376622\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1048989621 \tAcc: 0.9587500000 \tTPR:0.9681804399 \tFPR:0.0502393486 \tF1:0.9580016483 \t AUC:0.9589705457\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1043605388 \tAcc: 0.9610714286 \tTPR:0.9682497648 \tFPR:0.0463335409 \tF1:0.9600240692 \t AUC:0.9609581120\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.1926317471 \tAcc: 0.9285416667 \tTPR:0.9021661621 \tFPR:0.0453862679 \tF1:0.9249196560 \tAUC:0.9283899471 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.04884761947530029 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.11289928433741780456\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1169436035 \tAcc: 0.9554406682 \tTPR:0.9653425147 \tFPR:0.0550036358 \tF1:0.9538617192 \t AUC:0.9551694395\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1095674384 \tAcc: 0.9534821429 \tTPR:0.9622835511 \tFPR:0.0560411143 \tF1:0.9523528231 \t AUC:0.9531212184\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1021824865 \tAcc: 0.9588277650 \tTPR:0.9690891046 \tFPR:0.0511726187 \tF1:0.9573819586 \t AUC:0.9589582430\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0971558138 \tAcc: 0.9633928571 \tTPR:0.9710473664 \tFPR:0.0443889479 \tF1:0.9618383232 \t AUC:0.9633292092\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0901280273 \tAcc: 0.9621428571 \tTPR:0.9682862270 \tFPR:0.0440222423 \tF1:0.9609606730 \t AUC:0.9621319923\tTrain cost: 0:00:37\n",
      "Client8 Test =>                 \tLoss: 0.2059375528 \tAcc: 0.9322916667 \tTPR:0.9399069370 \tFPR:0.0746356909 \tF1:0.9297277147 \tAUC:0.9326356230 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.06998759113036045 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.12293750544389088486\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1013845563 \tAcc: 0.9571428571 \tTPR:0.9654765681 \tFPR:0.0502070925 \tF1:0.9567276091 \t AUC:0.9576347378\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0952475031 \tAcc: 0.9620506912 \tTPR:0.9683269458 \tFPR:0.0446680844 \tF1:0.9616157166 \t AUC:0.9618294307\tTrain cost: 0:00:35\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0898791054 \tAcc: 0.9635685484 \tTPR:0.9713794883 \tFPR:0.0453801151 \tF1:0.9632685550 \t AUC:0.9629996866\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0797805758 \tAcc: 0.9692828341 \tTPR:0.9756296134 \tFPR:0.0378688027 \tF1:0.9692536063 \t AUC:0.9688804054\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0800036202 \tAcc: 0.9691042627 \tTPR:0.9778492482 \tFPR:0.0392514027 \tF1:0.9694951374 \t AUC:0.9692989228\tTrain cost: 0:00:36\n",
      "Client7 Test =>                 \tLoss: 0.2141091391 \tAcc: 0.9395833333 \tTPR:0.9115922345 \tFPR:0.0335863569 \tF1:0.9357416360 \tAUC:0.9390029388 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.056608343844746174 \tALA epochs: 3\n",
      "Client 3: Local Initial ALA epochs: 3 Loss: 0.13823505741845509842\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1405222385 \tAcc: 0.9441820276 \tTPR:0.9543775298 \tFPR:0.0663015897 \tF1:0.9431888301 \t AUC:0.9440379701\tTrain cost: 0:00:35\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1292394730 \tAcc: 0.9487442396 \tTPR:0.9598752274 \tFPR:0.0616217197 \tF1:0.9478326247 \t AUC:0.9491267539\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1166576143 \tAcc: 0.9563364055 \tTPR:0.9678078814 \tFPR:0.0537430376 \tF1:0.9547805542 \t AUC:0.9570324219\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1161122588 \tAcc: 0.9550000000 \tTPR:0.9646765252 \tFPR:0.0548695706 \tF1:0.9539335934 \t AUC:0.9549034773\tTrain cost: 0:00:37\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1133707314 \tAcc: 0.9568750000 \tTPR:0.9684201578 \tFPR:0.0542493692 \tF1:0.9559322132 \t AUC:0.9570853943\tTrain cost: 0:00:37\n",
      "Client3 Test =>                 \tLoss: 0.1989470669 \tAcc: 0.9314583333 \tTPR:0.8965362679 \tFPR:0.0376561011 \tF1:0.9251722909 \tAUC:0.9294400834 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.1990996190 \tAcc: 0.9346666667 \tTPR:0.9158185958 \tFPR:0.0469544388 \tF1:0.9305803384 \tAUC:0.9344320785\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 15:  =============\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.06719172790207853 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.12205546897282634755\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1283410282 \tAcc: 0.9501699309 \tTPR:0.9611190665 \tFPR:0.0600004046 \tF1:0.9494513849 \t AUC:0.9505593310\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1182622776 \tAcc: 0.9523127880 \tTPR:0.9622708471 \tFPR:0.0573412000 \tF1:0.9517343415 \t AUC:0.9524648235\tTrain cost: 0:00:34\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1159908734 \tAcc: 0.9543721198 \tTPR:0.9626031644 \tFPR:0.0541341982 \tF1:0.9525766798 \t AUC:0.9542344831\tTrain cost: 0:00:37\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1104433479 \tAcc: 0.9578485023 \tTPR:0.9669070391 \tFPR:0.0515027268 \tF1:0.9570773661 \t AUC:0.9577021561\tTrain cost: 0:00:37\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1053357892 \tAcc: 0.9578571429 \tTPR:0.9683792398 \tFPR:0.0514488098 \tF1:0.9561958001 \t AUC:0.9584652150\tTrain cost: 0:00:37\n",
      "Client3 Test =>                 \tLoss: 0.1782042084 \tAcc: 0.9356250000 \tTPR:0.9192566932 \tFPR:0.0498548943 \tF1:0.9309711480 \tAUC:0.9347008995 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.05626716899023436 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.12219734912387271442\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.1281458324 \tAcc: 0.9490149770 \tTPR:0.9599793676 \tFPR:0.0609475927 \tF1:0.9480045073 \t AUC:0.9495158874\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.1194346551 \tAcc: 0.9514256912 \tTPR:0.9606349598 \tFPR:0.0586445673 \tF1:0.9507803614 \t AUC:0.9509951963\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.1095580234 \tAcc: 0.9580328341 \tTPR:0.9644984720 \tFPR:0.0501760237 \tF1:0.9568850638 \t AUC:0.9571612242\tTrain cost: 0:00:34\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.1062714111 \tAcc: 0.9592713134 \tTPR:0.9652826426 \tFPR:0.0463924076 \tF1:0.9578871587 \t AUC:0.9594451175\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.1004359912 \tAcc: 0.9607920507 \tTPR:0.9694662708 \tFPR:0.0473215260 \tF1:0.9601380223 \t AUC:0.9610723724\tTrain cost: 0:00:36\n",
      "Client9 Test =>                 \tLoss: 0.2413195040 \tAcc: 0.9304166667 \tTPR:0.9075648556 \tFPR:0.0438483546 \tF1:0.9281659218 \tAUC:0.9318582505 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.0979779813468246 \tALA epochs: 2\n",
      "Client 0: Local Initial ALA epochs: 2 Loss: 0.11660858974420884593\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1261707525 \tAcc: 0.9496428571 \tTPR:0.9583592686 \tFPR:0.0608936546 \tF1:0.9469838806 \t AUC:0.9487328070\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1146916110 \tAcc: 0.9529435484 \tTPR:0.9619553277 \tFPR:0.0568370473 \tF1:0.9511896018 \t AUC:0.9525591402\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1076665880 \tAcc: 0.9571399770 \tTPR:0.9633018002 \tFPR:0.0496534777 \tF1:0.9552094592 \t AUC:0.9568241612\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1029540677 \tAcc: 0.9584763825 \tTPR:0.9672899649 \tFPR:0.0498258440 \tF1:0.9572832676 \t AUC:0.9587320605\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0974233643 \tAcc: 0.9612500000 \tTPR:0.9690814070 \tFPR:0.0457520761 \tF1:0.9591097306 \t AUC:0.9616646655\tTrain cost: 0:00:36\n",
      "Client0 Test =>                 \tLoss: 0.1989130133 \tAcc: 0.9337500000 \tTPR:0.9312972702 \tFPR:0.0632487776 \tF1:0.9327036861 \tAUC:0.9340242463 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.03796533241934381 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.13319399693737860035\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1292926429 \tAcc: 0.9467799539 \tTPR:0.9583339905 \tFPR:0.0658179065 \tF1:0.9463255101 \t AUC:0.9462580420\tTrain cost: 0:00:34\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1216935785 \tAcc: 0.9502649770 \tTPR:0.9605668409 \tFPR:0.0601115881 \tF1:0.9496295372 \t AUC:0.9502276264\tTrain cost: 0:00:36\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1152029087 \tAcc: 0.9534821429 \tTPR:0.9641478246 \tFPR:0.0582607666 \tF1:0.9531874877 \t AUC:0.9529435290\tTrain cost: 0:00:36\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1120751514 \tAcc: 0.9549942396 \tTPR:0.9651627745 \tFPR:0.0549571048 \tF1:0.9541128108 \t AUC:0.9551028348\tTrain cost: 0:00:36\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1005347909 \tAcc: 0.9592828341 \tTPR:0.9677806781 \tFPR:0.0509288922 \tF1:0.9591893478 \t AUC:0.9584258929\tTrain cost: 0:00:36\n",
      "Client6 Test =>                 \tLoss: 0.2087503558 \tAcc: 0.9289583333 \tTPR:0.8993386866 \tFPR:0.0436323228 \tF1:0.9221458624 \tAUC:0.9278531819 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.08730911747012561 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.10921175015307423017\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1102678795 \tAcc: 0.9566071429 \tTPR:0.9662282295 \tFPR:0.0532983734 \tF1:0.9559846156 \t AUC:0.9564649280\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1010633448 \tAcc: 0.9600864055 \tTPR:0.9697113496 \tFPR:0.0488670415 \tF1:0.9593979767 \t AUC:0.9604221541\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0912142788 \tAcc: 0.9651756912 \tTPR:0.9740976028 \tFPR:0.0431101531 \tF1:0.9644501457 \t AUC:0.9654937248\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0912159124 \tAcc: 0.9645535714 \tTPR:0.9723720825 \tFPR:0.0431124893 \tF1:0.9640310809 \t AUC:0.9646297966\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0824537968 \tAcc: 0.9676785714 \tTPR:0.9753115403 \tFPR:0.0402910436 \tF1:0.9669206486 \t AUC:0.9675102483\tTrain cost: 0:00:36\n",
      "Client1 Test =>                 \tLoss: 0.1990572707 \tAcc: 0.9362500000 \tTPR:0.9045341621 \tFPR:0.0334382689 \tF1:0.9294984083 \tAUC:0.9355479466 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2052488704 \tAcc: 0.9330000000 \tTPR:0.9123983336 \tFPR:0.0468045236 \tF1:0.9286970053 \tAUC:0.9327969050\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 16:  =============\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.06914880519949247 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.09555443531523148681\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1005339572 \tAcc: 0.9591906682 \tTPR:0.9683729339 \tFPR:0.0495833821 \tF1:0.9584835118 \t AUC:0.9593947759\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0919429794 \tAcc: 0.9652620968 \tTPR:0.9727797336 \tFPR:0.0419735654 \tF1:0.9642853914 \t AUC:0.9654030841\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0850742872 \tAcc: 0.9675000000 \tTPR:0.9758208041 \tFPR:0.0411519077 \tF1:0.9667931066 \t AUC:0.9673344482\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0812881596 \tAcc: 0.9709792627 \tTPR:0.9771982484 \tFPR:0.0364844489 \tF1:0.9707296259 \t AUC:0.9703568997\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0766701958 \tAcc: 0.9700000000 \tTPR:0.9768346229 \tFPR:0.0372381829 \tF1:0.9693709266 \t AUC:0.9697982200\tTrain cost: 0:00:37\n",
      "Client1 Test =>                 \tLoss: 0.2098771828 \tAcc: 0.9356250000 \tTPR:0.9029893115 \tFPR:0.0337423974 \tF1:0.9286711049 \tAUC:0.9346234570 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.06150109974754854 \tALA epochs: 2\n",
      "Client 9: Local Initial ALA epochs: 2 Loss: 0.12119925553249059902\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.1139033445 \tAcc: 0.9556134793 \tTPR:0.9653639058 \tFPR:0.0525541443 \tF1:0.9545996605 \t AUC:0.9564048808\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.1065297848 \tAcc: 0.9599078341 \tTPR:0.9669502516 \tFPR:0.0462892297 \tF1:0.9588318102 \t AUC:0.9603305110\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0943214758 \tAcc: 0.9637442396 \tTPR:0.9723004145 \tFPR:0.0443791587 \tF1:0.9630365285 \t AUC:0.9639606279\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0904380797 \tAcc: 0.9656221198 \tTPR:0.9718767453 \tFPR:0.0414369215 \tF1:0.9651418313 \t AUC:0.9652199119\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0889575430 \tAcc: 0.9657949309 \tTPR:0.9725450684 \tFPR:0.0407419595 \tF1:0.9649449762 \t AUC:0.9659015544\tTrain cost: 0:00:36\n",
      "Client9 Test =>                 \tLoss: 0.2062740132 \tAcc: 0.9377083333 \tTPR:0.9282376899 \tFPR:0.0518213827 \tF1:0.9353837547 \tAUC:0.9382081536 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.04731291908331096 \tALA epochs: 5\n",
      "Client 4: Local Initial ALA epochs: 5 Loss: 0.14726033927602827367\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1371025133 \tAcc: 0.9435656682 \tTPR:0.9579270336 \tFPR:0.0710113351 \tF1:0.9419110139 \t AUC:0.9434578492\tTrain cost: 0:00:35\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1262443290 \tAcc: 0.9492857143 \tTPR:0.9609531388 \tFPR:0.0626757863 \tF1:0.9483419119 \t AUC:0.9491386762\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1223219489 \tAcc: 0.9502620968 \tTPR:0.9624511743 \tFPR:0.0619841910 \tF1:0.9494507307 \t AUC:0.9502334916\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1177752313 \tAcc: 0.9508870968 \tTPR:0.9620905041 \tFPR:0.0588931588 \tF1:0.9495862800 \t AUC:0.9515986727\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1100766756 \tAcc: 0.9569642857 \tTPR:0.9677526000 \tFPR:0.0538082763 \tF1:0.9564785786 \t AUC:0.9569721619\tTrain cost: 0:00:36\n",
      "Client4 Test =>                 \tLoss: 0.1898660552 \tAcc: 0.9383333333 \tTPR:0.9180829865 \tFPR:0.0421469830 \tF1:0.9351868141 \tAUC:0.9379680017 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.03958216483065961 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.10849386577804882859\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1151899911 \tAcc: 0.9538335253 \tTPR:0.9630173045 \tFPR:0.0545024438 \tF1:0.9521651635 \t AUC:0.9542574303\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1040204828 \tAcc: 0.9569614055 \tTPR:0.9661927866 \tFPR:0.0519319708 \tF1:0.9550790964 \t AUC:0.9571304079\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1006435686 \tAcc: 0.9608006912 \tTPR:0.9685289528 \tFPR:0.0469668715 \tF1:0.9590971504 \t AUC:0.9607810407\tTrain cost: 0:00:37\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0948301669 \tAcc: 0.9613392857 \tTPR:0.9682220232 \tFPR:0.0458187368 \tF1:0.9601398735 \t AUC:0.9612016432\tTrain cost: 0:00:37\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0890954589 \tAcc: 0.9652678571 \tTPR:0.9715722751 \tFPR:0.0403695701 \tF1:0.9633836526 \t AUC:0.9656013525\tTrain cost: 0:00:36\n",
      "Client0 Test =>                 \tLoss: 0.2195825462 \tAcc: 0.9325000000 \tTPR:0.9204091408 \tFPR:0.0564938165 \tF1:0.9307046724 \tAUC:0.9319576621 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.06349050632025134 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.12133548026769488959\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1252463236 \tAcc: 0.9497321429 \tTPR:0.9598637101 \tFPR:0.0600039388 \tF1:0.9482011804 \t AUC:0.9499298856\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1170394536 \tAcc: 0.9542857143 \tTPR:0.9625107182 \tFPR:0.0527990124 \tF1:0.9526685688 \t AUC:0.9548558529\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.1114027545 \tAcc: 0.9571399770 \tTPR:0.9675957538 \tFPR:0.0539960283 \tF1:0.9565081982 \t AUC:0.9567998627\tTrain cost: 0:00:37\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.1072644103 \tAcc: 0.9583870968 \tTPR:0.9665077637 \tFPR:0.0476284341 \tF1:0.9569419026 \t AUC:0.9594396648\tTrain cost: 0:00:37\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0993291699 \tAcc: 0.9599884793 \tTPR:0.9677525664 \tFPR:0.0477906949 \tF1:0.9591125424 \t AUC:0.9599809357\tTrain cost: 0:00:37\n",
      "Client2 Test =>                 \tLoss: 0.2161911840 \tAcc: 0.9302083333 \tTPR:0.8940049862 \tFPR:0.0332188433 \tF1:0.9247759777 \tAUC:0.9303930714 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2083581963 \tAcc: 0.9348750000 \tTPR:0.9127448229 \tFPR:0.0434846846 \tF1:0.9309444648 \tAUC:0.9346300692\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 17:  =============\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.06245219046674607 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.11884870134509992190\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1203575469 \tAcc: 0.9533899770 \tTPR:0.9629581244 \tFPR:0.0574336446 \tF1:0.9531551962 \t AUC:0.9527622399\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1089515906 \tAcc: 0.9572235023 \tTPR:0.9691445940 \tFPR:0.0555112526 \tF1:0.9567427455 \t AUC:0.9568166707\tTrain cost: 0:00:37\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1085730685 \tAcc: 0.9569642857 \tTPR:0.9670467243 \tFPR:0.0542984014 \tF1:0.9569680603 \t AUC:0.9563741614\tTrain cost: 0:00:36\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1000545594 \tAcc: 0.9600864055 \tTPR:0.9722215990 \tFPR:0.0505004598 \tF1:0.9599060709 \t AUC:0.9608605696\tTrain cost: 0:00:36\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0924724189 \tAcc: 0.9630357143 \tTPR:0.9720369603 \tFPR:0.0458959796 \tF1:0.9629169477 \t AUC:0.9630704903\tTrain cost: 0:00:36\n",
      "Client6 Test =>                 \tLoss: 0.2198162311 \tAcc: 0.9350000000 \tTPR:0.9158018472 \tFPR:0.0472320563 \tF1:0.9297963333 \tAUC:0.9342848955 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.05774701355589405 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.10400910757185108380\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1187887732 \tAcc: 0.9555328341 \tTPR:0.9659337531 \tFPR:0.0550842201 \tF1:0.9539127733 \t AUC:0.9554247665\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1063071132 \tAcc: 0.9606250000 \tTPR:0.9715455013 \tFPR:0.0485746831 \tF1:0.9595192871 \t AUC:0.9614854091\tTrain cost: 0:00:35\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0983192888 \tAcc: 0.9634821429 \tTPR:0.9690240894 \tFPR:0.0428069688 \tF1:0.9620332307 \t AUC:0.9631085603\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0932427675 \tAcc: 0.9641013825 \tTPR:0.9731971945 \tFPR:0.0461966959 \tF1:0.9637161912 \t AUC:0.9635002493\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0909222820 \tAcc: 0.9651699309 \tTPR:0.9744702099 \tFPR:0.0431058976 \tF1:0.9637254032 \t AUC:0.9656821561\tTrain cost: 0:00:36\n",
      "Client3 Test =>                 \tLoss: 0.1800664081 \tAcc: 0.9408333333 \tTPR:0.9284710767 \tFPR:0.0465562068 \tF1:0.9379085152 \tAUC:0.9409574349 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.08226618943257352 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.09950094389985653098\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.1021424420 \tAcc: 0.9585599078 \tTPR:0.9664950322 \tFPR:0.0512011495 \tF1:0.9569959418 \t AUC:0.9576469413\tTrain cost: 0:00:34\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0923552856 \tAcc: 0.9646313364 \tTPR:0.9735863443 \tFPR:0.0443118401 \tF1:0.9643018264 \t AUC:0.9646372521\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0871452539 \tAcc: 0.9661607143 \tTPR:0.9725734130 \tFPR:0.0410503896 \tF1:0.9649162387 \t AUC:0.9657615117\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0841222753 \tAcc: 0.9668721198 \tTPR:0.9726318633 \tFPR:0.0391880444 \tF1:0.9656729343 \t AUC:0.9667219095\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0773867161 \tAcc: 0.9706221198 \tTPR:0.9777317411 \tFPR:0.0363701554 \tF1:0.9695666213 \t AUC:0.9706807928\tTrain cost: 0:00:36\n",
      "Client9 Test =>                 \tLoss: 0.2295439542 \tAcc: 0.9318750000 \tTPR:0.9092024323 \tFPR:0.0431926337 \tF1:0.9297033672 \tAUC:0.9330048993 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.09848280570673086 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.11541036565018736315\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1151756745 \tAcc: 0.9557114055 \tTPR:0.9677806732 \tFPR:0.0547443185 \tF1:0.9551393980 \t AUC:0.9565181774\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1019711375 \tAcc: 0.9600835253 \tTPR:0.9689601939 \tFPR:0.0489428575 \tF1:0.9590401944 \t AUC:0.9600086682\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0973747731 \tAcc: 0.9609821429 \tTPR:0.9698435028 \tFPR:0.0472008480 \tF1:0.9602569938 \t AUC:0.9613213274\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0922253466 \tAcc: 0.9632114055 \tTPR:0.9688137774 \tFPR:0.0427338231 \tF1:0.9621070782 \t AUC:0.9630399772\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0832963693 \tAcc: 0.9679435484 \tTPR:0.9742794788 \tFPR:0.0387082815 \tF1:0.9673582361 \t AUC:0.9677855987\tTrain cost: 0:00:37\n",
      "Client8 Test =>                 \tLoss: 0.2125039907 \tAcc: 0.9343750000 \tTPR:0.9047687400 \tFPR:0.0358136253 \tF1:0.9300691656 \tAUC:0.9344775574 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.06315438298726371 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.12240019670107225858\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1198842830 \tAcc: 0.9533006912 \tTPR:0.9638497122 \tFPR:0.0567204502 \tF1:0.9527738668 \t AUC:0.9535646310\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1110281004 \tAcc: 0.9566042627 \tTPR:0.9649105899 \tFPR:0.0512762759 \tF1:0.9557465391 \t AUC:0.9568171570\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1053311354 \tAcc: 0.9583899770 \tTPR:0.9666692797 \tFPR:0.0503770754 \tF1:0.9577905148 \t AUC:0.9581461022\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0969997021 \tAcc: 0.9625835253 \tTPR:0.9729001123 \tFPR:0.0477004560 \tF1:0.9624397528 \t AUC:0.9625998282\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0919640560 \tAcc: 0.9644642857 \tTPR:0.9733602136 \tFPR:0.0439389415 \tF1:0.9641079683 \t AUC:0.9647106361\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.1877233278 \tAcc: 0.9381250000 \tTPR:0.9299162271 \tFPR:0.0525835231 \tF1:0.9360377704 \tAUC:0.9386663520 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2059307824 \tAcc: 0.9360416667 \tTPR:0.9176320647 \tFPR:0.0450756090 \tF1:0.9327030303 \tAUC:0.9362782278\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 18:  =============\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.03750526809098592 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.08527704059024868166\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0889222412 \tAcc: 0.9637384793 \tTPR:0.9716238600 \tFPR:0.0451501294 \tF1:0.9629357490 \t AUC:0.9632368653\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0827588315 \tAcc: 0.9674942396 \tTPR:0.9740437459 \tFPR:0.0398151440 \tF1:0.9668918197 \t AUC:0.9671143010\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0754628895 \tAcc: 0.9695506912 \tTPR:0.9787281798 \tFPR:0.0389447626 \tF1:0.9692481637 \t AUC:0.9698917086\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0724159642 \tAcc: 0.9724971198 \tTPR:0.9795596563 \tFPR:0.0335807110 \tF1:0.9720330136 \t AUC:0.9729894726\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0657945970 \tAcc: 0.9737500000 \tTPR:0.9779520787 \tFPR:0.0306537120 \tF1:0.9728155243 \t AUC:0.9736491834\tTrain cost: 0:00:36\n",
      "Client1 Test =>                 \tLoss: 0.2205665910 \tAcc: 0.9400000000 \tTPR:0.9202286698 \tFPR:0.0397708521 \tF1:0.9353469632 \tAUC:0.9402289089 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.05619613681048145 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.11775648382667830427\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1062375103 \tAcc: 0.9590149770 \tTPR:0.9688728307 \tFPR:0.0497827669 \tF1:0.9575595519 \t AUC:0.9595450319\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.0936240113 \tAcc: 0.9640149770 \tTPR:0.9726989195 \tFPR:0.0447565423 \tF1:0.9627641299 \t AUC:0.9639711886\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0892713720 \tAcc: 0.9666042627 \tTPR:0.9745412395 \tFPR:0.0407214202 \tF1:0.9659498652 \t AUC:0.9669099097\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0826945658 \tAcc: 0.9675864055 \tTPR:0.9741341783 \tFPR:0.0390933836 \tF1:0.9665526272 \t AUC:0.9675203974\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0806412274 \tAcc: 0.9687471198 \tTPR:0.9773971920 \tFPR:0.0408022747 \tF1:0.9681274578 \t AUC:0.9682974587\tTrain cost: 0:00:36\n",
      "Client3 Test =>                 \tLoss: 0.1947515093 \tAcc: 0.9383333333 \tTPR:0.9418975872 \tFPR:0.0648743760 \tF1:0.9360641803 \tAUC:0.9385116056 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.07854771776551663 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.12859447938187615335\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1141587341 \tAcc: 0.9544614055 \tTPR:0.9668339163 \tFPR:0.0565489498 \tF1:0.9527415483 \t AUC:0.9551424832\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1045244269 \tAcc: 0.9590092166 \tTPR:0.9684191742 \tFPR:0.0502569628 \tF1:0.9576013940 \t AUC:0.9590811057\tTrain cost: 0:00:37\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0967498822 \tAcc: 0.9613392857 \tTPR:0.9696614318 \tFPR:0.0475422919 \tF1:0.9596866647 \t AUC:0.9610595699\tTrain cost: 0:00:37\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0884053449 \tAcc: 0.9664285714 \tTPR:0.9738640895 \tFPR:0.0414850803 \tF1:0.9653654517 \t AUC:0.9661895046\tTrain cost: 0:00:37\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0781095776 \tAcc: 0.9685685484 \tTPR:0.9742810334 \tFPR:0.0367912588 \tF1:0.9670441403 \t AUC:0.9687448873\tTrain cost: 0:00:37\n",
      "Client0 Test =>                 \tLoss: 0.2285465574 \tAcc: 0.9345833333 \tTPR:0.9170918165 \tFPR:0.0463116522 \tF1:0.9324211574 \tAUC:0.9353900821 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.0732620901179419 \tALA epochs: 2\n",
      "Client 5: Local Initial ALA epochs: 2 Loss: 0.12694366926840250365\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1194047189 \tAcc: 0.9542828341 \tTPR:0.9635745108 \tFPR:0.0557980616 \tF1:0.9532550824 \t AUC:0.9538882246\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1087519642 \tAcc: 0.9566042627 \tTPR:0.9653981214 \tFPR:0.0525545068 \tF1:0.9552966429 \t AUC:0.9564218073\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1044880426 \tAcc: 0.9596370968 \tTPR:0.9667287209 \tFPR:0.0471409075 \tF1:0.9587227493 \t AUC:0.9597939067\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0984398396 \tAcc: 0.9614256912 \tTPR:0.9703028931 \tFPR:0.0467576830 \tF1:0.9603544487 \t AUC:0.9617726050\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0908540329 \tAcc: 0.9649971198 \tTPR:0.9739239362 \tFPR:0.0443500698 \tF1:0.9642680075 \t AUC:0.9647869332\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.1973527969 \tAcc: 0.9310416667 \tTPR:0.9009346404 \tFPR:0.0379360492 \tF1:0.9281520882 \tAUC:0.9314992956 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.08074808967511675 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.12523198926794357200\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.1007724435 \tAcc: 0.9609792627 \tTPR:0.9689241022 \tFPR:0.0472176985 \tF1:0.9608086631 \t AUC:0.9608532018\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0884850532 \tAcc: 0.9658870968 \tTPR:0.9742714344 \tFPR:0.0407739152 \tF1:0.9649659202 \t AUC:0.9667487596\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0806660503 \tAcc: 0.9688392857 \tTPR:0.9754597308 \tFPR:0.0381710858 \tF1:0.9677825688 \t AUC:0.9686443225\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0788856501 \tAcc: 0.9690092166 \tTPR:0.9759006497 \tFPR:0.0376331342 \tF1:0.9675950319 \t AUC:0.9691337577\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0724928892 \tAcc: 0.9716042627 \tTPR:0.9771653673 \tFPR:0.0352975319 \tF1:0.9707650541 \t AUC:0.9709339177\tTrain cost: 0:00:36\n",
      "Client9 Test =>                 \tLoss: 0.2465837769 \tAcc: 0.9356250000 \tTPR:0.9112005549 \tFPR:0.0404449350 \tF1:0.9325344048 \tAUC:0.9353778099 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2175602463 \tAcc: 0.9359166667 \tTPR:0.9182706537 \tFPR:0.0458675729 \tF1:0.9329037588 \tAUC:0.9362015404\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 19:  =============\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.08214040440914161 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.10515766185235933539\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1039376381 \tAcc: 0.9580328341 \tTPR:0.9662029429 \tFPR:0.0497016684 \tF1:0.9566304073 \t AUC:0.9582506372\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0966761974 \tAcc: 0.9624078341 \tTPR:0.9699200640 \tFPR:0.0458832075 \tF1:0.9615053460 \t AUC:0.9620184282\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0905726837 \tAcc: 0.9641935484 \tTPR:0.9712988305 \tFPR:0.0423748479 \tF1:0.9636943538 \t AUC:0.9644619913\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0825393800 \tAcc: 0.9691071429 \tTPR:0.9743793330 \tFPR:0.0368191540 \tF1:0.9681176138 \t AUC:0.9687800895\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0766069199 \tAcc: 0.9709821429 \tTPR:0.9760719377 \tFPR:0.0352712280 \tF1:0.9703336207 \t AUC:0.9704003549\tTrain cost: 0:00:37\n",
      "Client8 Test =>                 \tLoss: 0.1930677603 \tAcc: 0.9406250000 \tTPR:0.9222570974 \tFPR:0.0419181252 \tF1:0.9372007187 \tAUC:0.9401694861 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.02952887473284784 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.10166218632535226063\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.0969311061 \tAcc: 0.9608006912 \tTPR:0.9681536884 \tFPR:0.0458978468 \tF1:0.9585423680 \t AUC:0.9611279208\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0899579384 \tAcc: 0.9647292627 \tTPR:0.9719377453 \tFPR:0.0430937354 \tF1:0.9630953228 \t AUC:0.9644220049\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0825431485 \tAcc: 0.9677649770 \tTPR:0.9738099407 \tFPR:0.0380001028 \tF1:0.9665143986 \t AUC:0.9679049189\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0770198150 \tAcc: 0.9685714286 \tTPR:0.9740294911 \tFPR:0.0370580099 \tF1:0.9673384125 \t AUC:0.9684857406\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0697704405 \tAcc: 0.9733899770 \tTPR:0.9802646628 \tFPR:0.0329443387 \tF1:0.9721828299 \t AUC:0.9736601621\tTrain cost: 0:00:36\n",
      "Client0 Test =>                 \tLoss: 0.2342583616 \tAcc: 0.9337500000 \tTPR:0.9134974868 \tFPR:0.0471128682 \tF1:0.9307845759 \tAUC:0.9331923093 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.06653601855080096 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.11369109338662330977\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1104786449 \tAcc: 0.9570449309 \tTPR:0.9657676207 \tFPR:0.0508426938 \tF1:0.9570490589 \t AUC:0.9574624634\tTrain cost: 0:00:35\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0933263768 \tAcc: 0.9628571429 \tTPR:0.9695935343 \tFPR:0.0438704018 \tF1:0.9621277636 \t AUC:0.9628615662\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0850307694 \tAcc: 0.9661549539 \tTPR:0.9750952309 \tFPR:0.0435027316 \tF1:0.9663756662 \t AUC:0.9657962496\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0825153620 \tAcc: 0.9695506912 \tTPR:0.9770806363 \tFPR:0.0374194493 \tF1:0.9691172121 \t AUC:0.9698305935\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0798306677 \tAcc: 0.9693721198 \tTPR:0.9756613749 \tFPR:0.0360614793 \tF1:0.9691619085 \t AUC:0.9697999478\tTrain cost: 0:00:37\n",
      "Client7 Test =>                 \tLoss: 0.2182455958 \tAcc: 0.9368750000 \tTPR:0.9115460781 \tFPR:0.0366035287 \tF1:0.9312630501 \tAUC:0.9374712747 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.0466065556841777 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.10312940843700282856\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1116266553 \tAcc: 0.9569585253 \tTPR:0.9669447024 \tFPR:0.0528468876 \tF1:0.9562800505 \t AUC:0.9570489074\tTrain cost: 0:00:37\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1025081394 \tAcc: 0.9592828341 \tTPR:0.9706126605 \tFPR:0.0513435221 \tF1:0.9590297080 \t AUC:0.9596345692\tTrain cost: 0:00:37\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0991723797 \tAcc: 0.9608035714 \tTPR:0.9713815902 \tFPR:0.0501958622 \tF1:0.9609336142 \t AUC:0.9605928640\tTrain cost: 0:00:37\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0895425354 \tAcc: 0.9652649770 \tTPR:0.9755571813 \tFPR:0.0444015774 \tF1:0.9650971332 \t AUC:0.9655778020\tTrain cost: 0:00:37\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0819518797 \tAcc: 0.9686607143 \tTPR:0.9773211328 \tFPR:0.0411079985 \tF1:0.9682910277 \t AUC:0.9681065672\tTrain cost: 0:00:36\n",
      "Client6 Test =>                 \tLoss: 0.2084532361 \tAcc: 0.9414583333 \tTPR:0.9387979926 \tFPR:0.0559930709 \tF1:0.9393929148 \tAUC:0.9414024609 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.049124365501421983 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.09040961248557204122\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0851244207 \tAcc: 0.9663306452 \tTPR:0.9755631066 \tFPR:0.0420222288 \tF1:0.9653199699 \t AUC:0.9667704389\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0742623449 \tAcc: 0.9702620968 \tTPR:0.9771534496 \tFPR:0.0370787575 \tF1:0.9699915400 \t AUC:0.9700373461\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0689147685 \tAcc: 0.9724971198 \tTPR:0.9785848756 \tFPR:0.0334169475 \tF1:0.9722971999 \t AUC:0.9725839640\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0649025536 \tAcc: 0.9767828341 \tTPR:0.9836473733 \tFPR:0.0310353096 \tF1:0.9766249037 \t AUC:0.9763060319\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0583424386 \tAcc: 0.9787500000 \tTPR:0.9833626979 \tFPR:0.0263922076 \tF1:0.9779923157 \t AUC:0.9784852452\tTrain cost: 0:00:36\n",
      "Client1 Test =>                 \tLoss: 0.1811331812 \tAcc: 0.9504166667 \tTPR:0.9493721357 \tFPR:0.0485388500 \tF1:0.9480344060 \tAUC:0.9504166428 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2070316270 \tAcc: 0.9406250000 \tTPR:0.9270941581 \tFPR:0.0460332886 \tF1:0.9373351331 \tAUC:0.9405304348\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 20:  =============\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.0702899573622488 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.08871039976298376872\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.0765703648 \tAcc: 0.9692799539 \tTPR:0.9760233405 \tFPR:0.0368258883 \tF1:0.9684380729 \t AUC:0.9695987261\tTrain cost: 0:00:35\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0761312313 \tAcc: 0.9696399770 \tTPR:0.9767314103 \tFPR:0.0369071276 \tF1:0.9682736287 \t AUC:0.9699121413\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0668732167 \tAcc: 0.9738364055 \tTPR:0.9797073352 \tFPR:0.0316441069 \tF1:0.9730406112 \t AUC:0.9740316142\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0602188298 \tAcc: 0.9772292627 \tTPR:0.9825864857 \tFPR:0.0277203549 \tF1:0.9761793121 \t AUC:0.9774330654\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0571080679 \tAcc: 0.9783006912 \tTPR:0.9829895169 \tFPR:0.0263755833 \tF1:0.9773300048 \t AUC:0.9783069668\tTrain cost: 0:00:36\n",
      "Client0 Test =>                 \tLoss: 0.2502027885 \tAcc: 0.9368750000 \tTPR:0.9325349233 \tFPR:0.0570062845 \tF1:0.9358116027 \tAUC:0.9377643194 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.08970463608982869 \tALA epochs: 2\n",
      "Client 5: Local Initial ALA epochs: 2 Loss: 0.13490023770440451312\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1169718709 \tAcc: 0.9565092166 \tTPR:0.9661112270 \tFPR:0.0536355602 \tF1:0.9557947136 \t AUC:0.9562378334\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1020328460 \tAcc: 0.9591013825 \tTPR:0.9672133108 \tFPR:0.0484731049 \tF1:0.9587287533 \t AUC:0.9593701029\tTrain cost: 0:00:35\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0954441864 \tAcc: 0.9641013825 \tTPR:0.9726313766 \tFPR:0.0454302864 \tF1:0.9634941744 \t AUC:0.9636005451\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0904037045 \tAcc: 0.9645506912 \tTPR:0.9718158867 \tFPR:0.0438212724 \tF1:0.9639428457 \t AUC:0.9639973072\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0837194511 \tAcc: 0.9677678571 \tTPR:0.9771896744 \tFPR:0.0415011658 \tF1:0.9674101189 \t AUC:0.9678442543\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.1984911235 \tAcc: 0.9370833333 \tTPR:0.9205859779 \tFPR:0.0456852436 \tF1:0.9350090908 \tAUC:0.9374503671 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.06936238493580302 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.13258998125683571501\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1274660830 \tAcc: 0.9493692396 \tTPR:0.9601934374 \tFPR:0.0611484904 \tF1:0.9481118067 \t AUC:0.9495224735\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1140424943 \tAcc: 0.9535656682 \tTPR:0.9646400971 \tFPR:0.0575639585 \tF1:0.9526780162 \t AUC:0.9535380693\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1057935400 \tAcc: 0.9569642857 \tTPR:0.9645879879 \tFPR:0.0509622056 \tF1:0.9555068608 \t AUC:0.9568128912\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1024098632 \tAcc: 0.9594614055 \tTPR:0.9669284830 \tFPR:0.0491193418 \tF1:0.9576678157 \t AUC:0.9589045706\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0951325972 \tAcc: 0.9620535714 \tTPR:0.9705883009 \tFPR:0.0472671543 \tF1:0.9614801475 \t AUC:0.9616605733\tTrain cost: 0:00:37\n",
      "Client4 Test =>                 \tLoss: 0.1741632031 \tAcc: 0.9431250000 \tTPR:0.9376062280 \tFPR:0.0513666770 \tF1:0.9416125565 \tAUC:0.9431197755 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.03139720490799075 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.09260852200964438119\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0939526691 \tAcc: 0.9635656682 \tTPR:0.9705465219 \tFPR:0.0434339080 \tF1:0.9627807835 \t AUC:0.9635563069\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0830165717 \tAcc: 0.9679435484 \tTPR:0.9749549438 \tFPR:0.0381688486 \tF1:0.9672978610 \t AUC:0.9683930476\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0760231007 \tAcc: 0.9708006912 \tTPR:0.9780749229 \tFPR:0.0363550373 \tF1:0.9703587549 \t AUC:0.9708599428\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0688627654 \tAcc: 0.9743692396 \tTPR:0.9799401075 \tFPR:0.0302154763 \tF1:0.9739292795 \t AUC:0.9748623156\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0650339969 \tAcc: 0.9758842166 \tTPR:0.9804467566 \tFPR:0.0283871589 \tF1:0.9747204582 \t AUC:0.9760297988\tTrain cost: 0:00:36\n",
      "Client8 Test =>                 \tLoss: 0.2363961160 \tAcc: 0.9333333333 \tTPR:0.9068876378 \tFPR:0.0375589423 \tF1:0.9292603163 \tAUC:0.9346643477 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.0912572757511705 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.10921157185879090679\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.0983167568 \tAcc: 0.9622263825 \tTPR:0.9689991121 \tFPR:0.0438598679 \tF1:0.9607965124 \t AUC:0.9625696221\tTrain cost: 0:00:37\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.0888410323 \tAcc: 0.9667799539 \tTPR:0.9733858606 \tFPR:0.0402600617 \tF1:0.9657635172 \t AUC:0.9665628994\tTrain cost: 0:00:37\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0827118109 \tAcc: 0.9685656682 \tTPR:0.9752389906 \tFPR:0.0385038230 \tF1:0.9679286711 \t AUC:0.9683675838\tTrain cost: 0:00:37\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0770353755 \tAcc: 0.9711607143 \tTPR:0.9793850665 \tFPR:0.0363304366 \tF1:0.9704861123 \t AUC:0.9715273150\tTrain cost: 0:00:37\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0756992618 \tAcc: 0.9714285714 \tTPR:0.9788306986 \tFPR:0.0361829957 \tF1:0.9705292293 \t AUC:0.9713238514\tTrain cost: 0:00:37\n",
      "Client3 Test =>                 \tLoss: 0.1886003950 \tAcc: 0.9450000000 \tTPR:0.9304841644 \tFPR:0.0419404420 \tF1:0.9422692459 \tAUC:0.9442718612 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2095707252 \tAcc: 0.9390833333 \tTPR:0.9256197863 \tFPR:0.0467115179 \tF1:0.9367925624 \tAUC:0.9394541342\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 21:  =============\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.07380040496930436 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.13303468596406173297\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1227614900 \tAcc: 0.9512413594 \tTPR:0.9599668884 \tFPR:0.0573441511 \tF1:0.9501789274 \t AUC:0.9513113687\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1085185404 \tAcc: 0.9573185484 \tTPR:0.9661946116 \tFPR:0.0518257826 \tF1:0.9564853825 \t AUC:0.9571844145\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.1048680454 \tAcc: 0.9605299539 \tTPR:0.9682536891 \tFPR:0.0474105603 \tF1:0.9598536787 \t AUC:0.9604215644\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.1005194922 \tAcc: 0.9615149770 \tTPR:0.9692026532 \tFPR:0.0448268282 \tF1:0.9605103794 \t AUC:0.9621879125\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0964661067 \tAcc: 0.9626728111 \tTPR:0.9711289103 \tFPR:0.0464942554 \tF1:0.9618885496 \t AUC:0.9623173274\tTrain cost: 0:00:37\n",
      "Client2 Test =>                 \tLoss: 0.1646180000 \tAcc: 0.9475000000 \tTPR:0.9409013960 \tFPR:0.0454245162 \tF1:0.9453806911 \tAUC:0.9477384399 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.06863861710235174 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.13496097330462888952\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1113686687 \tAcc: 0.9562471198 \tTPR:0.9672592861 \tFPR:0.0537304054 \tF1:0.9554916058 \t AUC:0.9567644404\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1016400460 \tAcc: 0.9600000000 \tTPR:0.9690363002 \tFPR:0.0485578083 \tF1:0.9590591356 \t AUC:0.9602392459\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0960979529 \tAcc: 0.9630328341 \tTPR:0.9723082869 \tFPR:0.0469028168 \tF1:0.9620241590 \t AUC:0.9627027350\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0903360332 \tAcc: 0.9650835253 \tTPR:0.9743168441 \tFPR:0.0446865326 \tF1:0.9646995087 \t AUC:0.9648151557\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0850590220 \tAcc: 0.9674942396 \tTPR:0.9742023205 \tFPR:0.0399703863 \tF1:0.9665836022 \t AUC:0.9671159671\tTrain cost: 0:00:37\n",
      "Client4 Test =>                 \tLoss: 0.1747484797 \tAcc: 0.9447916667 \tTPR:0.9390472050 \tFPR:0.0492382421 \tF1:0.9428604929 \tAUC:0.9449044815 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.0844402854179312 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.09256934327329846557\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.0998560854 \tAcc: 0.9615178571 \tTPR:0.9714573629 \tFPR:0.0482839818 \tF1:0.9608340016 \t AUC:0.9615866905\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.0850143294 \tAcc: 0.9677620968 \tTPR:0.9753608303 \tFPR:0.0398670836 \tF1:0.9666263079 \t AUC:0.9677468733\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0791562230 \tAcc: 0.9679435484 \tTPR:0.9734346072 \tFPR:0.0382197222 \tF1:0.9669307995 \t AUC:0.9676074425\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0747578526 \tAcc: 0.9695478111 \tTPR:0.9762369252 \tFPR:0.0373937660 \tF1:0.9688872971 \t AUC:0.9694215796\tTrain cost: 0:00:36\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0709703155 \tAcc: 0.9733928571 \tTPR:0.9792823126 \tFPR:0.0333845541 \tF1:0.9726682256 \t AUC:0.9729488792\tTrain cost: 0:00:37\n",
      "Client3 Test =>                 \tLoss: 0.1833986347 \tAcc: 0.9456250000 \tTPR:0.9313979538 \tFPR:0.0408563501 \tF1:0.9428495171 \tAUC:0.9452708019 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.04818688330582859 \tALA epochs: 2\n",
      "Client 9: Local Initial ALA epochs: 2 Loss: 0.11656777243521335152\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.1026325798 \tAcc: 0.9611578341 \tTPR:0.9665488105 \tFPR:0.0449550388 \tF1:0.9600760101 \t AUC:0.9607968858\tTrain cost: 0:00:37\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0919593987 \tAcc: 0.9656192396 \tTPR:0.9719668444 \tFPR:0.0402636275 \tF1:0.9642766317 \t AUC:0.9658516085\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0818912531 \tAcc: 0.9687500000 \tTPR:0.9736347332 \tFPR:0.0355837461 \tF1:0.9675065659 \t AUC:0.9690254935\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0768579260 \tAcc: 0.9717857143 \tTPR:0.9761876830 \tFPR:0.0336163598 \tF1:0.9706694532 \t AUC:0.9712856616\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0733673053 \tAcc: 0.9715178571 \tTPR:0.9760672221 \tFPR:0.0329085886 \tF1:0.9707203454 \t AUC:0.9715793168\tTrain cost: 0:00:36\n",
      "Client9 Test =>                 \tLoss: 0.1951311152 \tAcc: 0.9450000000 \tTPR:0.9440999687 \tFPR:0.0552512290 \tF1:0.9426553904 \tAUC:0.9444243699 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.07204902813752938 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.08930818821586992973\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0907775415 \tAcc: 0.9619614055 \tTPR:0.9699839407 \tFPR:0.0455253627 \tF1:0.9614679759 \t AUC:0.9622292890\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0786975344 \tAcc: 0.9671370968 \tTPR:0.9720386978 \tFPR:0.0370660678 \tF1:0.9664160694 \t AUC:0.9674863150\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0729837413 \tAcc: 0.9719585253 \tTPR:0.9778816617 \tFPR:0.0329518568 \tF1:0.9709093545 \t AUC:0.9724649025\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0638461364 \tAcc: 0.9742857143 \tTPR:0.9800109497 \tFPR:0.0315433559 \tF1:0.9736783387 \t AUC:0.9742337969\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0606737420 \tAcc: 0.9758899770 \tTPR:0.9785719879 \tFPR:0.0268257377 \tF1:0.9749026171 \t AUC:0.9758731251\tTrain cost: 0:00:37\n",
      "Client8 Test =>                 \tLoss: 0.1888081518 \tAcc: 0.9462500000 \tTPR:0.9337767386 \tFPR:0.0413296752 \tF1:0.9422795246 \tAUC:0.9462235317 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.1813408763 \tAcc: 0.9458333333 \tTPR:0.9378446524 \tFPR:0.0464200025 \tF1:0.9432051232 \tAUC:0.9457123250\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 22:  =============\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.053649063108815426 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.10075287126760551493\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1067321288 \tAcc: 0.9595535714 \tTPR:0.9711688267 \tFPR:0.0516001824 \tF1:0.9593925260 \t AUC:0.9597843221\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.0926929866 \tAcc: 0.9632978111 \tTPR:0.9730319607 \tFPR:0.0459868228 \tF1:0.9633434670 \t AUC:0.9635225689\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0862567458 \tAcc: 0.9652649770 \tTPR:0.9723612169 \tFPR:0.0426113915 \tF1:0.9641652730 \t AUC:0.9648749127\tTrain cost: 0:00:35\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0823815870 \tAcc: 0.9669527650 \tTPR:0.9749154959 \tFPR:0.0419369718 \tF1:0.9668863950 \t AUC:0.9664892620\tTrain cost: 0:00:36\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0760487508 \tAcc: 0.9710714286 \tTPR:0.9786424800 \tFPR:0.0356103124 \tF1:0.9705300472 \t AUC:0.9715160838\tTrain cost: 0:00:36\n",
      "Client6 Test =>                 \tLoss: 0.2103703826 \tAcc: 0.9414583333 \tTPR:0.9354212717 \tFPR:0.0526783936 \tF1:0.9394630639 \tAUC:0.9413714391 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.0848716153620695 \tALA epochs: 2\n",
      "Client 0: Local Initial ALA epochs: 2 Loss: 0.09265961821622931138\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.0820176171 \tAcc: 0.9677649770 \tTPR:0.9749544199 \tFPR:0.0393312249 \tF1:0.9664908897 \t AUC:0.9678115975\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0739995145 \tAcc: 0.9703571429 \tTPR:0.9778157247 \tFPR:0.0364522421 \tF1:0.9687452455 \t AUC:0.9706817413\tTrain cost: 0:00:37\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0661831380 \tAcc: 0.9732978111 \tTPR:0.9798567354 \tFPR:0.0328169824 \tF1:0.9719211821 \t AUC:0.9735198765\tTrain cost: 0:00:37\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0590898817 \tAcc: 0.9760685484 \tTPR:0.9813982243 \tFPR:0.0294770629 \tF1:0.9752764389 \t AUC:0.9759605807\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0525297886 \tAcc: 0.9800000000 \tTPR:0.9844571554 \tFPR:0.0240589949 \tF1:0.9786956399 \t AUC:0.9801990802\tTrain cost: 0:00:36\n",
      "Client0 Test =>                 \tLoss: 0.2803696312 \tAcc: 0.9293750000 \tTPR:0.8940521894 \tFPR:0.0347508713 \tF1:0.9255711022 \tAUC:0.9296506591 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.0774791816312334 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.13902572750289371450\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1027195759 \tAcc: 0.9601785714 \tTPR:0.9684030728 \tFPR:0.0488280402 \tF1:0.9593901346 \t AUC:0.9597875163\tTrain cost: 0:00:35\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0878402043 \tAcc: 0.9653571429 \tTPR:0.9737843204 \tFPR:0.0427459388 \tF1:0.9645926492 \t AUC:0.9655191908\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0831460225 \tAcc: 0.9670506912 \tTPR:0.9752324459 \tFPR:0.0409986067 \tF1:0.9664029145 \t AUC:0.9671169196\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0799109968 \tAcc: 0.9673185484 \tTPR:0.9744694128 \tFPR:0.0399807501 \tF1:0.9669515289 \t AUC:0.9672443313\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0754563498 \tAcc: 0.9704406682 \tTPR:0.9768107386 \tFPR:0.0361142465 \tF1:0.9692298397 \t AUC:0.9703482460\tTrain cost: 0:00:37\n",
      "Client4 Test =>                 \tLoss: 0.1856611389 \tAcc: 0.9410416667 \tTPR:0.9363109803 \tFPR:0.0551380613 \tF1:0.9387399403 \tAUC:0.9405864595 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.05188341611388146 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.08598063553454003693\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0952229107 \tAcc: 0.9636607143 \tTPR:0.9722194148 \tFPR:0.0454284387 \tF1:0.9639193047 \t AUC:0.9633954880\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0890424893 \tAcc: 0.9644556452 \tTPR:0.9723494358 \tFPR:0.0431601431 \tF1:0.9643162288 \t AUC:0.9645946464\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0825605496 \tAcc: 0.9663335253 \tTPR:0.9725983437 \tFPR:0.0396897334 \tF1:0.9664651164 \t AUC:0.9664543051\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0758220853 \tAcc: 0.9683928571 \tTPR:0.9741526151 \tFPR:0.0367765215 \tF1:0.9682341836 \t AUC:0.9686880468\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0680998802 \tAcc: 0.9733006912 \tTPR:0.9800081152 \tFPR:0.0333892063 \tF1:0.9737477384 \t AUC:0.9733094545\tTrain cost: 0:00:36\n",
      "Client7 Test =>                 \tLoss: 0.1965491382 \tAcc: 0.9429166667 \tTPR:0.9231675427 \tFPR:0.0376817438 \tF1:0.9397563880 \tAUC:0.9427428995 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.05459369232468443 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.08974751318548468415\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0979044714 \tAcc: 0.9613335253 \tTPR:0.9689149593 \tFPR:0.0461098953 \tF1:0.9599598990 \t AUC:0.9614025320\tTrain cost: 0:00:37\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0869308885 \tAcc: 0.9669642857 \tTPR:0.9725112051 \tFPR:0.0388653914 \tF1:0.9663379197 \t AUC:0.9668229069\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0816827547 \tAcc: 0.9684792627 \tTPR:0.9746749466 \tFPR:0.0374320472 \tF1:0.9679593361 \t AUC:0.9686214497\tTrain cost: 0:00:37\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0731132456 \tAcc: 0.9720506912 \tTPR:0.9775523909 \tFPR:0.0337774409 \tF1:0.9710342691 \t AUC:0.9718874750\tTrain cost: 0:00:37\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0680219577 \tAcc: 0.9749107143 \tTPR:0.9803013015 \tFPR:0.0300122659 \tF1:0.9738059280 \t AUC:0.9751445178\tTrain cost: 0:00:36\n",
      "Client9 Test =>                 \tLoss: 0.2025125667 \tAcc: 0.9406250000 \tTPR:0.9335443712 \tFPR:0.0526023803 \tF1:0.9395009292 \tAUC:0.9404709955 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2150925715 \tAcc: 0.9390833333 \tTPR:0.9244992711 \tFPR:0.0465702900 \tF1:0.9366062847 \tAUC:0.9389644905\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 23:  =============\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.04325047289617689 \tALA epochs: 2\n",
      "Client 1: Local Initial ALA epochs: 2 Loss: 0.08531411354888931986\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0844582554 \tAcc: 0.9668721198 \tTPR:0.9757957316 \tFPR:0.0413802416 \tF1:0.9660335178 \t AUC:0.9672077450\tTrain cost: 0:00:35\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0747843236 \tAcc: 0.9708035714 \tTPR:0.9772173933 \tFPR:0.0353284779 \tF1:0.9704722311 \t AUC:0.9709444577\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0671297329 \tAcc: 0.9734792627 \tTPR:0.9808064033 \tFPR:0.0348543732 \tF1:0.9730931927 \t AUC:0.9729760150\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0621429507 \tAcc: 0.9758035714 \tTPR:0.9810631405 \tFPR:0.0292842362 \tF1:0.9755960795 \t AUC:0.9758894522\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0616831030 \tAcc: 0.9758899770 \tTPR:0.9817479547 \tFPR:0.0310141578 \tF1:0.9757460490 \t AUC:0.9753668984\tTrain cost: 0:00:37\n",
      "Client1 Test =>                 \tLoss: 0.1888624897 \tAcc: 0.9464583333 \tTPR:0.9385801369 \tFPR:0.0467547150 \tF1:0.9426018151 \tAUC:0.9459127109 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.09758925635090526 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.09137918742076642231\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.0888918388 \tAcc: 0.9646428571 \tTPR:0.9731708138 \tFPR:0.0433232640 \tF1:0.9638756756 \t AUC:0.9649237749\tTrain cost: 0:00:37\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.0775534385 \tAcc: 0.9700000000 \tTPR:0.9770755120 \tFPR:0.0358165640 \tF1:0.9694647205 \t AUC:0.9706294740\tTrain cost: 0:00:37\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0738164193 \tAcc: 0.9713364055 \tTPR:0.9774165631 \tFPR:0.0352123530 \tF1:0.9705949220 \t AUC:0.9711021050\tTrain cost: 0:00:37\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0644694258 \tAcc: 0.9744614055 \tTPR:0.9805753096 \tFPR:0.0308881155 \tF1:0.9735478338 \t AUC:0.9748435971\tTrain cost: 0:00:37\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0608509846 \tAcc: 0.9779464286 \tTPR:0.9812140043 \tFPR:0.0248261628 \tF1:0.9766510164 \t AUC:0.9781939207\tTrain cost: 0:00:37\n",
      "Client3 Test =>                 \tLoss: 0.1956330618 \tAcc: 0.9456250000 \tTPR:0.9332368148 \tFPR:0.0431536451 \tF1:0.9418995499 \tAUC:0.9450415849 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.029294111366276396 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.06789312269066230532\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.0714271354 \tAcc: 0.9732114055 \tTPR:0.9806018403 \tFPR:0.0336486313 \tF1:0.9717511034 \t AUC:0.9734766045\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0608952809 \tAcc: 0.9772292627 \tTPR:0.9804372421 \tFPR:0.0259634900 \tF1:0.9757072980 \t AUC:0.9772368760\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0550014939 \tAcc: 0.9781250000 \tTPR:0.9828742491 \tFPR:0.0261622294 \tF1:0.9769666320 \t AUC:0.9783560099\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0496802060 \tAcc: 0.9795535714 \tTPR:0.9831975100 \tFPR:0.0239292728 \tF1:0.9789212313 \t AUC:0.9796341186\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0491856715 \tAcc: 0.9816935484 \tTPR:0.9853334908 \tFPR:0.0212820533 \tF1:0.9804042986 \t AUC:0.9820257188\tTrain cost: 0:00:36\n",
      "Client0 Test =>                 \tLoss: 0.2513023562 \tAcc: 0.9366666667 \tTPR:0.9201034086 \tFPR:0.0461984832 \tF1:0.9350579765 \tAUC:0.9369524627 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.04995598386130859 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.09105696290667317228\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0940920096 \tAcc: 0.9621428571 \tTPR:0.9686640791 \tFPR:0.0440109586 \tF1:0.9617836632 \t AUC:0.9623265602\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0826245658 \tAcc: 0.9662442396 \tTPR:0.9727713679 \tFPR:0.0402835854 \tF1:0.9661387506 \t AUC:0.9662438912\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0759568362 \tAcc: 0.9685714286 \tTPR:0.9749574283 \tFPR:0.0384710711 \tF1:0.9685217544 \t AUC:0.9682431786\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0713618675 \tAcc: 0.9700835253 \tTPR:0.9765051277 \tFPR:0.0369421341 \tF1:0.9702511625 \t AUC:0.9697814968\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0658874362 \tAcc: 0.9739228111 \tTPR:0.9778524255 \tFPR:0.0303504221 \tF1:0.9735272569 \t AUC:0.9737510017\tTrain cost: 0:00:37\n",
      "Client7 Test =>                 \tLoss: 0.2327258134 \tAcc: 0.9395833333 \tTPR:0.9068895320 \tFPR:0.0273987731 \tF1:0.9357854512 \tAUC:0.9397453795 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.07132300882089211 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.13670121877373236918\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1126002329 \tAcc: 0.9553571429 \tTPR:0.9624149983 \tFPR:0.0516454624 \tF1:0.9537620991 \t AUC:0.9553847679\tTrain cost: 0:00:37\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0989494182 \tAcc: 0.9633006912 \tTPR:0.9727358536 \tFPR:0.0449954243 \tF1:0.9625223962 \t AUC:0.9638702146\tTrain cost: 0:00:37\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0928401332 \tAcc: 0.9641935484 \tTPR:0.9739630911 \tFPR:0.0451397110 \tF1:0.9639099120 \t AUC:0.9644116900\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0869969900 \tAcc: 0.9666906682 \tTPR:0.9744400533 \tFPR:0.0408520157 \tF1:0.9660277309 \t AUC:0.9667940188\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0819075118 \tAcc: 0.9695478111 \tTPR:0.9769767219 \tFPR:0.0374206159 \tF1:0.9692142511 \t AUC:0.9697780530\tTrain cost: 0:00:36\n",
      "Client2 Test =>                 \tLoss: 0.1857849263 \tAcc: 0.9435416667 \tTPR:0.9220436434 \tFPR:0.0345107883 \tF1:0.9411145674 \tAUC:0.9437664276 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2108617295 \tAcc: 0.9423750000 \tTPR:0.9241707071 \tFPR:0.0396032809 \tF1:0.9392918720 \tAUC:0.9422837131\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 24:  =============\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.05283622210849244 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.05518689393605766963\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.0575712972 \tAcc: 0.9782114055 \tTPR:0.9833669285 \tFPR:0.0265842696 \tF1:0.9775083612 \t AUC:0.9783913295\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0458974846 \tAcc: 0.9819642857 \tTPR:0.9856354782 \tFPR:0.0215900903 \tF1:0.9812752396 \t AUC:0.9820226940\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0422721259 \tAcc: 0.9827678571 \tTPR:0.9849393297 \tFPR:0.0195685509 \tF1:0.9822124540 \t AUC:0.9826853894\tTrain cost: 0:00:37\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0414820865 \tAcc: 0.9834821429 \tTPR:0.9860684368 \tFPR:0.0193899372 \tF1:0.9828628334 \t AUC:0.9833392498\tTrain cost: 0:00:37\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0415286296 \tAcc: 0.9849107143 \tTPR:0.9887661678 \tFPR:0.0192177610 \tF1:0.9844826913 \t AUC:0.9847742034\tTrain cost: 0:00:37\n",
      "Client0 Test =>                 \tLoss: 0.2584068981 \tAcc: 0.9377083333 \tTPR:0.9217736281 \tFPR:0.0465808603 \tF1:0.9356833043 \tAUC:0.9375963839 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.0730759305997226 \tALA epochs: 2\n",
      "Client 5: Local Initial ALA epochs: 2 Loss: 0.13684454625404940398\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1111034018 \tAcc: 0.9574078341 \tTPR:0.9680678185 \tFPR:0.0532911215 \tF1:0.9572031134 \t AUC:0.9573883485\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0957568356 \tAcc: 0.9631250000 \tTPR:0.9712848832 \tFPR:0.0456608558 \tF1:0.9625660131 \t AUC:0.9628120137\tTrain cost: 0:00:35\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0883849729 \tAcc: 0.9654464286 \tTPR:0.9739345922 \tFPR:0.0425172505 \tF1:0.9644887051 \t AUC:0.9657086708\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0796872677 \tAcc: 0.9696428571 \tTPR:0.9766218768 \tFPR:0.0370009601 \tF1:0.9693330710 \t AUC:0.9698104583\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0780867256 \tAcc: 0.9702649770 \tTPR:0.9775521111 \tFPR:0.0370798455 \tF1:0.9700641009 \t AUC:0.9702361328\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.1883275765 \tAcc: 0.9406250000 \tTPR:0.9217122715 \tFPR:0.0415034346 \tF1:0.9375509528 \tAUC:0.9401044185 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.07410706257632098 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.07287731989408316458\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0861801712 \tAcc: 0.9668721198 \tTPR:0.9739043843 \tFPR:0.0408558279 \tF1:0.9669092859 \t AUC:0.9665242782\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0741782980 \tAcc: 0.9729464286 \tTPR:0.9781731308 \tFPR:0.0322723209 \tF1:0.9724892269 \t AUC:0.9729504050\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0670954879 \tAcc: 0.9734792627 \tTPR:0.9795483249 \tFPR:0.0338235927 \tF1:0.9736752910 \t AUC:0.9728623661\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0649643918 \tAcc: 0.9749971198 \tTPR:0.9794281700 \tFPR:0.0296071133 \tF1:0.9745762154 \t AUC:0.9749105283\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0577423898 \tAcc: 0.9770535714 \tTPR:0.9815494802 \tFPR:0.0267984780 \tF1:0.9765609698 \t AUC:0.9773755011\tTrain cost: 0:00:37\n",
      "Client7 Test =>                 \tLoss: 0.1875547264 \tAcc: 0.9462500000 \tTPR:0.9311081875 \tFPR:0.0373452944 \tF1:0.9438757329 \tAUC:0.9468814466 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.0667805080864906 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.11215780485097480434\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1000461141 \tAcc: 0.9602649770 \tTPR:0.9674684612 \tFPR:0.0470261137 \tF1:0.9595014316 \t AUC:0.9602211738\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0849057116 \tAcc: 0.9671399770 \tTPR:0.9747172536 \tFPR:0.0394750366 \tF1:0.9663142921 \t AUC:0.9676211085\tTrain cost: 0:00:34\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0794205898 \tAcc: 0.9683006912 \tTPR:0.9748397591 \tFPR:0.0378735180 \tF1:0.9671659412 \t AUC:0.9684831206\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0722640310 \tAcc: 0.9727678571 \tTPR:0.9787264158 \tFPR:0.0322149565 \tF1:0.9719564372 \t AUC:0.9732557296\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0681420332 \tAcc: 0.9719642857 \tTPR:0.9790560965 \tFPR:0.0344493042 \tF1:0.9718162796 \t AUC:0.9723033961\tTrain cost: 0:00:37\n",
      "Client4 Test =>                 \tLoss: 0.2015170390 \tAcc: 0.9414583333 \tTPR:0.9411681043 \tFPR:0.0586027964 \tF1:0.9412241967 \tAUC:0.9412826540 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.055794367334941176 \tALA epochs: 3\n",
      "Client 1: Local Initial ALA epochs: 3 Loss: 0.07857098096671204235\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0785077668 \tAcc: 0.9685656682 \tTPR:0.9755057481 \tFPR:0.0375921664 \tF1:0.9678167758 \t AUC:0.9689567908\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0660974332 \tAcc: 0.9747321429 \tTPR:0.9809828835 \tFPR:0.0321356321 \tF1:0.9745157544 \t AUC:0.9744236257\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0621522044 \tAcc: 0.9746399770 \tTPR:0.9800936888 \tFPR:0.0309561708 \tF1:0.9741887433 \t AUC:0.9745687590\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0536911334 \tAcc: 0.9786549539 \tTPR:0.9832325364 \tFPR:0.0257262488 \tF1:0.9781983081 \t AUC:0.9787531438\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0498459631 \tAcc: 0.9808928571 \tTPR:0.9859738315 \tFPR:0.0240893665 \tF1:0.9805475011 \t AUC:0.9809422325\tTrain cost: 0:00:37\n",
      "Client1 Test =>                 \tLoss: 0.2182175127 \tAcc: 0.9416666667 \tTPR:0.9193169160 \tFPR:0.0381754552 \tF1:0.9349332193 \tAUC:0.9405707304 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2108047505 \tAcc: 0.9415416667 \tTPR:0.9270158215 \tFPR:0.0444415682 \tF1:0.9386534812 \tAUC:0.9412871267\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 25:  =============\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.047066771542018764 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.06215771429065237302\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0672712684 \tAcc: 0.9734821429 \tTPR:0.9780976830 \tFPR:0.0312711321 \tF1:0.9731931033 \t AUC:0.9734132755\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0642586256 \tAcc: 0.9743750000 \tTPR:0.9800552994 \tFPR:0.0315568039 \tF1:0.9743554052 \t AUC:0.9742492477\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0533512539 \tAcc: 0.9797321429 \tTPR:0.9836639892 \tFPR:0.0241938286 \tF1:0.9793345955 \t AUC:0.9797350803\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0524376480 \tAcc: 0.9795506912 \tTPR:0.9830910023 \tFPR:0.0243296109 \tF1:0.9794301612 \t AUC:0.9793806957\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0499602142 \tAcc: 0.9808928571 \tTPR:0.9839504071 \tFPR:0.0217082901 \tF1:0.9807389491 \t AUC:0.9811210585\tTrain cost: 0:00:36\n",
      "Client7 Test =>                 \tLoss: 0.2130308245 \tAcc: 0.9435416667 \tTPR:0.9258835051 \tFPR:0.0403456224 \tF1:0.9395276869 \tAUC:0.9427689414 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.04638694502722201 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.08007201559477201969\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0884045132 \tAcc: 0.9658035714 \tTPR:0.9711015720 \tFPR:0.0395688306 \tF1:0.9644376685 \t AUC:0.9657663707\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0801837549 \tAcc: 0.9691935484 \tTPR:0.9757598033 \tFPR:0.0389924057 \tF1:0.9684925258 \t AUC:0.9683836988\tTrain cost: 0:00:34\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0730303839 \tAcc: 0.9725864055 \tTPR:0.9782783540 \tFPR:0.0324768868 \tF1:0.9716243927 \t AUC:0.9729007336\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0647018880 \tAcc: 0.9745506912 \tTPR:0.9816172427 \tFPR:0.0318900350 \tF1:0.9745024663 \t AUC:0.9748636039\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0619188930 \tAcc: 0.9756250000 \tTPR:0.9816612100 \tFPR:0.0312996505 \tF1:0.9749405869 \t AUC:0.9751807797\tTrain cost: 0:00:36\n",
      "Client4 Test =>                 \tLoss: 0.2074111847 \tAcc: 0.9425000000 \tTPR:0.9431126881 \tFPR:0.0593697933 \tF1:0.9408423960 \tAUC:0.9418714474 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.06788181748880812 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.10502039651602398940\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0956461666 \tAcc: 0.9626785714 \tTPR:0.9708669838 \tFPR:0.0452844608 \tF1:0.9618518119 \t AUC:0.9627912615\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0864010567 \tAcc: 0.9649078341 \tTPR:0.9745778391 \tFPR:0.0448906185 \tF1:0.9642724213 \t AUC:0.9648436103\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0743655411 \tAcc: 0.9709792627 \tTPR:0.9751803592 \tFPR:0.0340094158 \tF1:0.9700398670 \t AUC:0.9705854717\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0716698042 \tAcc: 0.9717799539 \tTPR:0.9763006435 \tFPR:0.0323977807 \tF1:0.9709590568 \t AUC:0.9719514314\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0661292132 \tAcc: 0.9733928571 \tTPR:0.9773578998 \tFPR:0.0311495455 \tF1:0.9720321459 \t AUC:0.9731041771\tTrain cost: 0:00:36\n",
      "Client8 Test =>                 \tLoss: 0.1993146772 \tAcc: 0.9456250000 \tTPR:0.9362111023 \tFPR:0.0428294535 \tF1:0.9434668965 \tAUC:0.9466908244 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.06813979061612734 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.08545621295216614122\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0748840712 \tAcc: 0.9700864055 \tTPR:0.9768911745 \tFPR:0.0368513760 \tF1:0.9695648968 \t AUC:0.9700198993\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0682936327 \tAcc: 0.9739285714 \tTPR:0.9789787916 \tFPR:0.0313330862 \tF1:0.9738136509 \t AUC:0.9738228527\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0600095630 \tAcc: 0.9752678571 \tTPR:0.9810706258 \tFPR:0.0301313251 \tF1:0.9749406484 \t AUC:0.9754696503\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0535169254 \tAcc: 0.9786520737 \tTPR:0.9832840052 \tFPR:0.0251922733 \tF1:0.9781238248 \t AUC:0.9790458660\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0467385266 \tAcc: 0.9821428571 \tTPR:0.9864014129 \tFPR:0.0223550207 \tF1:0.9817374720 \t AUC:0.9820231961\tTrain cost: 0:00:36\n",
      "Client1 Test =>                 \tLoss: 0.2172581548 \tAcc: 0.9454166667 \tTPR:0.9325343557 \tFPR:0.0445337537 \tF1:0.9399145973 \tAUC:0.9440003010 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.09294873443360534 \tALA epochs: 2\n",
      "Client 6: Local Initial ALA epochs: 2 Loss: 0.13022182338054466566\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.0968781895 \tAcc: 0.9636578341 \tTPR:0.9728786905 \tFPR:0.0469451219 \tF1:0.9631296744 \t AUC:0.9629667843\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.0896325729 \tAcc: 0.9640149770 \tTPR:0.9740003265 \tFPR:0.0456173754 \tF1:0.9633907340 \t AUC:0.9641914755\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0781397668 \tAcc: 0.9705328341 \tTPR:0.9784152624 \tFPR:0.0378185919 \tF1:0.9701387247 \t AUC:0.9702983353\tTrain cost: 0:00:36\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0750412085 \tAcc: 0.9710656682 \tTPR:0.9798505910 \tFPR:0.0385776754 \tF1:0.9714975150 \t AUC:0.9706364578\tTrain cost: 0:00:37\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0675046918 \tAcc: 0.9743750000 \tTPR:0.9824908679 \tFPR:0.0336223596 \tF1:0.9740908417 \t AUC:0.9744342542\tTrain cost: 0:00:37\n",
      "Client6 Test =>                 \tLoss: 0.2109208537 \tAcc: 0.9422916667 \tTPR:0.9294884576 \tFPR:0.0464481902 \tF1:0.9379923010 \tAUC:0.9415201337 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2095871390 \tAcc: 0.9438750000 \tTPR:0.9334460218 \tFPR:0.0467053626 \tF1:0.9403487755 \tAUC:0.9433703296\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 26:  =============\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.053411517279922806 \tALA epochs: 2\n",
      "Client 5: Local Initial ALA epochs: 2 Loss: 0.08840341922368152860\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0903748178 \tAcc: 0.9638364055 \tTPR:0.9721965999 \tFPR:0.0453860817 \tF1:0.9631696553 \t AUC:0.9634052591\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0785533970 \tAcc: 0.9685685484 \tTPR:0.9758385337 \tFPR:0.0390118075 \tF1:0.9683931359 \t AUC:0.9684133631\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0720732135 \tAcc: 0.9700864055 \tTPR:0.9761850887 \tFPR:0.0364410263 \tF1:0.9698143836 \t AUC:0.9698720312\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0699675631 \tAcc: 0.9716964286 \tTPR:0.9772073517 \tFPR:0.0335325537 \tF1:0.9711421268 \t AUC:0.9718373990\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0680730064 \tAcc: 0.9732142857 \tTPR:0.9799659277 \tFPR:0.0334375639 \tF1:0.9723257031 \t AUC:0.9732641819\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.1900569344 \tAcc: 0.9412500000 \tTPR:0.9256213920 \tFPR:0.0454729189 \tF1:0.9372555097 \tAUC:0.9400742365 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.07518109774632636 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.10159457682132505552\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0922418795 \tAcc: 0.9654377880 \tTPR:0.9722464413 \tFPR:0.0412476506 \tF1:0.9647516766 \t AUC:0.9654993953\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0809458909 \tAcc: 0.9689228111 \tTPR:0.9753641548 \tFPR:0.0362602140 \tF1:0.9680049763 \t AUC:0.9695519704\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0755005887 \tAcc: 0.9721370968 \tTPR:0.9783726504 \tFPR:0.0344618700 \tF1:0.9712918239 \t AUC:0.9719553902\tTrain cost: 0:00:37\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0707923224 \tAcc: 0.9742857143 \tTPR:0.9811932094 \tFPR:0.0327540273 \tF1:0.9744189418 \t AUC:0.9742195911\tTrain cost: 0:00:37\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0644937295 \tAcc: 0.9754435484 \tTPR:0.9797457496 \tFPR:0.0285960740 \tF1:0.9744461182 \t AUC:0.9755748378\tTrain cost: 0:00:37\n",
      "Client9 Test =>                 \tLoss: 0.2014629079 \tAcc: 0.9439583333 \tTPR:0.9411952467 \tFPR:0.0514791278 \tF1:0.9428170534 \tAUC:0.9448580595 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.06941945153861155 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.08936673317752454049\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0854987903 \tAcc: 0.9664285714 \tTPR:0.9736766153 \tFPR:0.0416059294 \tF1:0.9656254905 \t AUC:0.9660353429\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0735071344 \tAcc: 0.9725864055 \tTPR:0.9790861709 \tFPR:0.0331383820 \tF1:0.9722821191 \t AUC:0.9729738944\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0673390639 \tAcc: 0.9732142857 \tTPR:0.9781227208 \tFPR:0.0313592389 \tF1:0.9716362479 \t AUC:0.9733817410\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0611225799 \tAcc: 0.9768692396 \tTPR:0.9818737607 \tFPR:0.0284586015 \tF1:0.9766091174 \t AUC:0.9767075796\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0561285771 \tAcc: 0.9776756912 \tTPR:0.9814373270 \tFPR:0.0264500794 \tF1:0.9772588549 \t AUC:0.9774936238\tTrain cost: 0:00:37\n",
      "Client8 Test =>                 \tLoss: 0.2030761681 \tAcc: 0.9483333333 \tTPR:0.9374836017 \tFPR:0.0423365804 \tF1:0.9456978061 \tAUC:0.9475735106 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.04161181963627977 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.09818737046874087548\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0813515077 \tAcc: 0.9685685484 \tTPR:0.9749185986 \tFPR:0.0369021942 \tF1:0.9678206837 \t AUC:0.9690082022\tTrain cost: 0:00:34\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0696439165 \tAcc: 0.9730299539 \tTPR:0.9784527536 \tFPR:0.0327777248 \tF1:0.9719906993 \t AUC:0.9728375144\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0671071887 \tAcc: 0.9751756912 \tTPR:0.9809439859 \tFPR:0.0303120220 \tF1:0.9744488674 \t AUC:0.9753159819\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0589079032 \tAcc: 0.9784763825 \tTPR:0.9838235051 \tFPR:0.0268202728 \tF1:0.9781270837 \t AUC:0.9785016161\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0549242398 \tAcc: 0.9798214286 \tTPR:0.9840147403 \tFPR:0.0244541203 \tF1:0.9795424753 \t AUC:0.9797803100\tTrain cost: 0:00:37\n",
      "Client4 Test =>                 \tLoss: 0.2057360145 \tAcc: 0.9439583333 \tTPR:0.9499536626 \tFPR:0.0612733582 \tF1:0.9434308472 \tAUC:0.9443401522 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.06033176098393249 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.06973070037834670776\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0720077364 \tAcc: 0.9709763825 \tTPR:0.9767947028 \tFPR:0.0340709106 \tF1:0.9701085815 \t AUC:0.9713618961\tTrain cost: 0:00:35\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0608270247 \tAcc: 0.9769614055 \tTPR:0.9814829994 \tFPR:0.0288040981 \tF1:0.9763794112 \t AUC:0.9763394506\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0551221737 \tAcc: 0.9785685484 \tTPR:0.9823418984 \tFPR:0.0258400391 \tF1:0.9780284172 \t AUC:0.9782509296\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0479715722 \tAcc: 0.9821399770 \tTPR:0.9860468661 \tFPR:0.0222028323 \tF1:0.9817976736 \t AUC:0.9819220169\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0474255051 \tAcc: 0.9814256912 \tTPR:0.9849203180 \tFPR:0.0230789003 \tF1:0.9808098806 \t AUC:0.9809207088\tTrain cost: 0:00:36\n",
      "Client1 Test =>                 \tLoss: 0.2182857823 \tAcc: 0.9445833333 \tTPR:0.9220092036 \tFPR:0.0351728253 \tF1:0.9398336543 \tAUC:0.9434181891 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2037235614 \tAcc: 0.9444166667 \tTPR:0.9352526213 \tFPR:0.0471469621 \tF1:0.9418069741 \tAUC:0.9440528296\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 27:  =============\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.04730239536125364 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.05812083487736358078\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0657475902 \tAcc: 0.9748156682 \tTPR:0.9802537737 \tFPR:0.0308874751 \tF1:0.9741687959 \t AUC:0.9746831493\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0572451358 \tAcc: 0.9782114055 \tTPR:0.9808711587 \tFPR:0.0253625204 \tF1:0.9774349798 \t AUC:0.9777543191\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0535018573 \tAcc: 0.9797321429 \tTPR:0.9853976431 \tFPR:0.0262602385 \tF1:0.9788400131 \t AUC:0.9795687023\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0496884801 \tAcc: 0.9800000000 \tTPR:0.9848191171 \tFPR:0.0241159555 \tF1:0.9794330107 \t AUC:0.9803515808\tTrain cost: 0:00:36\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0483134181 \tAcc: 0.9822321429 \tTPR:0.9856357083 \tFPR:0.0215188453 \tF1:0.9818124281 \t AUC:0.9820584315\tTrain cost: 0:00:36\n",
      "Client4 Test =>                 \tLoss: 0.2209127291 \tAcc: 0.9468750000 \tTPR:0.9471444892 \tFPR:0.0530821275 \tF1:0.9460472882 \tAUC:0.9470311808 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.09286200409062227 \tALA epochs: 2\n",
      "Client 9: Local Initial ALA epochs: 2 Loss: 0.08036908110944500361\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0828192583 \tAcc: 0.9683928571 \tTPR:0.9753926094 \tFPR:0.0369716010 \tF1:0.9676982644 \t AUC:0.9692105042\tTrain cost: 0:00:37\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0717361952 \tAcc: 0.9722263825 \tTPR:0.9773970240 \tFPR:0.0314373982 \tF1:0.9711582621 \t AUC:0.9729798129\tTrain cost: 0:00:37\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0615271589 \tAcc: 0.9765149770 \tTPR:0.9803813927 \tFPR:0.0273793411 \tF1:0.9760602286 \t AUC:0.9765010258\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0606952858 \tAcc: 0.9778542627 \tTPR:0.9833654798 \tFPR:0.0276848927 \tF1:0.9774056657 \t AUC:0.9778402935\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0537072780 \tAcc: 0.9816935484 \tTPR:0.9857619334 \tFPR:0.0218930927 \tF1:0.9809340053 \t AUC:0.9819344203\tTrain cost: 0:00:36\n",
      "Client9 Test =>                 \tLoss: 0.2320723043 \tAcc: 0.9408333333 \tTPR:0.9261315509 \tFPR:0.0464618943 \tF1:0.9380929456 \tAUC:0.9398348283 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.06511151598194004 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.07263545274896465731\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0766502909 \tAcc: 0.9722321429 \tTPR:0.9785985517 \tFPR:0.0330302132 \tF1:0.9715082902 \t AUC:0.9727841693\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0651625465 \tAcc: 0.9758006912 \tTPR:0.9809956076 \tFPR:0.0297477205 \tF1:0.9757361300 \t AUC:0.9756239435\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0549118654 \tAcc: 0.9783928571 \tTPR:0.9803253269 \tFPR:0.0245775509 \tF1:0.9775824639 \t AUC:0.9778738880\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0549992288 \tAcc: 0.9793692396 \tTPR:0.9827910319 \tFPR:0.0237553258 \tF1:0.9781403853 \t AUC:0.9795178530\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0479742299 \tAcc: 0.9816013825 \tTPR:0.9841236207 \tFPR:0.0208557465 \tF1:0.9805888926 \t AUC:0.9816339371\tTrain cost: 0:00:36\n",
      "Client8 Test =>                 \tLoss: 0.2062588674 \tAcc: 0.9445833333 \tTPR:0.9336984741 \tFPR:0.0460850452 \tF1:0.9420252152 \tAUC:0.9438067144 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.07713227640448744 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.07510557212610391442\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.0696470215 \tAcc: 0.9739285714 \tTPR:0.9779391021 \tFPR:0.0293916555 \tF1:0.9727001694 \t AUC:0.9742737233\tTrain cost: 0:00:35\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0561620347 \tAcc: 0.9779464286 \tTPR:0.9802456742 \tFPR:0.0254987081 \tF1:0.9767820967 \t AUC:0.9773734831\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0471858949 \tAcc: 0.9810714286 \tTPR:0.9842960493 \tFPR:0.0213347606 \tF1:0.9797293621 \t AUC:0.9814806443\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0465924259 \tAcc: 0.9822263825 \tTPR:0.9852505047 \tFPR:0.0207223523 \tF1:0.9818134465 \t AUC:0.9822640762\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0410671887 \tAcc: 0.9837471198 \tTPR:0.9850675115 \tFPR:0.0178433373 \tF1:0.9826745441 \t AUC:0.9836120871\tTrain cost: 0:00:36\n",
      "Client0 Test =>                 \tLoss: 0.2678369000 \tAcc: 0.9350000000 \tTPR:0.9064086910 \tFPR:0.0343623092 \tF1:0.9329331258 \tAUC:0.9360231909 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.06517253255542832 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.07979980876763770326\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0813952615 \tAcc: 0.9694614055 \tTPR:0.9738499185 \tFPR:0.0354946776 \tF1:0.9685767398 \t AUC:0.9691776205\tTrain cost: 0:00:35\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0735565807 \tAcc: 0.9690120968 \tTPR:0.9738017135 \tFPR:0.0366934561 \tF1:0.9679883346 \t AUC:0.9685541287\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0627357493 \tAcc: 0.9751785714 \tTPR:0.9808616761 \tFPR:0.0308260061 \tF1:0.9742984440 \t AUC:0.9750178350\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0575363747 \tAcc: 0.9775000000 \tTPR:0.9820400723 \tFPR:0.0279876552 \tF1:0.9769299992 \t AUC:0.9770262085\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0540748654 \tAcc: 0.9788364055 \tTPR:0.9827192931 \tFPR:0.0256036597 \tF1:0.9779710410 \t AUC:0.9785578167\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.1945227118 \tAcc: 0.9472916667 \tTPR:0.9467739327 \tFPR:0.0514861840 \tF1:0.9466125051 \tAUC:0.9476438744 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2243207025 \tAcc: 0.9429166667 \tTPR:0.9320314276 \tFPR:0.0462955120 \tF1:0.9411422160 \tAUC:0.9428679578\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 28:  =============\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.03755382607251814 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.03834144031440002431\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.0526781191 \tAcc: 0.9803571429 \tTPR:0.9840430413 \tFPR:0.0233549611 \tF1:0.9793843461 \t AUC:0.9803440401\tTrain cost: 0:00:35\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0434361102 \tAcc: 0.9837500000 \tTPR:0.9859621170 \tFPR:0.0178104278 \tF1:0.9831211547 \t AUC:0.9840758446\tTrain cost: 0:00:35\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0399490201 \tAcc: 0.9850000000 \tTPR:0.9878702765 \tFPR:0.0171611034 \tF1:0.9841317671 \t AUC:0.9853545865\tTrain cost: 0:00:35\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0389047929 \tAcc: 0.9851785714 \tTPR:0.9869515865 \tFPR:0.0163202242 \tF1:0.9844283803 \t AUC:0.9853156811\tTrain cost: 0:00:36\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0349559198 \tAcc: 0.9876785714 \tTPR:0.9904550159 \tFPR:0.0144724264 \tF1:0.9870096206 \t AUC:0.9879912947\tTrain cost: 0:00:36\n",
      "Client0 Test =>                 \tLoss: 0.2518415086 \tAcc: 0.9414583333 \tTPR:0.9257238162 \tFPR:0.0419971501 \tF1:0.9406579034 \tAUC:0.9418633331 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.0962131414787942 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.07802222867452444921\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0751512749 \tAcc: 0.9698214286 \tTPR:0.9750136112 \tFPR:0.0354790380 \tF1:0.9694451794 \t AUC:0.9697672866\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0632479136 \tAcc: 0.9732142857 \tTPR:0.9780273034 \tFPR:0.0328950865 \tF1:0.9728867692 \t AUC:0.9725661084\tTrain cost: 0:00:35\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0513111978 \tAcc: 0.9797292627 \tTPR:0.9825610930 \tFPR:0.0237874313 \tF1:0.9792121103 \t AUC:0.9793868309\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0482960240 \tAcc: 0.9805357143 \tTPR:0.9834649458 \tFPR:0.0231964929 \tF1:0.9804552830 \t AUC:0.9801342264\tTrain cost: 0:00:36\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0444959654 \tAcc: 0.9816042627 \tTPR:0.9854105927 \tFPR:0.0223040646 \tF1:0.9812404901 \t AUC:0.9815532640\tTrain cost: 0:00:37\n",
      "Client7 Test =>                 \tLoss: 0.2391940616 \tAcc: 0.9379166667 \tTPR:0.9068758060 \tFPR:0.0324954390 \tF1:0.9329562667 \tAUC:0.9371901835 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.08382856517790746 \tALA epochs: 2\n",
      "Client 9: Local Initial ALA epochs: 2 Loss: 0.09623069743679808774\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0756906717 \tAcc: 0.9709792627 \tTPR:0.9763643018 \tFPR:0.0343428562 \tF1:0.9707229204 \t AUC:0.9710107228\tTrain cost: 0:00:34\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0610004493 \tAcc: 0.9784792627 \tTPR:0.9829242877 \tFPR:0.0254894330 \tF1:0.9778979509 \t AUC:0.9787174274\tTrain cost: 0:00:37\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0497821220 \tAcc: 0.9814256912 \tTPR:0.9838896277 \tFPR:0.0213091681 \tF1:0.9805853471 \t AUC:0.9812902298\tTrain cost: 0:00:37\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0498913115 \tAcc: 0.9825864055 \tTPR:0.9849976212 \tFPR:0.0200543054 \tF1:0.9825331526 \t AUC:0.9824716579\tTrain cost: 0:00:36\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0445846890 \tAcc: 0.9848185484 \tTPR:0.9881686260 \tFPR:0.0181430004 \tF1:0.9840258790 \t AUC:0.9850128128\tTrain cost: 0:00:36\n",
      "Client9 Test =>                 \tLoss: 0.2377919013 \tAcc: 0.9433333333 \tTPR:0.9349547583 \tFPR:0.0479098458 \tF1:0.9415345547 \tAUC:0.9435224563 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.09825499416813485 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.13003008407068208929\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1152378583 \tAcc: 0.9571428571 \tTPR:0.9650556211 \tFPR:0.0510933155 \tF1:0.9561090693 \t AUC:0.9569811528\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1018280848 \tAcc: 0.9613392857 \tTPR:0.9699084486 \tFPR:0.0477363572 \tF1:0.9611471495 \t AUC:0.9610860457\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0893379820 \tAcc: 0.9657085253 \tTPR:0.9711684132 \tFPR:0.0400779083 \tF1:0.9646369313 \t AUC:0.9655452524\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0878037792 \tAcc: 0.9662471198 \tTPR:0.9733983106 \tFPR:0.0409668698 \tF1:0.9656022173 \t AUC:0.9662157204\tTrain cost: 0:00:38\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0827791731 \tAcc: 0.9693721198 \tTPR:0.9754648091 \tFPR:0.0378211617 \tF1:0.9688807761 \t AUC:0.9688218237\tTrain cost: 0:00:36\n",
      "Client2 Test =>                 \tLoss: 0.1690283357 \tAcc: 0.9447916667 \tTPR:0.9284404845 \tFPR:0.0391408681 \tF1:0.9415379221 \tAUC:0.9446498082 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.07736831613603487 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.08523351576287245546\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0806364937 \tAcc: 0.9683006912 \tTPR:0.9743654897 \tFPR:0.0387693471 \tF1:0.9671109645 \t AUC:0.9677980713\tTrain cost: 0:00:35\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0699011644 \tAcc: 0.9727678571 \tTPR:0.9793696960 \tFPR:0.0341155496 \tF1:0.9720971332 \t AUC:0.9726270732\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0576034130 \tAcc: 0.9772292627 \tTPR:0.9816260793 \tFPR:0.0270989231 \tF1:0.9767294161 \t AUC:0.9772635781\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0538998439 \tAcc: 0.9798214286 \tTPR:0.9842458574 \tFPR:0.0246412824 \tF1:0.9796326805 \t AUC:0.9798022875\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0521045255 \tAcc: 0.9790178571 \tTPR:0.9834172878 \tFPR:0.0247733478 \tF1:0.9789688402 \t AUC:0.9793219700\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.2100576254 \tAcc: 0.9385416667 \tTPR:0.9136525119 \tFPR:0.0356703941 \tF1:0.9352995220 \tAUC:0.9389910589 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2215826865 \tAcc: 0.9412083333 \tTPR:0.9219294754 \tFPR:0.0394427394 \tF1:0.9383972338 \tAUC:0.9412433680\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 29:  =============\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.03659436661347375 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.04791955436930816353\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0670214225 \tAcc: 0.9758928571 \tTPR:0.9810644434 \tFPR:0.0296966875 \tF1:0.9754478411 \t AUC:0.9756838780\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0612020727 \tAcc: 0.9764228111 \tTPR:0.9806427106 \tFPR:0.0276503994 \tF1:0.9758655975 \t AUC:0.9764961556\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0551195676 \tAcc: 0.9790149770 \tTPR:0.9840265203 \tFPR:0.0249591942 \tF1:0.9782405820 \t AUC:0.9795336630\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0502643597 \tAcc: 0.9800835253 \tTPR:0.9848126399 \tFPR:0.0240889511 \tF1:0.9798044635 \t AUC:0.9803618444\tTrain cost: 0:00:35\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0452660842 \tAcc: 0.9821399770 \tTPR:0.9853055048 \tFPR:0.0208019353 \tF1:0.9814581135 \t AUC:0.9822517847\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.2190393475 \tAcc: 0.9418750000 \tTPR:0.9298989978 \tFPR:0.0460221283 \tF1:0.9399804788 \tAUC:0.9419384348 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.04424818602821693 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.07219356294903579718\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0719608249 \tAcc: 0.9741964286 \tTPR:0.9785399117 \tFPR:0.0303755025 \tF1:0.9734857342 \t AUC:0.9740822046\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0587018859 \tAcc: 0.9764285714 \tTPR:0.9792745449 \tFPR:0.0263160976 \tF1:0.9758753357 \t AUC:0.9764792236\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0531195229 \tAcc: 0.9776756912 \tTPR:0.9807503105 \tFPR:0.0258331273 \tF1:0.9769845392 \t AUC:0.9774585916\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0469913354 \tAcc: 0.9834821429 \tTPR:0.9876481420 \tFPR:0.0206039579 \tF1:0.9832076698 \t AUC:0.9835220921\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0445096193 \tAcc: 0.9833035714 \tTPR:0.9861653351 \tFPR:0.0201520811 \tF1:0.9831016621 \t AUC:0.9830066270\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.2226370984 \tAcc: 0.9443750000 \tTPR:0.9446328363 \tFPR:0.0556682094 \tF1:0.9428383702 \tAUC:0.9444823134 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.061290598279180944 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.06501642352078056131\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0618146129 \tAcc: 0.9752649770 \tTPR:0.9791137426 \tFPR:0.0292723202 \tF1:0.9749117154 \t AUC:0.9749207112\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0493714273 \tAcc: 0.9809792627 \tTPR:0.9843286955 \tFPR:0.0226134517 \tF1:0.9809445036 \t AUC:0.9808576219\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0428937562 \tAcc: 0.9834821429 \tTPR:0.9852957970 \tFPR:0.0186780222 \tF1:0.9834979632 \t AUC:0.9833088874\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0391295361 \tAcc: 0.9846428571 \tTPR:0.9886439882 \tFPR:0.0193742524 \tF1:0.9843190979 \t AUC:0.9846348679\tTrain cost: 0:00:37\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0373146347 \tAcc: 0.9851699309 \tTPR:0.9885875723 \tFPR:0.0191207524 \tF1:0.9853179215 \t AUC:0.9847334099\tTrain cost: 0:00:36\n",
      "Client7 Test =>                 \tLoss: 0.2359557742 \tAcc: 0.9497916667 \tTPR:0.9616260511 \tFPR:0.0615279607 \tF1:0.9484346866 \tAUC:0.9500490452 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.08132246473477449 \tALA epochs: 5\n",
      "Client 1: Local Initial ALA epochs: 5 Loss: 0.12621730916637360909\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0792273616 \tAcc: 0.9677678571 \tTPR:0.9741044213 \tFPR:0.0393160036 \tF1:0.9671149728 \t AUC:0.9673942089\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0652766262 \tAcc: 0.9741935484 \tTPR:0.9799487938 \tFPR:0.0307425978 \tF1:0.9738734405 \t AUC:0.9746030980\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0557697022 \tAcc: 0.9777649770 \tTPR:0.9828452485 \tFPR:0.0268054864 \tF1:0.9778931564 \t AUC:0.9780198811\tTrain cost: 0:00:36\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0516269377 \tAcc: 0.9791042627 \tTPR:0.9831905409 \tFPR:0.0252167565 \tF1:0.9782931997 \t AUC:0.9789868922\tTrain cost: 0:00:37\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0531381752 \tAcc: 0.9779435484 \tTPR:0.9819617159 \tFPR:0.0251866340 \tF1:0.9771417143 \t AUC:0.9783875409\tTrain cost: 0:00:36\n",
      "Client1 Test =>                 \tLoss: 0.2052990071 \tAcc: 0.9456250000 \tTPR:0.9276143994 \tFPR:0.0379330698 \tF1:0.9412645806 \tAUC:0.9448406648 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.09874414635183448 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.08247206137056692365\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0735266138 \tAcc: 0.9719642857 \tTPR:0.9763539740 \tFPR:0.0336030814 \tF1:0.9709526687 \t AUC:0.9713754463\tTrain cost: 0:00:34\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0586242395 \tAcc: 0.9777678571 \tTPR:0.9829181862 \tFPR:0.0278010725 \tF1:0.9768800062 \t AUC:0.9775585568\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0548214745 \tAcc: 0.9791935484 \tTPR:0.9854457433 \tFPR:0.0270364039 \tF1:0.9787782975 \t AUC:0.9792046697\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0492996986 \tAcc: 0.9816071429 \tTPR:0.9858811116 \tFPR:0.0228762752 \tF1:0.9810333529 \t AUC:0.9815024182\tTrain cost: 0:00:37\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0435331132 \tAcc: 0.9843750000 \tTPR:0.9886418620 \tFPR:0.0195895669 \tF1:0.9839933854 \t AUC:0.9845261475\tTrain cost: 0:00:37\n",
      "Client4 Test =>                 \tLoss: 0.2333451811 \tAcc: 0.9460416667 \tTPR:0.9342294999 \tFPR:0.0413539660 \tF1:0.9440487669 \tAUC:0.9464377670 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2232552817 \tAcc: 0.9455416667 \tTPR:0.9396003569 \tFPR:0.0485010668 \tF1:0.9433133766 \tAUC:0.9455496450\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "Training and Test completed! total time cost: 8:03:17\n"
     ]
    }
   ],
   "source": [
    "print(\"Train and Test Begin!\")\n",
    "net_glob.train()\n",
    "w_net_glob = net_glob.state_dict()\n",
    "t0 = time.time()\n",
    "net_local = [copy.deepcopy(net_glob) for i in range(num_users)]\n",
    "\n",
    "lr = 2e-6\n",
    "\n",
    "local_test[\"loss\"] = []\n",
    "local_test[\"acc\"] = []\n",
    "local_test[\"tpr\"] = []\n",
    "local_test[\"fpr\"] = []\n",
    "local_test[\"f1\"] = []\n",
    "local_test[\"auc\"] = []\n",
    "\n",
    "local_testing[\"loss\"] = []\n",
    "local_testing[\"acc\"] = []\n",
    "local_testing[\"tpr\"] = []\n",
    "local_testing[\"fpr\"] = []\n",
    "local_testing[\"f1\"] = []\n",
    "local_testing[\"auc\"] = []\n",
    "\n",
    "for iter in range(epochs):\n",
    "    print(\"============== Round {}:  =============\".format(iter))\n",
    "    idx_collect = []\n",
    "    m = max(int(frac * num_users) ,1)\n",
    "    idxs_users = np.random.choice(range(num_users), m, replace = False)\n",
    "    w_locals_client = []\n",
    "\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    tpr_list = []\n",
    "    fpr_list = []\n",
    "    f1_list = []\n",
    "    auc_list = []\n",
    "\n",
    "    for idx in idxs_users:\n",
    "        local = Client(device, idx, lr, local_epochs, batch_size, train_dataset, test_dataset, dict_user_train[idx], dict_user_test[idx])\n",
    "        local.local_initialization(net = copy.deepcopy(net_glob).to(device))\n",
    "        w_client, client_loss, client_acc = local.train(net = copy.deepcopy(net_local[idx]).to(device))\n",
    "        w_locals_client.append(copy.deepcopy(w_client))\n",
    "        loss, acc, tpr, fpr, f1, auc = local.evaluate(net = copy.deepcopy(net_glob).to(device), ell=iter)\n",
    "\n",
    "        loss_list.append(loss)\n",
    "        acc_list.append(acc)\n",
    "        tpr_list.append(tpr)\n",
    "        fpr_list.append(fpr)\n",
    "        f1_list.append(f1)\n",
    "        auc_list.append(auc)\n",
    "\n",
    "    local_testing[\"loss\"].append(sum(loss_list)/len(loss_list))\n",
    "    local_testing[\"acc\"].append(sum(acc_list)/len(acc_list))\n",
    "    local_testing[\"tpr\"].append(sum(tpr_list)/len(tpr_list))\n",
    "    local_testing[\"fpr\"].append(sum(fpr_list)/len(fpr_list))\n",
    "    local_testing[\"f1\"].append(sum(f1_list)/len(f1_list))\n",
    "    local_testing[\"auc\"].append(sum(auc_list)/len(auc_list))\n",
    "    print(\"Test =>                 \\tLoss: {:.10f} \\tAcc: {:.10f} \\tTPR:{:.10f} \\tFPR:{:.10f} \\tF1:{:.10f} \\tAUC:{:.10f}\".format(sum(loss_list)/len(loss_list), sum(acc_list)/len(acc_list), sum(tpr_list)/len(tpr_list), sum(fpr_list)/len(fpr_list), sum(f1_list)/len(f1_list), sum(auc_list)/len(auc_list)  ))\n",
    "\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "    print(\"-------------- FedServer: Federation process  -------------\")\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "    w_net_glob = FedAvg(w_locals_client)\n",
    "    net_glob.load_state_dict(w_net_glob)\n",
    "elapsed = format_time(time.time()-t0)\n",
    "print(\"Training and Test completed! total time cost: {:}\".format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Final Result =============\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.04167861953381158 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.05165466052763487831\n",
      "Client0 Test =>                 \tLoss: 0.2167545885 \tAcc: 0.9497916667 \tTPR:0.9412479756 \tFPR:0.0408315727 \tF1:0.9491322895 \tAUC:0.9502082015 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.05998525175077766 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.05678780386359363191\n",
      "Client1 Test =>                 \tLoss: 0.2050177442 \tAcc: 0.9485416667 \tTPR:0.9383726951 \tFPR:0.0405304532 \tF1:0.9449942915 \tAUC:0.9489211209 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.0792003477031215 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.08957600393214439072\n",
      "Client2 Test =>                 \tLoss: 0.2022524081 \tAcc: 0.9504166667 \tTPR:0.9438446920 \tFPR:0.0425194988 \tF1:0.9487805835 \tAUC:0.9506625966 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.08551732184732501 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.07740725429839981353\n",
      "Client3 Test =>                 \tLoss: 0.1906467191 \tAcc: 0.9508333333 \tTPR:0.9437525590 \tFPR:0.0428927576 \tF1:0.9477653808 \tAUC:0.9504299007 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.04587909130331269 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.05124574342398378196\n",
      "Client4 Test =>                 \tLoss: 0.2112159664 \tAcc: 0.9481250000 \tTPR:0.9511327974 \tFPR:0.0521237682 \tF1:0.9464581521 \tAUC:0.9495045146 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.06670111099290664 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.05231317635828062335\n",
      "Client5 Test =>                 \tLoss: 0.2044146734 \tAcc: 0.9483333333 \tTPR:0.9420995942 \tFPR:0.0455978634 \tF1:0.9474951699 \tAUC:0.9482508654 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.08952677647961063 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.11176362420783202134\n",
      "Client6 Test =>                 \tLoss: 0.2428201599 \tAcc: 0.9418750000 \tTPR:0.9362331837 \tFPR:0.0530720634 \tF1:0.9386175348 \tAUC:0.9415805602 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.042057151060991185 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.05186838473689377865\n",
      "Client7 Test =>                 \tLoss: 0.2137542295 \tAcc: 0.9506250000 \tTPR:0.9408068301 \tFPR:0.0414976975 \tF1:0.9476889948 \tAUC:0.9496545663 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.01887709117410907 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.05046895080907405629\n",
      "Client8 Test =>                 \tLoss: 0.2212145078 \tAcc: 0.9475000000 \tTPR:0.9400878132 \tFPR:0.0438432489 \tF1:0.9453437294 \tAUC:0.9481222821 \ttest cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.053971505792616156 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.05506432251633563285\n",
      "Client9 Test =>                 \tLoss: 0.2250008447 \tAcc: 0.9460416667 \tTPR:0.9387615454 \tFPR:0.0469295648 \tF1:0.9443682343 \tAUC:0.9459159903 \ttest cost: 0:00:05\n"
     ]
    }
   ],
   "source": [
    "idx_collect = [i for i in range(num_users)]\n",
    "print(\"============= Final Result =============\")\n",
    "for idx in idx_collect:\n",
    "    loss_test_collect[idx] = []\n",
    "    acc_test_collect[idx] = []\n",
    "    TPR_test_collect[idx] = []\n",
    "    FPR_test_collect[idx] = []\n",
    "    f1_test_collect[idx] = []\n",
    "    AUC_test_collect[idx] = []\n",
    "    local = Client(device, idx, lr, local_epochs, batch_size, train_dataset, test_dataset, dict_user_train[idx], dict_user_test[idx])\n",
    "    local.local_initialization(net = copy.deepcopy(net_glob).to(device))\n",
    "    loss, acc, tpr, fpr, f1, auc = local.evaluate(net = copy.deepcopy(net_local[idx]).to(device), ell=0)\n",
    "    loss_test_collect[idx].append(loss)\n",
    "    acc_test_collect[idx].append(acc)\n",
    "    TPR_test_collect[idx].append(tpr)\n",
    "    FPR_test_collect[idx].append(fpr)\n",
    "    f1_test_collect[idx].append(f1)\n",
    "    AUC_test_collect[idx].append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import xlwt\n",
    "f = xlwt.Workbook('encoding = utf-8')\n",
    "sheet1 = f.add_sheet('sheet1',cell_overwrite_ok=True)\n",
    "for i in range(len(loss_collect)):\n",
    "    sheet1.write(i+1,0,loss_collect[i]) \n",
    "for i in range(len(acc_collect)):\n",
    "    sheet1.write(i+1,1,acc_collect[i])\n",
    "for i in range(len(TPR_collect)):\n",
    "    sheet1.write(i+1,2,TPR_collect[i])\n",
    "for i in range(len(FPR_collect)):\n",
    "    sheet1.write(i+1,3,FPR_collect[i])\n",
    "for i in range(len(F1_collect)):\n",
    "    sheet1.write(i+1,4,F1_collect[i])\n",
    "for i in range(len(AUC_collect)):\n",
    "    sheet1.write(i+1,5,AUC_collect[i])\n",
    "\n",
    "f.save('result.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(num_users):\n",
    "    f = xlwt.Workbook('encoding = utf-8')\n",
    "    sheet1 = f.add_sheet('sheet1', cell_overwrite_ok=True)\n",
    "    for j in range(len(loss_train_collect[i])):\n",
    "        sheet1.write(j+1, 0, loss_train_collect[i][j])\n",
    "    for j in range(len(acc_train_collect[i])):\n",
    "        sheet1.write(j+1, 1, acc_train_collect[i][j])\n",
    "    for j in range(len(TPR_train_collect[i])):\n",
    "        sheet1.write(j+1, 2, TPR_train_collect[i][j])\n",
    "    for j in range(len(FPR_train_collect[i])):\n",
    "        sheet1.write(j+1, 3, FPR_train_collect[i][j])\n",
    "    for j in range(len(f1_train_collect[i])):\n",
    "        sheet1.write(j+1, 4, f1_train_collect[i][j])\n",
    "    for j in range(len(AUC_train_collect[i])):\n",
    "        sheet1.write(j+1, 5, AUC_train_collect[i][j])\n",
    "\n",
    "    f.save('result_client{:}.xls'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(num_users):\n",
    "    f = xlwt.Workbook('encoding = utf-8')\n",
    "    sheet1 = f.add_sheet('sheet1', cell_overwrite_ok=True)\n",
    "    for j in range(len(loss_test_collect[i])):\n",
    "        sheet1.write(j+1, 0, loss_train_collect[i][j])\n",
    "    for j in range(len(acc_test_collect[i])):\n",
    "        sheet1.write(j+1, 1, acc_train_collect[i][j])\n",
    "    for j in range(len(TPR_test_collect[i])):\n",
    "        sheet1.write(j+1, 2, TPR_train_collect[i][j])\n",
    "    for j in range(len(FPR_test_collect[i])):\n",
    "        sheet1.write(j+1, 3, FPR_train_collect[i][j])\n",
    "    for j in range(len(f1_test_collect[i])):\n",
    "        sheet1.write(j+1, 4, f1_train_collect[i][j])\n",
    "    for j in range(len(AUC_test_collect[i])):\n",
    "        sheet1.write(j+1, 5, AUC_train_collect[i][j])\n",
    "\n",
    "    f.save('result_test_client{:}.xls'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import xlwt\n",
    "f = xlwt.Workbook('encoding = utf-8')\n",
    "sheet1 = f.add_sheet('sheet1',cell_overwrite_ok=True)\n",
    "for i in range(len(local_test[\"loss\"])):\n",
    "    sheet1.write(i+1,0,local_test[\"loss\"][i])\n",
    "for i in range(len(local_test[\"acc\"])):\n",
    "    sheet1.write(i+1,1,local_test[\"acc\"][i])\n",
    "for i in range(len(local_test[\"tpr\"])):\n",
    "    sheet1.write(i+1,2,local_test[\"tpr\"][i])\n",
    "for i in range(len(local_test[\"fpr\"])):\n",
    "    sheet1.write(i+1,3,local_test[\"fpr\"][i])\n",
    "for i in range(len(local_test[\"f1\"])):\n",
    "    sheet1.write(i+1,4,local_test[\"f1\"][i])\n",
    "for i in range(len(local_test[\"auc\"])):\n",
    "    sheet1.write(i+1,5,local_test[\"auc\"][i])\n",
    "\n",
    "f.save('Local_Test.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import xlwt\n",
    "f = xlwt.Workbook('encoding = utf-8')\n",
    "sheet1 = f.add_sheet('sheet1',cell_overwrite_ok=True)\n",
    "for i in range(len(local_testing[\"loss\"])):\n",
    "    sheet1.write(i+1,0,local_testing[\"loss\"][i])\n",
    "for i in range(len(local_testing[\"acc\"])):\n",
    "    sheet1.write(i+1,1,local_testing[\"acc\"][i])\n",
    "for i in range(len(local_testing[\"tpr\"])):\n",
    "    sheet1.write(i+1,2,local_testing[\"tpr\"][i])\n",
    "for i in range(len(local_testing[\"fpr\"])):\n",
    "    sheet1.write(i+1,3,local_testing[\"fpr\"][i])\n",
    "for i in range(len(local_testing[\"f1\"])):\n",
    "    sheet1.write(i+1,4,local_testing[\"f1\"][i])\n",
    "for i in range(len(local_testing[\"auc\"])):\n",
    "    sheet1.write(i+1,5,local_testing[\"auc\"][i])\n",
    "\n",
    "f.save('Local_Testing.xls')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
