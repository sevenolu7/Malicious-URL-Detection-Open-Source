{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "df_train = pd.read_csv(\"./fine_tuning.csv\")\n",
    "\n",
    "train_data_domain = df_train.domain.values\n",
    "train_data_label = df_train.label.values\n",
    "train_data_label = train_data_label.tolist()\n",
    "train_data_label = [0 if item == 2 else 1 for item in train_data_label]\n",
    "train_data_label = np.array(train_data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer(vocab_file=\"./bert_tokenizer/vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_ids_train = []\n",
    "attention_masks_train = []\n",
    "\n",
    "for sent in train_data_domain:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        sent,                      # Sentence to encode.\n",
    "        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "        max_length = 64,           # Pad & truncate all sentences.\n",
    "        pad_to_max_length = True,\n",
    "        return_attention_mask = True,   # Construct attn. masks.\n",
    "        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "    )\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_train.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks_train.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_train = torch.cat(input_ids_train, dim=0)\n",
    "attention_masks_train = torch.cat(attention_masks_train, dim=0)\n",
    "labels_train = torch.tensor(train_data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111,998 training samples\n",
      "48,000 test samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train,attention_masks_train, labels_train) \n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.7 * len(dataset_train))\n",
    "test_size = len(dataset_train) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset_train, [train_size, test_size])\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} test samples'.format(test_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "构造MyModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "EmbeddingPath = \"./FedBert/FedTransformer.pt\"\n",
    "TransformerPath = \"./FedBert/FedEmbedding.pt\"\n",
    "num_users = 10\n",
    "frac = 0.5\n",
    "local_epochs = 5\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_name_or_path\": \"./bert-base-uncased-model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.2,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.34.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 1000\n",
      "}\n",
      "\n",
      "BertPooler(\n",
      "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (activation): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoTokenizer,DataCollatorForLanguageModeling,HfArgumentParser,Trainer,TrainingArguments,set_seed,\n",
    ")\n",
    "\n",
    "config_kwargs = {\n",
    "    \"cache_dir\": None,\n",
    "    \"revision\": 'main',\n",
    "    \"use_auth_token\": None,\n",
    "    \"hidden_dropout_prob\": 0.2,\n",
    "    \"vocab_size\": 1000 \n",
    "}\n",
    "\n",
    "config = AutoConfig.from_pretrained('./bert-base-uncased-model/', **config_kwargs)\n",
    "print(config)\n",
    "\n",
    "model = AutoModelForMaskedLM.from_config(\n",
    "    config=config,\n",
    ")\n",
    "model.resize_token_embeddings(config_kwargs[\"vocab_size\"])\n",
    "\n",
    "embedding = model.bert.embeddings\n",
    "\n",
    "class Bert_Embedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Bert_Embedding, self).__init__()\n",
    "        self.embeddings = copy.deepcopy(embedding)\n",
    "\n",
    "    def forward(self, input_ids, attn_mask):\n",
    "        embedding_output = self.embeddings(input_ids, attn_mask)\n",
    "        return embedding_output\n",
    "\n",
    "embedding_model = Bert_Embedding()\n",
    "embedding_model.load_state_dict(torch.load(EmbeddingPath))\n",
    "\n",
    "encoder = model.bert.encoder\n",
    "cls = model.cls\n",
    "\n",
    "class Bert_Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Bert_Encoder, self).__init__()\n",
    "        self.encoder = copy.deepcopy(encoder)\n",
    "        self.cls = copy.deepcopy(cls)\n",
    "\n",
    "    def forward(self, embedding_output):\n",
    "        output_encoder = self.encoder(embedding_output).last_hidden_state\n",
    "        return output_encoder\n",
    "encoder_model = Bert_Encoder()\n",
    "encoder_model.load_state_dict(torch.load(TransformerPath))\n",
    "\n",
    "from transformers.models.bert.modeling_bert import BertPooler\n",
    "class Pooler_Config:\n",
    "    def __init__(self, entries: dict={}):\n",
    "        for k, v in entries.items():\n",
    "            if isinstance(v, dict):\n",
    "                self.__dict__[k] = Pooler_Config(v)\n",
    "            else:\n",
    "                self.__dict__[k] = v\n",
    "\n",
    "config_pooler = {\"hidden_size\": 768}\n",
    "config_pooler = Pooler_Config(config_pooler)\n",
    "pooler = BertPooler(config_pooler)\n",
    "print(pooler)\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, hidden_size=768, num_classes=2, freeze_bert=False):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.embedding = Bert_Embedding()\n",
    "        self.encoder = Bert_Encoder()\n",
    "        self.pooler = copy.deepcopy(pooler)\n",
    "        if freeze_bert:\n",
    "            for p in self.embedding.parameters():\n",
    "                p.requires_grad = False\n",
    "            for p in self.encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(hidden_size, num_classes, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attn_mask):\n",
    "        embedding_outputs = self.embedding(input_ids, attn_mask)\n",
    "        encoder_outputs = self.encoder(embedding_outputs)\n",
    "        pooler_outputs = self.pooler(encoder_outputs)\n",
    "\n",
    "        logits = self.fc(pooler_outputs)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "iid数据分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def dataset_iid(dataset, num_users):\n",
    "\n",
    "    num_items = int(len(dataset)/num_users)\n",
    "    dict_users, all_idxs = {}, [i for i in range(len(dataset))]\n",
    "    for i in range(num_users):\n",
    "        dict_users[i] = set(np.random.choice(all_idxs, num_items, replace = False))\n",
    "        all_idxs = list(set(all_idxs) - dict_users[i])\n",
    "    return dict_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "dict_user_train = dataset_iid(train_dataset, num_users)\n",
    "dict_user_test = dataset_iid(test_dataset, num_users)\n",
    "\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (embedding): Bert_Embedding(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(1000, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (encoder): Bert_Encoder(\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cls): Sequential()\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=768, out_features=2, bias=False)\n",
      "    (2): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net_glob = MyModel()\n",
    "net_glob.encoder.cls = nn.Sequential()\n",
    "print(net_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "loss_train_collect = {}\n",
    "acc_train_collect = {}\n",
    "loss_test_collect = {}\n",
    "acc_test_collect = {}\n",
    "TPR_train_collect = {}\n",
    "TPR_test_collect = {}\n",
    "FPR_train_collect = {}\n",
    "FPR_test_collect = {}\n",
    "f1_train_collect = {}\n",
    "f1_test_collect = {}\n",
    "AUC_train_collect = {}\n",
    "AUC_test_collect = {}\n",
    "ROC_train_collect = {}\n",
    "ROC_test_collect = {}\n",
    "\n",
    "local_test = {}\n",
    "local_testing = {}\n",
    "\n",
    "loss_collect = []\n",
    "acc_collect = []\n",
    "TPR_collect = []\n",
    "FPR_collect = []\n",
    "F1_collect = []\n",
    "AUC_collect = []\n",
    "\n",
    "count1 = 0\n",
    "count2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def FedAvg(w):\n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    for k in w_avg.keys():\n",
    "        for i in range(1, len(w)):\n",
    "            w_avg[k] += w[i][k]\n",
    "        w_avg[k] = torch.div(w_avg[k], len(w))\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "idx_collect = []\n",
    "l_epoch_check = False\n",
    "fed_check = False\n",
    "# Initialization of net_model_server and net_server (server-side model)\n",
    "net_model = [net_glob for i in range(num_users)]\n",
    "net_server = copy.deepcopy(net_model[0]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "class DatasetSplit(Dataset):\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = list(idxs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        domain, mask, label = self.dataset[self.idxs[item]]\n",
    "        return domain, mask, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    return np.sum(preds == labels) / len(labels)\n",
    "\n",
    "def tpr_calculate(preds, labels):\n",
    "    return recall_score(labels, preds, zero_division=1)\n",
    "\n",
    "def fpr_calculate(preds, labels):\n",
    "    conf_matrix = confusion_matrix(labels, preds)\n",
    "    fp = conf_matrix[0, 1]  # 0 表示负类别，1 表示正类别\n",
    "    tn = conf_matrix[0, 0]\n",
    "    fpr = fp / (fp + tn)\n",
    "    return fpr\n",
    "\n",
    "def f1_score_calculate(preds, labels):\n",
    "    return f1_score(labels, preds)\n",
    "\n",
    "def AUC_calculate(preds, labels):\n",
    "    return roc_auc_score(labels, preds)\n",
    "\n",
    "def roc_curve_calculate(preds, labels):\n",
    "    return roc_curve(labels, preds)\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Client(object):\n",
    "    def __init__(self, device, idx, lr, local_epochs, batch_size, dataset_train = None, dataset_test = None, idxs = None, idxs_test = None):\n",
    "        self.device = device\n",
    "        self.lr = lr\n",
    "        self.idx = idx\n",
    "        self.local_ep = local_epochs\n",
    "        self.ldr_train = DataLoader(DatasetSplit(dataset_train, idxs), batch_size = batch_size, shuffle = True)\n",
    "        self.ldr_test = DataLoader(DatasetSplit(dataset_test, idxs_test), batch_size = batch_size, shuffle= True)\n",
    "\n",
    "    def train(self, net):\n",
    "        net.train()\n",
    "        optimizer_client = torch.optim.Adam(net.parameters(), lr = self.lr)\n",
    "\n",
    "        TPR_train_collect[self.idx] = []\n",
    "        FPR_train_collect[self.idx] = []\n",
    "        f1_train_collect[self.idx] = []\n",
    "        AUC_train_collect[self.idx] = []\n",
    "        loss_train_collect[self.idx] = []\n",
    "        acc_train_collect[self.idx] = []\n",
    "\n",
    "        epoch_loss = []\n",
    "        epoch_accuracy = []\n",
    "        for iter in range(self.local_ep):\n",
    "            tmp_t0 = time.time()\n",
    "            batch_loss_train = []\n",
    "            batch_acc_train = []\n",
    "            batch_tpr_train = []\n",
    "            batch_fpr_train = []\n",
    "            batch_f1_train = []\n",
    "            batch_auc_train = []\n",
    "            for batch_idx, (ids, attn_mask, b_labels) in enumerate(self.ldr_train):\n",
    "                ids, attn_mask, b_labels = ids.to(self.device), attn_mask.to(self.device), b_labels.to(self.device)\n",
    "                optimizer_client.zero_grad()\n",
    "                b_labels = b_labels.unsqueeze(1)\n",
    "                b_labels = b_labels.repeat(1,2)\n",
    "                for i in range(len(b_labels)):\n",
    "                    b_labels[i][1] = 1-b_labels[i][0]\n",
    "                logits = net(ids, attn_mask)\n",
    "                BCEloss = criterion(logits, b_labels.float())\n",
    "                BCEloss.backward()\n",
    "                optimizer_client.step()\n",
    "                batch_loss_train.append(BCEloss.item())\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                label_ids = b_labels.to('cpu').numpy()\n",
    "                logits = np.argmax(logits, axis=1).flatten()\n",
    "                label_ids = np.argmax(label_ids,axis=1).flatten()\n",
    "                accuracy = flat_accuracy(logits, label_ids)\n",
    "                tpr = tpr_calculate(logits, label_ids)\n",
    "                fpr = fpr_calculate(logits, label_ids)\n",
    "                f1 = f1_score_calculate(logits, label_ids)\n",
    "                if len(set(label_ids)) == 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    auc = AUC_calculate(logits, label_ids)\n",
    "                    batch_auc_train.append(auc)\n",
    "                batch_acc_train.append(accuracy)\n",
    "                batch_tpr_train.append(tpr)\n",
    "                batch_fpr_train.append(fpr)\n",
    "                batch_f1_train.append(f1)\n",
    "            elapsed = format_time(time.time()-tmp_t0)\n",
    "            epoch_avg_loss = sum(batch_loss_train)/len(batch_loss_train)\n",
    "            epoch_avg_acc = sum(batch_acc_train)/len(batch_acc_train)\n",
    "            epoch_avg_tpr = sum(batch_tpr_train)/len(batch_tpr_train)\n",
    "            epoch_avg_fpr = sum(batch_fpr_train)/len(batch_fpr_train)\n",
    "            epoch_avg_f1 = sum(batch_f1_train)/len(batch_f1_train)\n",
    "            epoch_avg_auc = sum(batch_auc_train)/len(batch_auc_train)\n",
    "            epoch_loss.append(sum(batch_loss_train)/len(batch_loss_train))\n",
    "            epoch_accuracy.append(sum(batch_acc_train)/len(batch_acc_train))\n",
    "            loss_train_collect[self.idx].append(epoch_avg_loss)\n",
    "            acc_train_collect[self.idx].append(epoch_avg_acc)\n",
    "            TPR_train_collect[self.idx].append(epoch_avg_tpr)\n",
    "            FPR_train_collect[self.idx].append(epoch_avg_fpr)\n",
    "            f1_train_collect[self.idx].append(epoch_avg_f1)\n",
    "            AUC_train_collect[self.idx].append(epoch_avg_auc)\n",
    "            loss_collect.append(epoch_avg_loss)\n",
    "            acc_collect.append(epoch_avg_acc)\n",
    "            TPR_collect.append(epoch_avg_tpr)\n",
    "            FPR_collect.append(epoch_avg_fpr)\n",
    "            F1_collect.append(epoch_avg_f1)\n",
    "            AUC_collect.append(epoch_avg_auc)\n",
    "\n",
    "            print('Client{} Local Train => Local Epoch: {} \\tLoss: {:.10f} \\tAcc: {:.10f} \\tTPR:{:.10f} \\tFPR:{:.10f} \\tF1:{:.10f} \\t AUC:{:.10f}\\tTrain cost: {:}'.format(self.idx, iter, epoch_avg_loss,\\\n",
    "                                                                                                       epoch_avg_acc, epoch_avg_tpr, epoch_avg_fpr, epoch_avg_f1, epoch_avg_auc, elapsed))\n",
    "        net_glob.load_state_dict(net.state_dict())\n",
    "        return net.state_dict(), sum(epoch_loss) / len(epoch_loss), sum(epoch_accuracy) / len(epoch_accuracy)\n",
    "\n",
    "    def evaluate(self, net, ell):\n",
    "        net.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tmp_t0 = time.time()\n",
    "            len_batch = len(self.ldr_test)\n",
    "\n",
    "            batch_acc_test = []\n",
    "            batch_loss_test = []\n",
    "            batch_tpr_test = []\n",
    "            batch_fpr_test = []\n",
    "            batch_f1_test = []\n",
    "            batch_auc_test = []\n",
    "            for batch_idx, (ids, attn_mask, b_labels) in enumerate(self.ldr_test):\n",
    "                ids, attn_mask, b_labels = ids.to(self.device), attn_mask.to(self.device) , b_labels.to(self.device)\n",
    "                b_labels = b_labels.unsqueeze(1)\n",
    "                b_labels = b_labels.repeat(1,2)\n",
    "                for i in range(len(b_labels)):\n",
    "                    b_labels[i][1] = 1-b_labels[i][0]\n",
    "                logits = net(ids, attn_mask)\n",
    "                BCEloss = criterion(logits, b_labels.float())\n",
    "                batch_loss_test.append(BCEloss.item())\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                label_ids = b_labels.to('cpu').numpy()\n",
    "                logits = np.argmax(logits, axis=1).flatten()\n",
    "                label_ids = np.argmax(label_ids,axis=1).flatten()\n",
    "                accuracy = flat_accuracy(logits, label_ids)\n",
    "                tpr = tpr_calculate(logits, label_ids)\n",
    "                if len(set(label_ids)) == 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    fpr = fpr_calculate(logits, label_ids)\n",
    "                    batch_fpr_test.append(fpr)\n",
    "                f1 = f1_score_calculate(logits, label_ids)\n",
    "                if len(set(label_ids)) == 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    auc = AUC_calculate(logits, label_ids)\n",
    "                    batch_auc_test.append(auc)\n",
    "                batch_acc_test.append(accuracy)\n",
    "                batch_tpr_test.append(tpr)\n",
    "                batch_f1_test.append(f1)\n",
    "            elapsed = format_time(time.time()-tmp_t0)\n",
    "            test_avg_loss = sum(batch_loss_test) / len(batch_loss_test)\n",
    "            test_avg_acc = sum(batch_acc_test) / len(batch_acc_test)\n",
    "            test_avg_tpr = sum(batch_tpr_test)/len(batch_tpr_test)\n",
    "            test_avg_fpr = sum(batch_fpr_test) / len(batch_fpr_test)\n",
    "            test_avg_f1 = sum(batch_f1_test)/len(batch_f1_test)\n",
    "            test_avg_auc = sum(batch_auc_test)/len(batch_auc_test)\n",
    "            local_test[\"loss\"].append(test_avg_loss)\n",
    "            local_test[\"acc\"].append(test_avg_acc)\n",
    "            local_test[\"tpr\"].append(test_avg_tpr)\n",
    "            local_test[\"fpr\"].append(test_avg_fpr)\n",
    "            local_test[\"f1\"].append(test_avg_f1)\n",
    "            local_test[\"auc\"].append(test_avg_auc)\n",
    "            print('Client{} Test =>                 \\tLoss: {:.10f} \\tAcc: {:.10f} \\tTPR:{:.10f} \\tFPR:{:.10f} \\tF1:{:.10f} \\tAUC:{:.10f} \\ttest cost: {:}'.format(self.idx, test_avg_loss, test_avg_acc, test_avg_tpr, test_avg_fpr, test_avg_f1, test_avg_auc, elapsed))\n",
    "\n",
    "        return test_avg_loss, test_avg_acc, test_avg_tpr, test_avg_fpr, test_avg_f1, test_avg_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test Begin!\n",
      "============== Round 0:  =============\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.6272902027 \tAcc: 0.6537240783 \tTPR:0.7593991838 \tFPR:0.4528384268 \tF1:0.6838900180 \t AUC:0.6532803785\tTrain cost: 0:00:34\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.5961614575 \tAcc: 0.6848934332 \tTPR:0.7949938600 \tFPR:0.4271178049 \tF1:0.7120313939 \t AUC:0.6839380275\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.5019100147 \tAcc: 0.7570391705 \tTPR:0.8340190530 \tFPR:0.3251060476 \tF1:0.7700943178 \t AUC:0.7544565027\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.4176253469 \tAcc: 0.8094527650 \tTPR:0.8529519031 \tFPR:0.2381832702 \tF1:0.8148396144 \t AUC:0.8073843165\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.3759440225 \tAcc: 0.8287269585 \tTPR:0.8656580617 \tFPR:0.2100626500 \tF1:0.8317424047 \t AUC:0.8277977058\tTrain cost: 0:00:33\n",
      "Client6 Test =>                 \tLoss: 0.3389969882 \tAcc: 0.8475000000 \tTPR:0.8605162146 \tFPR:0.1682922419 \tF1:0.8437775864 \tAUC:0.8461119864 \ttest cost: 0:00:05\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.3719426459 \tAcc: 0.8331077189 \tTPR:0.8714010653 \tFPR:0.2055827396 \tF1:0.8351936365 \t AUC:0.8329091629\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.3539548816 \tAcc: 0.8447983871 \tTPR:0.8792515640 \tFPR:0.1916421126 \tF1:0.8457970061 \t AUC:0.8438047257\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.3410252364 \tAcc: 0.8516676267 \tTPR:0.8818930773 \tFPR:0.1799370077 \tF1:0.8499967064 \t AUC:0.8509780348\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.3283841978 \tAcc: 0.8594556452 \tTPR:0.8908218264 \tFPR:0.1732158400 \tF1:0.8595397431 \t AUC:0.8588029932\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.3185431059 \tAcc: 0.8638306452 \tTPR:0.8948373199 \tFPR:0.1671329089 \tF1:0.8635528926 \t AUC:0.8638522055\tTrain cost: 0:00:34\n",
      "Client8 Test =>                 \tLoss: 0.2864434659 \tAcc: 0.8812500000 \tTPR:0.8866228725 \tFPR:0.1268365850 \tF1:0.8769681686 \tAUC:0.8798931438 \ttest cost: 0:00:05\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.3092226243 \tAcc: 0.8705184332 \tTPR:0.8999073199 \tFPR:0.1587925450 \tF1:0.8708684663 \t AUC:0.8705573875\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.2938165516 \tAcc: 0.8782978111 \tTPR:0.9050532382 \tFPR:0.1508522499 \tF1:0.8789304563 \t AUC:0.8771004942\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.2889158493 \tAcc: 0.8798156682 \tTPR:0.9054344731 \tFPR:0.1469966946 \tF1:0.8790347171 \t AUC:0.8792188892\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.2765090984 \tAcc: 0.8818692396 \tTPR:0.9025979017 \tFPR:0.1439231042 \tF1:0.8800158380 \t AUC:0.8793373987\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.2729314103 \tAcc: 0.8881192396 \tTPR:0.9107361405 \tFPR:0.1344106454 \tF1:0.8881403726 \t AUC:0.8881627476\tTrain cost: 0:00:34\n",
      "Client1 Test =>                 \tLoss: 0.2517954849 \tAcc: 0.8989583333 \tTPR:0.8649870174 \tFPR:0.0695999445 \tF1:0.8900094512 \tAUC:0.8976935364 \ttest cost: 0:00:05\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.2744374354 \tAcc: 0.8878341014 \tTPR:0.9117553857 \tFPR:0.1378788620 \tF1:0.8892376615 \t AUC:0.8869382619\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.2659176873 \tAcc: 0.8916013825 \tTPR:0.9170231261 \tFPR:0.1348304277 \tF1:0.8929117415 \t AUC:0.8910963492\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.2591644144 \tAcc: 0.8934821429 \tTPR:0.9145230282 \tFPR:0.1279702207 \tF1:0.8950642677 \t AUC:0.8932764037\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.2518746305 \tAcc: 0.8941964286 \tTPR:0.9083024908 \tFPR:0.1228099793 \tF1:0.8932766343 \t AUC:0.8927462557\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.2419129532 \tAcc: 0.8996342166 \tTPR:0.9170879010 \tFPR:0.1192745078 \tF1:0.8998280433 \t AUC:0.8989066966\tTrain cost: 0:00:34\n",
      "Client7 Test =>                 \tLoss: 0.2192710062 \tAcc: 0.9104166667 \tTPR:0.8965084911 \tFPR:0.0758489993 \tF1:0.9058172323 \tAUC:0.9103297459 \ttest cost: 0:00:05\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.2531844663 \tAcc: 0.8961520737 \tTPR:0.9113617910 \tFPR:0.1205917333 \tF1:0.8929202764 \t AUC:0.8953850288\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.2436714592 \tAcc: 0.8989228111 \tTPR:0.9109008405 \tFPR:0.1109662611 \tF1:0.8951296495 \t AUC:0.8999672897\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.2344918054 \tAcc: 0.9048185484 \tTPR:0.9165310859 \tFPR:0.1046058169 \tF1:0.9011942004 \t AUC:0.9059626345\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.2312495910 \tAcc: 0.9057891705 \tTPR:0.9191773454 \tFPR:0.1066072935 \tF1:0.9028163287 \t AUC:0.9062850259\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.2239580026 \tAcc: 0.9085627880 \tTPR:0.9203880761 \tFPR:0.1023549580 \tF1:0.9050027199 \t AUC:0.9090165590\tTrain cost: 0:00:34\n",
      "Client0 Test =>                 \tLoss: 0.2221623254 \tAcc: 0.9083333333 \tTPR:0.8950519902 \tFPR:0.0800835469 \tF1:0.9065207888 \tAUC:0.9074842217 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2637338541 \tAcc: 0.8892916667 \tTPR:0.8807373172 \tFPR:0.1041322635 \tF1:0.8846186455 \tAUC:0.8883025268\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 1:  =============\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.2775204542 \tAcc: 0.8863277650 \tTPR:0.9089419927 \tFPR:0.1350510069 \tF1:0.8854627379 \t AUC:0.8869454929\tTrain cost: 0:00:34\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.2639404616 \tAcc: 0.8904377880 \tTPR:0.9106329094 \tFPR:0.1298858239 \tF1:0.8882408946 \t AUC:0.8903735428\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.2525858311 \tAcc: 0.8973185484 \tTPR:0.9159757248 \tFPR:0.1198523637 \tF1:0.8956809653 \t AUC:0.8980616805\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.2403483441 \tAcc: 0.9020391705 \tTPR:0.9191698479 \tFPR:0.1161465130 \tF1:0.8996912893 \t AUC:0.9015116674\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.2350823864 \tAcc: 0.9061491935 \tTPR:0.9195009729 \tFPR:0.1069372052 \tF1:0.9036435370 \t AUC:0.9062818838\tTrain cost: 0:00:33\n",
      "Client3 Test =>                 \tLoss: 0.2406150049 \tAcc: 0.9041666667 \tTPR:0.8755775276 \tFPR:0.0701945703 \tF1:0.8993006212 \tAUC:0.9026914786 \ttest cost: 0:00:05\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.2442157639 \tAcc: 0.9003456221 \tTPR:0.9175262002 \tFPR:0.1168282624 \tF1:0.8988884756 \t AUC:0.9003489689\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.2457856966 \tAcc: 0.8983784562 \tTPR:0.9162322716 \tFPR:0.1192577987 \tF1:0.8967240833 \t AUC:0.8984872365\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.2311749743 \tAcc: 0.9088248848 \tTPR:0.9215233937 \tFPR:0.1060579710 \tF1:0.9061480356 \t AUC:0.9077327114\tTrain cost: 0:00:34\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.2269697327 \tAcc: 0.9092770737 \tTPR:0.9238918804 \tFPR:0.1057823938 \tF1:0.9072680333 \t AUC:0.9090547433\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.2213516751 \tAcc: 0.9134792627 \tTPR:0.9290114330 \tFPR:0.1014008176 \tF1:0.9124124883 \t AUC:0.9138053077\tTrain cost: 0:00:33\n",
      "Client9 Test =>                 \tLoss: 0.2490522686 \tAcc: 0.9066666667 \tTPR:0.8563970686 \tFPR:0.0443141749 \tF1:0.8993488271 \tAUC:0.9060414468 \ttest cost: 0:00:05\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.2314297128 \tAcc: 0.9047177419 \tTPR:0.9212178492 \tFPR:0.1113871555 \tF1:0.9042743110 \t AUC:0.9049153469\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.2285054019 \tAcc: 0.9054435484 \tTPR:0.9185355517 \tFPR:0.1077165466 \tF1:0.9033460050 \t AUC:0.9054095026\tTrain cost: 0:00:34\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.2190863209 \tAcc: 0.9125806452 \tTPR:0.9256768777 \tFPR:0.0999642462 \tF1:0.9113119935 \t AUC:0.9128563157\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.2125064649 \tAcc: 0.9122206221 \tTPR:0.9282401842 \tFPR:0.1045537194 \tF1:0.9103188628 \t AUC:0.9118432324\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.2074884904 \tAcc: 0.9160714286 \tTPR:0.9278174848 \tFPR:0.0962206053 \tF1:0.9145872347 \t AUC:0.9157984398\tTrain cost: 0:00:33\n",
      "Client4 Test =>                 \tLoss: 0.2260693354 \tAcc: 0.9122916667 \tTPR:0.9001812776 \tFPR:0.0757445478 \tF1:0.9072478491 \tAUC:0.9122183649 \ttest cost: 0:00:05\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.2303452789 \tAcc: 0.9040092166 \tTPR:0.9217018407 \tFPR:0.1123274009 \tF1:0.9026081106 \t AUC:0.9046872199\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.2255437011 \tAcc: 0.9110627880 \tTPR:0.9258261762 \tFPR:0.1036412041 \tF1:0.9098508542 \t AUC:0.9110924861\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.2139505347 \tAcc: 0.9115149770 \tTPR:0.9270582842 \tFPR:0.1046306187 \tF1:0.9102665677 \t AUC:0.9112138328\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.2083415744 \tAcc: 0.9165034562 \tTPR:0.9316331868 \tFPR:0.0995628340 \tF1:0.9153849251 \t AUC:0.9160351764\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.2047663168 \tAcc: 0.9205299539 \tTPR:0.9362841214 \tFPR:0.0948084909 \tF1:0.9202403755 \t AUC:0.9207378153\tTrain cost: 0:00:33\n",
      "Client5 Test =>                 \tLoss: 0.2022808471 \tAcc: 0.9204166667 \tTPR:0.8889388412 \tFPR:0.0464130333 \tF1:0.9173469892 \tAUC:0.9212629039 \ttest cost: 0:00:05\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.2074060227 \tAcc: 0.9175806452 \tTPR:0.9337777638 \tFPR:0.0989952695 \tF1:0.9182981046 \t AUC:0.9173912471\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1994907214 \tAcc: 0.9206192396 \tTPR:0.9367705508 \tFPR:0.0949001391 \tF1:0.9212287248 \t AUC:0.9209352058\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1901184953 \tAcc: 0.9239256912 \tTPR:0.9376831728 \tFPR:0.0897040599 \tF1:0.9237487582 \t AUC:0.9239895565\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1915401880 \tAcc: 0.9253456221 \tTPR:0.9396588304 \tFPR:0.0891169011 \tF1:0.9248033207 \t AUC:0.9252709646\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1844836613 \tAcc: 0.9281163594 \tTPR:0.9424292801 \tFPR:0.0855803985 \tF1:0.9287341330 \t AUC:0.9284244408\tTrain cost: 0:00:33\n",
      "Client7 Test =>                 \tLoss: 0.2010383837 \tAcc: 0.9233333333 \tTPR:0.9036139363 \tFPR:0.0576154795 \tF1:0.9193561574 \tAUC:0.9229992284 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2238111679 \tAcc: 0.9133750000 \tTPR:0.8849417302 \tFPR:0.0588563612 \tF1:0.9085200888 \tAUC:0.9130426845\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 2:  =============\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.2115704738 \tAcc: 0.9166906682 \tTPR:0.9287354866 \tFPR:0.0935894360 \tF1:0.9143349545 \t AUC:0.9175730253\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.2077251452 \tAcc: 0.9154349078 \tTPR:0.9263572709 \tFPR:0.0956557066 \tF1:0.9136386547 \t AUC:0.9153507822\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1995717196 \tAcc: 0.9191071429 \tTPR:0.9316944099 \tFPR:0.0952102600 \tF1:0.9170904410 \t AUC:0.9182420750\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1982178219 \tAcc: 0.9210656682 \tTPR:0.9351760097 \tFPR:0.0924899825 \tF1:0.9193610898 \t AUC:0.9213430136\tTrain cost: 0:00:34\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1892222906 \tAcc: 0.9242770737 \tTPR:0.9390607344 \tFPR:0.0895210090 \tF1:0.9232574837 \t AUC:0.9247698627\tTrain cost: 0:00:33\n",
      "Client4 Test =>                 \tLoss: 0.2503750848 \tAcc: 0.9062500000 \tTPR:0.8527154089 \tFPR:0.0377388259 \tF1:0.8982379683 \tAUC:0.9074882915 \ttest cost: 0:00:05\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.2176267119 \tAcc: 0.9111578341 \tTPR:0.9299523326 \tFPR:0.1080059960 \tF1:0.9108278178 \t AUC:0.9109731683\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.2091950580 \tAcc: 0.9166877880 \tTPR:0.9340934753 \tFPR:0.0996340065 \tF1:0.9155566298 \t AUC:0.9172297344\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.2057559938 \tAcc: 0.9188306452 \tTPR:0.9339621857 \tFPR:0.0964783787 \tF1:0.9173892862 \t AUC:0.9187419035\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.2008993128 \tAcc: 0.9180241935 \tTPR:0.9337891468 \tFPR:0.0990115365 \tF1:0.9173835601 \t AUC:0.9173888052\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1976332913 \tAcc: 0.9220506912 \tTPR:0.9379211715 \tFPR:0.0926278261 \tF1:0.9205927358 \t AUC:0.9226466727\tTrain cost: 0:00:33\n",
      "Client5 Test =>                 \tLoss: 0.2201794279 \tAcc: 0.9102083333 \tTPR:0.8584025192 \tFPR:0.0370816033 \tF1:0.9029253266 \tAUC:0.9106604580 \ttest cost: 0:00:05\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1961143305 \tAcc: 0.9223185484 \tTPR:0.9318990270 \tFPR:0.0881849147 \tF1:0.9200168496 \t AUC:0.9218570561\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1889434362 \tAcc: 0.9247235023 \tTPR:0.9388958657 \tFPR:0.0873039453 \tF1:0.9225431999 \t AUC:0.9257959602\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1844562650 \tAcc: 0.9263335253 \tTPR:0.9380505247 \tFPR:0.0854770951 \tF1:0.9248231595 \t AUC:0.9262867148\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1772860175 \tAcc: 0.9308784562 \tTPR:0.9434157805 \tFPR:0.0802187504 \tF1:0.9288841629 \t AUC:0.9315985151\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1789714078 \tAcc: 0.9301699309 \tTPR:0.9425640936 \tFPR:0.0808470911 \tF1:0.9283775303 \t AUC:0.9308585013\tTrain cost: 0:00:33\n",
      "Client3 Test =>                 \tLoss: 0.2305801308 \tAcc: 0.9139583333 \tTPR:0.8729735358 \tFPR:0.0441079630 \tF1:0.9080031028 \tAUC:0.9144327864 \ttest cost: 0:00:05\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.2033761285 \tAcc: 0.9182949309 \tTPR:0.9305004975 \tFPR:0.0936499803 \tF1:0.9163271670 \t AUC:0.9184252586\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.1909872427 \tAcc: 0.9255213134 \tTPR:0.9395223841 \tFPR:0.0892684918 \tF1:0.9245610630 \t AUC:0.9251269462\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.1883023560 \tAcc: 0.9238335253 \tTPR:0.9352672695 \tFPR:0.0889174267 \tF1:0.9226773276 \t AUC:0.9231749214\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.1850295430 \tAcc: 0.9254349078 \tTPR:0.9382349137 \tFPR:0.0870661214 \tF1:0.9245149072 \t AUC:0.9255843962\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.1779028184 \tAcc: 0.9284763825 \tTPR:0.9394968438 \tFPR:0.0830807208 \tF1:0.9270812942 \t AUC:0.9282080615\tTrain cost: 0:00:33\n",
      "Client9 Test =>                 \tLoss: 0.2598030457 \tAcc: 0.9016666667 \tTPR:0.8442418917 \tFPR:0.0396253408 \tF1:0.8937260746 \tAUC:0.9023082755 \ttest cost: 0:00:05\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1995986810 \tAcc: 0.9207949309 \tTPR:0.9360320372 \tFPR:0.0953727051 \tF1:0.9196588629 \t AUC:0.9203296661\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1920151738 \tAcc: 0.9220449309 \tTPR:0.9383975127 \tFPR:0.0952911534 \tF1:0.9214439156 \t AUC:0.9215531796\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1878861716 \tAcc: 0.9226699309 \tTPR:0.9377392395 \tFPR:0.0951679936 \tF1:0.9211175352 \t AUC:0.9212856230\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1850357409 \tAcc: 0.9250806452 \tTPR:0.9411402573 \tFPR:0.0921992732 \tF1:0.9247388834 \t AUC:0.9244704920\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1794634859 \tAcc: 0.9301728111 \tTPR:0.9468263657 \tFPR:0.0877778704 \tF1:0.9304654295 \t AUC:0.9295242476\tTrain cost: 0:00:34\n",
      "Client1 Test =>                 \tLoss: 0.2404101931 \tAcc: 0.9043750000 \tTPR:0.8325446778 \tFPR:0.0274859387 \tF1:0.8909520213 \tAUC:0.9025293696 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2402695765 \tAcc: 0.9072916667 \tTPR:0.8521756067 \tFPR:0.0372079343 \tF1:0.8987688987 \tAUC:0.9074838362\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 3:  =============\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1883025744 \tAcc: 0.9230299539 \tTPR:0.9385987908 \tFPR:0.0914633886 \tF1:0.9225349638 \t AUC:0.9235677011\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1819719493 \tAcc: 0.9274049539 \tTPR:0.9429718036 \tFPR:0.0895899970 \tF1:0.9272295733 \t AUC:0.9266909033\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1802178229 \tAcc: 0.9293692396 \tTPR:0.9436561940 \tFPR:0.0858673352 \tF1:0.9289450859 \t AUC:0.9288944294\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1743018892 \tAcc: 0.9306250000 \tTPR:0.9438113460 \tFPR:0.0823936613 \tF1:0.9300914593 \t AUC:0.9307088424\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1738055558 \tAcc: 0.9291935484 \tTPR:0.9444037248 \tFPR:0.0851126495 \tF1:0.9295459543 \t AUC:0.9296455376\tTrain cost: 0:00:33\n",
      "Client6 Test =>                 \tLoss: 0.2608085412 \tAcc: 0.8989583333 \tTPR:0.8321921238 \tFPR:0.0353807766 \tF1:0.8858132920 \tAUC:0.8984056736 \ttest cost: 0:00:05\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1808292140 \tAcc: 0.9282085253 \tTPR:0.9416837885 \tFPR:0.0858963972 \tF1:0.9273731443 \t AUC:0.9278936957\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1751966999 \tAcc: 0.9322263825 \tTPR:0.9440634371 \tFPR:0.0793694491 \tF1:0.9304165828 \t AUC:0.9323469940\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1689784434 \tAcc: 0.9340149770 \tTPR:0.9458862815 \tFPR:0.0780965209 \tF1:0.9324110931 \t AUC:0.9338948803\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1692097115 \tAcc: 0.9336491935 \tTPR:0.9443184086 \tFPR:0.0786306258 \tF1:0.9320382884 \t AUC:0.9328438914\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1606616436 \tAcc: 0.9390149770 \tTPR:0.9511903349 \tFPR:0.0737042938 \tF1:0.9372881148 \t AUC:0.9387430206\tTrain cost: 0:00:33\n",
      "Client3 Test =>                 \tLoss: 0.2331826819 \tAcc: 0.9181250000 \tTPR:0.8821876447 \tFPR:0.0448750265 \tF1:0.9115466120 \tAUC:0.9186563091 \ttest cost: 0:00:05\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1896632827 \tAcc: 0.9233813364 \tTPR:0.9402148384 \tFPR:0.0936885511 \tF1:0.9236527400 \t AUC:0.9232631437\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1824819616 \tAcc: 0.9285656682 \tTPR:0.9418081744 \tFPR:0.0862034781 \tF1:0.9289057464 \t AUC:0.9278023481\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1793082250 \tAcc: 0.9286578341 \tTPR:0.9419374135 \tFPR:0.0853755431 \tF1:0.9287739394 \t AUC:0.9282809352\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1775418879 \tAcc: 0.9279435484 \tTPR:0.9394562251 \tFPR:0.0834083984 \tF1:0.9269231005 \t AUC:0.9280239133\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1734936707 \tAcc: 0.9293721198 \tTPR:0.9430305324 \tFPR:0.0854201196 \tF1:0.9296110793 \t AUC:0.9288052064\tTrain cost: 0:00:33\n",
      "Client7 Test =>                 \tLoss: 0.2122469709 \tAcc: 0.9175000000 \tTPR:0.8741129120 \tFPR:0.0403320380 \tF1:0.9106048782 \tAUC:0.9168904370 \ttest cost: 0:00:05\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1834812311 \tAcc: 0.9286578341 \tTPR:0.9427307294 \tFPR:0.0858357070 \tF1:0.9274529779 \t AUC:0.9284475112\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1797692102 \tAcc: 0.9268692396 \tTPR:0.9419087347 \tFPR:0.0893216079 \tF1:0.9259223532 \t AUC:0.9262935634\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1773549526 \tAcc: 0.9290149770 \tTPR:0.9437618896 \tFPR:0.0866024608 \tF1:0.9283212888 \t AUC:0.9285797144\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1730987926 \tAcc: 0.9322263825 \tTPR:0.9482994396 \tFPR:0.0825114487 \tF1:0.9318099434 \t AUC:0.9328939955\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1723241021 \tAcc: 0.9317655530 \tTPR:0.9420863841 \tFPR:0.0796002672 \tF1:0.9296870164 \t AUC:0.9312430585\tTrain cost: 0:00:33\n",
      "Client8 Test =>                 \tLoss: 0.2525231690 \tAcc: 0.9097916667 \tTPR:0.8541189493 \tFPR:0.0327517082 \tF1:0.9008658105 \tAUC:0.9106836205 \ttest cost: 0:00:05\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1820572291 \tAcc: 0.9282027650 \tTPR:0.9442562470 \tFPR:0.0881889619 \tF1:0.9269438314 \t AUC:0.9280336425\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1763761993 \tAcc: 0.9279349078 \tTPR:0.9433963601 \tFPR:0.0860647210 \tF1:0.9262815683 \t AUC:0.9286658196\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1717904770 \tAcc: 0.9310656682 \tTPR:0.9436623047 \tFPR:0.0817101882 \tF1:0.9295105812 \t AUC:0.9309760582\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1677673249 \tAcc: 0.9303427419 \tTPR:0.9449117274 \tFPR:0.0845465277 \tF1:0.9285123941 \t AUC:0.9301825999\tTrain cost: 0:00:34\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1622356016 \tAcc: 0.9347321429 \tTPR:0.9492211816 \tFPR:0.0789973399 \tF1:0.9334974063 \t AUC:0.9351119208\tTrain cost: 0:00:34\n",
      "Client4 Test =>                 \tLoss: 0.2112968707 \tAcc: 0.9218750000 \tTPR:0.8953543692 \tFPR:0.0492719963 \tF1:0.9182565000 \tAUC:0.9230411864 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2340116467 \tAcc: 0.9132500000 \tTPR:0.8675931998 \tFPR:0.0405223091 \tF1:0.9054174185 \tAUC:0.9135354453\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 4:  =============\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1795200096 \tAcc: 0.9297263825 \tTPR:0.9452069855 \tFPR:0.0847884075 \tF1:0.9292001508 \t AUC:0.9302092890\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1722305221 \tAcc: 0.9320478111 \tTPR:0.9456471162 \tFPR:0.0816339733 \tF1:0.9304339323 \t AUC:0.9320065715\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1725805556 \tAcc: 0.9307027650 \tTPR:0.9440431474 \tFPR:0.0838139789 \tF1:0.9299898430 \t AUC:0.9301145842\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1652218234 \tAcc: 0.9332978111 \tTPR:0.9448902374 \tFPR:0.0810274461 \tF1:0.9319186286 \t AUC:0.9319313957\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1635827755 \tAcc: 0.9357142857 \tTPR:0.9494211120 \tFPR:0.0775201885 \tF1:0.9349018258 \t AUC:0.9359504617\tTrain cost: 0:00:34\n",
      "Client8 Test =>                 \tLoss: 0.2338995595 \tAcc: 0.9152083333 \tTPR:0.8757211388 \tFPR:0.0465084804 \tF1:0.9087651724 \tAUC:0.9146063292 \ttest cost: 0:00:05\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1725723501 \tAcc: 0.9324078341 \tTPR:0.9489838479 \tFPR:0.0839538491 \tF1:0.9323665049 \t AUC:0.9325149994\tTrain cost: 0:00:34\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1656072666 \tAcc: 0.9332978111 \tTPR:0.9508736441 \tFPR:0.0855927178 \tF1:0.9335813432 \t AUC:0.9326404631\tTrain cost: 0:00:34\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1618689049 \tAcc: 0.9347292627 \tTPR:0.9476389606 \tFPR:0.0799869760 \tF1:0.9345424561 \t AUC:0.9338259923\tTrain cost: 0:00:34\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1520314855 \tAcc: 0.9399078341 \tTPR:0.9556540671 \tFPR:0.0748909366 \tF1:0.9395466629 \t AUC:0.9403815653\tTrain cost: 0:00:34\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1518601317 \tAcc: 0.9398127880 \tTPR:0.9543473243 \tFPR:0.0751760705 \tF1:0.9391242285 \t AUC:0.9395856269\tTrain cost: 0:00:34\n",
      "Client6 Test =>                 \tLoss: 0.2497962430 \tAcc: 0.9129166667 \tTPR:0.8687935774 \tFPR:0.0430948661 \tF1:0.9044036381 \tAUC:0.9128493557 \ttest cost: 0:00:05\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1836586754 \tAcc: 0.9253542627 \tTPR:0.9410792570 \tFPR:0.0906650582 \tF1:0.9255708701 \t AUC:0.9252070994\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1776195662 \tAcc: 0.9266906682 \tTPR:0.9415832388 \tFPR:0.0872113219 \tF1:0.9264991983 \t AUC:0.9271859585\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1747044399 \tAcc: 0.9307085253 \tTPR:0.9488849128 \tFPR:0.0878963459 \tF1:0.9300086641 \t AUC:0.9304942834\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1730641612 \tAcc: 0.9289285714 \tTPR:0.9452512974 \tFPR:0.0875996282 \tF1:0.9288164902 \t AUC:0.9288258346\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1656134972 \tAcc: 0.9320506912 \tTPR:0.9465857536 \tFPR:0.0819696883 \tF1:0.9315827980 \t AUC:0.9323080327\tTrain cost: 0:00:34\n",
      "Client1 Test =>                 \tLoss: 0.1770899208 \tAcc: 0.9322916667 \tTPR:0.9106404620 \tFPR:0.0459679795 \tF1:0.9267096848 \tAUC:0.9323362412 \ttest cost: 0:00:05\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1783367491 \tAcc: 0.9265120968 \tTPR:0.9421733827 \tFPR:0.0878739832 \tF1:0.9253071077 \t AUC:0.9271496997\tTrain cost: 0:00:34\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1731205358 \tAcc: 0.9309792627 \tTPR:0.9475562066 \tFPR:0.0853687469 \tF1:0.9293694450 \t AUC:0.9310937299\tTrain cost: 0:00:34\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1646144094 \tAcc: 0.9300835253 \tTPR:0.9427384077 \tFPR:0.0839746132 \tF1:0.9285190721 \t AUC:0.9293818972\tTrain cost: 0:00:34\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1614208840 \tAcc: 0.9350835253 \tTPR:0.9492491052 \tFPR:0.0804998448 \tF1:0.9341683627 \t AUC:0.9343746302\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1557448113 \tAcc: 0.9388364055 \tTPR:0.9524341709 \tFPR:0.0729940728 \tF1:0.9376912609 \t AUC:0.9397200491\tTrain cost: 0:00:34\n",
      "Client4 Test =>                 \tLoss: 0.1944468932 \tAcc: 0.9293750000 \tTPR:0.9199257119 \tFPR:0.0627501971 \tF1:0.9259172570 \tAUC:0.9285877574 \ttest cost: 0:00:05\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1733440270 \tAcc: 0.9297263825 \tTPR:0.9415878788 \tFPR:0.0841049469 \tF1:0.9284284901 \t AUC:0.9287414659\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1682920091 \tAcc: 0.9324913594 \tTPR:0.9454256059 \tFPR:0.0786009924 \tF1:0.9314453784 \t AUC:0.9334123068\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.1605831453 \tAcc: 0.9348185484 \tTPR:0.9450606716 \tFPR:0.0760237773 \tF1:0.9338431074 \t AUC:0.9345184471\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.1584588854 \tAcc: 0.9375835253 \tTPR:0.9489539872 \tFPR:0.0732296637 \tF1:0.9369568721 \t AUC:0.9378621617\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.1555044159 \tAcc: 0.9391013825 \tTPR:0.9506872785 \tFPR:0.0722080289 \tF1:0.9379079498 \t AUC:0.9392396248\tTrain cost: 0:00:33\n",
      "Client2 Test =>                 \tLoss: 0.2038640624 \tAcc: 0.9272916667 \tTPR:0.9228813943 \tFPR:0.0683222401 \tF1:0.9249070762 \tAUC:0.9272795771 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2118193358 \tAcc: 0.9234166667 \tTPR:0.8995924569 \tFPR:0.0533287526 \tF1:0.9181405657 \tAUC:0.9231318521\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 5:  =============\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1618012823 \tAcc: 0.9358035714 \tTPR:0.9482051326 \tFPR:0.0776333054 \tF1:0.9349844130 \t AUC:0.9352859136\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1592002539 \tAcc: 0.9383006912 \tTPR:0.9495692072 \tFPR:0.0732953547 \tF1:0.9369172615 \t AUC:0.9381369262\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1557234871 \tAcc: 0.9380328341 \tTPR:0.9520278090 \tFPR:0.0760599474 \tF1:0.9370013964 \t AUC:0.9379839308\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1497385496 \tAcc: 0.9391906682 \tTPR:0.9522680342 \tFPR:0.0723953345 \tF1:0.9379850083 \t AUC:0.9399363499\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1493001868 \tAcc: 0.9412413594 \tTPR:0.9533040298 \tFPR:0.0714330220 \tF1:0.9405423404 \t AUC:0.9409355039\tTrain cost: 0:00:34\n",
      "Client8 Test =>                 \tLoss: 0.2266865635 \tAcc: 0.9172916667 \tTPR:0.8787937060 \tFPR:0.0443450137 \tF1:0.9105071065 \tAUC:0.9172243462 \ttest cost: 0:00:05\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1734539122 \tAcc: 0.9330299539 \tTPR:0.9452650729 \tFPR:0.0793358761 \tF1:0.9325006864 \t AUC:0.9329645984\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1700847793 \tAcc: 0.9333870968 \tTPR:0.9455546411 \tFPR:0.0805630153 \tF1:0.9325712055 \t AUC:0.9324958129\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1655570996 \tAcc: 0.9351728111 \tTPR:0.9489944653 \tFPR:0.0791828719 \tF1:0.9357884066 \t AUC:0.9349057967\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1582252916 \tAcc: 0.9398185484 \tTPR:0.9517891154 \tFPR:0.0726567246 \tF1:0.9397405230 \t AUC:0.9395661954\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1579831723 \tAcc: 0.9366906682 \tTPR:0.9487364875 \tFPR:0.0752647871 \tF1:0.9358997917 \t AUC:0.9367358502\tTrain cost: 0:00:33\n",
      "Client7 Test =>                 \tLoss: 0.1989790128 \tAcc: 0.9229166667 \tTPR:0.8915043117 \tFPR:0.0447228759 \tF1:0.9178332296 \tAUC:0.9233907179 \ttest cost: 0:00:05\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.1784520999 \tAcc: 0.9298214286 \tTPR:0.9430401118 \tFPR:0.0835682607 \tF1:0.9288694963 \t AUC:0.9297359256\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.1700618100 \tAcc: 0.9352678571 \tTPR:0.9499350344 \tFPR:0.0803691253 \tF1:0.9345323321 \t AUC:0.9347829545\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.1674583415 \tAcc: 0.9341013825 \tTPR:0.9481682349 \tFPR:0.0797159541 \tF1:0.9328074203 \t AUC:0.9342261404\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.1639273521 \tAcc: 0.9334763825 \tTPR:0.9470792643 \tFPR:0.0803800436 \tF1:0.9329723708 \t AUC:0.9333496103\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.1567861784 \tAcc: 0.9373070276 \tTPR:0.9487839844 \tFPR:0.0739165390 \tF1:0.9356175781 \t AUC:0.9374337227\tTrain cost: 0:00:33\n",
      "Client9 Test =>                 \tLoss: 0.2277839815 \tAcc: 0.9191666667 \tTPR:0.8720270748 \tFPR:0.0332497593 \tF1:0.9130662688 \tAUC:0.9193886577 \ttest cost: 0:00:05\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1789491950 \tAcc: 0.9308813364 \tTPR:0.9466906662 \tFPR:0.0842227495 \tF1:0.9293928860 \t AUC:0.9312339584\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1731933100 \tAcc: 0.9290092166 \tTPR:0.9446744272 \tFPR:0.0859601357 \tF1:0.9282834123 \t AUC:0.9293571457\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1699830345 \tAcc: 0.9331221198 \tTPR:0.9473996416 \tFPR:0.0814512697 \tF1:0.9321383258 \t AUC:0.9329741860\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1630125897 \tAcc: 0.9349913594 \tTPR:0.9481428224 \tFPR:0.0791893387 \tF1:0.9339954651 \t AUC:0.9344767418\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1588599340 \tAcc: 0.9396399770 \tTPR:0.9528679187 \tFPR:0.0730541553 \tF1:0.9386691102 \t AUC:0.9399068817\tTrain cost: 0:00:33\n",
      "Client5 Test =>                 \tLoss: 0.1762586217 \tAcc: 0.9314583333 \tTPR:0.9109650255 \tFPR:0.0464268143 \tF1:0.9292449927 \tAUC:0.9322691056 \ttest cost: 0:00:05\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1689208068 \tAcc: 0.9346370968 \tTPR:0.9501750704 \tFPR:0.0819687163 \tF1:0.9336800424 \t AUC:0.9341031770\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1623803856 \tAcc: 0.9365149770 \tTPR:0.9474944971 \tFPR:0.0744492133 \tF1:0.9354694437 \t AUC:0.9365226419\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.1562233452 \tAcc: 0.9382142857 \tTPR:0.9517797692 \tFPR:0.0741473785 \tF1:0.9374238777 \t AUC:0.9388161953\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.1516418543 \tAcc: 0.9410656682 \tTPR:0.9514484298 \tFPR:0.0687399129 \tF1:0.9403840752 \t AUC:0.9413542585\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.1485051091 \tAcc: 0.9407056452 \tTPR:0.9518942316 \tFPR:0.0719859721 \tF1:0.9395103479 \t AUC:0.9399541297\tTrain cost: 0:00:34\n",
      "Client2 Test =>                 \tLoss: 0.2659913725 \tAcc: 0.9064583333 \tTPR:0.8542076694 \tFPR:0.0412101811 \tF1:0.8983877307 \tAUC:0.9064987442 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2191399104 \tAcc: 0.9194583333 \tTPR:0.8814995575 \tFPR:0.0419909289 \tF1:0.9138078657 \tAUC:0.9197543143\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 6:  =============\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1575692930 \tAcc: 0.9384792627 \tTPR:0.9505763913 \tFPR:0.0742052370 \tF1:0.9383848061 \t AUC:0.9381855772\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1504289978 \tAcc: 0.9416013825 \tTPR:0.9538140727 \tFPR:0.0697707181 \tF1:0.9422133198 \t AUC:0.9420216773\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1476208618 \tAcc: 0.9422235023 \tTPR:0.9522985246 \tFPR:0.0689671958 \tF1:0.9423814748 \t AUC:0.9416656644\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1483938892 \tAcc: 0.9424884793 \tTPR:0.9546006952 \tFPR:0.0697792342 \tF1:0.9422322734 \t AUC:0.9424107305\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1418936975 \tAcc: 0.9452649770 \tTPR:0.9573757228 \tFPR:0.0688105651 \tF1:0.9457443130 \t AUC:0.9442825788\tTrain cost: 0:00:34\n",
      "Client7 Test =>                 \tLoss: 0.2111000422 \tAcc: 0.9183333333 \tTPR:0.8724495775 \tFPR:0.0371840115 \tF1:0.9117619413 \tAUC:0.9176327830 \ttest cost: 0:00:05\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1742320713 \tAcc: 0.9313335253 \tTPR:0.9463871848 \tFPR:0.0846944960 \tF1:0.9302540830 \t AUC:0.9308463444\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1692032844 \tAcc: 0.9342799539 \tTPR:0.9484253433 \tFPR:0.0808776398 \tF1:0.9334657998 \t AUC:0.9337738518\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1613481077 \tAcc: 0.9357056452 \tTPR:0.9491901017 \tFPR:0.0776431244 \tF1:0.9349646178 \t AUC:0.9357734887\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1569287877 \tAcc: 0.9387413594 \tTPR:0.9541356241 \tFPR:0.0762269043 \tF1:0.9379273147 \t AUC:0.9389543599\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1535603019 \tAcc: 0.9375864055 \tTPR:0.9513571069 \tFPR:0.0753218697 \tF1:0.9366245248 \t AUC:0.9380176186\tTrain cost: 0:00:34\n",
      "Client5 Test =>                 \tLoss: 0.1889560700 \tAcc: 0.9272916667 \tTPR:0.8991020257 \tFPR:0.0468816128 \tF1:0.9227918825 \tAUC:0.9261102065 \ttest cost: 0:00:05\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1775975253 \tAcc: 0.9286578341 \tTPR:0.9440177256 \tFPR:0.0846229527 \tF1:0.9269908371 \t AUC:0.9296973865\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1702707450 \tAcc: 0.9307978111 \tTPR:0.9420263726 \tFPR:0.0807771786 \tF1:0.9286769848 \t AUC:0.9306245970\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1658015740 \tAcc: 0.9342741935 \tTPR:0.9465225665 \tFPR:0.0775201681 \tF1:0.9324539001 \t AUC:0.9345011992\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1620773849 \tAcc: 0.9347292627 \tTPR:0.9429533478 \tFPR:0.0737078262 \tF1:0.9324202818 \t AUC:0.9346227608\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1570067020 \tAcc: 0.9379406682 \tTPR:0.9490829832 \tFPR:0.0728250938 \tF1:0.9353205647 \t AUC:0.9381289447\tTrain cost: 0:00:34\n",
      "Client0 Test =>                 \tLoss: 0.2258432657 \tAcc: 0.9181250000 \tTPR:0.8840534372 \tFPR:0.0504538930 \tF1:0.9127797015 \tAUC:0.9167997721 \ttest cost: 0:00:05\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1688017406 \tAcc: 0.9316935484 \tTPR:0.9440968369 \tFPR:0.0822118289 \tF1:0.9307701153 \t AUC:0.9309425040\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1612817638 \tAcc: 0.9356192396 \tTPR:0.9497302710 \tFPR:0.0794296935 \tF1:0.9349434695 \t AUC:0.9351502887\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1599278146 \tAcc: 0.9350748848 \tTPR:0.9490413962 \tFPR:0.0789060102 \tF1:0.9351657760 \t AUC:0.9350676930\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1518231205 \tAcc: 0.9402620968 \tTPR:0.9561964485 \tFPR:0.0758417143 \tF1:0.9398323140 \t AUC:0.9401773671\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1484911509 \tAcc: 0.9412413594 \tTPR:0.9537095896 \tFPR:0.0727205971 \tF1:0.9402236671 \t AUC:0.9404944962\tTrain cost: 0:00:34\n",
      "Client1 Test =>                 \tLoss: 0.1765835237 \tAcc: 0.9341666667 \tTPR:0.9134001009 \tFPR:0.0461064442 \tF1:0.9265558884 \tAUC:0.9336468283 \ttest cost: 0:00:05\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1566722299 \tAcc: 0.9365956221 \tTPR:0.9505782651 \tFPR:0.0777224294 \tF1:0.9353107836 \t AUC:0.9364279179\tTrain cost: 0:00:34\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1510471434 \tAcc: 0.9406192396 \tTPR:0.9532728915 \tFPR:0.0715093941 \tF1:0.9385251936 \t AUC:0.9408817487\tTrain cost: 0:00:34\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1424549488 \tAcc: 0.9428542627 \tTPR:0.9522446914 \tFPR:0.0658761942 \tF1:0.9408667541 \t AUC:0.9431842486\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1382376580 \tAcc: 0.9463335253 \tTPR:0.9572211544 \tFPR:0.0645158307 \tF1:0.9449842689 \t AUC:0.9463526619\tTrain cost: 0:00:34\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1332311359 \tAcc: 0.9462500000 \tTPR:0.9576981237 \tFPR:0.0661784295 \tF1:0.9447203761 \t AUC:0.9457598471\tTrain cost: 0:00:34\n",
      "Client3 Test =>                 \tLoss: 0.2228621358 \tAcc: 0.9231250000 \tTPR:0.8857956496 \tFPR:0.0378998736 \tF1:0.9171410695 \tAUC:0.9239478880 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2050690075 \tAcc: 0.9242083333 \tTPR:0.8909601582 \tFPR:0.0437051670 \tF1:0.9182060966 \tAUC:0.9236274956\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 7:  =============\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1431386824 \tAcc: 0.9442799539 \tTPR:0.9571704073 \tFPR:0.0710579695 \tF1:0.9434171269 \t AUC:0.9430562189\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1399970775 \tAcc: 0.9460685484 \tTPR:0.9559577954 \tFPR:0.0644412441 \tF1:0.9461681423 \t AUC:0.9457582756\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1401726974 \tAcc: 0.9440092166 \tTPR:0.9539700292 \tFPR:0.0664027768 \tF1:0.9440908713 \t AUC:0.9437836262\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1340764815 \tAcc: 0.9462500000 \tTPR:0.9577522874 \tFPR:0.0651353055 \tF1:0.9458548056 \t AUC:0.9463084909\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1298603485 \tAcc: 0.9468721198 \tTPR:0.9559287699 \tFPR:0.0639052049 \tF1:0.9470703862 \t AUC:0.9460117825\tTrain cost: 0:00:34\n",
      "Client7 Test =>                 \tLoss: 0.2105714297 \tAcc: 0.9320833333 \tTPR:0.9065886029 \tFPR:0.0435078621 \tF1:0.9284040193 \tAUC:0.9315403704 \ttest cost: 0:00:05\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1704776689 \tAcc: 0.9299827189 \tTPR:0.9434918051 \tFPR:0.0807278630 \tF1:0.9271402981 \t AUC:0.9313819710\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1619457947 \tAcc: 0.9335656682 \tTPR:0.9458909653 \tFPR:0.0780700905 \tF1:0.9317266583 \t AUC:0.9339104374\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1583552020 \tAcc: 0.9376699309 \tTPR:0.9471532280 \tFPR:0.0711484223 \tF1:0.9349257820 \t AUC:0.9380024029\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1547223478 \tAcc: 0.9375892857 \tTPR:0.9479215354 \tFPR:0.0722580410 \tF1:0.9347680442 \t AUC:0.9378317472\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1509310833 \tAcc: 0.9365149770 \tTPR:0.9476593311 \tFPR:0.0724920504 \tF1:0.9340180738 \t AUC:0.9375836403\tTrain cost: 0:00:34\n",
      "Client0 Test =>                 \tLoss: 0.2309757585 \tAcc: 0.9162500000 \tTPR:0.8727776796 \tFPR:0.0361290602 \tF1:0.9117235368 \tAUC:0.9183243097 \ttest cost: 0:00:05\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1618536952 \tAcc: 0.9358006912 \tTPR:0.9483729677 \tFPR:0.0771318885 \tF1:0.9342834507 \t AUC:0.9356205396\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1540783012 \tAcc: 0.9377678571 \tTPR:0.9498282289 \tFPR:0.0737683581 \tF1:0.9365310619 \t AUC:0.9380299354\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1506034673 \tAcc: 0.9405299539 \tTPR:0.9530051426 \tFPR:0.0714471029 \tF1:0.9398548889 \t AUC:0.9407790199\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1437046230 \tAcc: 0.9418750000 \tTPR:0.9571376317 \tFPR:0.0728637273 \tF1:0.9416634361 \t AUC:0.9421369522\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1443015733 \tAcc: 0.9433842166 \tTPR:0.9564526459 \tFPR:0.0702421506 \tF1:0.9430561319 \t AUC:0.9431052477\tTrain cost: 0:00:34\n",
      "Client5 Test =>                 \tLoss: 0.1830334651 \tAcc: 0.9314583333 \tTPR:0.9181490022 \tFPR:0.0552920797 \tF1:0.9290128224 \tAUC:0.9314284612 \ttest cost: 0:00:05\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1611810732 \tAcc: 0.9344642857 \tTPR:0.9488991222 \tFPR:0.0809766444 \tF1:0.9335189042 \t AUC:0.9339612389\tTrain cost: 0:00:34\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1533688538 \tAcc: 0.9386549539 \tTPR:0.9540953500 \tFPR:0.0761673195 \tF1:0.9372796149 \t AUC:0.9389640152\tTrain cost: 0:00:34\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1480493264 \tAcc: 0.9403542627 \tTPR:0.9534608283 \tFPR:0.0730374232 \tF1:0.9390361645 \t AUC:0.9402117025\tTrain cost: 0:00:34\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1405049572 \tAcc: 0.9428571429 \tTPR:0.9573910858 \tFPR:0.0724913169 \tF1:0.9422017524 \t AUC:0.9424498845\tTrain cost: 0:00:34\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1381289582 \tAcc: 0.9455299539 \tTPR:0.9546160986 \tFPR:0.0637842904 \tF1:0.9444745191 \t AUC:0.9454159041\tTrain cost: 0:00:34\n",
      "Client4 Test =>                 \tLoss: 0.2110558176 \tAcc: 0.9268750000 \tTPR:0.8983410694 \tFPR:0.0438440280 \tF1:0.9235807606 \tAUC:0.9272485207 \ttest cost: 0:00:05\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1614502700 \tAcc: 0.9347292627 \tTPR:0.9504323907 \tFPR:0.0817453849 \tF1:0.9346679834 \t AUC:0.9343435029\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1550312617 \tAcc: 0.9373156682 \tTPR:0.9500990031 \tFPR:0.0758599531 \tF1:0.9368118486 \t AUC:0.9371195250\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1508533307 \tAcc: 0.9371342166 \tTPR:0.9492113214 \tFPR:0.0761601604 \tF1:0.9364177420 \t AUC:0.9365255805\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1446472338 \tAcc: 0.9410685484 \tTPR:0.9528094928 \tFPR:0.0703261965 \tF1:0.9397269693 \t AUC:0.9412416482\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1398137860 \tAcc: 0.9441071429 \tTPR:0.9577496726 \tFPR:0.0684912429 \tF1:0.9429280811 \t AUC:0.9446292148\tTrain cost: 0:00:34\n",
      "Client1 Test =>                 \tLoss: 0.1789312595 \tAcc: 0.9372916667 \tTPR:0.9184416741 \tFPR:0.0438013225 \tF1:0.9320624223 \tAUC:0.9373201758 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2029135461 \tAcc: 0.9287916667 \tTPR:0.9028596056 \tFPR:0.0445148705 \tF1:0.9249567123 \tAUC:0.9291723676\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 8:  =============\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1557720908 \tAcc: 0.9365120968 \tTPR:0.9498590006 \tFPR:0.0764711449 \tF1:0.9355148351 \t AUC:0.9366939278\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1532555749 \tAcc: 0.9370449309 \tTPR:0.9477411347 \tFPR:0.0732453831 \tF1:0.9359477218 \t AUC:0.9372478758\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.1454064522 \tAcc: 0.9426756912 \tTPR:0.9507213070 \tFPR:0.0656353774 \tF1:0.9409840175 \t AUC:0.9425429648\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.1426041885 \tAcc: 0.9429349078 \tTPR:0.9517304322 \tFPR:0.0661668272 \tF1:0.9420722744 \t AUC:0.9427818025\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.1398585905 \tAcc: 0.9454464286 \tTPR:0.9582210771 \tFPR:0.0677292145 \tF1:0.9445743479 \t AUC:0.9452459313\tTrain cost: 0:00:34\n",
      "Client2 Test =>                 \tLoss: 0.1681191684 \tAcc: 0.9368750000 \tTPR:0.9417613443 \tFPR:0.0684723330 \tF1:0.9352326632 \tAUC:0.9366445056 \ttest cost: 0:00:05\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1373634325 \tAcc: 0.9447263825 \tTPR:0.9558497366 \tFPR:0.0662607820 \tF1:0.9447620311 \t AUC:0.9447944773\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1322684361 \tAcc: 0.9479435484 \tTPR:0.9591683554 \tFPR:0.0652031089 \tF1:0.9480408831 \t AUC:0.9469826233\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1247064915 \tAcc: 0.9506221198 \tTPR:0.9604560397 \tFPR:0.0585772015 \tF1:0.9504274697 \t AUC:0.9509394191\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1208709992 \tAcc: 0.9524107143 \tTPR:0.9614005114 \tFPR:0.0573249923 \tF1:0.9516188845 \t AUC:0.9520377595\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1183216145 \tAcc: 0.9557085253 \tTPR:0.9632050120 \tFPR:0.0519181541 \tF1:0.9551990500 \t AUC:0.9556434289\tTrain cost: 0:00:34\n",
      "Client7 Test =>                 \tLoss: 0.2049928098 \tAcc: 0.9335416667 \tTPR:0.9095447937 \tFPR:0.0420627508 \tF1:0.9297817420 \tAUC:0.9337410214 \ttest cost: 0:00:05\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1509639892 \tAcc: 0.9400892857 \tTPR:0.9519417101 \tFPR:0.0724208060 \tF1:0.9387736828 \t AUC:0.9397604521\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1462614108 \tAcc: 0.9418663594 \tTPR:0.9525183847 \tFPR:0.0697247557 \tF1:0.9405907301 \t AUC:0.9413968145\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1377232398 \tAcc: 0.9469585253 \tTPR:0.9608801120 \tFPR:0.0649608684 \tF1:0.9456030124 \t AUC:0.9479596218\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1406148090 \tAcc: 0.9414256912 \tTPR:0.9534219279 \tFPR:0.0703792736 \tF1:0.9400843528 \t AUC:0.9415213271\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1277658752 \tAcc: 0.9495420507 \tTPR:0.9608935462 \tFPR:0.0622009670 \tF1:0.9487238107 \t AUC:0.9493462896\tTrain cost: 0:00:34\n",
      "Client5 Test =>                 \tLoss: 0.2436365882 \tAcc: 0.9177083333 \tTPR:0.8700256570 \tFPR:0.0344241835 \tF1:0.9108299501 \tAUC:0.9178007368 \ttest cost: 0:00:05\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1601280129 \tAcc: 0.9347263825 \tTPR:0.9489182637 \tFPR:0.0793519407 \tF1:0.9337254804 \t AUC:0.9347831615\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1529023027 \tAcc: 0.9395478111 \tTPR:0.9520798650 \tFPR:0.0721441508 \tF1:0.9382998285 \t AUC:0.9399678571\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1447216672 \tAcc: 0.9427620968 \tTPR:0.9570080372 \tFPR:0.0718342935 \tF1:0.9422732669 \t AUC:0.9425868718\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1400309095 \tAcc: 0.9449020737 \tTPR:0.9558258396 \tFPR:0.0658237323 \tF1:0.9440157396 \t AUC:0.9450010537\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1389812074 \tAcc: 0.9431134793 \tTPR:0.9549277296 \tFPR:0.0700850419 \tF1:0.9423483315 \t AUC:0.9424213439\tTrain cost: 0:00:34\n",
      "Client1 Test =>                 \tLoss: 0.1819644824 \tAcc: 0.9304166667 \tTPR:0.8999800179 \tFPR:0.0385436339 \tF1:0.9241799794 \tAUC:0.9307181920 \ttest cost: 0:00:05\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1565454753 \tAcc: 0.9382114055 \tTPR:0.9493294630 \tFPR:0.0716736640 \tF1:0.9356614137 \t AUC:0.9388278995\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1498329597 \tAcc: 0.9400777650 \tTPR:0.9504396226 \tFPR:0.0686663968 \tF1:0.9379245298 \t AUC:0.9408866129\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1415352287 \tAcc: 0.9422206221 \tTPR:0.9520020369 \tFPR:0.0664397213 \tF1:0.9397866864 \t AUC:0.9427811578\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1383717261 \tAcc: 0.9440120968 \tTPR:0.9544451246 \tFPR:0.0637028058 \tF1:0.9422385068 \t AUC:0.9453711594\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1367350936 \tAcc: 0.9454435484 \tTPR:0.9526071049 \tFPR:0.0610532474 \tF1:0.9431455429 \t AUC:0.9457769287\tTrain cost: 0:00:34\n",
      "Client0 Test =>                 \tLoss: 0.2061519076 \tAcc: 0.9258333333 \tTPR:0.9006702362 \tFPR:0.0480422075 \tF1:0.9246590950 \tAUC:0.9263140144 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2009729913 \tAcc: 0.9288750000 \tTPR:0.9043964098 \tFPR:0.0463090217 \tF1:0.9249366859 \tAUC:0.9290436940\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 9:  =============\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1418571319 \tAcc: 0.9432114055 \tTPR:0.9538807794 \tFPR:0.0680842721 \tF1:0.9419807630 \t AUC:0.9428982536\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1350729441 \tAcc: 0.9460685484 \tTPR:0.9565428806 \tFPR:0.0644084928 \tF1:0.9446634082 \t AUC:0.9460671939\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.1317643879 \tAcc: 0.9476756912 \tTPR:0.9582983230 \tFPR:0.0628659596 \tF1:0.9469661890 \t AUC:0.9477161817\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.1286775793 \tAcc: 0.9485656682 \tTPR:0.9589790383 \tFPR:0.0603928512 \tF1:0.9482287889 \t AUC:0.9492930936\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.1237053811 \tAcc: 0.9529435484 \tTPR:0.9627333639 \tFPR:0.0565691880 \tF1:0.9520785807 \t AUC:0.9530820879\tTrain cost: 0:00:34\n",
      "Client2 Test =>                 \tLoss: 0.2344167076 \tAcc: 0.9193750000 \tTPR:0.8852029089 \tFPR:0.0472314433 \tF1:0.9136929976 \tAUC:0.9189857328 \ttest cost: 0:00:05\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1504056699 \tAcc: 0.9398185484 \tTPR:0.9538079735 \tFPR:0.0751619701 \tF1:0.9397266274 \t AUC:0.9393230017\tTrain cost: 0:00:34\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1419246944 \tAcc: 0.9424078341 \tTPR:0.9575416535 \tFPR:0.0736317817 \tF1:0.9421285175 \t AUC:0.9419549359\tTrain cost: 0:00:34\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1365597265 \tAcc: 0.9466906682 \tTPR:0.9617447817 \tFPR:0.0677238419 \tF1:0.9468747430 \t AUC:0.9470104699\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1321645521 \tAcc: 0.9482027650 \tTPR:0.9592961840 \tFPR:0.0631399181 \tF1:0.9476699045 \t AUC:0.9480781330\tTrain cost: 0:00:34\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1295017199 \tAcc: 0.9483035714 \tTPR:0.9609561520 \tFPR:0.0638605672 \tF1:0.9486733495 \t AUC:0.9485477924\tTrain cost: 0:00:34\n",
      "Client6 Test =>                 \tLoss: 0.2113566404 \tAcc: 0.9308333333 \tTPR:0.9226972336 \tFPR:0.0592480687 \tF1:0.9275871194 \tAUC:0.9317245825 \ttest cost: 0:00:05\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1475454851 \tAcc: 0.9407142857 \tTPR:0.9539228566 \tFPR:0.0729450477 \tF1:0.9398165812 \t AUC:0.9404889045\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1421320103 \tAcc: 0.9431134793 \tTPR:0.9531822045 \tFPR:0.0674825997 \tF1:0.9415035828 \t AUC:0.9428498024\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1373980855 \tAcc: 0.9459735023 \tTPR:0.9579602885 \tFPR:0.0659112237 \tF1:0.9448891304 \t AUC:0.9460245324\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1292449711 \tAcc: 0.9474971198 \tTPR:0.9595026090 \tFPR:0.0644226669 \tF1:0.9468555628 \t AUC:0.9475399710\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1256935511 \tAcc: 0.9510656682 \tTPR:0.9611259567 \tFPR:0.0594809086 \tF1:0.9504433713 \t AUC:0.9508225240\tTrain cost: 0:00:34\n",
      "Client8 Test =>                 \tLoss: 0.1937934512 \tAcc: 0.9327083333 \tTPR:0.9109702634 \tFPR:0.0449174944 \tF1:0.9277283818 \tAUC:0.9330263845 \ttest cost: 0:00:05\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1468271937 \tAcc: 0.9422263825 \tTPR:0.9538862699 \tFPR:0.0694837478 \tF1:0.9403087095 \t AUC:0.9422012611\tTrain cost: 0:00:34\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1390680138 \tAcc: 0.9456221198 \tTPR:0.9555226660 \tFPR:0.0630007206 \tF1:0.9434617241 \t AUC:0.9462609727\tTrain cost: 0:00:34\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1335218846 \tAcc: 0.9477620968 \tTPR:0.9578550797 \tFPR:0.0629635481 \tF1:0.9460468175 \t AUC:0.9474457658\tTrain cost: 0:00:34\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1283227387 \tAcc: 0.9513335253 \tTPR:0.9608640832 \tFPR:0.0577705577 \tF1:0.9501553519 \t AUC:0.9515467627\tTrain cost: 0:00:34\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1284777658 \tAcc: 0.9507027650 \tTPR:0.9628866910 \tFPR:0.0618542300 \tF1:0.9491560259 \t AUC:0.9505162305\tTrain cost: 0:00:34\n",
      "Client3 Test =>                 \tLoss: 0.1960001391 \tAcc: 0.9337500000 \tTPR:0.9178183424 \tFPR:0.0518938679 \tF1:0.9296002752 \tAUC:0.9329622373 \ttest cost: 0:00:05\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1497246505 \tAcc: 0.9399078341 \tTPR:0.9543559695 \tFPR:0.0750768865 \tF1:0.9397356152 \t AUC:0.9396395415\tTrain cost: 0:00:34\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1432344003 \tAcc: 0.9403485023 \tTPR:0.9550300855 \tFPR:0.0746560331 \tF1:0.9382911914 \t AUC:0.9401870262\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1363761053 \tAcc: 0.9453542627 \tTPR:0.9554786258 \tFPR:0.0639163667 \tF1:0.9434592342 \t AUC:0.9457811296\tTrain cost: 0:00:34\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1317218389 \tAcc: 0.9450864055 \tTPR:0.9557956439 \tFPR:0.0660799567 \tF1:0.9441085911 \t AUC:0.9448578436\tTrain cost: 0:00:34\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1281217529 \tAcc: 0.9471342166 \tTPR:0.9579687533 \tFPR:0.0657462038 \tF1:0.9460635729 \t AUC:0.9461112748\tTrain cost: 0:00:34\n",
      "Client4 Test =>                 \tLoss: 0.2080670805 \tAcc: 0.9245833333 \tTPR:0.8955644983 \tFPR:0.0449686012 \tF1:0.9195418001 \tAUC:0.9252979485 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2087268038 \tAcc: 0.9282500000 \tTPR:0.9064506493 \tFPR:0.0496518951 \tF1:0.9236301148 \tAUC:0.9283993771\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 10:  =============\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1390097330 \tAcc: 0.9455270737 \tTPR:0.9566257537 \tFPR:0.0656229026 \tF1:0.9445963394 \t AUC:0.9455014256\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1289162252 \tAcc: 0.9483870968 \tTPR:0.9577012479 \tFPR:0.0613971203 \tF1:0.9478615804 \t AUC:0.9481520638\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1206037963 \tAcc: 0.9524078341 \tTPR:0.9611390496 \tFPR:0.0570834865 \tF1:0.9518317235 \t AUC:0.9520277816\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1199165603 \tAcc: 0.9531163594 \tTPR:0.9644788212 \tFPR:0.0576181712 \tF1:0.9524814050 \t AUC:0.9534303250\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1158390197 \tAcc: 0.9541013825 \tTPR:0.9643704817 \tFPR:0.0579189382 \tF1:0.9535107130 \t AUC:0.9532257718\tTrain cost: 0:00:34\n",
      "Client8 Test =>                 \tLoss: 0.2195339712 \tAcc: 0.9258333333 \tTPR:0.8911704321 \tFPR:0.0389773087 \tF1:0.9208574685 \tAUC:0.9260965617 \ttest cost: 0:00:05\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1345949629 \tAcc: 0.9456163594 \tTPR:0.9561051890 \tFPR:0.0660179889 \tF1:0.9456866986 \t AUC:0.9450436000\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1276275569 \tAcc: 0.9471399770 \tTPR:0.9572537825 \tFPR:0.0644518846 \tF1:0.9475445215 \t AUC:0.9464009489\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1180167516 \tAcc: 0.9534735023 \tTPR:0.9630043172 \tFPR:0.0566091187 \tF1:0.9534903708 \t AUC:0.9531975993\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1148614789 \tAcc: 0.9549020737 \tTPR:0.9653749597 \tFPR:0.0553509101 \tF1:0.9550676159 \t AUC:0.9550120248\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1115841929 \tAcc: 0.9551699309 \tTPR:0.9653381251 \tFPR:0.0544268572 \tF1:0.9548253546 \t AUC:0.9554556340\tTrain cost: 0:00:34\n",
      "Client7 Test =>                 \tLoss: 0.2291601806 \tAcc: 0.9283333333 \tTPR:0.8966446078 \tFPR:0.0384404005 \tF1:0.9231012997 \tAUC:0.9291021036 \ttest cost: 0:00:05\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1497793240 \tAcc: 0.9391935484 \tTPR:0.9532031214 \tFPR:0.0751607259 \tF1:0.9382497848 \t AUC:0.9390211978\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1420056802 \tAcc: 0.9425892857 \tTPR:0.9536748119 \tFPR:0.0688071681 \tF1:0.9411177772 \t AUC:0.9424338219\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1346091128 \tAcc: 0.9466013825 \tTPR:0.9569214776 \tFPR:0.0640890443 \tF1:0.9461749535 \t AUC:0.9464162166\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1321715105 \tAcc: 0.9465985023 \tTPR:0.9612917500 \tFPR:0.0677424083 \tF1:0.9459798085 \t AUC:0.9467746709\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1277638918 \tAcc: 0.9481192396 \tTPR:0.9555458764 \tFPR:0.0596856400 \tF1:0.9464117167 \t AUC:0.9479301182\tTrain cost: 0:00:34\n",
      "Client1 Test =>                 \tLoss: 0.1618790474 \tAcc: 0.9402083333 \tTPR:0.9253954273 \tFPR:0.0483735004 \tF1:0.9347321890 \tAUC:0.9385109634 \ttest cost: 0:00:05\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1511549329 \tAcc: 0.9403542627 \tTPR:0.9509407836 \tFPR:0.0691066762 \tF1:0.9379195541 \t AUC:0.9409170537\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1444138975 \tAcc: 0.9420506912 \tTPR:0.9550960804 \tFPR:0.0691152905 \tF1:0.9402024709 \t AUC:0.9429903950\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1387175458 \tAcc: 0.9427620968 \tTPR:0.9535812326 \tFPR:0.0680228840 \tF1:0.9401936900 \t AUC:0.9427791743\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1303768431 \tAcc: 0.9493634793 \tTPR:0.9569148117 \tFPR:0.0589956823 \tF1:0.9473953618 \t AUC:0.9489595647\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1298038707 \tAcc: 0.9484763825 \tTPR:0.9574414906 \tFPR:0.0608026256 \tF1:0.9461031244 \t AUC:0.9483194325\tTrain cost: 0:00:34\n",
      "Client0 Test =>                 \tLoss: 0.1935936712 \tAcc: 0.9339583333 \tTPR:0.9214350729 \tFPR:0.0517894171 \tF1:0.9313153471 \tAUC:0.9348228279 \ttest cost: 0:00:05\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1320720067 \tAcc: 0.9463277650 \tTPR:0.9601016901 \tFPR:0.0665177914 \tF1:0.9462263740 \t AUC:0.9467919494\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1261791449 \tAcc: 0.9474078341 \tTPR:0.9577888784 \tFPR:0.0645493910 \tF1:0.9469901287 \t AUC:0.9466197437\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.1189464721 \tAcc: 0.9518721198 \tTPR:0.9614146414 \tFPR:0.0571183751 \tF1:0.9509859753 \t AUC:0.9521481331\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.1122857159 \tAcc: 0.9561578341 \tTPR:0.9630804223 \tFPR:0.0515361397 \tF1:0.9549200111 \t AUC:0.9557721413\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.1120738000 \tAcc: 0.9552649770 \tTPR:0.9652654699 \tFPR:0.0568861718 \tF1:0.9544204285 \t AUC:0.9541896491\tTrain cost: 0:00:34\n",
      "Client2 Test =>                 \tLoss: 0.2872466510 \tAcc: 0.9116666667 \tTPR:0.8532196417 \tFPR:0.0306016090 \tF1:0.9028830374 \tAUC:0.9113090164 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2182827043 \tAcc: 0.9280000000 \tTPR:0.8975730364 \tFPR:0.0416364471 \tF1:0.9225778683 \tAUC:0.9279682946\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 11:  =============\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1122154153 \tAcc: 0.9549107143 \tTPR:0.9634957152 \tFPR:0.0546128134 \tF1:0.9553400216 \t AUC:0.9544414509\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1101559841 \tAcc: 0.9543750000 \tTPR:0.9618781081 \tFPR:0.0538498347 \tF1:0.9546982524 \t AUC:0.9540141367\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1042976648 \tAcc: 0.9565178571 \tTPR:0.9642981779 \tFPR:0.0525074642 \tF1:0.9566176059 \t AUC:0.9558953568\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1018329330 \tAcc: 0.9584763825 \tTPR:0.9676940964 \tFPR:0.0505793880 \tF1:0.9581177743 \t AUC:0.9585573542\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0963656981 \tAcc: 0.9624078341 \tTPR:0.9706657500 \tFPR:0.0468466064 \tF1:0.9623809049 \t AUC:0.9619095718\tTrain cost: 0:00:33\n",
      "Client7 Test =>                 \tLoss: 0.2556557089 \tAcc: 0.9241666667 \tTPR:0.8938372508 \tFPR:0.0450683452 \tF1:0.9177861269 \tAUC:0.9243844528 \ttest cost: 0:00:05\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1307104334 \tAcc: 0.9481192396 \tTPR:0.9581839268 \tFPR:0.0609912331 \tF1:0.9471367348 \t AUC:0.9485963469\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1181458693 \tAcc: 0.9529377880 \tTPR:0.9629921398 \tFPR:0.0574136099 \tF1:0.9521388368 \t AUC:0.9527892649\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1150839127 \tAcc: 0.9548099078 \tTPR:0.9639632065 \tFPR:0.0549023301 \tF1:0.9536864796 \t AUC:0.9545304382\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1100523008 \tAcc: 0.9556221198 \tTPR:0.9659448694 \tFPR:0.0535040580 \tF1:0.9544406711 \t AUC:0.9562204057\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1051166599 \tAcc: 0.9587500000 \tTPR:0.9661916944 \tFPR:0.0492635800 \tF1:0.9573607776 \t AUC:0.9584640572\tTrain cost: 0:00:34\n",
      "Client8 Test =>                 \tLoss: 0.2658988793 \tAcc: 0.9212500000 \tTPR:0.8822601794 \tFPR:0.0393959663 \tF1:0.9151951220 \tAUC:0.9214321066 \ttest cost: 0:00:05\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1493861229 \tAcc: 0.9398185484 \tTPR:0.9532435364 \tFPR:0.0732668379 \tF1:0.9373268548 \t AUC:0.9399883492\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1414511235 \tAcc: 0.9409735023 \tTPR:0.9521004599 \tFPR:0.0704643208 \tF1:0.9397752077 \t AUC:0.9408180695\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1337589416 \tAcc: 0.9464199309 \tTPR:0.9562142658 \tFPR:0.0632421161 \tF1:0.9442786536 \t AUC:0.9464860749\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1282513849 \tAcc: 0.9499049539 \tTPR:0.9579904912 \tFPR:0.0574734060 \tF1:0.9473417478 \t AUC:0.9502585426\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1237927316 \tAcc: 0.9524942396 \tTPR:0.9612772597 \tFPR:0.0559228093 \tF1:0.9501596528 \t AUC:0.9526772252\tTrain cost: 0:00:34\n",
      "Client0 Test =>                 \tLoss: 0.2361904045 \tAcc: 0.9235416667 \tTPR:0.9025765231 \tFPR:0.0539330769 \tF1:0.9218953503 \tAUC:0.9243217231 \ttest cost: 0:00:05\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1412968996 \tAcc: 0.9424971198 \tTPR:0.9550691285 \tFPR:0.0695620663 \tF1:0.9420573577 \t AUC:0.9427535311\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1326615544 \tAcc: 0.9455270737 \tTPR:0.9548506724 \tFPR:0.0649200884 \tF1:0.9444150454 \t AUC:0.9449652920\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1232909487 \tAcc: 0.9506250000 \tTPR:0.9621200819 \tFPR:0.0604168130 \tF1:0.9502922306 \t AUC:0.9508516345\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1205484759 \tAcc: 0.9509763825 \tTPR:0.9606442528 \tFPR:0.0598392526 \tF1:0.9503705091 \t AUC:0.9504025001\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1151168321 \tAcc: 0.9543663594 \tTPR:0.9649800430 \tFPR:0.0551846387 \tF1:0.9532062232 \t AUC:0.9548977021\tTrain cost: 0:00:34\n",
      "Client1 Test =>                 \tLoss: 0.1912579848 \tAcc: 0.9368750000 \tTPR:0.9101004843 \tFPR:0.0381429211 \tF1:0.9307409729 \tAUC:0.9359787816 \ttest cost: 0:00:05\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1446274389 \tAcc: 0.9447263825 \tTPR:0.9562836753 \tFPR:0.0665165522 \tF1:0.9428872743 \t AUC:0.9448835615\tTrain cost: 0:00:34\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1324621767 \tAcc: 0.9488335253 \tTPR:0.9617643126 \tFPR:0.0639478533 \tF1:0.9477517839 \t AUC:0.9489082296\tTrain cost: 0:00:34\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1291184239 \tAcc: 0.9501756912 \tTPR:0.9609378832 \tFPR:0.0614514347 \tF1:0.9488516928 \t AUC:0.9497432242\tTrain cost: 0:00:34\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1231310856 \tAcc: 0.9533842166 \tTPR:0.9657693733 \tFPR:0.0586390778 \tF1:0.9528000024 \t AUC:0.9535651478\tTrain cost: 0:00:34\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1160200561 \tAcc: 0.9545449309 \tTPR:0.9654522204 \tFPR:0.0545585273 \tF1:0.9535379490 \t AUC:0.9554468466\tTrain cost: 0:00:34\n",
      "Client3 Test =>                 \tLoss: 0.1764949761 \tAcc: 0.9404166667 \tTPR:0.9368773673 \tFPR:0.0578486035 \tF1:0.9382351254 \tAUC:0.9395143819 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2250995908 \tAcc: 0.9292500000 \tTPR:0.9051303610 \tFPR:0.0468777826 \tF1:0.9247705395 \tAUC:0.9291262892\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 12:  =============\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.1530636275 \tAcc: 0.9399078341 \tTPR:0.9526231727 \tFPR:0.0730298570 \tF1:0.9391595696 \t AUC:0.9397966579\tTrain cost: 0:00:34\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.1429981495 \tAcc: 0.9434792627 \tTPR:0.9523427070 \tFPR:0.0666346061 \tF1:0.9415280566 \t AUC:0.9428540504\tTrain cost: 0:00:34\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.1382609420 \tAcc: 0.9471313364 \tTPR:0.9578189773 \tFPR:0.0634228229 \tF1:0.9459646670 \t AUC:0.9471980772\tTrain cost: 0:00:34\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.1319533763 \tAcc: 0.9475892857 \tTPR:0.9551012055 \tFPR:0.0581342343 \tF1:0.9463204956 \t AUC:0.9484834856\tTrain cost: 0:00:34\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.1273558326 \tAcc: 0.9509821429 \tTPR:0.9599201292 \tFPR:0.0571870316 \tF1:0.9499034940 \t AUC:0.9513665488\tTrain cost: 0:00:34\n",
      "Client9 Test =>                 \tLoss: 0.1789974926 \tAcc: 0.9370833333 \tTPR:0.9214549209 \tFPR:0.0481838518 \tF1:0.9335136780 \tAUC:0.9366355345 \ttest cost: 0:00:05\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1311323846 \tAcc: 0.9489228111 \tTPR:0.9609201758 \tFPR:0.0631974532 \tF1:0.9484791815 \t AUC:0.9488613613\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1244817758 \tAcc: 0.9505328341 \tTPR:0.9623223776 \tFPR:0.0595363450 \tF1:0.9497014958 \t AUC:0.9513930163\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1195477210 \tAcc: 0.9511520737 \tTPR:0.9628362133 \tFPR:0.0605406034 \tF1:0.9505332011 \t AUC:0.9511478049\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1150865107 \tAcc: 0.9539199309 \tTPR:0.9636241520 \tFPR:0.0560663217 \tF1:0.9535040940 \t AUC:0.9537789152\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1048671191 \tAcc: 0.9563392857 \tTPR:0.9645283868 \tFPR:0.0514345940 \tF1:0.9554530556 \t AUC:0.9565468964\tTrain cost: 0:00:34\n",
      "Client1 Test =>                 \tLoss: 0.1927776534 \tAcc: 0.9360416667 \tTPR:0.9097659039 \tFPR:0.0375362480 \tF1:0.9312662402 \tAUC:0.9361148279 \ttest cost: 0:00:05\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1153017709 \tAcc: 0.9535685484 \tTPR:0.9662591745 \tFPR:0.0592901434 \tF1:0.9543610903 \t AUC:0.9534845155\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0997467469 \tAcc: 0.9614285714 \tTPR:0.9693972013 \tFPR:0.0469768117 \tF1:0.9610533911 \t AUC:0.9612101948\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0957501026 \tAcc: 0.9616906682 \tTPR:0.9691527502 \tFPR:0.0455966724 \tF1:0.9615249079 \t AUC:0.9617780389\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0907868405 \tAcc: 0.9643721198 \tTPR:0.9735856531 \tFPR:0.0443728944 \tF1:0.9647413529 \t AUC:0.9646063793\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0888176401 \tAcc: 0.9645506912 \tTPR:0.9725036486 \tFPR:0.0435683832 \tF1:0.9642263678 \t AUC:0.9644676327\tTrain cost: 0:00:34\n",
      "Client7 Test =>                 \tLoss: 0.1887589116 \tAcc: 0.9397916667 \tTPR:0.9315082927 \tFPR:0.0514961724 \tF1:0.9363733819 \tAUC:0.9400060601 \ttest cost: 0:00:05\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1449928527 \tAcc: 0.9422263825 \tTPR:0.9554639216 \tFPR:0.0711693593 \tF1:0.9407656341 \t AUC:0.9421472811\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1348186131 \tAcc: 0.9459763825 \tTPR:0.9611056562 \tFPR:0.0673238844 \tF1:0.9448366161 \t AUC:0.9468908859\tTrain cost: 0:00:34\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1312091199 \tAcc: 0.9479464286 \tTPR:0.9595256296 \tFPR:0.0635997112 \tF1:0.9466367381 \t AUC:0.9479629592\tTrain cost: 0:00:34\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1250962774 \tAcc: 0.9511549539 \tTPR:0.9645959962 \tFPR:0.0603854959 \tF1:0.9504989627 \t AUC:0.9521052501\tTrain cost: 0:00:34\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1214564980 \tAcc: 0.9523156682 \tTPR:0.9633625278 \tFPR:0.0597167231 \tF1:0.9515432491 \t AUC:0.9518229024\tTrain cost: 0:00:34\n",
      "Client4 Test =>                 \tLoss: 0.1958571653 \tAcc: 0.9291666667 \tTPR:0.9078021368 \tFPR:0.0490617226 \tF1:0.9255118584 \tAUC:0.9293702071 \ttest cost: 0:00:05\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1209825579 \tAcc: 0.9521428571 \tTPR:0.9635678920 \tFPR:0.0593715309 \tF1:0.9518305221 \t AUC:0.9520981805\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1097206269 \tAcc: 0.9558928571 \tTPR:0.9627175160 \tFPR:0.0518437274 \tF1:0.9547002948 \t AUC:0.9554368943\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1055453366 \tAcc: 0.9576756912 \tTPR:0.9667035372 \tFPR:0.0529591499 \tF1:0.9572711975 \t AUC:0.9568721937\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1034326088 \tAcc: 0.9588392857 \tTPR:0.9673153261 \tFPR:0.0490792205 \tF1:0.9580720843 \t AUC:0.9591180528\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0981798674 \tAcc: 0.9624107143 \tTPR:0.9704831462 \tFPR:0.0463205714 \tF1:0.9620612152 \t AUC:0.9620812874\tTrain cost: 0:00:34\n",
      "Client8 Test =>                 \tLoss: 0.2159319297 \tAcc: 0.9293750000 \tTPR:0.9019651935 \tFPR:0.0428172711 \tF1:0.9247938934 \tAUC:0.9295739612 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.1944646305 \tAcc: 0.9342916667 \tTPR:0.9144992896 \tFPR:0.0458190532 \tF1:0.9302918104 \tAUC:0.9343401182\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 13:  =============\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1354070100 \tAcc: 0.9450835253 \tTPR:0.9538222390 \tFPR:0.0640411513 \tF1:0.9427804216 \t AUC:0.9448905439\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1233283034 \tAcc: 0.9529435484 \tTPR:0.9629255968 \tFPR:0.0565115505 \tF1:0.9516326835 \t AUC:0.9532070232\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1188219871 \tAcc: 0.9548185484 \tTPR:0.9647509456 \tFPR:0.0539405836 \tF1:0.9531990174 \t AUC:0.9554051810\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1168910678 \tAcc: 0.9527649770 \tTPR:0.9618270785 \tFPR:0.0558488748 \tF1:0.9515540910 \t AUC:0.9529891018\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1126350976 \tAcc: 0.9562500000 \tTPR:0.9647971964 \tFPR:0.0513075733 \tF1:0.9540610017 \t AUC:0.9567448116\tTrain cost: 0:00:34\n",
      "Client0 Test =>                 \tLoss: 0.1998275262 \tAcc: 0.9295833333 \tTPR:0.9031658929 \tFPR:0.0414092305 \tF1:0.9272486343 \tAUC:0.9308783312 \ttest cost: 0:00:05\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1419896500 \tAcc: 0.9459821429 \tTPR:0.9568141451 \tFPR:0.0653031740 \tF1:0.9450834491 \t AUC:0.9457554856\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1372843447 \tAcc: 0.9440985023 \tTPR:0.9554489512 \tFPR:0.0669568896 \tF1:0.9427936893 \t AUC:0.9442460308\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1271885325 \tAcc: 0.9495420507 \tTPR:0.9597523702 \tFPR:0.0616831036 \tF1:0.9485398665 \t AUC:0.9490346333\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1251538377 \tAcc: 0.9530299539 \tTPR:0.9637364019 \tFPR:0.0567068048 \tF1:0.9520548574 \t AUC:0.9535147985\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1167268481 \tAcc: 0.9527678571 \tTPR:0.9615222284 \tFPR:0.0553111774 \tF1:0.9508877928 \t AUC:0.9531055255\tTrain cost: 0:00:34\n",
      "Client5 Test =>                 \tLoss: 0.2323697422 \tAcc: 0.9214583333 \tTPR:0.8688118597 \tFPR:0.0270142219 \tF1:0.9141214049 \tAUC:0.9208988189 \ttest cost: 0:00:05\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.1374248426 \tAcc: 0.9458928571 \tTPR:0.9533091639 \tFPR:0.0614776736 \tF1:0.9439705395 \t AUC:0.9459157451\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.1263289782 \tAcc: 0.9514256912 \tTPR:0.9614022093 \tFPR:0.0593072930 \tF1:0.9509616523 \t AUC:0.9510474581\tTrain cost: 0:00:34\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.1185251702 \tAcc: 0.9534706221 \tTPR:0.9635589495 \tFPR:0.0557801779 \tF1:0.9526650328 \t AUC:0.9538893858\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.1152379913 \tAcc: 0.9561549539 \tTPR:0.9635482609 \tFPR:0.0505361461 \tF1:0.9549546307 \t AUC:0.9565060574\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.1089667200 \tAcc: 0.9579406682 \tTPR:0.9679803510 \tFPR:0.0519609181 \tF1:0.9570495139 \t AUC:0.9580097165\tTrain cost: 0:00:33\n",
      "Client9 Test =>                 \tLoss: 0.2278018084 \tAcc: 0.9262500000 \tTPR:0.8852451896 \tFPR:0.0310669491 \tF1:0.9216885225 \tAUC:0.9270891203 \ttest cost: 0:00:05\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1229758029 \tAcc: 0.9492799539 \tTPR:0.9599382777 \tFPR:0.0599778191 \tF1:0.9484791773 \t AUC:0.9499802293\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1142105954 \tAcc: 0.9552592166 \tTPR:0.9655599662 \tFPR:0.0546600415 \tF1:0.9543580536 \t AUC:0.9554499624\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1100705724 \tAcc: 0.9550000000 \tTPR:0.9629203160 \tFPR:0.0530480084 \tF1:0.9540339075 \t AUC:0.9549361538\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1030924941 \tAcc: 0.9601756912 \tTPR:0.9689761450 \tFPR:0.0487561764 \tF1:0.9601128907 \t AUC:0.9601099843\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0988827909 \tAcc: 0.9597263825 \tTPR:0.9690798142 \tFPR:0.0481716596 \tF1:0.9587857286 \t AUC:0.9604540773\tTrain cost: 0:00:34\n",
      "Client1 Test =>                 \tLoss: 0.1937471668 \tAcc: 0.9379166667 \tTPR:0.9100524048 \tFPR:0.0357098295 \tF1:0.9327080696 \tAUC:0.9371712877 \ttest cost: 0:00:05\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1053917505 \tAcc: 0.9608899770 \tTPR:0.9700178150 \tFPR:0.0479370724 \tF1:0.9608750016 \t AUC:0.9610403713\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0954114078 \tAcc: 0.9621370968 \tTPR:0.9704522598 \tFPR:0.0469919603 \tF1:0.9619536060 \t AUC:0.9617301497\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0942775618 \tAcc: 0.9654435484 \tTPR:0.9739197939 \tFPR:0.0426372855 \tF1:0.9652392869 \t AUC:0.9656412542\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0874495312 \tAcc: 0.9658899770 \tTPR:0.9727257019 \tFPR:0.0409467548 \tF1:0.9658679896 \t AUC:0.9658894735\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0842218253 \tAcc: 0.9670506912 \tTPR:0.9735425687 \tFPR:0.0401901975 \tF1:0.9665706394 \t AUC:0.9666761856\tTrain cost: 0:00:34\n",
      "Client7 Test =>                 \tLoss: 0.2744437872 \tAcc: 0.9185416667 \tTPR:0.8599588171 \tFPR:0.0237957464 \tF1:0.9098779244 \tAUC:0.9180815353 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2256380062 \tAcc: 0.9267500000 \tTPR:0.8854468328 \tFPR:0.0317991955 \tF1:0.9211289112 \tAUC:0.9268238187\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 14:  =============\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1078720764 \tAcc: 0.9567828341 \tTPR:0.9668988773 \tFPR:0.0521780230 \tF1:0.9558847504 \t AUC:0.9573604272\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1034633136 \tAcc: 0.9589228111 \tTPR:0.9690707407 \tFPR:0.0514151484 \tF1:0.9587054223 \t AUC:0.9588277961\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1000247627 \tAcc: 0.9592828341 \tTPR:0.9669054791 \tFPR:0.0494434969 \tF1:0.9581663578 \t AUC:0.9587309911\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0968469707 \tAcc: 0.9614228111 \tTPR:0.9713771327 \tFPR:0.0484571688 \tF1:0.9609913741 \t AUC:0.9614599819\tTrain cost: 0:00:34\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0930644306 \tAcc: 0.9633035714 \tTPR:0.9730022415 \tFPR:0.0458414977 \tF1:0.9630266339 \t AUC:0.9635803719\tTrain cost: 0:00:34\n",
      "Client1 Test =>                 \tLoss: 0.2144387865 \tAcc: 0.9316666667 \tTPR:0.9001826404 \tFPR:0.0387072775 \tF1:0.9259827971 \tAUC:0.9307376815 \ttest cost: 0:00:05\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1284826626 \tAcc: 0.9505270737 \tTPR:0.9611859261 \tFPR:0.0604934992 \tF1:0.9493320741 \t AUC:0.9503462135\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1223241456 \tAcc: 0.9506221198 \tTPR:0.9615047983 \tFPR:0.0610918652 \tF1:0.9496141520 \t AUC:0.9502064665\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1133099730 \tAcc: 0.9573156682 \tTPR:0.9691024524 \tFPR:0.0542188339 \tF1:0.9564605665 \t AUC:0.9574418093\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1085544371 \tAcc: 0.9571399770 \tTPR:0.9680312696 \tFPR:0.0527598914 \tF1:0.9567386304 \t AUC:0.9576356891\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1040010807 \tAcc: 0.9607114055 \tTPR:0.9687669097 \tFPR:0.0474851089 \tF1:0.9605904331 \t AUC:0.9606409004\tTrain cost: 0:00:34\n",
      "Client5 Test =>                 \tLoss: 0.2093689689 \tAcc: 0.9329166667 \tTPR:0.9101542226 \tFPR:0.0445040069 \tF1:0.9297999028 \tAUC:0.9328251078 \ttest cost: 0:00:05\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1221099654 \tAcc: 0.9515063364 \tTPR:0.9625394241 \tFPR:0.0589750823 \tF1:0.9507648060 \t AUC:0.9517821709\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1104268010 \tAcc: 0.9551699309 \tTPR:0.9642604537 \tFPR:0.0532297902 \tF1:0.9534546064 \t AUC:0.9555153317\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1060796524 \tAcc: 0.9582142857 \tTPR:0.9648696863 \tFPR:0.0484746500 \tF1:0.9568091474 \t AUC:0.9581975182\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0979446998 \tAcc: 0.9622292627 \tTPR:0.9701544246 \tFPR:0.0448379711 \tF1:0.9609145350 \t AUC:0.9626582267\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0920725026 \tAcc: 0.9634792627 \tTPR:0.9702952594 \tFPR:0.0428054787 \tF1:0.9623606860 \t AUC:0.9637448903\tTrain cost: 0:00:34\n",
      "Client8 Test =>                 \tLoss: 0.2135735926 \tAcc: 0.9331250000 \tTPR:0.9109266627 \tFPR:0.0447155623 \tF1:0.9300517956 \tAUC:0.9331055502 \ttest cost: 0:00:05\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1078249906 \tAcc: 0.9573156682 \tTPR:0.9656305075 \tFPR:0.0520563999 \tF1:0.9565480729 \t AUC:0.9567870538\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0925517570 \tAcc: 0.9646428571 \tTPR:0.9732026799 \tFPR:0.0452029149 \tF1:0.9643950560 \t AUC:0.9639998825\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0936542228 \tAcc: 0.9633899770 \tTPR:0.9722477795 \tFPR:0.0454252631 \tF1:0.9633781017 \t AUC:0.9634112582\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0873934448 \tAcc: 0.9647292627 \tTPR:0.9726794496 \tFPR:0.0424812144 \tF1:0.9642384428 \t AUC:0.9650991176\tTrain cost: 0:00:34\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0780612998 \tAcc: 0.9700864055 \tTPR:0.9767524097 \tFPR:0.0361072698 \tF1:0.9699934161 \t AUC:0.9703225700\tTrain cost: 0:00:34\n",
      "Client7 Test =>                 \tLoss: 0.2476059406 \tAcc: 0.9304166667 \tTPR:0.8928036781 \tFPR:0.0301853215 \tF1:0.9249076384 \tAUC:0.9313091783 \ttest cost: 0:00:05\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1354398013 \tAcc: 0.9489228111 \tTPR:0.9588333616 \tFPR:0.0610918871 \tF1:0.9469926368 \t AUC:0.9488707373\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1263639295 \tAcc: 0.9529435484 \tTPR:0.9628880973 \tFPR:0.0565526173 \tF1:0.9514630338 \t AUC:0.9531677400\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1216583414 \tAcc: 0.9536578341 \tTPR:0.9639637744 \tFPR:0.0558602019 \tF1:0.9523678564 \t AUC:0.9540517862\tTrain cost: 0:00:34\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1162312766 \tAcc: 0.9540120968 \tTPR:0.9633975607 \tFPR:0.0542126966 \tF1:0.9526187679 \t AUC:0.9545924321\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1133484486 \tAcc: 0.9546428571 \tTPR:0.9663742916 \tFPR:0.0553230687 \tF1:0.9539942627 \t AUC:0.9555256114\tTrain cost: 0:00:33\n",
      "Client3 Test =>                 \tLoss: 0.1994947387 \tAcc: 0.9339583333 \tTPR:0.9021824723 \tFPR:0.0342408867 \tF1:0.9292037017 \tAUC:0.9339707928 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2168964054 \tAcc: 0.9324166667 \tTPR:0.9032499352 \tFPR:0.0384706110 \tF1:0.9279891671 \tAUC:0.9323896621\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 15:  =============\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1276109007 \tAcc: 0.9512500000 \tTPR:0.9625427551 \tFPR:0.0594552252 \tF1:0.9500834549 \t AUC:0.9515437649\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1215594050 \tAcc: 0.9546313364 \tTPR:0.9653371766 \tFPR:0.0561082433 \tF1:0.9535899650 \t AUC:0.9546144667\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1153417060 \tAcc: 0.9552678571 \tTPR:0.9649760841 \tFPR:0.0543489965 \tF1:0.9536046516 \t AUC:0.9553135438\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1095029720 \tAcc: 0.9563364055 \tTPR:0.9665578717 \tFPR:0.0539817875 \tF1:0.9550102499 \t AUC:0.9562880421\tTrain cost: 0:00:34\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1041887462 \tAcc: 0.9598185484 \tTPR:0.9675140458 \tFPR:0.0482954550 \tF1:0.9580558382 \t AUC:0.9596092954\tTrain cost: 0:00:34\n",
      "Client3 Test =>                 \tLoss: 0.1740648883 \tAcc: 0.9422916667 \tTPR:0.9438280864 \tFPR:0.0587384157 \tF1:0.9408398036 \tAUC:0.9425448354 \ttest cost: 0:00:05\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.1239349472 \tAcc: 0.9516935484 \tTPR:0.9594984626 \tFPR:0.0565061213 \tF1:0.9505036868 \t AUC:0.9514961706\tTrain cost: 0:00:34\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.1150006177 \tAcc: 0.9557056452 \tTPR:0.9646989289 \tFPR:0.0521550864 \tF1:0.9545272290 \t AUC:0.9562719212\tTrain cost: 0:00:34\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.1086097264 \tAcc: 0.9591935484 \tTPR:0.9666885378 \tFPR:0.0478356509 \tF1:0.9583339499 \t AUC:0.9594264435\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.1061780064 \tAcc: 0.9591042627 \tTPR:0.9664553397 \tFPR:0.0481351431 \tF1:0.9582937345 \t AUC:0.9591600983\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.1001850655 \tAcc: 0.9627649770 \tTPR:0.9706266779 \tFPR:0.0462580761 \tF1:0.9614946749 \t AUC:0.9621843009\tTrain cost: 0:00:33\n",
      "Client9 Test =>                 \tLoss: 0.2057366566 \tAcc: 0.9341666667 \tTPR:0.9189174448 \tFPR:0.0523142541 \tF1:0.9307565773 \tAUC:0.9333015953 \ttest cost: 0:00:05\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1245207301 \tAcc: 0.9524020737 \tTPR:0.9623044881 \tFPR:0.0560993483 \tF1:0.9507196515 \t AUC:0.9531025699\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1112225853 \tAcc: 0.9563364055 \tTPR:0.9651358799 \tFPR:0.0518071733 \tF1:0.9541914437 \t AUC:0.9566643533\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1087619636 \tAcc: 0.9573156682 \tTPR:0.9681378674 \tFPR:0.0523948336 \tF1:0.9560854839 \t AUC:0.9578715169\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1019949513 \tAcc: 0.9586578341 \tTPR:0.9653183835 \tFPR:0.0479565734 \tF1:0.9561738737 \t AUC:0.9586809051\tTrain cost: 0:00:34\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1008100111 \tAcc: 0.9613392857 \tTPR:0.9686909289 \tFPR:0.0457069351 \tF1:0.9591811319 \t AUC:0.9614919969\tTrain cost: 0:00:34\n",
      "Client0 Test =>                 \tLoss: 0.1924624137 \tAcc: 0.9350000000 \tTPR:0.9176570660 \tFPR:0.0480519288 \tF1:0.9316811631 \tAUC:0.9348025686 \ttest cost: 0:00:05\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1342466042 \tAcc: 0.9455328341 \tTPR:0.9560270313 \tFPR:0.0644793829 \tF1:0.9452401888 \t AUC:0.9457738242\tTrain cost: 0:00:34\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1210168535 \tAcc: 0.9537471198 \tTPR:0.9659360625 \tFPR:0.0577810124 \tF1:0.9538756076 \t AUC:0.9540775251\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1195332840 \tAcc: 0.9529406682 \tTPR:0.9634986516 \tFPR:0.0571969690 \tF1:0.9521030663 \t AUC:0.9531508413\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1086410599 \tAcc: 0.9557114055 \tTPR:0.9656102157 \tFPR:0.0554004512 \tF1:0.9551154826 \t AUC:0.9551048823\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1044298181 \tAcc: 0.9590178571 \tTPR:0.9691616364 \tFPR:0.0522052249 \tF1:0.9584705264 \t AUC:0.9584782057\tTrain cost: 0:00:33\n",
      "Client6 Test =>                 \tLoss: 0.2237334177 \tAcc: 0.9266666667 \tTPR:0.8972848468 \tFPR:0.0430214036 \tF1:0.9217233099 \tAUC:0.9271317216 \ttest cost: 0:00:05\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1079104368 \tAcc: 0.9569614055 \tTPR:0.9655081289 \tFPR:0.0525263706 \tF1:0.9559101352 \t AUC:0.9564908792\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1007920937 \tAcc: 0.9599078341 \tTPR:0.9689084696 \tFPR:0.0488664130 \tF1:0.9589533169 \t AUC:0.9600210283\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0897637507 \tAcc: 0.9638335253 \tTPR:0.9712473480 \tFPR:0.0436482104 \tF1:0.9634308231 \t AUC:0.9637995688\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0846042458 \tAcc: 0.9658899770 \tTPR:0.9754399501 \tFPR:0.0430768316 \tF1:0.9652800182 \t AUC:0.9661815592\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0818955390 \tAcc: 0.9681221198 \tTPR:0.9735489417 \tFPR:0.0365715991 \tF1:0.9673754410 \t AUC:0.9684886713\tTrain cost: 0:00:33\n",
      "Client1 Test =>                 \tLoss: 0.2334743638 \tAcc: 0.9337500000 \tTPR:0.8936611320 \tFPR:0.0291296245 \tF1:0.9264585475 \tAUC:0.9322657537 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2058943480 \tAcc: 0.9343750000 \tTPR:0.9142697152 \tFPR:0.0462511253 \tF1:0.9302918803 \tAUC:0.9340092949\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 16:  =============\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0956276997 \tAcc: 0.9631250000 \tTPR:0.9718481850 \tFPR:0.0449982460 \tF1:0.9626762263 \t AUC:0.9634249695\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0912014289 \tAcc: 0.9641964286 \tTPR:0.9717880013 \tFPR:0.0446117794 \tF1:0.9641229741 \t AUC:0.9635881110\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0870581971 \tAcc: 0.9643721198 \tTPR:0.9731185079 \tFPR:0.0453234058 \tF1:0.9644080785 \t AUC:0.9638975511\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0805415186 \tAcc: 0.9661607143 \tTPR:0.9734403705 \tFPR:0.0411719153 \tF1:0.9657657629 \t AUC:0.9661342276\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0740048476 \tAcc: 0.9702678571 \tTPR:0.9770406498 \tFPR:0.0357284626 \tF1:0.9692885693 \t AUC:0.9706560936\tTrain cost: 0:00:33\n",
      "Client1 Test =>                 \tLoss: 0.2159707766 \tAcc: 0.9345833333 \tTPR:0.9006947106 \tFPR:0.0345004865 \tF1:0.9283268487 \tAUC:0.9330971121 \ttest cost: 0:00:05\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.1111915458 \tAcc: 0.9571313364 \tTPR:0.9665082045 \tFPR:0.0521482923 \tF1:0.9560066509 \t AUC:0.9571799561\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.1064864479 \tAcc: 0.9577649770 \tTPR:0.9666659693 \tFPR:0.0504569459 \tF1:0.9565668398 \t AUC:0.9581045117\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0991322323 \tAcc: 0.9618721198 \tTPR:0.9697688356 \tFPR:0.0447370956 \tF1:0.9604412728 \t AUC:0.9625158700\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0943677113 \tAcc: 0.9642770737 \tTPR:0.9719993203 \tFPR:0.0432298488 \tF1:0.9634060609 \t AUC:0.9643847357\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0844774812 \tAcc: 0.9677678571 \tTPR:0.9736147847 \tFPR:0.0386627666 \tF1:0.9669816733 \t AUC:0.9674760090\tTrain cost: 0:00:33\n",
      "Client9 Test =>                 \tLoss: 0.2495565216 \tAcc: 0.9343750000 \tTPR:0.9110728072 \tFPR:0.0402171660 \tF1:0.9311304166 \tAUC:0.9354278206 \ttest cost: 0:00:05\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1333437184 \tAcc: 0.9470478111 \tTPR:0.9615029473 \tFPR:0.0667192223 \tF1:0.9459547435 \t AUC:0.9473918625\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1269325134 \tAcc: 0.9491042627 \tTPR:0.9620411165 \tFPR:0.0639113178 \tF1:0.9484217444 \t AUC:0.9490648993\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1238639261 \tAcc: 0.9503513825 \tTPR:0.9621485965 \tFPR:0.0605310669 \tF1:0.9493191235 \t AUC:0.9508087648\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1147792594 \tAcc: 0.9532085253 \tTPR:0.9658307313 \tFPR:0.0589820422 \tF1:0.9522851947 \t AUC:0.9534243445\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1093761093 \tAcc: 0.9568634793 \tTPR:0.9671628030 \tFPR:0.0525296861 \tF1:0.9551422837 \t AUC:0.9573165585\tTrain cost: 0:00:33\n",
      "Client4 Test =>                 \tLoss: 0.1758260870 \tAcc: 0.9397916667 \tTPR:0.9274656555 \tFPR:0.0470082359 \tF1:0.9364393909 \tAUC:0.9402287098 \ttest cost: 0:00:05\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1161020435 \tAcc: 0.9556105991 \tTPR:0.9663112754 \tFPR:0.0536507339 \tF1:0.9542505743 \t AUC:0.9563302708\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1076832569 \tAcc: 0.9561578341 \tTPR:0.9652917637 \tFPR:0.0521762593 \tF1:0.9541096244 \t AUC:0.9565577522\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0986884787 \tAcc: 0.9604435484 \tTPR:0.9670699276 \tFPR:0.0455982278 \tF1:0.9584825946 \t AUC:0.9607358499\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0898343065 \tAcc: 0.9649078341 \tTPR:0.9716558834 \tFPR:0.0398038089 \tF1:0.9637281996 \t AUC:0.9659260373\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0863419453 \tAcc: 0.9649107143 \tTPR:0.9703229489 \tFPR:0.0402240068 \tF1:0.9633381975 \t AUC:0.9650494711\tTrain cost: 0:00:33\n",
      "Client0 Test =>                 \tLoss: 0.2522150901 \tAcc: 0.9243750000 \tTPR:0.8906845626 \tFPR:0.0422136637 \tF1:0.9219281368 \tAUC:0.9242354494 \ttest cost: 0:00:05\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1295819308 \tAcc: 0.9504435484 \tTPR:0.9610633651 \tFPR:0.0604296532 \tF1:0.9498119349 \t AUC:0.9503168559\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1161149865 \tAcc: 0.9550892857 \tTPR:0.9639526484 \tFPR:0.0533303797 \tF1:0.9543992037 \t AUC:0.9553111344\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.1109110588 \tAcc: 0.9560627880 \tTPR:0.9654983739 \tFPR:0.0537782180 \tF1:0.9552061528 \t AUC:0.9558600780\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.1018955359 \tAcc: 0.9592828341 \tTPR:0.9684916194 \tFPR:0.0497361478 \tF1:0.9581449354 \t AUC:0.9593777358\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.1018991728 \tAcc: 0.9597235023 \tTPR:0.9715911176 \tFPR:0.0503994515 \tF1:0.9591821544 \t AUC:0.9605958331\tTrain cost: 0:00:33\n",
      "Client2 Test =>                 \tLoss: 0.1960310985 \tAcc: 0.9366666667 \tTPR:0.9134211588 \tFPR:0.0378572890 \tF1:0.9334227927 \tAUC:0.9377819349 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2179199148 \tAcc: 0.9339583333 \tTPR:0.9086677790 \tFPR:0.0403593682 \tF1:0.9302495171 \tAUC:0.9341542054\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 17:  =============\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1212928369 \tAcc: 0.9508870968 \tTPR:0.9607429238 \tFPR:0.0594287377 \tF1:0.9501863904 \t AUC:0.9506570931\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1128521317 \tAcc: 0.9549078341 \tTPR:0.9662603913 \tFPR:0.0571047814 \tF1:0.9549380400 \t AUC:0.9545778050\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1056730460 \tAcc: 0.9574107143 \tTPR:0.9681706515 \tFPR:0.0533907849 \tF1:0.9573722564 \t AUC:0.9573899333\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1008959224 \tAcc: 0.9600835253 \tTPR:0.9683313563 \tFPR:0.0500430385 \tF1:0.9593410054 \t AUC:0.9591441589\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0942256576 \tAcc: 0.9633035714 \tTPR:0.9743906497 \tFPR:0.0488344221 \tF1:0.9633100102 \t AUC:0.9627781138\tTrain cost: 0:00:33\n",
      "Client6 Test =>                 \tLoss: 0.2645482418 \tAcc: 0.9222916667 \tTPR:0.8770615696 \tFPR:0.0329534377 \tF1:0.9156529701 \tAUC:0.9220540660 \ttest cost: 0:00:05\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1183507183 \tAcc: 0.9546399770 \tTPR:0.9639667107 \tFPR:0.0552099889 \tF1:0.9527588963 \t AUC:0.9543783609\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1090089898 \tAcc: 0.9580270737 \tTPR:0.9678121929 \tFPR:0.0520400506 \tF1:0.9568706529 \t AUC:0.9578860712\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1006164475 \tAcc: 0.9626756912 \tTPR:0.9701097633 \tFPR:0.0451569072 \tF1:0.9613240259 \t AUC:0.9624764280\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0959046600 \tAcc: 0.9617828341 \tTPR:0.9708095398 \tFPR:0.0466476786 \tF1:0.9605083939 \t AUC:0.9620809306\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0886347461 \tAcc: 0.9668750000 \tTPR:0.9741528720 \tFPR:0.0405606464 \tF1:0.9657027698 \t AUC:0.9667961128\tTrain cost: 0:00:33\n",
      "Client3 Test =>                 \tLoss: 0.1825585980 \tAcc: 0.9429166667 \tTPR:0.9365573643 \tFPR:0.0518286120 \tF1:0.9396433023 \tAUC:0.9423643761 \ttest cost: 0:00:05\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.1015269951 \tAcc: 0.9630328341 \tTPR:0.9684948152 \tFPR:0.0441693571 \tF1:0.9618144585 \t AUC:0.9621627291\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0931761550 \tAcc: 0.9643750000 \tTPR:0.9725414434 \tFPR:0.0431914112 \tF1:0.9632508073 \t AUC:0.9646750161\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0877089739 \tAcc: 0.9662500000 \tTPR:0.9762970284 \tFPR:0.0435496542 \tF1:0.9657380711 \t AUC:0.9663736871\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0823698518 \tAcc: 0.9670535714 \tTPR:0.9744151704 \tFPR:0.0399177783 \tF1:0.9662406672 \t AUC:0.9672486960\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0756033472 \tAcc: 0.9716964286 \tTPR:0.9791318286 \tFPR:0.0355736233 \tF1:0.9712403002 \t AUC:0.9717791026\tTrain cost: 0:00:33\n",
      "Client9 Test =>                 \tLoss: 0.2597276655 \tAcc: 0.9322916667 \tTPR:0.9011773425 \tFPR:0.0370615963 \tF1:0.9285007395 \tAUC:0.9320578731 \ttest cost: 0:00:05\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1160323983 \tAcc: 0.9541042627 \tTPR:0.9645269336 \tFPR:0.0561468198 \tF1:0.9534153665 \t AUC:0.9541900569\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1063520688 \tAcc: 0.9582978111 \tTPR:0.9677435122 \tFPR:0.0506135431 \tF1:0.9575994177 \t AUC:0.9585649845\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0958187865 \tAcc: 0.9632978111 \tTPR:0.9694355631 \tFPR:0.0428158213 \tF1:0.9623454819 \t AUC:0.9633098709\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0896487353 \tAcc: 0.9643721198 \tTPR:0.9722153895 \tFPR:0.0429558652 \tF1:0.9631560645 \t AUC:0.9646297622\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0870579273 \tAcc: 0.9655299539 \tTPR:0.9730859571 \tFPR:0.0426094038 \tF1:0.9641093086 \t AUC:0.9652382766\tTrain cost: 0:00:33\n",
      "Client8 Test =>                 \tLoss: 0.1869843126 \tAcc: 0.9379166667 \tTPR:0.9172706914 \tFPR:0.0417719686 \tF1:0.9344907163 \tAUC:0.9377493614 \ttest cost: 0:00:05\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1195439226 \tAcc: 0.9531163594 \tTPR:0.9645965523 \tFPR:0.0578371054 \tF1:0.9519981702 \t AUC:0.9533797235\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1116643973 \tAcc: 0.9563335253 \tTPR:0.9654132058 \tFPR:0.0535869350 \tF1:0.9560351059 \t AUC:0.9559131354\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1054143080 \tAcc: 0.9600864055 \tTPR:0.9692537811 \tFPR:0.0482973680 \tF1:0.9589321402 \t AUC:0.9604782066\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0983089274 \tAcc: 0.9623214286 \tTPR:0.9698376009 \tFPR:0.0459243923 \tF1:0.9612005169 \t AUC:0.9619566043\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0924176765 \tAcc: 0.9640985023 \tTPR:0.9721111665 \tFPR:0.0449647038 \tF1:0.9635853528 \t AUC:0.9635732313\tTrain cost: 0:00:33\n",
      "Client5 Test =>                 \tLoss: 0.1869141856 \tAcc: 0.9377083333 \tTPR:0.9144746325 \tFPR:0.0399829378 \tF1:0.9336445808 \tAUC:0.9372458473 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2161466007 \tAcc: 0.9346250000 \tTPR:0.9093083200 \tFPR:0.0407197105 \tF1:0.9303864618 \tAUC:0.9342943048\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 18:  =============\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0892495712 \tAcc: 0.9652678571 \tTPR:0.9742125555 \tFPR:0.0427489923 \tF1:0.9647333250 \t AUC:0.9657317816\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0808381144 \tAcc: 0.9684792627 \tTPR:0.9759968705 \tFPR:0.0387994489 \tF1:0.9679243996 \t AUC:0.9685987108\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0743047758 \tAcc: 0.9713335253 \tTPR:0.9772161424 \tFPR:0.0345105947 \tF1:0.9703836676 \t AUC:0.9713527739\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0726151355 \tAcc: 0.9715956221 \tTPR:0.9778324468 \tFPR:0.0350054470 \tF1:0.9710119190 \t AUC:0.9714134999\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0659901212 \tAcc: 0.9730357143 \tTPR:0.9787898816 \tFPR:0.0320446872 \tF1:0.9724126619 \t AUC:0.9733725972\tTrain cost: 0:00:33\n",
      "Client1 Test =>                 \tLoss: 0.2027205020 \tAcc: 0.9441666667 \tTPR:0.9294831346 \tFPR:0.0425983578 \tF1:0.9401440689 \tAUC:0.9434423884 \ttest cost: 0:00:05\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1020050886 \tAcc: 0.9609821429 \tTPR:0.9726233851 \tFPR:0.0504578430 \tF1:0.9598624353 \t AUC:0.9610827710\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.0922350028 \tAcc: 0.9642828341 \tTPR:0.9713115354 \tFPR:0.0425256169 \tF1:0.9621304211 \t AUC:0.9643929593\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0896631502 \tAcc: 0.9650835253 \tTPR:0.9729470762 \tFPR:0.0428765669 \tF1:0.9640352112 \t AUC:0.9650352547\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0838947910 \tAcc: 0.9675000000 \tTPR:0.9729646615 \tFPR:0.0379268445 \tF1:0.9656987917 \t AUC:0.9675189085\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0758664380 \tAcc: 0.9705299539 \tTPR:0.9762088844 \tFPR:0.0359773845 \tF1:0.9692093949 \t AUC:0.9701157499\tTrain cost: 0:00:33\n",
      "Client3 Test =>                 \tLoss: 0.2036727092 \tAcc: 0.9372916667 \tTPR:0.9190244919 \tFPR:0.0441475811 \tF1:0.9336738380 \tAUC:0.9374384554 \ttest cost: 0:00:05\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1150208071 \tAcc: 0.9544498848 \tTPR:0.9631206716 \tFPR:0.0542082770 \tF1:0.9520904585 \t AUC:0.9544561973\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1018039355 \tAcc: 0.9594585253 \tTPR:0.9666026807 \tFPR:0.0478216823 \tF1:0.9578536822 \t AUC:0.9593904992\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0964205917 \tAcc: 0.9622321429 \tTPR:0.9682063246 \tFPR:0.0439743608 \tF1:0.9600094259 \t AUC:0.9621159819\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0921321715 \tAcc: 0.9611607143 \tTPR:0.9655520434 \tFPR:0.0442313715 \tF1:0.9590978646 \t AUC:0.9606603360\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0860993225 \tAcc: 0.9656221198 \tTPR:0.9732829410 \tFPR:0.0416388863 \tF1:0.9644651151 \t AUC:0.9658220273\tTrain cost: 0:00:33\n",
      "Client0 Test =>                 \tLoss: 0.2040062883 \tAcc: 0.9400000000 \tTPR:0.9195791878 \tFPR:0.0407340976 \tF1:0.9370576171 \tAUC:0.9394225451 \ttest cost: 0:00:05\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1207013413 \tAcc: 0.9538220046 \tTPR:0.9647453496 \tFPR:0.0557474434 \tF1:0.9539844839 \t AUC:0.9544989531\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1093106198 \tAcc: 0.9579464286 \tTPR:0.9671837612 \tFPR:0.0507263346 \tF1:0.9572993539 \t AUC:0.9582287133\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1056102450 \tAcc: 0.9586578341 \tTPR:0.9665077627 \tFPR:0.0492609388 \tF1:0.9577899247 \t AUC:0.9586234119\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0979335988 \tAcc: 0.9624078341 \tTPR:0.9706536562 \tFPR:0.0453743924 \tF1:0.9617931923 \t AUC:0.9626396319\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0923209802 \tAcc: 0.9636607143 \tTPR:0.9727675307 \tFPR:0.0451418484 \tF1:0.9622270917 \t AUC:0.9638128411\tTrain cost: 0:00:33\n",
      "Client5 Test =>                 \tLoss: 0.2350655814 \tAcc: 0.9220833333 \tTPR:0.8731209235 \tFPR:0.0266542150 \tF1:0.9169271130 \tAUC:0.9232333542 \ttest cost: 0:00:05\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0970119607 \tAcc: 0.9613392857 \tTPR:0.9665769952 \tFPR:0.0434771829 \tF1:0.9602131937 \t AUC:0.9615499061\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0899444327 \tAcc: 0.9642857143 \tTPR:0.9712510388 \tFPR:0.0426694716 \tF1:0.9633829893 \t AUC:0.9642907836\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0782895994 \tAcc: 0.9696399770 \tTPR:0.9777506526 \tFPR:0.0382244775 \tF1:0.9691154465 \t AUC:0.9697630876\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0757308660 \tAcc: 0.9723214286 \tTPR:0.9776706001 \tFPR:0.0337361038 \tF1:0.9717415100 \t AUC:0.9719672482\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0734941638 \tAcc: 0.9723214286 \tTPR:0.9779075227 \tFPR:0.0339868033 \tF1:0.9718410635 \t AUC:0.9719603597\tTrain cost: 0:00:33\n",
      "Client9 Test =>                 \tLoss: 0.2443082508 \tAcc: 0.9370833333 \tTPR:0.9191689125 \tFPR:0.0457071230 \tF1:0.9332954355 \tAUC:0.9367308947 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2179546664 \tAcc: 0.9361250000 \tTPR:0.9120753301 \tFPR:0.0399682749 \tF1:0.9322196145 \tAUC:0.9360535276\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 19:  =============\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1009824606 \tAcc: 0.9595506912 \tTPR:0.9686780144 \tFPR:0.0487390841 \tF1:0.9591172126 \t AUC:0.9599694652\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0960153972 \tAcc: 0.9640149770 \tTPR:0.9705059965 \tFPR:0.0428816843 \tF1:0.9632785627 \t AUC:0.9638121561\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0888216236 \tAcc: 0.9646399770 \tTPR:0.9708526960 \tFPR:0.0423472712 \tF1:0.9626946396 \t AUC:0.9642527124\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0847051254 \tAcc: 0.9678542627 \tTPR:0.9753440159 \tFPR:0.0405465090 \tF1:0.9677159855 \t AUC:0.9673987535\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0782829161 \tAcc: 0.9697292627 \tTPR:0.9752832480 \tFPR:0.0359133333 \tF1:0.9689648725 \t AUC:0.9696849573\tTrain cost: 0:00:33\n",
      "Client8 Test =>                 \tLoss: 0.1956704071 \tAcc: 0.9387500000 \tTPR:0.9293135082 \tFPR:0.0515015659 \tF1:0.9365647861 \tAUC:0.9389059712 \ttest cost: 0:00:05\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1023656971 \tAcc: 0.9603571429 \tTPR:0.9679784839 \tFPR:0.0472442118 \tF1:0.9586450378 \t AUC:0.9603671360\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0885131918 \tAcc: 0.9649971198 \tTPR:0.9723059976 \tFPR:0.0425125280 \tF1:0.9636501252 \t AUC:0.9648967348\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0823911690 \tAcc: 0.9691071429 \tTPR:0.9753000649 \tFPR:0.0367169132 \tF1:0.9670649120 \t AUC:0.9692915758\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0774959164 \tAcc: 0.9701785714 \tTPR:0.9755381802 \tFPR:0.0357916247 \tF1:0.9684679100 \t AUC:0.9698732777\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0726516918 \tAcc: 0.9728571429 \tTPR:0.9777615246 \tFPR:0.0319544782 \tF1:0.9712572429 \t AUC:0.9729035232\tTrain cost: 0:00:33\n",
      "Client0 Test =>                 \tLoss: 0.2063950003 \tAcc: 0.9395833333 \tTPR:0.9251950376 \tFPR:0.0457697611 \tF1:0.9375811766 \tAUC:0.9397126383 \ttest cost: 0:00:05\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1048905077 \tAcc: 0.9593750000 \tTPR:0.9682853831 \tFPR:0.0506074846 \tF1:0.9592621132 \t AUC:0.9588389493\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0915054768 \tAcc: 0.9624020737 \tTPR:0.9686314671 \tFPR:0.0447051031 \tF1:0.9622904740 \t AUC:0.9619631820\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0813956439 \tAcc: 0.9679435484 \tTPR:0.9756334659 \tFPR:0.0412495199 \tF1:0.9680677400 \t AUC:0.9671919730\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0835122505 \tAcc: 0.9670535714 \tTPR:0.9729783741 \tFPR:0.0399189272 \tF1:0.9671617511 \t AUC:0.9665297235\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0763072847 \tAcc: 0.9686578341 \tTPR:0.9751474514 \tFPR:0.0378010756 \tF1:0.9685224112 \t AUC:0.9686731879\tTrain cost: 0:00:33\n",
      "Client7 Test =>                 \tLoss: 0.1836744124 \tAcc: 0.9458333333 \tTPR:0.9519183690 \tFPR:0.0577829057 \tF1:0.9446899181 \tAUC:0.9470677317 \ttest cost: 0:00:05\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1126585495 \tAcc: 0.9549971198 \tTPR:0.9657133224 \tFPR:0.0565180077 \tF1:0.9548198275 \t AUC:0.9545976573\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1023920645 \tAcc: 0.9588392857 \tTPR:0.9686465104 \tFPR:0.0520054238 \tF1:0.9586008694 \t AUC:0.9583205433\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0940455079 \tAcc: 0.9623214286 \tTPR:0.9728263355 \tFPR:0.0477737475 \tF1:0.9623394077 \t AUC:0.9625262940\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0903706841 \tAcc: 0.9652649770 \tTPR:0.9730940967 \tFPR:0.0435075708 \tF1:0.9648681746 \t AUC:0.9647932630\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0837710034 \tAcc: 0.9673214286 \tTPR:0.9756140082 \tFPR:0.0412418893 \tF1:0.9674372671 \t AUC:0.9671860594\tTrain cost: 0:00:33\n",
      "Client6 Test =>                 \tLoss: 0.2094943141 \tAcc: 0.9375000000 \tTPR:0.9180358631 \tFPR:0.0439251803 \tF1:0.9341792788 \tAUC:0.9370553414 \ttest cost: 0:00:05\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0865679256 \tAcc: 0.9666071429 \tTPR:0.9726829056 \tFPR:0.0399887681 \tF1:0.9658304610 \t AUC:0.9663470688\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0744928121 \tAcc: 0.9698214286 \tTPR:0.9757480077 \tFPR:0.0355540710 \tF1:0.9688022181 \t AUC:0.9700969683\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0704299940 \tAcc: 0.9721428571 \tTPR:0.9795435113 \tFPR:0.0343889858 \tF1:0.9717626747 \t AUC:0.9725772627\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0609844257 \tAcc: 0.9767857143 \tTPR:0.9819670446 \tFPR:0.0278498568 \tF1:0.9764394495 \t AUC:0.9770585939\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0585050664 \tAcc: 0.9776756912 \tTPR:0.9841873641 \tFPR:0.0294281157 \tF1:0.9778531744 \t AUC:0.9773796242\tTrain cost: 0:00:33\n",
      "Client1 Test =>                 \tLoss: 0.2093707741 \tAcc: 0.9431250000 \tTPR:0.9302664360 \tFPR:0.0456752555 \tF1:0.9380572841 \tAUC:0.9422955902 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2009209816 \tAcc: 0.9409583333 \tTPR:0.9309458428 \tFPR:0.0489309337 \tF1:0.9382144887 \tAUC:0.9410074545\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 20:  =============\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.0773913363 \tAcc: 0.9707978111 \tTPR:0.9766980599 \tFPR:0.0347126015 \tF1:0.9696313214 \t AUC:0.9709927292\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0688307931 \tAcc: 0.9748214286 \tTPR:0.9814382915 \tFPR:0.0315604605 \tF1:0.9736056869 \t AUC:0.9749389155\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0653745534 \tAcc: 0.9746399770 \tTPR:0.9801019580 \tFPR:0.0305764379 \tF1:0.9732562703 \t AUC:0.9747627601\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0649080195 \tAcc: 0.9749971198 \tTPR:0.9802469965 \tFPR:0.0301611194 \tF1:0.9739127216 \t AUC:0.9750429386\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0630280871 \tAcc: 0.9738392857 \tTPR:0.9781499924 \tFPR:0.0302744788 \tF1:0.9722342782 \t AUC:0.9739377568\tTrain cost: 0:00:33\n",
      "Client0 Test =>                 \tLoss: 0.2536911619 \tAcc: 0.9331250000 \tTPR:0.9060714165 \tFPR:0.0388796172 \tF1:0.9304017881 \tAUC:0.9335958997 \ttest cost: 0:00:05\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1139598247 \tAcc: 0.9574020737 \tTPR:0.9662652269 \tFPR:0.0524989003 \tF1:0.9562881340 \t AUC:0.9568831633\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1040156816 \tAcc: 0.9590120968 \tTPR:0.9682402822 \tFPR:0.0503015109 \tF1:0.9579081467 \t AUC:0.9589693857\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0956708754 \tAcc: 0.9629435484 \tTPR:0.9718307268 \tFPR:0.0453877747 \tF1:0.9619353767 \t AUC:0.9632214761\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0915703283 \tAcc: 0.9638335253 \tTPR:0.9711746001 \tFPR:0.0429015878 \tF1:0.9631456231 \t AUC:0.9641365061\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0844609181 \tAcc: 0.9667741935 \tTPR:0.9744490984 \tFPR:0.0408459112 \tF1:0.9659363761 \t AUC:0.9668015936\tTrain cost: 0:00:33\n",
      "Client5 Test =>                 \tLoss: 0.2157113966 \tAcc: 0.9339583333 \tTPR:0.9007054879 \tFPR:0.0309486319 \tF1:0.9302503196 \tAUC:0.9348784280 \ttest cost: 0:00:05\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1259601620 \tAcc: 0.9489256912 \tTPR:0.9619722306 \tFPR:0.0628996428 \tF1:0.9483404358 \t AUC:0.9495362939\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1156111294 \tAcc: 0.9537500000 \tTPR:0.9632771569 \tFPR:0.0557325972 \tF1:0.9522777750 \t AUC:0.9537722799\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1103310104 \tAcc: 0.9559763825 \tTPR:0.9674537769 \tFPR:0.0543950997 \tF1:0.9540407833 \t AUC:0.9565293386\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1008683947 \tAcc: 0.9591964286 \tTPR:0.9690272070 \tFPR:0.0510241807 \tF1:0.9586329262 \t AUC:0.9590015132\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0955895614 \tAcc: 0.9636578341 \tTPR:0.9715575992 \tFPR:0.0438389856 \tF1:0.9625484278 \t AUC:0.9638593068\tTrain cost: 0:00:33\n",
      "Client4 Test =>                 \tLoss: 0.1748964828 \tAcc: 0.9439583333 \tTPR:0.9442057234 \tFPR:0.0558738530 \tF1:0.9439289779 \tAUC:0.9441659352 \ttest cost: 0:00:05\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0952022235 \tAcc: 0.9635685484 \tTPR:0.9725552378 \tFPR:0.0454613854 \tF1:0.9625053071 \t AUC:0.9635469262\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0847549881 \tAcc: 0.9658035714 \tTPR:0.9735193871 \tFPR:0.0416665932 \tF1:0.9652649418 \t AUC:0.9659263970\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0778331815 \tAcc: 0.9700892857 \tTPR:0.9745172180 \tFPR:0.0351079974 \tF1:0.9695273182 \t AUC:0.9697046103\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0705396662 \tAcc: 0.9724107143 \tTPR:0.9773059277 \tFPR:0.0318389595 \tF1:0.9713995165 \t AUC:0.9727334841\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0692410164 \tAcc: 0.9723185484 \tTPR:0.9781431774 \tFPR:0.0327787592 \tF1:0.9719690526 \t AUC:0.9726822091\tTrain cost: 0:00:33\n",
      "Client8 Test =>                 \tLoss: 0.2245033414 \tAcc: 0.9391666667 \tTPR:0.9394116803 \tFPR:0.0621705757 \tF1:0.9358609612 \tAUC:0.9386205523 \ttest cost: 0:00:05\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.0992446218 \tAcc: 0.9618692396 \tTPR:0.9691534541 \tFPR:0.0446278289 \tF1:0.9603350346 \t AUC:0.9622628126\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.0904811660 \tAcc: 0.9638392857 \tTPR:0.9709374821 \tFPR:0.0430216840 \tF1:0.9621833103 \t AUC:0.9639578990\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0848825069 \tAcc: 0.9675864055 \tTPR:0.9749210710 \tFPR:0.0395314397 \tF1:0.9664907535 \t AUC:0.9676948156\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0795955974 \tAcc: 0.9693721198 \tTPR:0.9770702335 \tFPR:0.0379269763 \tF1:0.9690365860 \t AUC:0.9695716286\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0737232788 \tAcc: 0.9725892857 \tTPR:0.9789656609 \tFPR:0.0332241030 \tF1:0.9719463677 \t AUC:0.9728707789\tTrain cost: 0:00:33\n",
      "Client3 Test =>                 \tLoss: 0.1979547240 \tAcc: 0.9420833333 \tTPR:0.9263784100 \tFPR:0.0405551718 \tF1:0.9392627067 \tAUC:0.9429116191 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2133514214 \tAcc: 0.9384583333 \tTPR:0.9233545436 \tFPR:0.0456855699 \tF1:0.9359409507 \tAUC:0.9388344869\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 21:  =============\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1234711560 \tAcc: 0.9520478111 \tTPR:0.9622485806 \tFPR:0.0586821794 \tF1:0.9512109184 \t AUC:0.9517832006\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1105169687 \tAcc: 0.9558928571 \tTPR:0.9642323248 \tFPR:0.0506109919 \tF1:0.9541711473 \t AUC:0.9568106665\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.1027186592 \tAcc: 0.9590985023 \tTPR:0.9669509423 \tFPR:0.0493654802 \tF1:0.9578128868 \t AUC:0.9587927311\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0960686563 \tAcc: 0.9627678571 \tTPR:0.9721848369 \tFPR:0.0475138380 \tF1:0.9627361573 \t AUC:0.9623354995\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0935645088 \tAcc: 0.9644614055 \tTPR:0.9723876013 \tFPR:0.0443798482 \tF1:0.9638066066 \t AUC:0.9640038765\tTrain cost: 0:00:33\n",
      "Client2 Test =>                 \tLoss: 0.1810092399 \tAcc: 0.9414583333 \tTPR:0.9207481933 \tFPR:0.0359649817 \tF1:0.9385701260 \tAUC:0.9423916058 \ttest cost: 0:00:05\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1099561830 \tAcc: 0.9580328341 \tTPR:0.9686969631 \tFPR:0.0520800070 \tF1:0.9565043334 \t AUC:0.9583084781\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1035489995 \tAcc: 0.9600835253 \tTPR:0.9698803685 \tFPR:0.0495541691 \tF1:0.9595243217 \t AUC:0.9601630997\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0968705952 \tAcc: 0.9619556452 \tTPR:0.9702711465 \tFPR:0.0460262127 \tF1:0.9609620635 \t AUC:0.9621224669\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0881330851 \tAcc: 0.9656192396 \tTPR:0.9738800161 \tFPR:0.0428351405 \tF1:0.9644175068 \t AUC:0.9655224378\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0858472529 \tAcc: 0.9673214286 \tTPR:0.9736617326 \tFPR:0.0394438188 \tF1:0.9666088089 \t AUC:0.9671089569\tTrain cost: 0:00:33\n",
      "Client4 Test =>                 \tLoss: 0.1805896184 \tAcc: 0.9420833333 \tTPR:0.9357533378 \tFPR:0.0518568366 \tF1:0.9400516097 \tAUC:0.9419482506 \ttest cost: 0:00:05\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.0955762716 \tAcc: 0.9625864055 \tTPR:0.9704643640 \tFPR:0.0455726874 \tF1:0.9604025807 \t AUC:0.9624458383\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.0863527219 \tAcc: 0.9678571429 \tTPR:0.9763515483 \tFPR:0.0396881507 \tF1:0.9670729711 \t AUC:0.9683316988\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0817764516 \tAcc: 0.9678571429 \tTPR:0.9749092839 \tFPR:0.0386668744 \tF1:0.9669481253 \t AUC:0.9681212048\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0746648102 \tAcc: 0.9723214286 \tTPR:0.9792594819 \tFPR:0.0356662450 \tF1:0.9716924399 \t AUC:0.9717966185\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0724283087 \tAcc: 0.9717799539 \tTPR:0.9790615476 \tFPR:0.0344718491 \tF1:0.9707057910 \t AUC:0.9722948492\tTrain cost: 0:00:33\n",
      "Client3 Test =>                 \tLoss: 0.1924887861 \tAcc: 0.9410416667 \tTPR:0.9251083306 \tFPR:0.0433101458 \tF1:0.9382974140 \tAUC:0.9408990924 \ttest cost: 0:00:05\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.1043879625 \tAcc: 0.9605328341 \tTPR:0.9682353862 \tFPR:0.0475379652 \tF1:0.9594151508 \t AUC:0.9603487105\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0872426157 \tAcc: 0.9676699309 \tTPR:0.9741225228 \tFPR:0.0385870774 \tF1:0.9664709366 \t AUC:0.9677677227\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0852247781 \tAcc: 0.9688335253 \tTPR:0.9748833211 \tFPR:0.0372311173 \tF1:0.9682924876 \t AUC:0.9688261019\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0801291918 \tAcc: 0.9686607143 \tTPR:0.9727924876 \tFPR:0.0369932344 \tF1:0.9678745188 \t AUC:0.9678996266\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0736838797 \tAcc: 0.9714285714 \tTPR:0.9770691960 \tFPR:0.0341685131 \tF1:0.9708287410 \t AUC:0.9714503414\tTrain cost: 0:00:33\n",
      "Client9 Test =>                 \tLoss: 0.2111002548 \tAcc: 0.9416666667 \tTPR:0.9335295744 \tFPR:0.0491372698 \tF1:0.9406814766 \tAUC:0.9421961523 \ttest cost: 0:00:05\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0922433506 \tAcc: 0.9645535714 \tTPR:0.9727002001 \tFPR:0.0435792344 \tF1:0.9636983257 \t AUC:0.9645604829\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0782177378 \tAcc: 0.9689228111 \tTPR:0.9739148644 \tFPR:0.0362977570 \tF1:0.9682432438 \t AUC:0.9688085537\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0749577024 \tAcc: 0.9710714286 \tTPR:0.9771634715 \tFPR:0.0344698473 \tF1:0.9705380220 \t AUC:0.9713468121\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0702590108 \tAcc: 0.9724107143 \tTPR:0.9776350526 \tFPR:0.0330315878 \tF1:0.9718261679 \t AUC:0.9723017324\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0605872667 \tAcc: 0.9768692396 \tTPR:0.9806414283 \tFPR:0.0270988416 \tF1:0.9760520897 \t AUC:0.9767712933\tTrain cost: 0:00:33\n",
      "Client8 Test =>                 \tLoss: 0.2095962197 \tAcc: 0.9452083333 \tTPR:0.9322600788 \tFPR:0.0406060659 \tF1:0.9419509969 \tAUC:0.9458270065 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.1949568238 \tAcc: 0.9422916667 \tTPR:0.9294799030 \tFPR:0.0441750600 \tF1:0.9399103246 \tAUC:0.9426524215\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 22:  =============\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1032394754 \tAcc: 0.9595506912 \tTPR:0.9709819772 \tFPR:0.0536468409 \tF1:0.9599923369 \t AUC:0.9586675682\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.0964766728 \tAcc: 0.9627620968 \tTPR:0.9733590829 \tFPR:0.0483905862 \tF1:0.9628203669 \t AUC:0.9624842484\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0874605765 \tAcc: 0.9653542627 \tTPR:0.9750692270 \tFPR:0.0438987994 \tF1:0.9655229532 \t AUC:0.9655852138\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0823468930 \tAcc: 0.9678571429 \tTPR:0.9778364200 \tFPR:0.0426482036 \tF1:0.9681249676 \t AUC:0.9675941082\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0764449678 \tAcc: 0.9690120968 \tTPR:0.9768436829 \tFPR:0.0392981550 \tF1:0.9683983429 \t AUC:0.9687727640\tTrain cost: 0:00:33\n",
      "Client6 Test =>                 \tLoss: 0.2280088294 \tAcc: 0.9339583333 \tTPR:0.9103700266 \tFPR:0.0430773207 \tF1:0.9302637455 \tAUC:0.9336463529 \ttest cost: 0:00:05\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.0794571214 \tAcc: 0.9700864055 \tTPR:0.9778894951 \tFPR:0.0373338699 \tF1:0.9689280502 \t AUC:0.9702778126\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0736526508 \tAcc: 0.9694642857 \tTPR:0.9762926153 \tFPR:0.0365157933 \tF1:0.9679171415 \t AUC:0.9698884110\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0627024133 \tAcc: 0.9755299539 \tTPR:0.9805917047 \tFPR:0.0288513998 \tF1:0.9748475477 \t AUC:0.9758701524\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0613692907 \tAcc: 0.9758035714 \tTPR:0.9809757986 \tFPR:0.0296407038 \tF1:0.9754893246 \t AUC:0.9756675474\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0567557263 \tAcc: 0.9783035714 \tTPR:0.9820070120 \tFPR:0.0252859919 \tF1:0.9772939733 \t AUC:0.9783605100\tTrain cost: 0:00:33\n",
      "Client0 Test =>                 \tLoss: 0.2513270606 \tAcc: 0.9343750000 \tTPR:0.9087439490 \tFPR:0.0379262087 \tF1:0.9312194028 \tAUC:0.9354088702 \ttest cost: 0:00:05\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1035991864 \tAcc: 0.9586607143 \tTPR:0.9666527217 \tFPR:0.0488070618 \tF1:0.9575700216 \t AUC:0.9589228299\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0893699795 \tAcc: 0.9641964286 \tTPR:0.9734556992 \tFPR:0.0454662252 \tF1:0.9636802326 \t AUC:0.9639947370\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0861800337 \tAcc: 0.9634821429 \tTPR:0.9712429589 \tFPR:0.0442428498 \tF1:0.9621687236 \t AUC:0.9635000545\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0815654825 \tAcc: 0.9688364055 \tTPR:0.9766273527 \tFPR:0.0379235823 \tF1:0.9679931211 \t AUC:0.9693518852\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0707651670 \tAcc: 0.9716964286 \tTPR:0.9789288781 \tFPR:0.0355424618 \tF1:0.9710659920 \t AUC:0.9716932081\tTrain cost: 0:00:33\n",
      "Client4 Test =>                 \tLoss: 0.1896383039 \tAcc: 0.9391666667 \tTPR:0.9281572134 \tFPR:0.0501871711 \tF1:0.9358974092 \tAUC:0.9389850211 \ttest cost: 0:00:05\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0959202633 \tAcc: 0.9607114055 \tTPR:0.9686097701 \tFPR:0.0477447487 \tF1:0.9608647398 \t AUC:0.9604325107\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0897210403 \tAcc: 0.9645535714 \tTPR:0.9724661228 \tFPR:0.0422277402 \tF1:0.9646343058 \t AUC:0.9651191913\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0799344216 \tAcc: 0.9680357143 \tTPR:0.9737517068 \tFPR:0.0386186462 \tF1:0.9673709478 \t AUC:0.9675665303\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0740623755 \tAcc: 0.9703571429 \tTPR:0.9761235034 \tFPR:0.0373011108 \tF1:0.9702026859 \t AUC:0.9694111963\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0666881058 \tAcc: 0.9741935484 \tTPR:0.9798651937 \tFPR:0.0319434746 \tF1:0.9739478177 \t AUC:0.9739608595\tTrain cost: 0:00:33\n",
      "Client7 Test =>                 \tLoss: 0.1968601211 \tAcc: 0.9435416667 \tTPR:0.9282573486 \tFPR:0.0405878107 \tF1:0.9399173573 \tAUC:0.9438347689 \ttest cost: 0:00:05\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0989268238 \tAcc: 0.9610627880 \tTPR:0.9692966162 \tFPR:0.0462041881 \tF1:0.9602520815 \t AUC:0.9615462141\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0827336701 \tAcc: 0.9697321429 \tTPR:0.9768588485 \tFPR:0.0368092098 \tF1:0.9690872117 \t AUC:0.9700248194\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0774380989 \tAcc: 0.9714256912 \tTPR:0.9766467935 \tFPR:0.0344876842 \tF1:0.9705962832 \t AUC:0.9710795547\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0714896242 \tAcc: 0.9729406682 \tTPR:0.9794831744 \tFPR:0.0338448755 \tF1:0.9720438561 \t AUC:0.9728191495\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0661488769 \tAcc: 0.9747292627 \tTPR:0.9793564022 \tFPR:0.0297406267 \tF1:0.9739027823 \t AUC:0.9748078878\tTrain cost: 0:00:33\n",
      "Client9 Test =>                 \tLoss: 0.2073979567 \tAcc: 0.9450000000 \tTPR:0.9423455250 \tFPR:0.0515560328 \tF1:0.9436013100 \tAUC:0.9453947461 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2146464543 \tAcc: 0.9392083333 \tTPR:0.9235748125 \tFPR:0.0446669088 \tF1:0.9361798449 \tAUC:0.9394539519\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 23:  =============\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0837739273 \tAcc: 0.9671399770 \tTPR:0.9754485977 \tFPR:0.0411275514 \tF1:0.9665444826 \t AUC:0.9671605232\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0732006286 \tAcc: 0.9716042627 \tTPR:0.9774559906 \tFPR:0.0352540646 \tF1:0.9711040288 \t AUC:0.9711009630\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0687098442 \tAcc: 0.9729406682 \tTPR:0.9782212205 \tFPR:0.0327467531 \tF1:0.9717334987 \t AUC:0.9727372337\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0642133926 \tAcc: 0.9743750000 \tTPR:0.9797602850 \tFPR:0.0296052796 \tF1:0.9737392398 \t AUC:0.9750775027\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0577455216 \tAcc: 0.9758899770 \tTPR:0.9795885472 \tFPR:0.0280414877 \tF1:0.9752003241 \t AUC:0.9757735298\tTrain cost: 0:00:33\n",
      "Client1 Test =>                 \tLoss: 0.1878299356 \tAcc: 0.9458333333 \tTPR:0.9310913221 \tFPR:0.0406904237 \tF1:0.9431775137 \tAUC:0.9452004492 \ttest cost: 0:00:05\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.0915559281 \tAcc: 0.9642828341 \tTPR:0.9713747750 \tFPR:0.0429150188 \tF1:0.9628732304 \t AUC:0.9642298781\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.0798592806 \tAcc: 0.9699913594 \tTPR:0.9780583537 \tFPR:0.0382329661 \tF1:0.9687917866 \t AUC:0.9699126938\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0730429640 \tAcc: 0.9706250000 \tTPR:0.9762748237 \tFPR:0.0343554942 \tF1:0.9694286222 \t AUC:0.9709596648\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0656162890 \tAcc: 0.9750864055 \tTPR:0.9803270322 \tFPR:0.0301652869 \tF1:0.9744752700 \t AUC:0.9750808727\tTrain cost: 0:00:33\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0636337171 \tAcc: 0.9757142857 \tTPR:0.9817452682 \tFPR:0.0298160411 \tF1:0.9747954883 \t AUC:0.9759646136\tTrain cost: 0:00:33\n",
      "Client3 Test =>                 \tLoss: 0.1999889085 \tAcc: 0.9395833333 \tTPR:0.9193288056 \tFPR:0.0408986945 \tF1:0.9355194473 \tAUC:0.9392150556 \ttest cost: 0:00:05\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.0741485478 \tAcc: 0.9708035714 \tTPR:0.9791549671 \tFPR:0.0375661075 \tF1:0.9700152119 \t AUC:0.9707944298\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0650137746 \tAcc: 0.9738392857 \tTPR:0.9798059827 \tFPR:0.0317953138 \tF1:0.9726511139 \t AUC:0.9740053344\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0566338532 \tAcc: 0.9775806452 \tTPR:0.9809817788 \tFPR:0.0258645887 \tF1:0.9769035213 \t AUC:0.9775585950\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0519232140 \tAcc: 0.9807142857 \tTPR:0.9857833050 \tFPR:0.0239099115 \tF1:0.9800227292 \t AUC:0.9809366968\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0485942920 \tAcc: 0.9815178571 \tTPR:0.9836952253 \tFPR:0.0210338267 \tF1:0.9802270381 \t AUC:0.9813306993\tTrain cost: 0:00:33\n",
      "Client0 Test =>                 \tLoss: 0.2885138000 \tAcc: 0.9258333333 \tTPR:0.8852024474 \tFPR:0.0318430838 \tF1:0.9219204458 \tAUC:0.9266796818 \ttest cost: 0:00:05\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0975173814 \tAcc: 0.9616935484 \tTPR:0.9698164763 \tFPR:0.0455342361 \tF1:0.9613376186 \t AUC:0.9621411201\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0822906975 \tAcc: 0.9674971198 \tTPR:0.9719941209 \tFPR:0.0377408255 \tF1:0.9673722890 \t AUC:0.9671266477\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0763808970 \tAcc: 0.9708928571 \tTPR:0.9765248267 \tFPR:0.0339012773 \tF1:0.9706108615 \t AUC:0.9713117747\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0688690715 \tAcc: 0.9730328341 \tTPR:0.9787285330 \tFPR:0.0322527929 \tF1:0.9726188650 \t AUC:0.9732378701\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0660844481 \tAcc: 0.9739285714 \tTPR:0.9783249602 \tFPR:0.0304712813 \tF1:0.9736531340 \t AUC:0.9739268394\tTrain cost: 0:00:33\n",
      "Client7 Test =>                 \tLoss: 0.1864802540 \tAcc: 0.9462500000 \tTPR:0.9432865646 \tFPR:0.0502486687 \tF1:0.9436698083 \tAUC:0.9465189480 \ttest cost: 0:00:05\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1127777323 \tAcc: 0.9553513825 \tTPR:0.9617803589 \tFPR:0.0506005323 \tF1:0.9541090034 \t AUC:0.9555899133\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0993746390 \tAcc: 0.9614228111 \tTPR:0.9697593719 \tFPR:0.0458272522 \tF1:0.9609761266 \t AUC:0.9619660599\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0906539482 \tAcc: 0.9644614055 \tTPR:0.9714809203 \tFPR:0.0421311691 \tF1:0.9634195954 \t AUC:0.9646748756\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0846391061 \tAcc: 0.9680299539 \tTPR:0.9763908541 \tFPR:0.0405834775 \tF1:0.9679136409 \t AUC:0.9679036883\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0797158903 \tAcc: 0.9688392857 \tTPR:0.9760544599 \tFPR:0.0392159515 \tF1:0.9677816513 \t AUC:0.9684192542\tTrain cost: 0:00:33\n",
      "Client2 Test =>                 \tLoss: 0.1931899364 \tAcc: 0.9385416667 \tTPR:0.9147274088 \tFPR:0.0361051636 \tF1:0.9348268360 \tAUC:0.9393111226 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2112005669 \tAcc: 0.9392083333 \tTPR:0.9187273097 \tFPR:0.0399572068 \tF1:0.9358228102 \tAUC:0.9393850514\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 24:  =============\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.0540088484 \tAcc: 0.9794614055 \tTPR:0.9829011751 \tFPR:0.0241182680 \tF1:0.9785031096 \t AUC:0.9793914536\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0486876277 \tAcc: 0.9810714286 \tTPR:0.9829457847 \tFPR:0.0210669730 \tF1:0.9799275445 \t AUC:0.9809394058\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0495356172 \tAcc: 0.9800864055 \tTPR:0.9818415563 \tFPR:0.0216280227 \tF1:0.9790130946 \t AUC:0.9801067668\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0393288553 \tAcc: 0.9857114055 \tTPR:0.9885403217 \tFPR:0.0168999103 \tF1:0.9849011941 \t AUC:0.9858202057\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0352805353 \tAcc: 0.9866964286 \tTPR:0.9886080063 \tFPR:0.0148044771 \tF1:0.9860598709 \t AUC:0.9869017646\tTrain cost: 0:00:33\n",
      "Client0 Test =>                 \tLoss: 0.3328808656 \tAcc: 0.9250000000 \tTPR:0.8802575197 \tFPR:0.0272009980 \tF1:0.9200898200 \tAUC:0.9265282608 \ttest cost: 0:00:05\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1133151168 \tAcc: 0.9583006912 \tTPR:0.9686884242 \tFPR:0.0512412696 \tF1:0.9580568711 \t AUC:0.9587235773\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0986345459 \tAcc: 0.9617857143 \tTPR:0.9692210919 \tFPR:0.0458324346 \tF1:0.9605723358 \t AUC:0.9616943287\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0872036514 \tAcc: 0.9663364055 \tTPR:0.9747236287 \tFPR:0.0414464757 \tF1:0.9660504306 \t AUC:0.9666385765\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0818917445 \tAcc: 0.9683928571 \tTPR:0.9770597246 \tFPR:0.0408791155 \tF1:0.9677049593 \t AUC:0.9680903045\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0745945210 \tAcc: 0.9719614055 \tTPR:0.9773205987 \tFPR:0.0340214690 \tF1:0.9710883934 \t AUC:0.9716495649\tTrain cost: 0:00:33\n",
      "Client5 Test =>                 \tLoss: 0.1763296802 \tAcc: 0.9435416667 \tTPR:0.9334560295 \tFPR:0.0475923325 \tF1:0.9428022625 \tAUC:0.9429318485 \ttest cost: 0:00:05\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0814737091 \tAcc: 0.9678571429 \tTPR:0.9745007968 \tFPR:0.0387772298 \tF1:0.9681346117 \t AUC:0.9678617835\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0758742434 \tAcc: 0.9705328341 \tTPR:0.9762299995 \tFPR:0.0365130451 \tF1:0.9704104309 \t AUC:0.9698584772\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0687648573 \tAcc: 0.9741042627 \tTPR:0.9787175587 \tFPR:0.0307202773 \tF1:0.9736957963 \t AUC:0.9739986407\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0604091343 \tAcc: 0.9768750000 \tTPR:0.9812800749 \tFPR:0.0272696849 \tF1:0.9766344309 \t AUC:0.9770051950\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0569561075 \tAcc: 0.9777620968 \tTPR:0.9819692337 \tFPR:0.0267085726 \tF1:0.9774032691 \t AUC:0.9776303305\tTrain cost: 0:00:33\n",
      "Client7 Test =>                 \tLoss: 0.2330321347 \tAcc: 0.9397916667 \tTPR:0.9134946137 \tFPR:0.0327632856 \tF1:0.9356348140 \tAUC:0.9403656640 \ttest cost: 0:00:05\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0986513098 \tAcc: 0.9616906682 \tTPR:0.9693715837 \tFPR:0.0466323217 \tF1:0.9607882237 \t AUC:0.9613696310\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0861872842 \tAcc: 0.9657114055 \tTPR:0.9713303491 \tFPR:0.0399164900 \tF1:0.9650423439 \t AUC:0.9657069296\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0766510073 \tAcc: 0.9709821429 \tTPR:0.9756853750 \tFPR:0.0336230880 \tF1:0.9696652916 \t AUC:0.9710311435\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0704020284 \tAcc: 0.9725806452 \tTPR:0.9803538387 \tFPR:0.0346356390 \tF1:0.9720332753 \t AUC:0.9728590998\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0658269790 \tAcc: 0.9756221198 \tTPR:0.9828879389 \tFPR:0.0311229971 \tF1:0.9748914996 \t AUC:0.9758824709\tTrain cost: 0:00:33\n",
      "Client4 Test =>                 \tLoss: 0.2030542000 \tAcc: 0.9391666667 \tTPR:0.9349497785 \tFPR:0.0583422418 \tF1:0.9376976600 \tAUC:0.9383037683 \ttest cost: 0:00:05\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0761890526 \tAcc: 0.9707978111 \tTPR:0.9763736383 \tFPR:0.0356681295 \tF1:0.9706463524 \t AUC:0.9703527544\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0638234402 \tAcc: 0.9740985023 \tTPR:0.9790564979 \tFPR:0.0316327269 \tF1:0.9735442107 \t AUC:0.9737118855\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0601594714 \tAcc: 0.9770506912 \tTPR:0.9827452678 \tFPR:0.0288017445 \tF1:0.9765120340 \t AUC:0.9769717617\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0526083910 \tAcc: 0.9803571429 \tTPR:0.9849149712 \tFPR:0.0241570982 \tF1:0.9802420508 \t AUC:0.9803789365\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0482661805 \tAcc: 0.9817799539 \tTPR:0.9858318456 \tFPR:0.0226005495 \tF1:0.9817145068 \t AUC:0.9816156481\tTrain cost: 0:00:33\n",
      "Client1 Test =>                 \tLoss: 0.2260803205 \tAcc: 0.9485416667 \tTPR:0.9286969281 \tFPR:0.0335077109 \tF1:0.9440793313 \tAUC:0.9475946086 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2342754402 \tAcc: 0.9392083333 \tTPR:0.9181709739 \tFPR:0.0398813138 \tF1:0.9360607776 \tAUC:0.9391448301\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 25:  =============\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0642104877 \tAcc: 0.9756192396 \tTPR:0.9807123940 \tFPR:0.0297414579 \tF1:0.9750843454 \t AUC:0.9754854680\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0598998515 \tAcc: 0.9776785714 \tTPR:0.9832857193 \tFPR:0.0279240349 \tF1:0.9775834506 \t AUC:0.9776808422\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0549665835 \tAcc: 0.9797321429 \tTPR:0.9844094203 \tFPR:0.0249364332 \tF1:0.9797884869 \t AUC:0.9797364935\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0522854719 \tAcc: 0.9807949309 \tTPR:0.9863583739 \tFPR:0.0242755183 \tF1:0.9809554026 \t AUC:0.9810414278\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0482737380 \tAcc: 0.9812500000 \tTPR:0.9847265430 \tFPR:0.0226363259 \tF1:0.9807838158 \t AUC:0.9810451086\tTrain cost: 0:00:33\n",
      "Client7 Test =>                 \tLoss: 0.2214677974 \tAcc: 0.9441666667 \tTPR:0.9304355754 \tFPR:0.0443265426 \tF1:0.9411830755 \tAUC:0.9430545164 \ttest cost: 0:00:05\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0917610064 \tAcc: 0.9641071429 \tTPR:0.9722438184 \tFPR:0.0437186751 \tF1:0.9631037430 \t AUC:0.9642625717\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0799417629 \tAcc: 0.9699971198 \tTPR:0.9776761825 \tFPR:0.0372831246 \tF1:0.9694102192 \t AUC:0.9701965290\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0743394696 \tAcc: 0.9713392857 \tTPR:0.9758340682 \tFPR:0.0332634611 \tF1:0.9702698015 \t AUC:0.9712853036\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0648297090 \tAcc: 0.9758928571 \tTPR:0.9801921325 \tFPR:0.0297741053 \tF1:0.9750510492 \t AUC:0.9752090136\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0602733150 \tAcc: 0.9776756912 \tTPR:0.9829840969 \tFPR:0.0274254045 \tF1:0.9774104510 \t AUC:0.9777793462\tTrain cost: 0:00:33\n",
      "Client4 Test =>                 \tLoss: 0.2036703085 \tAcc: 0.9422916667 \tTPR:0.9420534905 \tFPR:0.0583639875 \tF1:0.9417878310 \tAUC:0.9418447515 \ttest cost: 0:00:05\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0973153985 \tAcc: 0.9625864055 \tTPR:0.9700258252 \tFPR:0.0448496698 \tF1:0.9616849468 \t AUC:0.9625880777\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0840370451 \tAcc: 0.9679406682 \tTPR:0.9760620460 \tFPR:0.0404554901 \tF1:0.9669497456 \t AUC:0.9678032780\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0739543295 \tAcc: 0.9718721198 \tTPR:0.9768619073 \tFPR:0.0331360230 \tF1:0.9710894248 \t AUC:0.9718629421\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0705599655 \tAcc: 0.9729406682 \tTPR:0.9790694437 \tFPR:0.0330741789 \tF1:0.9724525603 \t AUC:0.9729976324\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0651583289 \tAcc: 0.9740985023 \tTPR:0.9793892650 \tFPR:0.0305833149 \tF1:0.9734537503 \t AUC:0.9744029750\tTrain cost: 0:00:33\n",
      "Client8 Test =>                 \tLoss: 0.1983116087 \tAcc: 0.9412500000 \tTPR:0.9229474823 \tFPR:0.0402576748 \tF1:0.9379199057 \tAUC:0.9413449037 \ttest cost: 0:00:05\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0754483211 \tAcc: 0.9686520737 \tTPR:0.9763049947 \tFPR:0.0386459625 \tF1:0.9684302752 \t AUC:0.9688295161\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0674161198 \tAcc: 0.9729406682 \tTPR:0.9781420055 \tFPR:0.0325191382 \tF1:0.9722256634 \t AUC:0.9728114337\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0594788386 \tAcc: 0.9770478111 \tTPR:0.9818163051 \tFPR:0.0280616624 \tF1:0.9768254946 \t AUC:0.9768773213\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0544488501 \tAcc: 0.9794614055 \tTPR:0.9846936819 \tFPR:0.0260202435 \tF1:0.9792785345 \t AUC:0.9793367192\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0487475466 \tAcc: 0.9804464286 \tTPR:0.9852784737 \tFPR:0.0246341774 \tF1:0.9800219033 \t AUC:0.9803221481\tTrain cost: 0:00:33\n",
      "Client1 Test =>                 \tLoss: 0.2000508618 \tAcc: 0.9483333333 \tTPR:0.9349499631 \tFPR:0.0400199747 \tF1:0.9447998556 \tAUC:0.9474649942 \ttest cost: 0:00:05\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.0972462237 \tAcc: 0.9621399770 \tTPR:0.9705142962 \tFPR:0.0465119126 \tF1:0.9608623314 \t AUC:0.9620011918\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.0822090430 \tAcc: 0.9691935484 \tTPR:0.9783080745 \tFPR:0.0396225839 \tF1:0.9685901382 \t AUC:0.9693427453\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0741875982 \tAcc: 0.9698185484 \tTPR:0.9767865248 \tFPR:0.0379945924 \tF1:0.9689780850 \t AUC:0.9693959662\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0732260241 \tAcc: 0.9719614055 \tTPR:0.9786871528 \tFPR:0.0352199859 \tF1:0.9722068580 \t AUC:0.9717335835\tTrain cost: 0:00:33\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0689838144 \tAcc: 0.9727649770 \tTPR:0.9797124555 \tFPR:0.0336250397 \tF1:0.9726481753 \t AUC:0.9730437079\tTrain cost: 0:00:33\n",
      "Client6 Test =>                 \tLoss: 0.2247861583 \tAcc: 0.9400000000 \tTPR:0.9277715001 \tFPR:0.0471080281 \tF1:0.9372116114 \tAUC:0.9403317360 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2096573470 \tAcc: 0.9432083333 \tTPR:0.9316316023 \tFPR:0.0460152415 \tF1:0.9405804558 \tAUC:0.9428081804\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 26:  =============\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0882208636 \tAcc: 0.9663364055 \tTPR:0.9746471000 \tFPR:0.0406744705 \tF1:0.9655405128 \t AUC:0.9669863147\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0784329626 \tAcc: 0.9699107143 \tTPR:0.9772575031 \tFPR:0.0381589763 \tF1:0.9689636961 \t AUC:0.9695492634\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0715589001 \tAcc: 0.9733842166 \tTPR:0.9803999285 \tFPR:0.0342675088 \tF1:0.9728484599 \t AUC:0.9730662098\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0702070096 \tAcc: 0.9733035714 \tTPR:0.9797807829 \tFPR:0.0323365334 \tF1:0.9727092707 \t AUC:0.9737221247\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0626247350 \tAcc: 0.9751785714 \tTPR:0.9809757969 \tFPR:0.0313250348 \tF1:0.9746623673 \t AUC:0.9748253810\tTrain cost: 0:00:33\n",
      "Client5 Test =>                 \tLoss: 0.1777848218 \tAcc: 0.9462500000 \tTPR:0.9414294800 \tFPR:0.0500144344 \tF1:0.9442061816 \tAUC:0.9457075228 \ttest cost: 0:00:05\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0937820926 \tAcc: 0.9637442396 \tTPR:0.9702880328 \tFPR:0.0434182025 \tF1:0.9628325158 \t AUC:0.9634349152\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0821486366 \tAcc: 0.9689256912 \tTPR:0.9759264774 \tFPR:0.0373115593 \tF1:0.9682175732 \t AUC:0.9693074591\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0764266258 \tAcc: 0.9723214286 \tTPR:0.9788192347 \tFPR:0.0340949123 \tF1:0.9719297768 \t AUC:0.9723621612\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0693166538 \tAcc: 0.9733928571 \tTPR:0.9796601150 \tFPR:0.0330111663 \tF1:0.9729134288 \t AUC:0.9733244744\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0666427827 \tAcc: 0.9756192396 \tTPR:0.9809659157 \tFPR:0.0299402820 \tF1:0.9750142239 \t AUC:0.9755128168\tTrain cost: 0:00:33\n",
      "Client9 Test =>                 \tLoss: 0.2137861285 \tAcc: 0.9427083333 \tTPR:0.9378528185 \tFPR:0.0529696294 \tF1:0.9420700444 \tAUC:0.9424415946 \ttest cost: 0:00:05\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0832913494 \tAcc: 0.9688392857 \tTPR:0.9755384394 \tFPR:0.0385479819 \tF1:0.9680567740 \t AUC:0.9684952287\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0749307846 \tAcc: 0.9712500000 \tTPR:0.9772701018 \tFPR:0.0348293472 \tF1:0.9709460791 \t AUC:0.9712203773\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0678461515 \tAcc: 0.9740149770 \tTPR:0.9793562383 \tFPR:0.0317215901 \tF1:0.9731741307 \t AUC:0.9738173241\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0618960078 \tAcc: 0.9759821429 \tTPR:0.9810072133 \tFPR:0.0291128127 \tF1:0.9754386703 \t AUC:0.9759472003\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0550511366 \tAcc: 0.9787500000 \tTPR:0.9818731958 \tFPR:0.0246829855 \tF1:0.9781758406 \t AUC:0.9785951051\tTrain cost: 0:00:33\n",
      "Client8 Test =>                 \tLoss: 0.2078028845 \tAcc: 0.9443750000 \tTPR:0.9369927217 \tFPR:0.0469215705 \tF1:0.9414357443 \tAUC:0.9450355756 \ttest cost: 0:00:05\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0827017820 \tAcc: 0.9658899770 \tTPR:0.9730711166 \tFPR:0.0407528776 \tF1:0.9652080528 \t AUC:0.9661591195\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0718416521 \tAcc: 0.9733035714 \tTPR:0.9784616809 \tFPR:0.0318850807 \tF1:0.9725711685 \t AUC:0.9732883001\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0643557283 \tAcc: 0.9753571429 \tTPR:0.9801410012 \tFPR:0.0297902652 \tF1:0.9748331148 \t AUC:0.9751753680\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0622226694 \tAcc: 0.9753571429 \tTPR:0.9801391012 \tFPR:0.0284732914 \tF1:0.9742351584 \t AUC:0.9758329049\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0544684603 \tAcc: 0.9792857143 \tTPR:0.9848772405 \tFPR:0.0259692931 \tF1:0.9785621676 \t AUC:0.9794539737\tTrain cost: 0:00:33\n",
      "Client4 Test =>                 \tLoss: 0.2066320643 \tAcc: 0.9445833333 \tTPR:0.9503237503 \tFPR:0.0598333257 \tF1:0.9431097995 \tAUC:0.9452452123 \ttest cost: 0:00:05\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0757573125 \tAcc: 0.9694614055 \tTPR:0.9756340270 \tFPR:0.0361207549 \tF1:0.9694573976 \t AUC:0.9697566361\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0609940382 \tAcc: 0.9766042627 \tTPR:0.9821892648 \tFPR:0.0291485751 \tF1:0.9759184120 \t AUC:0.9765203448\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0565816797 \tAcc: 0.9778542627 \tTPR:0.9829883351 \tFPR:0.0273903363 \tF1:0.9778749992 \t AUC:0.9777989994\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0532638134 \tAcc: 0.9797321429 \tTPR:0.9828282216 \tFPR:0.0233918882 \tF1:0.9789295751 \t AUC:0.9797181667\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0481068404 \tAcc: 0.9804435484 \tTPR:0.9842702746 \tFPR:0.0234457813 \tF1:0.9797759698 \t AUC:0.9804122467\tTrain cost: 0:00:33\n",
      "Client1 Test =>                 \tLoss: 0.2035727411 \tAcc: 0.9479166667 \tTPR:0.9340803138 \tFPR:0.0368753942 \tF1:0.9441298881 \tAUC:0.9486024598 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2019157280 \tAcc: 0.9451666667 \tTPR:0.9401358169 \tFPR:0.0493228709 \tF1:0.9429903316 \tAUC:0.9454064730\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 27:  =============\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0671383402 \tAcc: 0.9735685484 \tTPR:0.9786801321 \tFPR:0.0309604784 \tF1:0.9729391319 \t AUC:0.9738598268\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0601061497 \tAcc: 0.9749971198 \tTPR:0.9803554238 \tFPR:0.0308336108 \tF1:0.9744461874 \t AUC:0.9747609065\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0550384018 \tAcc: 0.9786549539 \tTPR:0.9825500090 \tFPR:0.0240363912 \tF1:0.9778842863 \t AUC:0.9792568089\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0487207951 \tAcc: 0.9831250000 \tTPR:0.9871095653 \tFPR:0.0205673793 \tF1:0.9829149766 \t AUC:0.9832710930\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0442110908 \tAcc: 0.9836607143 \tTPR:0.9864049540 \tFPR:0.0194760577 \tF1:0.9830198650 \t AUC:0.9834644481\tTrain cost: 0:00:33\n",
      "Client4 Test =>                 \tLoss: 0.2370269551 \tAcc: 0.9420833333 \tTPR:0.9304923752 \tFPR:0.0471957564 \tF1:0.9388524931 \tAUC:0.9416483094 \ttest cost: 0:00:05\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0830608315 \tAcc: 0.9701756912 \tTPR:0.9772068204 \tFPR:0.0373443310 \tF1:0.9698409120 \t AUC:0.9699312447\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0698237390 \tAcc: 0.9721428571 \tTPR:0.9790318214 \tFPR:0.0342110416 \tF1:0.9711732047 \t AUC:0.9724103899\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0626056287 \tAcc: 0.9753485023 \tTPR:0.9789821326 \tFPR:0.0285287647 \tF1:0.9742030252 \t AUC:0.9752266840\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0575100101 \tAcc: 0.9787500000 \tTPR:0.9824389103 \tFPR:0.0249520836 \tF1:0.9778039769 \t AUC:0.9787434134\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0534853938 \tAcc: 0.9816071429 \tTPR:0.9859214700 \tFPR:0.0222733415 \tF1:0.9809898404 \t AUC:0.9818240642\tTrain cost: 0:00:33\n",
      "Client9 Test =>                 \tLoss: 0.2134328049 \tAcc: 0.9458333333 \tTPR:0.9448962897 \tFPR:0.0535602524 \tF1:0.9439859145 \tAUC:0.9456680186 \ttest cost: 0:00:05\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0797746359 \tAcc: 0.9694585253 \tTPR:0.9772040580 \tFPR:0.0375863787 \tF1:0.9686174927 \t AUC:0.9698088396\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0644642633 \tAcc: 0.9753571429 \tTPR:0.9808477171 \tFPR:0.0300278448 \tF1:0.9748267474 \t AUC:0.9754099362\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0592373965 \tAcc: 0.9777678571 \tTPR:0.9828879091 \tFPR:0.0270189305 \tF1:0.9770052487 \t AUC:0.9779344893\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0553798736 \tAcc: 0.9790178571 \tTPR:0.9829393092 \tFPR:0.0246085160 \tF1:0.9785711201 \t AUC:0.9791653966\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0495514932 \tAcc: 0.9813277650 \tTPR:0.9846166432 \tFPR:0.0225216105 \tF1:0.9810176688 \t AUC:0.9810475164\tTrain cost: 0:00:33\n",
      "Client8 Test =>                 \tLoss: 0.2397929586 \tAcc: 0.9364583333 \tTPR:0.9058118409 \tFPR:0.0317190336 \tF1:0.9318207518 \tAUC:0.9370464037 \ttest cost: 0:00:05\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.0712032538 \tAcc: 0.9740149770 \tTPR:0.9790726083 \tFPR:0.0316660322 \tF1:0.9730142316 \t AUC:0.9737032880\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0552679777 \tAcc: 0.9783899770 \tTPR:0.9810336201 \tFPR:0.0247215162 \tF1:0.9776245842 \t AUC:0.9781560520\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0517779768 \tAcc: 0.9808006912 \tTPR:0.9838402452 \tFPR:0.0222601877 \tF1:0.9801356082 \t AUC:0.9807900287\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0431865449 \tAcc: 0.9841071429 \tTPR:0.9869175462 \tFPR:0.0182376858 \tF1:0.9830765825 \t AUC:0.9843399302\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0409958799 \tAcc: 0.9833035714 \tTPR:0.9855923559 \tFPR:0.0187755611 \tF1:0.9829626765 \t AUC:0.9834083974\tTrain cost: 0:00:33\n",
      "Client0 Test =>                 \tLoss: 0.2553477892 \tAcc: 0.9420833333 \tTPR:0.9302047567 \tFPR:0.0451286009 \tF1:0.9411538233 \tAUC:0.9425380779 \ttest cost: 0:00:05\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0812287212 \tAcc: 0.9689256912 \tTPR:0.9735615690 \tFPR:0.0347393554 \tF1:0.9674257393 \t AUC:0.9694111068\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0689311010 \tAcc: 0.9735714286 \tTPR:0.9787866556 \tFPR:0.0322845188 \tF1:0.9733467193 \t AUC:0.9732510684\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0631146079 \tAcc: 0.9758006912 \tTPR:0.9803468112 \tFPR:0.0284660110 \tF1:0.9747712103 \t AUC:0.9759404001\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0592499382 \tAcc: 0.9783035714 \tTPR:0.9829212421 \tFPR:0.0269173782 \tF1:0.9775152763 \t AUC:0.9780019319\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0536546705 \tAcc: 0.9792857143 \tTPR:0.9838974610 \tFPR:0.0241552335 \tF1:0.9790389031 \t AUC:0.9798711137\tTrain cost: 0:00:33\n",
      "Client5 Test =>                 \tLoss: 0.1861845642 \tAcc: 0.9464583333 \tTPR:0.9363219350 \tFPR:0.0434152111 \tF1:0.9431254532 \tAUC:0.9464533619 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2263570144 \tAcc: 0.9425833333 \tTPR:0.9295454395 \tFPR:0.0442037709 \tF1:0.9397876872 \tAUC:0.9426708343\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 28:  =============\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.0555620447 \tAcc: 0.9789256912 \tTPR:0.9830426078 \tFPR:0.0254524389 \tF1:0.9776728077 \t AUC:0.9787950844\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0457740777 \tAcc: 0.9817857143 \tTPR:0.9840601414 \tFPR:0.0210168414 \tF1:0.9810613841 \t AUC:0.9815216500\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0405749748 \tAcc: 0.9845506912 \tTPR:0.9866892339 \tFPR:0.0178357858 \tF1:0.9833958054 \t AUC:0.9844267240\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0370582400 \tAcc: 0.9861578341 \tTPR:0.9877164542 \tFPR:0.0158278825 \tF1:0.9853249055 \t AUC:0.9859442858\tTrain cost: 0:00:33\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0312136625 \tAcc: 0.9895506912 \tTPR:0.9912080446 \tFPR:0.0120178000 \tF1:0.9887718968 \t AUC:0.9895951223\tTrain cost: 0:00:33\n",
      "Client0 Test =>                 \tLoss: 0.2781331864 \tAcc: 0.9427083333 \tTPR:0.9315117121 \tFPR:0.0464835014 \tF1:0.9411401532 \tAUC:0.9425141054 \ttest cost: 0:00:05\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0727522132 \tAcc: 0.9722321429 \tTPR:0.9764090386 \tFPR:0.0315192350 \tF1:0.9717462610 \t AUC:0.9724449018\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0617600144 \tAcc: 0.9761607143 \tTPR:0.9809513261 \tFPR:0.0279845090 \tF1:0.9761628816 \t AUC:0.9764834085\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0551824042 \tAcc: 0.9791013825 \tTPR:0.9829767493 \tFPR:0.0250382344 \tF1:0.9786666659 \t AUC:0.9789692574\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0473998757 \tAcc: 0.9809821429 \tTPR:0.9851787375 \tFPR:0.0227317273 \tF1:0.9810717182 \t AUC:0.9812235051\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0440119893 \tAcc: 0.9841071429 \tTPR:0.9862884930 \tFPR:0.0180941199 \tF1:0.9840860399 \t AUC:0.9840971865\tTrain cost: 0:00:33\n",
      "Client7 Test =>                 \tLoss: 0.2328589144 \tAcc: 0.9452083333 \tTPR:0.9219516358 \tFPR:0.0318734736 \tF1:0.9410426486 \tAUC:0.9450390811 \ttest cost: 0:00:05\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0691754850 \tAcc: 0.9727678571 \tTPR:0.9763320505 \tFPR:0.0303362236 \tF1:0.9713572602 \t AUC:0.9729979134\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0576958363 \tAcc: 0.9767857143 \tTPR:0.9813467079 \tFPR:0.0269469144 \tF1:0.9760820224 \t AUC:0.9771998968\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0532748746 \tAcc: 0.9806250000 \tTPR:0.9846107597 \tFPR:0.0238259544 \tF1:0.9801612512 \t AUC:0.9803924027\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0506811988 \tAcc: 0.9812442396 \tTPR:0.9855449877 \tFPR:0.0231724606 \tF1:0.9805790182 \t AUC:0.9811862635\tTrain cost: 0:00:33\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0413265521 \tAcc: 0.9854464286 \tTPR:0.9893983831 \tFPR:0.0184711218 \tF1:0.9851442648 \t AUC:0.9854636306\tTrain cost: 0:00:33\n",
      "Client9 Test =>                 \tLoss: 0.2551272742 \tAcc: 0.9420833333 \tTPR:0.9284389895 \tFPR:0.0442382136 \tF1:0.9400354367 \tAUC:0.9421003880 \ttest cost: 0:00:05\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1144527967 \tAcc: 0.9566935484 \tTPR:0.9650518160 \tFPR:0.0512387604 \tF1:0.9564449847 \t AUC:0.9569065278\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1025678790 \tAcc: 0.9595478111 \tTPR:0.9682940611 \tFPR:0.0490133530 \tF1:0.9586753569 \t AUC:0.9596403541\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0900595864 \tAcc: 0.9647263825 \tTPR:0.9711600714 \tFPR:0.0417709819 \tF1:0.9636351183 \t AUC:0.9646945447\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0845734267 \tAcc: 0.9674107143 \tTPR:0.9743846543 \tFPR:0.0402440611 \tF1:0.9667829465 \t AUC:0.9670702966\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0798511829 \tAcc: 0.9690120968 \tTPR:0.9741957105 \tFPR:0.0370012784 \tF1:0.9679952683 \t AUC:0.9685972160\tTrain cost: 0:00:33\n",
      "Client2 Test =>                 \tLoss: 0.1554104825 \tAcc: 0.9489583333 \tTPR:0.9515407883 \tFPR:0.0525038945 \tF1:0.9484292813 \tAUC:0.9495184469 \ttest cost: 0:00:05\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0818577756 \tAcc: 0.9693750000 \tTPR:0.9777593597 \tFPR:0.0387660680 \tF1:0.9689260938 \t AUC:0.9694966459\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0675685140 \tAcc: 0.9728542627 \tTPR:0.9795078903 \tFPR:0.0330487333 \tF1:0.9722529956 \t AUC:0.9732295785\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0627876492 \tAcc: 0.9762500000 \tTPR:0.9821209133 \tFPR:0.0293261704 \tF1:0.9756127935 \t AUC:0.9763973714\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0597845148 \tAcc: 0.9761549539 \tTPR:0.9812727472 \tFPR:0.0288466480 \tF1:0.9756312337 \t AUC:0.9762130496\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0520787493 \tAcc: 0.9806163594 \tTPR:0.9855635045 \tFPR:0.0242364819 \tF1:0.9797052575 \t AUC:0.9806635113\tTrain cost: 0:00:33\n",
      "Client5 Test =>                 \tLoss: 0.1940990827 \tAcc: 0.9456250000 \tTPR:0.9465352217 \tFPR:0.0570318630 \tF1:0.9440019980 \tAUC:0.9447516794 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2231257880 \tAcc: 0.9449166667 \tTPR:0.9359956695 \tFPR:0.0464261892 \tF1:0.9429299036 \tAUC:0.9447847401\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 29:  =============\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0679273736 \tAcc: 0.9728542627 \tTPR:0.9773381503 \tFPR:0.0309249482 \tF1:0.9720456022 \t AUC:0.9732066010\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0577753962 \tAcc: 0.9801756912 \tTPR:0.9855001339 \tFPR:0.0251388338 \tF1:0.9794621003 \t AUC:0.9801806501\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0559250574 \tAcc: 0.9798185484 \tTPR:0.9850992306 \tFPR:0.0259813325 \tF1:0.9793983137 \t AUC:0.9795589490\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0474780969 \tAcc: 0.9815178571 \tTPR:0.9840735587 \tFPR:0.0213836869 \tF1:0.9812479821 \t AUC:0.9813449359\tTrain cost: 0:00:33\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0467926585 \tAcc: 0.9818750000 \tTPR:0.9863412803 \tFPR:0.0231414092 \tF1:0.9817040412 \t AUC:0.9815999355\tTrain cost: 0:00:33\n",
      "Client5 Test =>                 \tLoss: 0.2260665665 \tAcc: 0.9470833333 \tTPR:0.9427472935 \tFPR:0.0468550067 \tF1:0.9453901486 \tAUC:0.9479461434 \ttest cost: 0:00:05\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0732441684 \tAcc: 0.9726756912 \tTPR:0.9774357132 \tFPR:0.0327215584 \tF1:0.9716392459 \t AUC:0.9723570774\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0563266564 \tAcc: 0.9790178571 \tTPR:0.9826320063 \tFPR:0.0238278163 \tF1:0.9779582137 \t AUC:0.9794020950\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0546292757 \tAcc: 0.9791071429 \tTPR:0.9831481401 \tFPR:0.0246459017 \tF1:0.9788383873 \t AUC:0.9792511192\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0489868315 \tAcc: 0.9819614055 \tTPR:0.9862588139 \tFPR:0.0222728340 \tF1:0.9814451423 \t AUC:0.9819929900\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0423583946 \tAcc: 0.9854464286 \tTPR:0.9892164031 \tFPR:0.0181959293 \tF1:0.9846842622 \t AUC:0.9855102369\tTrain cost: 0:00:33\n",
      "Client8 Test =>                 \tLoss: 0.2393234176 \tAcc: 0.9412500000 \tTPR:0.9288106588 \tFPR:0.0461305762 \tF1:0.9386509318 \tAUC:0.9413400413 \ttest cost: 0:00:05\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0646706767 \tAcc: 0.9757085253 \tTPR:0.9819257250 \tFPR:0.0297662446 \tF1:0.9755973431 \t AUC:0.9760797402\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0558838337 \tAcc: 0.9777592166 \tTPR:0.9825518759 \tFPR:0.0263309768 \tF1:0.9778457802 \t AUC:0.9781104496\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0442562669 \tAcc: 0.9825864055 \tTPR:0.9854829923 \tFPR:0.0199490064 \tF1:0.9825058355 \t AUC:0.9827669929\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0421130265 \tAcc: 0.9841071429 \tTPR:0.9877053197 \tFPR:0.0198911010 \tF1:0.9842156041 \t AUC:0.9839071094\tTrain cost: 0:00:33\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0385207178 \tAcc: 0.9854435484 \tTPR:0.9882209761 \tFPR:0.0171754787 \tF1:0.9854457510 \t AUC:0.9855227487\tTrain cost: 0:00:33\n",
      "Client7 Test =>                 \tLoss: 0.2328880496 \tAcc: 0.9470833333 \tTPR:0.9398939415 \tFPR:0.0465080348 \tF1:0.9445966633 \tAUC:0.9466929533 \ttest cost: 0:00:05\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0756364047 \tAcc: 0.9703542627 \tTPR:0.9746692169 \tFPR:0.0351005883 \tF1:0.9696938412 \t AUC:0.9697843143\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0638281785 \tAcc: 0.9732114055 \tTPR:0.9780889706 \tFPR:0.0311899323 \tF1:0.9727264959 \t AUC:0.9734495191\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0553862109 \tAcc: 0.9792857143 \tTPR:0.9847371387 \tFPR:0.0260191435 \tF1:0.9790564531 \t AUC:0.9793589976\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0491355430 \tAcc: 0.9797263825 \tTPR:0.9837165937 \tFPR:0.0254304052 \tF1:0.9797526337 \t AUC:0.9791430942\tTrain cost: 0:00:33\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0445280897 \tAcc: 0.9824107143 \tTPR:0.9856996486 \tFPR:0.0214661034 \tF1:0.9816374881 \t AUC:0.9821167726\tTrain cost: 0:00:33\n",
      "Client1 Test =>                 \tLoss: 0.2221408688 \tAcc: 0.9441666667 \tTPR:0.9278342710 \tFPR:0.0408066040 \tF1:0.9395333741 \tAUC:0.9435138335 \ttest cost: 0:00:05\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0732142864 \tAcc: 0.9722263825 \tTPR:0.9785698883 \tFPR:0.0337465256 \tF1:0.9716496597 \t AUC:0.9724116814\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0604025804 \tAcc: 0.9782142857 \tTPR:0.9822429536 \tFPR:0.0267131558 \tF1:0.9779319463 \t AUC:0.9777648989\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0545896334 \tAcc: 0.9797321429 \tTPR:0.9844105887 \tFPR:0.0250175125 \tF1:0.9797902621 \t AUC:0.9796965381\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0450331987 \tAcc: 0.9829435484 \tTPR:0.9868516704 \tFPR:0.0214262670 \tF1:0.9826044009 \t AUC:0.9827127017\tTrain cost: 0:00:33\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0460512543 \tAcc: 0.9826785714 \tTPR:0.9854382142 \tFPR:0.0204632096 \tF1:0.9821255948 \t AUC:0.9824875023\tTrain cost: 0:00:33\n",
      "Client4 Test =>                 \tLoss: 0.2167270725 \tAcc: 0.9468750000 \tTPR:0.9408745855 \tFPR:0.0470825245 \tF1:0.9443265569 \tAUC:0.9468960305 \ttest cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2274291950 \tAcc: 0.9452916667 \tTPR:0.9360321501 \tFPR:0.0454765492 \tF1:0.9424995350 \tAUC:0.9452778004\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "Training and Test completed! total time cost: 7:11:34\n"
     ]
    }
   ],
   "source": [
    "print(\"Train and Test Begin!\")\n",
    "net_glob.train()\n",
    "w_net_glob = net_glob.state_dict()\n",
    "t0 = time.time()\n",
    "\n",
    "lr = 2e-6\n",
    "\n",
    "local_test[\"loss\"] = []\n",
    "local_test[\"acc\"] = []\n",
    "local_test[\"tpr\"] = []\n",
    "local_test[\"fpr\"] = []\n",
    "local_test[\"f1\"] = []\n",
    "local_test[\"auc\"] = []\n",
    "\n",
    "local_testing[\"loss\"] = []\n",
    "local_testing[\"acc\"] = []\n",
    "local_testing[\"tpr\"] = []\n",
    "local_testing[\"fpr\"] = []\n",
    "local_testing[\"f1\"] = []\n",
    "local_testing[\"auc\"] = []\n",
    "\n",
    "for iter in range(epochs):\n",
    "    print(\"============== Round {}:  =============\".format(iter))\n",
    "    idx_collect = []\n",
    "    m = max(int(frac * num_users) ,1)\n",
    "    idxs_users = np.random.choice(range(num_users), m, replace = False)\n",
    "    w_locals_client = []\n",
    "\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    tpr_list = []\n",
    "    fpr_list = []\n",
    "    f1_list = []\n",
    "    auc_list = []\n",
    "\n",
    "    for idx in idxs_users:\n",
    "        local = Client(device, idx, lr, local_epochs, batch_size, train_dataset, test_dataset, dict_user_train[idx], dict_user_test[idx])\n",
    "        w_client, client_loss, client_acc = local.train(net = copy.deepcopy(net_glob).to(device))\n",
    "        w_locals_client.append(copy.deepcopy(w_client))\n",
    "        loss, acc, tpr, fpr, f1, auc = local.evaluate(net = copy.deepcopy(net_glob).to(device), ell=iter)\n",
    "\n",
    "        loss_list.append(loss)\n",
    "        acc_list.append(acc)\n",
    "        tpr_list.append(tpr)\n",
    "        fpr_list.append(fpr)\n",
    "        f1_list.append(f1)\n",
    "        auc_list.append(auc)\n",
    "\n",
    "    local_testing[\"loss\"].append(sum(loss_list)/len(loss_list))\n",
    "    local_testing[\"acc\"].append(sum(acc_list)/len(acc_list))\n",
    "    local_testing[\"tpr\"].append(sum(tpr_list)/len(tpr_list))\n",
    "    local_testing[\"fpr\"].append(sum(fpr_list)/len(fpr_list))\n",
    "    local_testing[\"f1\"].append(sum(f1_list)/len(f1_list))\n",
    "    local_testing[\"auc\"].append(sum(auc_list)/len(auc_list))\n",
    "    print(\"Test =>                 \\tLoss: {:.10f} \\tAcc: {:.10f} \\tTPR:{:.10f} \\tFPR:{:.10f} \\tF1:{:.10f} \\tAUC:{:.10f}\".format(sum(loss_list)/len(loss_list), sum(acc_list)/len(acc_list), sum(tpr_list)/len(tpr_list), sum(fpr_list)/len(fpr_list), sum(f1_list)/len(f1_list), sum(auc_list)/len(auc_list)  ))\n",
    "\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "    print(\"-------------- FedServer: Federation process  -------------\")\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "    w_net_glob = FedAvg(w_locals_client)\n",
    "    net_glob.load_state_dict(w_net_glob)\n",
    "elapsed = format_time(time.time()-t0)\n",
    "print(\"Training and Test completed! total time cost: {:}\".format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Final Result =============\n",
      "Client0 Test =>                 \tLoss: 0.2250312189 \tAcc: 0.9477083333 \tTPR:0.9380063564 \tFPR:0.0413853546 \tF1:0.9461283454 \tAUC:0.9483105009 \ttest cost: 0:00:05\n",
      "Client1 Test =>                 \tLoss: 0.2126830298 \tAcc: 0.9485416667 \tTPR:0.9373552546 \tFPR:0.0407879890 \tF1:0.9445267842 \tAUC:0.9482836328 \ttest cost: 0:00:05\n",
      "Client2 Test =>                 \tLoss: 0.2094410632 \tAcc: 0.9485416667 \tTPR:0.9387017154 \tFPR:0.0436460504 \tF1:0.9455704344 \tAUC:0.9475278325 \ttest cost: 0:00:05\n",
      "Client3 Test =>                 \tLoss: 0.2074308546 \tAcc: 0.9500000000 \tTPR:0.9431603846 \tFPR:0.0425244285 \tF1:0.9478621177 \tAUC:0.9503179780 \ttest cost: 0:00:05\n",
      "Client4 Test =>                 \tLoss: 0.2173823855 \tAcc: 0.9477083333 \tTPR:0.9470937408 \tFPR:0.0513131402 \tF1:0.9460843285 \tAUC:0.9478903003 \ttest cost: 0:00:05\n",
      "Client5 Test =>                 \tLoss: 0.2067223586 \tAcc: 0.9472916667 \tTPR:0.9348032965 \tFPR:0.0421061879 \tF1:0.9450334401 \tAUC:0.9463485543 \ttest cost: 0:00:05\n",
      "Client6 Test =>                 \tLoss: 0.2479442328 \tAcc: 0.9414583333 \tTPR:0.9359195667 \tFPR:0.0521187092 \tF1:0.9394580928 \tAUC:0.9419004287 \ttest cost: 0:00:05\n",
      "Client7 Test =>                 \tLoss: 0.2271742843 \tAcc: 0.9500000000 \tTPR:0.9387659519 \tFPR:0.0380036050 \tF1:0.9474682413 \tAUC:0.9503811735 \ttest cost: 0:00:05\n",
      "Client8 Test =>                 \tLoss: 0.2260796018 \tAcc: 0.9464583333 \tTPR:0.9368697397 \tFPR:0.0422520842 \tF1:0.9444587327 \tAUC:0.9473088278 \ttest cost: 0:00:05\n",
      "Client9 Test =>                 \tLoss: 0.2419086392 \tAcc: 0.9450000000 \tTPR:0.9358220152 \tFPR:0.0436603457 \tF1:0.9432615889 \tAUC:0.9460808347 \ttest cost: 0:00:05\n"
     ]
    }
   ],
   "source": [
    "idx_collect = [i for i in range(num_users)]\n",
    "print(\"============= Final Result =============\")\n",
    "for idx in idx_collect:\n",
    "    loss_test_collect[idx] = []\n",
    "    acc_test_collect[idx] = []\n",
    "    TPR_test_collect[idx] = []\n",
    "    FPR_test_collect[idx] = []\n",
    "    f1_test_collect[idx] = []\n",
    "    AUC_test_collect[idx] = []\n",
    "    local = Client(device, idx, lr, local_epochs, batch_size, train_dataset, test_dataset, dict_user_train[idx], dict_user_test[idx])\n",
    "    loss, acc, tpr, fpr, f1, auc = local.evaluate(net = copy.deepcopy(net_glob).to(device), ell=0)\n",
    "    loss_test_collect[idx].append(loss)\n",
    "    acc_test_collect[idx].append(acc)\n",
    "    TPR_test_collect[idx].append(tpr)\n",
    "    FPR_test_collect[idx].append(fpr)\n",
    "    f1_test_collect[idx].append(f1)\n",
    "    AUC_test_collect[idx].append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt\n",
    "f = xlwt.Workbook('encoding = utf-8')\n",
    "sheet1 = f.add_sheet('sheet1',cell_overwrite_ok=True)\n",
    "for i in range(len(loss_collect)):\n",
    "    sheet1.write(i+1,0,loss_collect[i]) #写入数据参数对应 行, 列, 值\n",
    "for i in range(len(acc_collect)):\n",
    "    sheet1.write(i+1,1,acc_collect[i])\n",
    "for i in range(len(TPR_collect)):\n",
    "    sheet1.write(i+1,2,TPR_collect[i])\n",
    "for i in range(len(FPR_collect)):\n",
    "    sheet1.write(i+1,3,FPR_collect[i])\n",
    "for i in range(len(F1_collect)):\n",
    "    sheet1.write(i+1,4,F1_collect[i])\n",
    "for i in range(len(AUC_collect)):\n",
    "    sheet1.write(i+1,5,AUC_collect[i])\n",
    "\n",
    "f.save('result.xls')#保存.xls到当前工作目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_users):\n",
    "    f = xlwt.Workbook('encoding = utf-8')\n",
    "    sheet1 = f.add_sheet('sheet1', cell_overwrite_ok=True)\n",
    "    for j in range(len(loss_train_collect[i])):\n",
    "        sheet1.write(j+1, 0, loss_train_collect[i][j])\n",
    "    for j in range(len(acc_train_collect[i])):\n",
    "        sheet1.write(j+1, 1, acc_train_collect[i][j])\n",
    "    for j in range(len(TPR_train_collect[i])):\n",
    "        sheet1.write(j+1, 2, TPR_train_collect[i][j])\n",
    "    for j in range(len(FPR_train_collect[i])):\n",
    "        sheet1.write(j+1, 3, FPR_train_collect[i][j])\n",
    "    for j in range(len(f1_train_collect[i])):\n",
    "        sheet1.write(j+1, 4, f1_train_collect[i][j])\n",
    "    for j in range(len(AUC_train_collect[i])):\n",
    "        sheet1.write(j+1, 5, AUC_train_collect[i][j])\n",
    "\n",
    "    f.save('result_client{:}.xls'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_users):\n",
    "    f = xlwt.Workbook('encoding = utf-8')\n",
    "    sheet1 = f.add_sheet('sheet1', cell_overwrite_ok=True)\n",
    "    for j in range(len(loss_test_collect[i])):\n",
    "        sheet1.write(j+1, 0, loss_test_collect[i][j])\n",
    "    for j in range(len(acc_test_collect[i])):\n",
    "        sheet1.write(j+1, 1, acc_test_collect[i][j])\n",
    "    for j in range(len(TPR_test_collect[i])):\n",
    "        sheet1.write(j+1, 2, TPR_test_collect[i][j])\n",
    "    for j in range(len(FPR_test_collect[i])):\n",
    "        sheet1.write(j+1, 3, FPR_test_collect[i][j])\n",
    "    for j in range(len(f1_test_collect[i])):\n",
    "        sheet1.write(j+1, 4, f1_test_collect[i][j])\n",
    "    for j in range(len(AUC_test_collect[i])):\n",
    "        sheet1.write(j+1, 5, AUC_test_collect[i][j])\n",
    "\n",
    "    f.save('result_test_client{:}.xls'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import xlwt\n",
    "f = xlwt.Workbook('encoding = utf-8')\n",
    "sheet1 = f.add_sheet('sheet1',cell_overwrite_ok=True)\n",
    "for i in range(len(local_test[\"loss\"])):\n",
    "    sheet1.write(i+1,0,local_test[\"loss\"][i])\n",
    "for i in range(len(local_test[\"acc\"])):\n",
    "    sheet1.write(i+1,1,local_test[\"acc\"][i])\n",
    "for i in range(len(local_test[\"tpr\"])):\n",
    "    sheet1.write(i+1,2,local_test[\"tpr\"][i])\n",
    "for i in range(len(local_test[\"fpr\"])):\n",
    "    sheet1.write(i+1,3,local_test[\"fpr\"][i])\n",
    "for i in range(len(local_test[\"f1\"])):\n",
    "    sheet1.write(i+1,4,local_test[\"f1\"][i])\n",
    "for i in range(len(local_test[\"auc\"])):\n",
    "    sheet1.write(i+1,5,local_test[\"auc\"][i])\n",
    "\n",
    "f.save('Local_Test.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import xlwt\n",
    "f = xlwt.Workbook('encoding = utf-8')\n",
    "sheet1 = f.add_sheet('sheet1',cell_overwrite_ok=True)\n",
    "for i in range(len(local_testing[\"loss\"])):\n",
    "    sheet1.write(i+1,0,local_testing[\"loss\"][i])\n",
    "for i in range(len(local_testing[\"acc\"])):\n",
    "    sheet1.write(i+1,1,local_testing[\"acc\"][i])\n",
    "for i in range(len(local_testing[\"tpr\"])):\n",
    "    sheet1.write(i+1,2,local_testing[\"tpr\"][i])\n",
    "for i in range(len(local_testing[\"fpr\"])):\n",
    "    sheet1.write(i+1,3,local_testing[\"fpr\"][i])\n",
    "for i in range(len(local_testing[\"f1\"])):\n",
    "    sheet1.write(i+1,4,local_testing[\"f1\"][i])\n",
    "for i in range(len(local_testing[\"auc\"])):\n",
    "    sheet1.write(i+1,5,local_testing[\"auc\"][i])\n",
    "\n",
    "f.save('Local_Testing.xls')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
